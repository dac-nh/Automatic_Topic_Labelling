ID|Title|Summary
1|Data Streams: Algorithms and Applications|In the data stream scenario, input arrives very rapidly and there is limited memory to store the input. Algorithms have to work with one or few passes over the data, space less than linear in the input size or time significantly less than the input size. In the past few years, a new theory has emerged for reasoning about algorithms that work within these constraints on space, time, and number of passes. Some of the methods rely on metric embeddings, pseudo-random computations, sparse approximation theory and communication complexity. The applications for this scenario include IP network traffic analysis, mining text message streams and processing massive data sets in general. Researchers in Theoretical Computer Science, Databases, IP Networking and Computer Systems are working on the data stream challenges. This article is an overview and survey of data stream algorithmics and is an updated version of [175].1
3|Greed is Good: Algorithmic Results for Sparse Approximation|This article presents new results on using a greedy algorithm, orthogonal matching pursuit (OMP), to solve the sparse approximation problem over redundant dictionaries. It provides a sufficient condition under which both OMP and Donoho’s basis pursuit (BP) paradigm can recover the optimal representation of an exactly sparse signal. It leverages this theory to show that both OMP and BP succeed for every sparse input signal from a wide class of dictionaries. These quasi-incoherent dictionaries offer a natural generalization of incoherent dictionaries, and the cumulative coherence function is introduced to quantify the level of incoherence. This analysis unifies all the recent results on BP and extends them to OMP. Furthermore, the paper develops a sufficient condition under which OMP can identify atoms from an optimal approximation of a nonsparse signal. From there, it argues that OMP is an approximation algorithm for the sparse problem over a quasi-incoherent dictionary. That is, for every input signal, OMP calculates a sparse approximant whose error is only a small factor worse than the minimal error that can be attained with the same number of terms. 
4|The space complexity of approximating the frequency moments|The frequency moments of a sequence containing mi elements of type i, for 1 = i = n, are the numbers Fk = ?n i=1 mki. We consider the space complexity of randomized algorithms that approximate the numbers Fk, when the elements of the sequence are given one by one and cannot be stored. Surprisingly, it turns out that the numbers F0, F1 and F2 can be approximated in logarithmic space, whereas the approximation of Fk for k = 6 requires n?(1) space. Applications to data bases are mentioned as well. 
5|Models and issues in data stream systems|In this overview paper we motivate the need for and research issues arising from a new model of data processing. In this model, data does not take the form of persistent relations, but rather arrives in multiple, continuous, rapid, time-varying data streams. In addition to reviewing past work relevant to data stream systems and current projects in the area, the paper explores topics in stream query languages, new requirements and challenges in query processing, and algorithmic issues. 
6|NiagaraCQ: A Scalable Continuous Query System for Internet Databases|Continuous queries are persistent queries that allow users to receive new results when they become available. While continuous query systems can transform a passive web into an active environment, they need to be able to support millions of queries due to the scale of the Internet. No existing systems have achieved this level of scalability. NiagaraCQ addresses this problem by grouping continuous queries based on the observation that many web queries share similar structures. Grouped queries can share the common computation, tend to fit in memory and can reduce the I/O cost significantly. Furthermore, grouping on selection predicates can eliminate a large number of unnecessary query invocations. Our grouping technique is distinguished from previous group optimization approaches in the following ways. First, we use an incremental group optimization strategy with dynamic re-grouping. New queries are added to existing query groups, without having to regroup already installed queries. Second, we use a query-split scheme that requires minimal changes to a general-purpose query engine. Third, NiagaraCQ groups both change-based and timer-based queries in a uniform way. To insure that NiagaraCQ is scalable, we have also employed other techniques including incremental evaluation of continuous queries, use of both pull and push models for detecting heterogeneous data source changes, and memory caching. This paper presents the design of NiagaraCQ system and gives some experimental results on the system’s performance and scalability. 1.
7|Network Applications of Bloom Filters: A Survey|Abstract. ABloomfilter is a simple space-efficient randomized data structure for representing a set in order to support membership queries. Bloom filters allow false positives but the space savings often outweigh this drawback when the probability of an error is controlled. Bloom filters have been used in database applications since the 1970s, but only in recent years have they become popular in the networking literature. The aim of this paper is to survey the ways in which Bloom filters have been used and modified in a variety of network problems, with the aim of providing a unified mathematical and practical framework for understanding them and stimulating their use in future applications. 1.
8|Approximate Frequency Counts over Data Streams|We present algorithms for computing frequency counts exceeding a user-specified threshold over data streams. Our algorithms are simple and have provably small memory footprints. Although the output is approximate, the error is guaranteed not to exceed a user-specified parameter. Our algorithms can easily be deployed for streams of singleton items like those found in IP network monitoring. We can also handle streams of variable sized sets of items exemplified by a sequence of market basket transactions at a retail store. For such streams, we describe an optimized implementation to compute frequent itemsets in a single pass.
9|Bursty and Hierarchical Structure in Streams|A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise --- that the appearance of a topic in a document stream is signaled by a &#034;burst of activity,&#034; with certain features rising sharply in frequency as the topic emerges.
10|External Memory Algorithms and Data Structures|Data sets in large applications are often too massive to fit completely inside the computer&#039;s internal memory. The resulting input/output communication (or I/O) between fast internal memory and slower external memory (such as disks) can be a major performance bottleneck. In this paper, we survey the state of the art in the design and analysis of external memory algorithms and data structures (which are sometimes referred to as &#034;EM&#034; or &#034;I/O&#034; or &#034;out-of-core&#034; algorithms and data structures). EM algorithms and data structures are often designed and analyzed using the parallel disk model (PDM). The three machine-independent measures of performance in PDM are the number of I/O operations, the CPU time, and the amount of disk space. PDM allows for multiple disks (or disk arrays) and parallel CPUs, and it can be generalized to handle tertiary storage and hierarchical memory. We discuss several important paradigms for how to solve batched and online problems efficiently in external memory. Programming tools and environments are available for simplifying the programming task. The TPIE system (Transparent Parallel I/O programming Environment) is both easy to use and efficient in terms of execution speed. We report on some experiments using TPIE in the domain of spatial databases. The newly developed EM algorithms and data structures that incorporate the paradigms we discuss are significantly faster than methods currently used in practice.  
11|Finding frequent items in data streams|Abstract. We present a 1-pass algorithm for estimating the most frequent items in a data stream using very limited storage space. Our method relies on a novel data structure called a count sketch, which allows us to estimate the frequencies of all the items in the stream. Our algorithm achieves better space bounds than the previous best known algorithms for this problem for many natural distributions on the item frequencies. In addition, our algorithm leads directly to a 2-pass algorithm for the problem of estimating the items with the largest (absolute) change in frequency between two data streams. To our knowledge, this problem has not been previously studied in the literature. 1
12|Stable Distributions, Pseudorandom Generators, Embeddings and Data Stream Computation|In this paper we show several results obtained by combining the use of stable distributions with pseudorandom generators for bounded space. In particular: ffl we show how to maintain (using only O(log n=ffl  2  ) words of storage) a sketch C(p) of a point p 2 l  n  1 under dynamic updates of its coordinates, such that given sketches C(p) and C(q) one can estimate jp \Gamma qj 1 up to a factor of (1 + ffl) with large probability. This solves the main open problem of [10].  ffl we obtain another sketch function C  0  which maps l  n  1 into a normed space l  m  1 (as opposed to C), such that m = m(n) is much smaller than n; to our knowledge this is the first dimensionality reduction lemma for l 1 norm  ffl we give an explicit embedding of l  n  2 into l  n  O(log n) 1  with distortion (1 + 1=n  \Theta(1)  ) and a nonconstructive embedding of l  n  2 into l  O(n)  1 with distortion  (1 + ffl) such that the embedding can be represented using only O(n log  2  n) bits (as opposed to at least...
13|Chromium: A Stream-Processing Framework for Interactive Rendering on Clusters|We describe Chromium, a system for manipulating streams of graphics API commands on clusters of workstations. Chromium&#039;s stream filters can be arranged to create sort-first and sort-last parallel graphics architectures that, in many cases, support the same applications while using only commodity graphics accelerators. In addition, these stream filters can be extended programmatically, allowing the user to customize the stream transformations performed by nodes in a cluster. Because our stream processing mechanism is completely general, any cluster-parallel rendering algorithm can be either implemented on top of or embedded in Chromium. In this paper, we give examples of real-world applications that use Chromium to achieve good scalability on clusters of workstations, and describe other potential uses of this stream processing technology. By completely abstracting the underlying graphics architecture, network topology, and API command processing semantics, we allow a variety of applications to run in different environments.
15|Min-wise Independent Permutations|We define and study the notion of min-wise independent families of permutations. We say that F ? Sn is min-wise independent if for any set X ? [n] and any x ? X, when p is chosen at random in F we have Pr(min{p(X)}  = p(x))  = 1 |X |. In other words we require that all the elements of any fixed set X have an equal chance to become the minimum element of the image of X under p. Our research was motivated by the fact that such a family (under some relaxations) is essential to the algorithm used in practice by the AltaVista web index software to detect and filter near-duplicate documents. However, in the course of our investigation we have discovered interesting and challenging theoretical questions related to this concept – we present the solutions to some of them and we list the rest as open problems.
16|Maintaining Stream Statistics over Sliding Windows (Extended Abstract)  (2002) |Mayur Datar  Aristides Gionis  y  Piotr Indyk  z  Rajeev Motwani  x  Abstract  We consider the problem of maintaining aggregates and statistics over data streams, with respect to the last N data elements seen so far. We refer to this model as the sliding window model. We consider the following basic problem: Given a stream of bits, maintain a count of the number of 1&#039;s in the last N elements seen from the stream. We show that using O(  1  ffl log  2  N) bits of memory, we can estimate the number of 1&#039;s to within a factor of 1 + ffl. We also give a matching lower bound of \Omega\Gamma  1  ffl log  2  N) memory bits for any deterministic or randomized algorithms. We extend our scheme to maintain the sum of the last N positive integers. We provide matching upper and lower bounds for this more general problem as well. We apply our techniques to obtain efficient algorithms for the Lp norms (for p 2 [1; 2]) of vectors under the sliding window model. Using the algorithm for the basic counting problem, one can adapt many other techniques to work for the sliding window model, with a multiplicative overhead of O(  1  ffl log N) in memory and a 1 + ffl factor loss in accuracy. These include maintaining approximate histograms, hash tables, and statistics or aggregates such as sum and averages.
17|Trajectory Sampling for Direct Traffic Observation|Traffic measurement is a critical component for the control and engineering of communication networks. We argue that traffic measurement should make it possible to obtain the spatial flow of traffic through the domain, i.e., the paths followed by packets between any ingress and egress point of the domain. Most resource allocation and capacity planning tasks can benefit from such information. Also, traffic measurements should be obtained without a routing model and without knowledge of network state. This allows the traffic measurement process to be resilient to network failures and state uncertainty.  We propose a method that allows the direct inference of traffic flows through a domain by observing the trajectories of a subset of all packets traversing the network. The key advantages of the method are that (i) it does not rely on routing state, (ii) its implementation cost is small, and (iii) the measurement reporting traffic is modest and can be controlled precisely. The key idea of the method is to sample packets based on a hash function computed over the packet content. Using the same hash function will yield the same sample set of packets in the entire domain, and enables us to reconstruct packet trajectories.  I. 
18|Space-Efficient Online Computation of Quantile Summaries|An &amp;epsilon;-approximate quantile summary of a sequence of N elements is a data structure that can answer quantile queries about the sequence to within a precision of &amp;epsilon;N . We present a new online...
19|What’s Hot and What’s Not: Tracking Most Frequent Items Dynamically|Most database management systems maintain statistics on the underlying relation. One of the important statistics is that of the “hot items” in the relation: those that appear many times (most frequently, or more than some threshold). For example, end-biased histograms keep the hot items as part of the histogram and are used in selectivity estimation. Hot items are used as simple outliers in data mining, and in anomaly detection in networking applications. We present a new algorithm for dynamically determining the hot items at any time in the relation that is undergoing deletion operations as well as inserts. Our algorithm maintains a small space data structure that monitors the transactions on the relation, and when required, quickly outputs all hot items, without rescanning the relation in the database. With user-specified probability, it is able to report all hot items. Our algorithm relies on the idea of “group testing”, is simple to implement, and has provable quality, space and time guarantees. Previously known algorithms for this problem that make similar quality and performance guarantees can not handle deletions, and those that handle deletions can not make similar guarantees without rescanning the database. Our experiments with real and synthetic data shows that our algorithm is remarkably accurate in dynamically tracking the hot items independent of the rate of insertions and deletions. 
20|High-dimensional data analysis: The curses and blessings of dimensionality| The coming century is surely the century of data. A combination of blind faith and serious purpose makes our society invest massively in the collection and processing of data of all kinds, on scales unimaginable until recently. Hyperspectral Imagery, Internet Portals, Financial tick-by-tick data, and DNA Microarrays are just a few of the betterknown sources, feeding data in torrential streams into scientific and business databases worldwide. In traditional statistical data analysis, we think of observations of instances of particular phenomena (e.g. instance ? human being), these observations being a vector of values we measured on several variables (e.g. blood pressure, weight, height,...). In traditional statistical methodology, we assumed many observations and a few, wellchosen variables. The trend today is towards more observations but even more so, to radically larger numbers of variables – voracious, automatic, systematic collection of hyper-informative detail about each observed instance. We are seeing examples where the observations gathered on individual instances are curves, or spectra, or images, or
21|Reductions in Streaming Algorithms, with an Application to Counting Triangles in Graphs |We introduce reductions in the streaming model as a tool in the design of streaming algorithms. We develop
22|Random Sampling for Histogram Construction: How much is enough?|Random sampling is a standard technique for constructing (approximate) histograms for query optimization. However, any real implementation in commercial products requires solving the hard problem of determining &#034;How much sampling is enough?&#034; We address this critical question in the context of equi-height histograms used in many commercial products, including Microsoft SQL Server. We introduce a  conservative error metric capturing the intuition that for an approximate histogram to have low error, the error must be small in all regions of the histogram. We then present a result establishing an optimal bound on the amount of sampling required for pre-specified error bounds. We also describe an adaptive page sampling algorithm which achieves greater efficiency by using all values in a sampled page but adjusts the amount of sampling depending on clustering of values in pages. Next, we establish that the problem of estimating the number of distinct values is provably difficult, but propose ...
23|Distinct sampling for highly-accurate answers to distinct values queries and event reports |Estimating the number of distinct values is a wellstudied problem, due to its frequent occurrence in queries and its importance in selecting good query plans. Previous work has shown powerful negative results on the quality of distinct-values estimates based on sampling (or other techniques that examine only part of the input data). We present an approach, called distinct sampling, that collects a specially tailored sample over the distinct values in the input, in a single scan of the data. In contrast to the previous negative results, our small Distinct Samples are guaranteed to accurately estimate the number of distinct values. The samples can be incrementally maintained up-to-date in the presence of data insertions and deletions, with minimal time and memory overheads, so that the full scan may be performed only once. Moreover, a stored Distinct Sample can be used to accurately estimate the number of distinct values within any range specified by the query, or within any other subset of the data satisfying a query predicate. We present an extensive experimental study of distinct sampling. Using synthetic and real-world data sets, we show that distinct sampling gives distinct-values estimates to within 0%–10 % relative error, whereas previous methods typically incur 50%–250 % relative error. Next, we show how distinct sampling can provide fast, highlyaccurate approximate answers for “report ” queries in high-volume, session-based event recording environments, such as IP networks, customer service call centers, etc. For a commercial call center environment, we show that a 1 % Distinct Sample
25|How to Summarize the Universe: Dynamic Maintenance of Quantiles|Order statistics, i.e., quantiles, are frequently  used in databases both at the database server  as well as the application level. For example,  they are useful in selectivity estimation during  query optimization, in partitioning large relations,  in estimating query result sizes when  building user interfaces, and in characterizing  the data distribution of evolving datasets in  the process of data mining.
26|Secure multiparty computation of approximations|Approximation algorithms can sometimes provide efficient solutions when no efficient exact computation is known. In particular, approximations are often useful in a distributed setting where the inputs are held by different parties and may be extremely large. Furthermore, for some applications, the parties want to compute a function of their inputs securely, without revealing more information than necessary. In this work we study the question of simultaneously addressing the above efficiency and security concerns via what we call secure approximations. We start by extending standard definitions of secure (exact) computation to the setting of secure approximations. Our definitions guarantee that no additional information is revealed by the approximation beyond what follows from the output of the function being approximated. We then study the complexity of specific secure approximation problems. In particular, we obtain a sublinear-communication protocol for securely approximating the Hamming distance and a polynomial-time protocol for securely approximating the permanent and related #P-hard problems. 1
28|Comparing data streams using hamming norms (how to zero in)  (2003) | Massive data streams are now fundamental to many data processing applications. For example, Internet routers produce large scale diagnostic data streams. Such streams are rarely stored in traditional databases and instead must be processed “on the fly” as they are produced. Similarly, sensor networks produce multiple data streams of observations from their sensors. There is growing focus on manipulating data streams and, hence, there is a need to identify basic operations of interest in managing data streams, and to support them efficiently. We propose computation of the Hamming norm as a basic operation of interest. The Hamming norm formalizes ideas that are used throughout data processing. When applied to a single stream, the Hamming norm gives the number of distinct items that are present in that data stream, which is a statistic of great interest in databases. When applied to a pair of streams, the Hamming norm gives an important measure of (dis)similarity: the number of unequal item counts in the two streams. Hamming norms have many uses in comparing data streams. We present a novel approximation technique for estimating the Hamming norm for massive data streams; this relies on what we call the “l0 sketch ” and we prove its accuracy. We test our approximation method on a large quantity of synthetic and real stream data, and show that the estimation is accurate to within a few percentage points.
29|A Small Approximately Min-Wise Independent Family of Hash Functions|In this paper we give a construction of a small approximately min-wise independent family of hash functions. The number of bits needed to represent each function is  O(logn \Delta log 1=ffl). This construction gives a solution to the main open problem of [2].  1 Introduction  A family of functions H ae [n] ! [n] (where [n] =  f0 : : : n \Gamma 1g) is called ffl-min-wise independent if for any  X ae [n] and x 2 [n] \Gamma X we have Pr  h2H  [h(x) ! minh(X)] = 1  jXj + 1 (1 \Sigma ffl)  1 This definition can be generalized to the case when  jXj is restricted to be smaller than a prespecified bound s. Such families (restricted to the case when all functions from H are permutations) were introduced and investigated in [2] and independently earlier in [6] (cf. [7]). The motivation for studying such families is to reduce amount of randomness used by algorithms [6, 2, 3]. In particular (as pointed out in [2]) they have immediate application to efficient detection of similar documents in large...
30|Set Reconciliation with Nearly Optimal Communication Complexity|We consider the problem of efficiently reconciling two similar sets held by different hosts while minimizing the communication complexity. This type of problem arises naturally from gossip protocols used for the distribution of information. We describe an approach to set reconciliation based on the encoding of sets as polynomials. The resulting protocols exhibit tractable computational complexity and nearly optimal communication complexity. Also, these protocols can be adapted to work over a broadcast channel, allowing many clients to reconcile with one host based on a single broadcast, even if each client is missing a different subset.
31|The String Edit Distance  Matching Problems with Moves|The edit distance between two strings S and R is defined to be the minimum number of character inserts, deletes and changes needed to convert R to S. Given a text string t of length n, and a pattern string p of length m, informally, the string edit distance matching problem is to compute the smallest edit distance between p and substrings of t. We relax the problem so that (a) we allow an additional operation, namely, substring moves, and (b) we allow approximation of this string edit distance. Our result is a near linear time deterministic algorithm to produce a factor of O(log n log * n) approximation to the string edit distance with moves. This is the first known significantly subquadratic algorithm for a string edit distance problem in which the distance involves nontrivial alignments. Our results are obtained by embedding strings into L1 vector space using a simplified parsing technique we call Edit
32|Learn More, Sample Less: Control of Volume and Variance in Network Measurement |objects 289-43596         . We wish to estimate the sums   !#&#034; %$ &amp;(&#039;*)+&amp; ,  of the sizes of objects of a given color    , from a sampled subset of objects. How should the sampling distribution be chosen in order to jointly control both the variance of the estimators  -     ./   and the number of samples taken? This problem is motivated from network measurement, in which the    are the byte sizes of traffic flows reported by routers, and the     are the common properties of the packet of the flow, e.g., source and destination IP address. In this paper we propose a sampling scheme that optimally controls the volume of the measurements, and the variance of unbiased usage estimates  - 0/   , while retaining usage detail down to the finest level of granularity in the colors. We provide algorithms for dynamic control of sample volumes and evaluate them on flow data gathered from a commercial IP network. The algorithms are simple to implement and robust to variation in network conditions. The work reported here has been applied in the measurement infrastructure of the commercial IP network. To not have employed sampling would have entailed an order of magnitude greater capital expenditure to accommodate the measurement traffic and its processing.
33|Mining database structure; or, how to build a data quality browser|ABSTRACT Data mining research typically assumes that the data to be analyzed has been identified, gathered, cleaned, and processed into a convenient form. While data mining tools greatly enhance the ability of the analyst to make datadriven discoveries, most of the time spent in performing an analysis is spent in data identification, gathering, cleaning and processing the data. Similarly, schema mapping tools have been developed to help automate the task of using legacy or federated data sources for a new purpose, but assume that the structure of the data sources is well understood. However the data sets to be federated may come from dozens of databases containing thousands of tables and tens of thousands of fields, with little reliable documentation about primary keys or foreign keys. We are developing a system, Bellman, which performs data mining on the structure of the database. In this paper, we present techniques for quickly identifying which fields have similar values, identifying join paths, estimating join directions and sizes, and identifying structures in the database. The results of the database structure mining allow the analyst to make sense of the database content. This information can be used to e.g., prepare data for data mining, find foreign key joins for schema mapping, or identify steps to be taken to prevent the database from collapsing under the weight of its complexity. 1.
35|On the Dynamic Finger Conjecture for Splay Trees. Part II: The Proof|The following result is shown: On an n-node splay tree, the amortized cost of an access  at distance d from the preceding access is O(log(d + 1)). In addition, there is an O(n)  initialization cost. The accesses include searches, insertions and deletions.  1 Introduction  The reader is advised that this paper quotes results from the companion Part I paper [CMSS93]; in addition, the Part I paper introduces a number of the techniques used here, but in a somewhat less involved way.  The splay tree is a self-adjusting binary search tree devised by Sleator and Tarjan [ST85]. They showed that it is competitive with many of the balanced search tree schemes for maintaining a dictionary. Specifically, Sleator and Tarjan showed that a sequence of m accesses performed on a splay tree takes time O(m log n), where n is the maximum size attained by the tree (n  m). They also showed that in an amortized sense, up to a constant factor, on sufficiently long sequences of searches, the splay tree has as ...
36|Communities of Interest|We consider problems that can be characterized by large dynamic  graphs. Communication networks provide the prototypical example  of such problems where nodes in the graph are network IDs and the  edges represent communication between pairs of network IDs. In such  graphs, nodes and edges appear and disappear through time so that  methods that apply to static graphs are not sufficient. We introduce a  data structure that captures, in an approximate sense, the graph and  its evolution through time. The data structure arises from a bottom-up  representation of the large graph as the union of small subgraphs, called  Communities of Interest (COI), centered on every node. These subgraphs  are interesting in their own right and we discuss two applications in the  area of telecommunications fraud detection to help motivate the ideas.
37|QuickSAND: Quick Summary and Analysis of Network Data|Monitoring and analyzing traffic data generated from large ISP networks imposes challenges both at the data gathering phase as well as the data analysis itself. Still both tasks are crucial for responding to day to day challenges of engineering large networks with thousands of customers. In this paper we build on the premise that approximation is a necessary evil of handling massive datasets such as network data. We propose building compact summaries of the traffic data called sketches at distributed network elements and centers. These sketches are able to respond well to queries that seek features that stand out of the data. We call such features &#034;heavy hitters.&#034; In this paper, we describe sketches and show how to use sketches to answer aggregate and trend-related queries and identify heavy hitters. This may be used for exploratory data analysis of network operations interest. We support our proposal by experimentally studying AT&amp;T WorldNet data and performing a feasibility study on the Cisco NetFlow data collected at several routers.  1 
39|Reverse Nearest Neighbor Aggregates Over Data Streams|Reverse Nearest Neighbor (RNN) queries  have been studied for finite, stored data  sets and are of interest for decision support.
40|Sublinear Time Approximate Clustering|Clustering is of central importance in a number of disciplines including Machine Learning, Statistics, and Data Mining. This paper has two foci: (1) It describes how existing algorithms for clustering can benefit from simple sampling techniques arising from work in statistics [Pol84]. (2) It motivates and introduces a new model of clustering that is in the spirit of the &#034;PAC (probably approximately correct)&#034; learning model, and gives examples of efficient PAC-clustering algorithms.  
41|Counting inversions in lists|issues we face here. In a recent paper, Ajtai et al. [1] give a streaming algorithm In the rest of the paper, , where is the to count the number of inversions in a stream ??using allowed error. We will make the reasonable assumption in two passes and space. Here, this paper that??. We have not made an attempt to we present a simple randomized streaming algorithm for the optimize constants. same problem that uses one pass and space. Our algorithm is based on estimating quantiles of the 2 The Algorithm items already seen in the stream, and using that to estimate Suppose for all ?  ?  ? ????, we knew the the number of inversions involving each element. quantiles ? of?exactly. We claim that we can use this to approximate??to within a factor of. 1
42|Estimating dominance norms of multiple data streams|Abstract. There is much focus in the algorithms and database communities on designing tools to manage and mine data streams. Typically, data streams consist of multiple signals. Formally, a stream of multiple signals is (i, ai,j) where i’s correspond to the domain, j’s index the different signals and ai,j = 0 give the value of the jth signal at point i. We study the problem of finding norms that are cumulative of the multiple signals in the data stream. For example, consider the max-dominance norm, defined as i maxj{ai,j}. It may be thought as estimating the norm of the “upper envelope ” of the multiple signals, or alternatively, as estimating the norm of the “marginal ” distribution of tabular data streams. It is used in applications to estimate the “worst case influence” of multiple processes,for example in IP traffic analysis, electrical grid monitoring and financial domain. In addition, it is a natural measure, generalizing the union of data streams or counting distinct elements in data streams. We present the first known data stream algorithms for estimating max-dominance of multiple signals. In particular, we use workspace and time-per-item that are both sublinear (in fact, poly-logarithmic) in the input size. In contrast other notions of dominance on streams a, b — min-dominance ( i minj{ai,j}), countdominance (|{i|ai&gt; bi}|) or relative-dominance ( i ai / max{1, bi} )  — are all impossible to estimate accurately with sublinear space. 1
43|Maintaining Statistics Counters in Router Line Cards|this article, we assume that an arriving packet increments only one counter. If we instead considered the case where each packet arrival updates C counters, the line rate on the interface would be CR
44|Better algorithms for high-dimensional proximity problems via asymmetric embeddings|Abstract In this paper we give several results based on randomized embeddings of l2 into l1 (or &amp;quot;l1-like&amp;quot;) spaces. Our first result is a (1 + ffl)-distortion asymmetric embedding of n points in l2 into l1 with polylog(n) dimension, for any 1 + ffl. This gives the first known O(1)- approximate nearest neighbor algorithm with fast query time and almost polynomial space for a product of Euclidean norms, a common generalization of both l2 and l1 norms. Our embedding also clarifies the relative complexity of approximate nearest neighbor in l2 and l1 spaces. Our second result in a (1+ffl)-approximate algorithm for the diameter of n points in ld2, running in time ~O(dn1+1=(1+ffl)2); the algorithm is fully dynamic. This improves several previous algorithms for this problem (see Table 1 for more information). 1 Introduction Embeddings between normed spaces are known to be very useful tools for designing geometric algorithms. A classic example is an O(2dn)-time algorithm for computing diameter of n points in ld1 [GBT84]: since the problem seems difficult in the original space, we can embed1 ld1 isometrically into l2
45|Three Thresholds for a Liar|Motivated by the problem of making correct computations from partly false information, we study a corruption of the classic game &#034;Twenty Questions&#034; in which the player who answers the yes-or-no questions is permitted to lie up to a fixed fraction r of the time. The other player is allowed q arbitrary questions with which to try to determine, with certainty, which of n objects his opponent has in mind; he &#034;wins&#034; if he can always do so, and &#034;wins quickly&#034; if he can do so using only O(log n) questions. It turns out that there is a threshold value for r below which the querier can win quickly, and above which he cannot win at all. However, the threshold value varies according to the precise rules of the game. Our &#034;three thresholds theorem&#034; says that when the answerer is forbidden at any point to have answered more than a fraction r of the questions incorrectly, then the threshold value is r =  1 2 ; when the requirement is merely that the total number of lies cannot exceed rq, the threshol...
46|Inferring mixtures of markov chains|Abstract. We define the problem of inferring a “mixture of Markov chains ” based on observing a stream of interleaved outputs from these chains. We show a sharp characterization of the inference process. The problems we consider also has applications such as gene finding, intrusion detection, etc., and more generally in analyzing interleaved sequences. 1
47|Petabyte Scale Data Mining: Dream or Reality?|Science is becoming very data intensive. Today&#039;s astronomy datasets with tens of millions of galaxies already present substantial challenges for data mining. In less than 10 years the catalogs are expected to grow to billions of objects, and image archives will reach Petabytes. Imagine having a 100GB database in 1996, when disk scanning speeds were  30MB/s, and database tools were immature. Such a task today is trivial, almost manageable with a laptop. We think that  the issue of a PB database will be very similar in six years. In this paper we scale our current experiments in data  archiving and analysis on the Sloan Digital Sky Survey  2,3  data six years into the future. We analyze these projections and look at the requirements of performing data mining on such data sets. We conclude that the task scales rather well: we could do the job today, although it would be expensive. There do not seem to be any show-stoppers that would prevent us from storing and using a Petabyte dataset six years from today.
48|Application of the Two-Sided Depth Test to CSG Rendering|Shadow mapping is a technique for doing real-time shadowing. Recent work has shown that shadow mapping hardware can be used as a second depth test in addition to the z-test. In this paper, we explore the computational power provided by this second depth test by examining the problem of rendering objects described as CSG (Constructive Solid Geometry) expressions. We provide an algorithm that asymptotically improves the number of rendering passes required to display a CSG object by a factor of n by exploiting the two-sided depth test. Interestingly, a matching lower bound can be proved demonstrating that our algorithm is optimal.
49|Space-efficient finger search on degree-balanced search trees|We show how to support the finger search operation on degree-balanced search trees in a space-efficient manner that retains a worst-case time bound of O(log d), where d is the difference in rank between successive search targets. While most existing tree-based designs allocate linear extra storage in the nodes (e.g., for side links and parent pointers), our design maintains a compact auxiliary data structure called the “hand” during the lifetime of the tree and imposes no other storage requirement within the tree. The hand requires O(log n) space for an n-node tree and has a relatively simple structure. It can be updated synchronously during insertions and deletions with time proportional to the number of structural changes in the tree. The auxiliary nature of the hand also makes it possible to introduce finger searches into any existing implementation without modifying the underlying data representation (e.g., any implementation of Red-Black trees can be used). Together these factors make finger searches more appealing in practice. Our design also yields a simple yet optimal inorder walk algorithm with worst-case O(1) work per increment (again without any extra storage requirement in the nodes), and we believe our algorithm can be used in database applications when the overall performance is very sensitive to retrieval latency.
50|Randomized Algorithms|Randomized algorithms, once viewed as a tool in computational number theory, have by now found widespread application. Growth has been fueled by the two major benefits of randomization: simplicity and speed. For many applications a randomized algorithm is the fastest algorithm available, or the simplest, or both. A randomized algorithm is an algorithm that uses random numbers to influence the choices it makes in the course of its computation. Thus its behavior (typically quantified as running time or quality of output) varies from
51|Multiparty Communication Complexity|A given Boolean function has its input distributed among many parties. The aim is to determine which parties to tMk to and what information to exchange with each of them in order to evaluate the function while minimizing the total communication. This paper shows that it is possible to obtain the Boolean answer deterministically with only a polynomial increase in communication with respect to the information lower bound given by the nondeterministic communication complexity of the function.
52|Fast subsequence matching in time-series databases|We present an efficient indexing method to locate 1-dimensional subsequences within a collection of sequences, such that the subsequences match a given (query) pattern within a specified tolerance. The idea is to map each data sequence into a small set of multidimensional rectangles in feature space. Then, these rectangles can be readily indexed using traditional spatial access methods, like the R*-tree [9]. In more detail, we use a sliding window over the data sequence and extract its features; the result is a trail in feature space. We propose an ecient and eective algorithm to divide such trails into sub-trails, which are subsequently represented by their Minimum Bounding Rectangles (MBRs). We also examine queries of varying lengths, and we show how to handle each case efficiently. We implemented our method and carried out experiments on synthetic and real data (stock price movements). We compared the method to sequential scanning, which is the only obvious competitor. The results were excellent: our method accelerated the search time from 3 times up to 100 times.  
53|Eddies: Continuously Adaptive Query Processing|In large federated and shared-nothing databases, resources can exhibit widely fluctuating characteristics. Assumptions made at the time a query is submitted will rarely hold throughout the duration of query processing. As a result, traditional static query optimization and execution techniques are ineffective in these environments.  In this paper we introduce a query processing mechanism called an eddy, which continuously reorders operators in a query plan as it runs. We characterize the moments of symmetry  during which pipelined joins can be easily reordered, and the synchronization barriers that require inputs from different sources to be coordinated. By combining eddies with appropriate join algorithms, we merge the optimization and execution phases of query processing, allowing each tuple to have a flexible ordering of the query operators. This flexibility is controlled by a combination of fluid dynamics and a simple learning algorithm. Our initial implementation demonstrates prom...
54|Mining high-speed data streams|Categories and Subject ?????????? ? ?¨?????????????????????????¦???¦??????????¡¤?? ¡  ? ¡????????????????¦¡¤????§?£????
55|Online Aggregation|Aggregation in traditional database systems is performed in batch mode: a query is submitted, the system processes a large volume of data over a long period of time, and, eventually, the final answer is returned. This archaic approach is frustrating to users and has been abandoned in most other areas of computing. In this paper we propose a new online aggregation interface that permits users to both observe the progress of their aggregation queries and control execution on the fly. After outlining usability and performance requirements for a system supporting online aggregation, we present a suite of techniques that extend a database system to meet these requirements. These include methods for returning the output in random order, for providing control over the relative rate at which different aggregates are computed, and for computing running confidence intervals. Finally, we report on an initial implementation of online aggregation in postgres. 1 Introduction  Aggregation is an incre...
56|Efficient Filtering of XML Documents for Selective Dissemination of Information|Information Dissemination applications are gaining increasing  popularity due to dramatic improvements in  communications bandwidth and ubiquity. The sheer  volume of data available necessitates the use of selective  approaches to dissemination in order to avoid overwhelming  users with unnecessaryinformation. Existing  mechanisms for selective dissemination typically rely  on simple keyword matching or &#034;bag of words&#034; information  retrieval techniques. The advent of XML as a  standard for information exchangeand the development  of query languages for XML data enables the development  of more sophisticated filtering mechanisms that  take structure information into account. We have developed  several index organizations and search algorithms  for performing efficient filtering of XML documents for  large-scale information dissemination systems. In this  paper we describe these techniques and examine their  performance across a range of document, workload, and  scale scenarios.  1 
57|Random sampling with a reservoir|We introduce fast algorithms for selecting a random sample of n records without replacement from a pool of N records, where the value of N is unknown beforehand. The main result of the paper is the design and analysis of Algorithm Z; it does the sampling in one pass using constant space and in O(n(1 + log(N/n))) expected time, which is optimum, up to a constant factor. Several optimizations are studied that collectively improve the speed of the naive version of the algorithm by an order of magnitude. We give an efficient Pascal-like implementation that incorporates these modifications and that is suitable for general use. Theoretical and empirical results indicate that Algorithm Z outperforms current methods by a significant margin.
58|Mining time-changing data streams|Most statistical and machine-learning algorithms assume that the data is a random sample drawn from a station-ary distribution. Unfortunately, most of the large databases available for mining today violate this assumption. They were gathered over months or years, and the underlying pro-cesses generating them changed during this time, sometimes radically. Although a number of algorithms have been pro-posed for learning time-changing concepts, they generally do not scale well to very large databases. In this paper we propose an efficient algorithm for mining decision trees from continuously-changing data streams, based on the ultra-fast VFDT decision tree learner. This algorithm, called CVFDT, stays current while making the most of old data by growing an alternative subtree whenever an old one becomes ques-tionable, and replacing the old with the new when the new becomes more accurate. CVFDT learns a model which is similar in accuracy to the one that would be learned by reapplying VFDT to a moving window of examples every time a new example arrives, but with O(1) complexity per example, as opposed to O(w), where w is the size of the window. Experiments on a set of large time-changing data streams demonstrate the utility of this approach.
59|Continuous Queries over Data Streams|In many recent applications, data may take the form of continuous data streams, rather than finite stored data sets. Several aspects of data management need to be re-considered in the presence of data streams, offering a new research direction for the database community. In this pa-per we focus primarily on the problem of query processing, specifically on how to define and evaluate continuous queries over data streams. We address semantic issues as well as efficiency concerns. Our main contributions are threefold. First, we specify a general and flexible architecture for query processing in the presence of data streams. Second, we use our basic architecture as a tool to clarify alternative semantics and processing techniques for continuous queries. The architecture also captures most previous work on continuous queries and data streams, as
60|Fjording the Stream: An Architecture for Queries over Streaming Sensor Data|If industry visionaries are correct, our lives will soon be full of sensors, connected together in loose conglomerations via wireless networks, each monitoring and collecting data about the environment at large. These sensors behave very differently from traditional database sources: they have intermittent connectivity, are limited by severe power constraints, and typically sample periodically and push immediately, keeping no record of historical information. These limitations make traditional database systems inappropriate for queries over sensors. We present the Fjords architecture for managing multiple queries over many sensors, and show how it can be used to limit sensor resource demands while maintaining high query throughput. We evaluate our architecture using traces from a network of traffic sensors deployed on Interstate 80 near Berkeley and present performance results that show how query throughput, communication costs, and power consumption are necessarily coupled in sensor environments.
61|Continuously Adaptive Continuous Queries over Streams|We present a continuously adaptive, continuous query (CACQ) implementation based on the eddy query processing framework. We show that our design provides significant performance benefits over existing approaches to evaluating continuous queries, not only because of its adaptivity, but also because of the aggressive crossquery sharing of work and space that it enables. By breaking the abstraction of shared relational algebra expressions, our Telegraph CACQ implementation is able to share physical operators -- both selections and join state -- at a very fine grain. We augment these features with a grouped-filter index to simultaneously evaluate multiple selection predicates. We include measurements of the performance of our core system, along with a comparison to existing continuous query approaches.
62|Multiple-Query Optimization|Some recently proposed extensions to relational database systems, as well as to deductive database systems, require support for multiple-query processing. For example, in a database system enhanced with inference capabilities, a simple query involving a rule with multiple definitions may expand to more than one actual query that has to be run over the database. It is an interesting problem then to come up with algorithms that process these queries together instead of one query at a time. The main motivation for performing such an interquery optimization lies in the fact that queries may share common data. We examine the problem of multiple-query optimization in this paper. The first major contribution of the paper is a systematic look at the problem, along with the presentation and analysis of algorithms that can be used for multiple-query optimization. The second contribution lies in the presentation of experimental results. Our results show that using multiple-query processing algorithms may reduce execution cost considerably.
63|  Wavelet-Based Histograms for Selectivity Estimation |Query optimization is an integral part of relational database management systems. One important task in query optimization is selectivity estimation, that is, given a query P, we need to estimate the fraction of records in the database that satisfy P. Many commercial database systems maintain histograms to approximate the frequency distribution of values in the attributes of relations. In this paper, we present a technique based upon a multiresolution wavelet decomposition for building histograms on the underlying data distributions, with applications to databases, statistics, and simulation. Histograms built on the cumulative data values give very good approximations with limited space usage. We give fast algorithms for constructing histograms and using
64|An Adaptive Query Execution System for Data Integration|Query processing in data integration occurs over networkbound, autonomous data sources. This requires extensions to traditional optimization and execution techniques for three reasons: there is an absence of quality statistics about the data, data transfer rates are unpredictable and bursty, and slow or unavailable data sources can often be replaced by overlapping or mirrored sources. This paper presents the  Tukwila data integration system, designed to support adaptivity at its core using a two-pronged approach. Interleaved planning and execution with partial optimization allows Tukwila  to quickly recover from decisions based on inaccurate estimates. During execution, Tukwila uses adaptive query operators such as the double pipelined hash join, which produces answers quickly, and the dynamic collector, which robustly and efficiently computes unions across overlapping data sources. We demonstrate that the Tukwila architecture extends previous innovations in adaptive execution (such as...
65|Surfing wavelets on streams: One-pass summaries for approximate aggregate queries|Abstract We present techniques for computing small spacerepresentations of massive data streams. These are inspired by traditional wavelet-based approx-imations that consist of specific linear projections of the underlying data. We present general&amp;quot;sketch &amp;quot; based methods for capturing various linear projections of the data and use them to pro-vide pointwise and rangesum estimation of data streams. These methods use small amounts ofspace and per-item time while streaming through the data, and provide accurate representation asour experiments with real data streams show.
66|Approximate Query Processing Using Wavelets|Abstract. Approximate query processing has emerged as a cost-effective approach for dealing with the huge data volumes and stringent response-time requirements of today’s decision support systems (DSS). Most work in this area, however, has so far been limited in its query processing scope, typically focusing on specific forms of aggregate queries. Furthermore, conventional approaches based on sampling or histograms appear to be inherently limited when it comes to approximating the results of complex queries over high-dimensional DSS data sets. In this paper, we propose the use of multi-dimensional wavelets as an effective tool for general-purpose approximate query processing in modern, high-dimensional applications. Our approach is based on building wavelet-coefficient synopses of the data and using these synopses to provide approximate answers to queries. We develop novel query processing
67| Approximate Computation of Multidimensional Aggregates of Sparse Data Using Wavelets |Computing multidimensional aggregates in high dimensions is a performance bottleneck for many OLAP applications. Obtaining the exact answer to an aggregation query can be prohibitively expensive in terms of time and/or storage space in a data warehouse environment. It is advantageous to have fast, approximate answers to OLAP aggregation queries. In this paper, we present anovel method that provides approximate answers to high-dimensional OLAP aggregation queries in massive sparse data sets in a time-efficient and space-efficient manner. We construct a compact data cube, which is an approximate and space-efficient representation of the underlying multidimensional array, based upon a multiresolution wavelet decomposition. In the on-line phase, each aggregation query can generally be answered using the compact data cube in one I/O or a small number of I/Os, depending upon the desired accuracy. We present two I/O-efficient algorithms to construct the compact data cube for the important case of sparse high-dimensional arrays, which often arise in practice. The traditional histogram methods are infeasible for the massive high-dimensional data sets in OLAP applications. Previously developed wavelet techniques are efficient only for dense data. Our on-line query processing algorithm is very fast and capable of refining answers as the user demands more accuracy. Experiments on real data show that our method provides significantly more accurate results for typical OLAP aggregation queries than other efficient approximation techniques such as random sampling.
68|Computing on Data Streams|In this paper we study the space requirement of algorithms that make  only one (or a small number of) pass(es) over the input data. We study such  algorithms under a model of data streams that we introduce here. We give  a number of upper and lower bounds for problems stemming from queryprocessing,  invoking in the process tools from the area of communication  complexity.
69|Processing Complex Aggregate Queries over Data Streams|Recent years have witnessed an increasing interest in designing algorithms for querying and analyzing streaming data (i.e., data that is seen only once in a fixed order) with only limited memory. Providing (perhaps approximate) answers to queries over such continuous data streams is a crucial requirement for many application environments; examples include large telecom and IP network installations where performance data from different parts of the network needs to be continuously collected and analyzed.
70|Continual Queries for Internet Scale Event-Driven Information Delivery|In this paper we introduce the concept of continual queries, describe the design of a distributed  event-driven continual query system -- OpenCQ, and outline the initial implementation of OpenCQ  on top of the distributed interoperable information mediation system DIOM [21, 19]. Continual  queries are standing queries that monitor update of interest and return results whenever the update  reaches specified thresholds. In OpenCQ, users may specify to the system the information they would  like to monitor (such as the events or the update thresholds they are interested in). Whenever the  information of interest becomes available, the system immediately delivers it to the relevant users;  otherwise, the system continually monitors the arrival of the desired information and pushes it to the  relevant users as it meets the specified update thresholds. In contrast to conventional pull-based data  management systems such as DBMSs and Web search engines, OpenCQ exhibits two important featu...
71|Join synopses for approximate query answering|In large data warehousing environments, it is often advantageous to provide fast, approximate answers to complex aggregate queries based on statistical summaries of the full data. In this paper, we demonstrate the difficulty of providing good approximate answers for join-queries using only statistics (in particular, samples) from the base relations. We propose join synopses (join samples) as an effective solution for this problem and show how precomputing just one join synopsis for each relation suffices to significantly improve the quality of approximate answers for arbitrary queries with foreign key joins. We present optimal strategies for allocating the available space among the various join synopses when the query work load is known and identify heuristics for the common case when the work load is not known. We also present efficient algorithms for incrementally maintaining join synopses in the presence of updates to the base relations. One of our key contributions is a detailed analysis of the error bounds obtained for approximate answers that demonstrates the trade-offs in various methods, as well as the advantages in certain scenarios of a new subsampling method we propose. Our extensive set of experiments on the TPC-D benchmark database show the effectiveness of join synopses and various other techniques proposed in this paper. 1
72|An efficient cost-driven index selection tool for Microsoft SQL Server|In this paper we describe novel techniques that make it possible to build an industrial-strength tool for automating the choice of indexes in the physical design of a SQL database. The tool takes as input a workload of SQL queries, and suggests a set of suitable indexes. We ensure that the indexes chosen are effective in reducing the cost of the workload by keeping the index selection tool and the query optimizer &amp;quot;in step&amp;quot;. The number of index sets that must be evaluated to find the optimal configuration is very large. We reduce the complexity of this problem using three techniques. First, we remove a large number of spurious indexes from consideration by taking into account both query syntax and cost information. Second, we introduce optimizations that make it possible to cheaply evaluate the “goodness ” of an index set. Third, we describe an iterative approach to handle the complexity arising from multicolumn indexes. The tool has been implemented on Microsoft SQL Server 7.0. We performed extensive experiments over a range of workloads, including TPC-D. The results indicate that the tool is efficient and its choices are close to optimal. 1.
73|Computing iceberg queries efficiently|Many applications compute aggregate functions...
74|Data-Streams and Histograms|Histograms have been used widely to capture data distribution, to represent the data by a small number of step functions. Dynamic programming algorithms which provide optimal construction of these histograms exist, albeit running in quadratic time and linear space. In this paper we provide linear time construction of 1 + epsilon approximation of optimal histograms, running in polylogarithmic space. Our results extend to the context of data-streams, and in fact generalize to give 1 + epsilon approximation of several problems in data-streams which require partitioning the index set into intervals. The only assumptions required are that the cost of an interval is monotonic under inclusion (larger interval has larger cost) and that the cost can be computed or approximated in small space. This exhibits a nice class of problems for which we can have near optimal data-stream algorithms.
75|XJoin: A Reactively-Scheduled Pipelined Join Operator|Wide-area distribution raises significant performance problems for traditional query processing techniques as data access becomes less predictable due to link congestion, load imbalances, and temporary outages. Pipelined query execution is a promising approach to coping with unpredictability in such environments as it allows scheduling to adjust to the arrival properties of the data. We have developed a non-blocking join operator, called XJoin, which has a small memory footprint, allowing many such operators to be active in parallel. XJoin is optimized to produce initial results quickly and can hide intermittent delays in data arrival by reactively scheduling background processing. We show that XJoin is an effective solution for providing fast query responses to users even in the presence of slow and bursty remote sources.  
76|Rate-Based Query Optimization for Streaming Information Sources|Relational query optimizers have traditionally relied upon table cardinalities when estimating the cost of the query plans they consider. While this approach has been and continues to be successful, the advent of the Internet and the need to execute queries over streaming sources requires a different approach, since for streaming inputs the cardinality may not be known or may not even be knowable (as is the case for an unbounded stream.) In view of this, we propose shifting from a cardinality-based approach to a rate-based approach, and give an optimization framework that aims at maximizing the output rate of query evaluation plans. This approach can be applied to cases where the cardinality-based approach cannot be used. It may also be useful for cases where cardinalities are known, because by focusing on rates we are able not only to optimize the time at which the last result tuple appears, but also to optimize for the number of answers computed at any specified time after the query evaluation commences. We present a preliminary validation of our rate-based optimization framework on a prototype XML query engine, though it is generic enough to be used in other database contexts. The results show that rate-based optimization is feasible and can indeed yield correct decisions.
77|Making Views Self-Maintainable for Data Warehousing|A data warehouse stores materialized views over data from one or more sources in order to provide fast access to the integrated data, regardless of the availability of the data sources. Warehouse views need to be maintained inresponse to changes to the base data in the sources. Except for very simple views, maintaining a warehouse view requires access to data that is not available in the view itself. Hence, to maintain the view, one either has to query the data sources or store auxiliary data in the warehouse. We show that by using key and referential integrity constraints, we often can maintain a select-project-join view without going to the data sources or replicating the base relations in their entirety in the warehouse. We derive a set of auxiliary views such that the warehouse view and the auxiliary views together are self-maintainable|they can be maintained without going to the data sources or replicating all base data. In addition, our technique can be applied to simplify traditional materialized view maintenance by exploiting key and referential integrity constraints. 1
78|Approximate Medians and other Quantiles in One Pass and with Limited Memory|We present new algorithms for computing approximate quantiles of large datasets in a single pass. The approximation guarantees are explicit, and apply without regard to the value distribution or the arrival distributions of the dataset. The main memory requirements are smaller than those reported earlier by an order of magnitude.  We also discuss methods that couple the approximation algorithms with random sampling to further reduce memory requirements. With sampling, the approximation guarantees are explicit but probabilistic, i.e., they apply with respect to a (user controlled) confidence parameter.  We present the algorithms, their theoretical analysis and simulation results.  1 Introduction  This article studies the problem of computing order statistics  of large sequences of online or disk-resident data using as little main memory as possible. We focus on computing  quantiles, which are elements at specific positions in the sorted order of the input. The OE-quantile, for OE 2 [0; ...
79|Sampling From a Moving Window Over Streaming Data|We introduce the problem of sampling from a moving window of recent items from a data stream and develop the &#034;chain-sample&#034; and &#034;priority-sample&#034; algorithms for this problem.
80|Tracking join and self-join sizes in limited storage|This paper presents algorithms for tracking (approximate) join and self-join sizes in limited storage, in the presence of insertions and deletions to the data set(s). Such algorithms detect changes in join and self-join sizes without an expensive recomputation from the base data, and without the large space overhead required to maintain such sizes exactly. Query optimizers rely on fast, high-quality estimates of join sizes in order to select between various join plans, and estimates of self-join sizes are used to indicate the degree of skew in the data. For self-joins, we considertwo approaches proposed in [Alon, Matias, and Szegedy. The Space Complexity of Approximating the Frequency Moments. JCSS, vol. 58, 1999, p.137-147], which we denote tug-of-war and sample-count. Wepresent fast algorithms for implementing these approaches, and extensions to handle deletions as well as insertions. We also report on the rst experimental study of the two approaches, on a range of synthetic and real-world data sets. Our study shows that tug-of-war provides more accurate estimates for a given storage limit than sample-count, which in turn is far more accurate than a standard sampling-based approach. For example, tug-of-war needed only 4{256 memory words, depending on the data set, in order to estimate the self-join size
81|Data Cube Approximation and Histograms via Wavelets (Extended Abstract)  (1998) |) Jeffrey Scott Vitter   Center for Geometric Computing and Department of Computer Science Duke University Durham, NC 27708--0129 USA  jsv@cs.duke.edu Min Wang  y Center for Geometric Computing and Department of Computer Science Duke University Durham, NC 27708--0129 USA  minw@cs.duke.edu Bala Iyer  Database Technology Institute IBM Santa Teresa Laboratory P.O. Box 49023 San Jose, CA 95161 USA  balaiyer@vnet.ibm.com Abstract  There has recently been an explosion of interest in the analysis of data in data warehouses in the field of On-Line Analytical Processing (OLAP). Data warehouses can be extremely large, yet obtaining quick answers to queries is important. In many situations, obtaining the exact answer to an OLAP query is prohibitively expensive in terms of time and/or storage space. It can be advantageous to have fast, approximate answers to queries. In this paper, we present an I/O-efficient technique based upon a multiresolution wavelet decomposition that yields an approximate a...
82|The design and implementation of a sequence database system|This paper discusses the design and implementation of SEQ, a database system with support for sequence data. SEQ models a sequence as an ordered collection of records, and supports a declarative sequence query language based on an algebra of query operators, thereby permitting algebraic query optimization and evaluation. SEQ has been built as a component of the PREDATOR database system that provides support for relational and other kinds of complex data as well. There are three distinct contributions made in this paper. (1) We describe the specification of sequence queries using the SEQUIN query language. (2) We quantitatively demonstrate the importance of various storage and optimization techniques by studying their effect on performance. (3) We present a novel nested design paradigm used in PREDATOR to combine sequence ‘and relational data.
83|Random sampling techniques for space efficient online computation of order statistics of large datasets|In a recent paper [MRL98], we had described a general framework for single pass approximate quantile nding algorithms. This framework included several known algorithms as special cases. We had identi ed a new algorithm, within the framework, which had a signi cantly smaller requirement for main memory than other known algorithms. In this paper, we address two issues left open in our earlier paper. First, all known and space e cient algorithms for approximate quantile nding require advance knowledge of the length of the input sequence. Many important database applications employing quantiles cannot provide this information. In this paper, we present anovel non-uniform random sampling scheme and an extension of our framework. Together, they form the basis of a new algorithm which computes approximate quantiles without knowing the input sequence length. Second, if the desired quantile is an extreme value (e.g., within the top 1 % of the elements), the space requirements of currently known algorithms are overly pessimistic. We provide a simple algorithm which estimates extreme values using less space than required by the earlier more general technique for computing all quantiles. Our principal observation here is that random sampling is quanti ably better when estimating extreme values than is the case with the median.  
84|Characterizing Memory Requirements for Queries over Continuous Data|This paper deals with continuous conjunctive queries with arithmetic comparisons and optional aggregation over multiple data streams. An algorithm is presented for determining whether or not any given query can be evaluated using a bounded amount of memory for all possible instances of the data streams. For queries that can be evaluated using bounded memory, an execution strategy based on constant-sized synopses of the data streams is proposed. For queries that cannot be evaluated using bounded memory, data stream scenarios are identified in which evaluating the queries requires memory linear in the size of the unbounded streams
85|Congressional samples for approximate answering of group-by queries|In large data warehousing environments, it is often advantageous to provide fast, approximate answers to complex decision support queries using precomputed summary statistics, such as samples. Decision support queries routinely segment the data into groups and then aggregate the information in each group (group-by queries). Depending on the data, there can be a wide disparity between the number of data items in each group. As a result, approximate answers based on uniform random samples of the data can result in poor accuracy for groups with very few data items, since such groups will be represented in the sample by very few (often zero) tuples. In this paper, we propose a general class of techniques for obtaining fast, highly-accurate answers for group-by queries. These techniques rely on precomputed non-uniform (biased) samples of the data. In particular, we proposecongressional samples, ahybrid union of uniform and biased samples. Given a xed amount of space, congressional samples seek to maximize the accuracy for all possible group-by queries on a set of columns. We present a one pass algorithm for constructing a congressional sample and use this technique to also incrementally maintain the sample up-to-date without accessing the base relation. We also evaluate query rewriting strategies for providing approximate answers from congressional samples. Finally, we conduct an extensive set of experiments on the TPC-D database, which demonstrates the e cacy of the techniques proposed. 1
86|Histogram-Based Approximation of Set-Valued Query Answers|Answering queries approximately has recently  been proposed as a way to reduce query response  times in on-line decision support systems,  when the precise answer is not necessary  or early feedback is helpful. Most of the  work in this area uses sampling-based techniques  and handles aggregate queries, ignoring  queries that return relations as answers. In  this paper, we extend the scope of approximate  query answering to general queries. We propose  a novel and intuitive error measure for  quantifying the error in an approximate query  answer, which can be a multiset in general.
87|Data Integration using Self-Maintainable Views|.  In this paper we de#ne the concept of self-maintainable views  # these are views that can be maintained using only the contents of  the view and the database modi#cations, without accessing any of the  underlying databases. We derive tight conditions under which several  types of select-project-join are self-maintainable upon insertions, deletions  and updates. Self-Maintainability is a desirable property for e#-  ciently maintaining large views in applications where fast response and  high availability are important. One example of suchanenvironment  is data warehousing wherein views are used for integrating data from  multiple databases.  1 Introduction  Most large organizations have related data in distinct databases. Many of these databases may be legacy systems, or systems separated for organizational reasons like funding and ownership. Integrating data from such distinct databases is a pressing business need. A common approach for integration is to de#ne an integrated view and...
88|Monitoring XML Data on the Web|We consider the monitoring of a flow of incoming documents. More precisely, we present here the monitoring used in a very large warehouse built from XML documents found on the web. The flow of documents consists in XML pages (that are warehoused) and HTML pages (that are not). Our contributions are the following:  ffl a subscription language which specifies the monitoring of pages when fetched, the periodical evaluation of continuous queries and the production of XML reports. ffl the description of the architecture of the system we implemented that makes it possible to monitor a flow of millions of pages per day with millions of subscriptions on a single PC, and scales up by using more machines. ffl a new algorithm for processing alerts that can be used in a wider context. We support
89|Expiring data in a warehouse|Data warehouses collect data into materi-alized views for analysis. After some time, some of the data may no longer be needed or may not be of interest. In this pa-per, we handle this by expiring or remov-ing unneeded materialized view tuples. A framework supporting such expiration is presented. Within it, a user or adminis-trator can declaratively request expirations and can specify what type of modifications are expected from external sources. The lat-ter can significantly increase the amount of data that can be expired. We present effi-cient algorithms for determining what data can be expired (data not needed for main-tenance of other views), taking into account the types of updates that may occur. 1
91|Sequence Query Processing|Many applications require the ability to manipulate sequences of data. We motivate the importance of sequence query processing, and present a framework for the optimization of sequence queries based on several novel techniques. These include query transformations, optimizations that utilize meta--data, and caching of intermediate results. We present a bottom-up algorithm that generates an efficient query evaluation plan based on cost estimates. This work also identifies a number of directions in which future research can be directed.  1 Introduction  Many real life applications manipulate data that is inherently sequential. Such data is logically viewed and queried in terms of a sequence abstraction and is often physically stored as a sequence. Databases should (a) allow sequences to be queried in a declarative manner, utilizing the ordered semantics of the data, and (b) take advantage of the opportunities available for query optimization. Relational databases are inadequate in this re...
92|SEQ: A Model for Sequence Databases|This paper presents the model which is the basis for a system to manage various kinds of sequence data. The model separates the data from the ordering information, and includes operators based on two distinct abstractions of a sequence. The main contributions of the model are: (a) it can deal with different types of sequence data, (b) it supports an expressive range of sequence queries, (c) it draws from many of the diverse existing approaches to modeling sequence data. 1
93|Sampling Algorithms: Lower Bounds and Applications (Extended Abstract)  (2001) |]  Ziv Bar-Yossef  y  Computer Science Division  U. C. Berkeley  Berkeley, CA 94720  zivi@cs.berkeley.edu  Ravi Kumar  IBM Almaden  650 Harry Road  San Jose, CA 95120  ravi@almaden.ibm.com  D. Sivakumar  IBM Almaden  650 Harry Road  San Jose, CA 95120  siva@almaden.ibm.com  ABSTRACT  We develop a framework to study probabilistic sampling algorithms that approximate general functions of the form f : A  n  ! B, where A and B are arbitrary sets. Our goal is to obtain lower bounds on the query complexity of functions, namely the number of input variables x i that any sampling algorithm needs to query to approximate f(x1 ; : : : ; xn ).  We define two quantitative properties of functions --- the block sensitivity and the minimum Hellinger distance --- that give us techniques to prove lower bounds on the query complexity. These techniques are quite general, easy to use, yet powerful enough to yield tight results. Our applications include the mean and higher statistical moments, the median and other selection functions, and the frequency moments, where we obtain lower bounds that are close to the corresponding upper bounds.  We also point out some connections between sampling and streaming algorithms and lossy compression schemes.  1. 
94|Approximating a Data Stream for Querying and Estimation: Algorithms and Performance Evaluation|Obtaining fast and good quality approximations to data distributions is a problem of central interest to database management. A variety of popular database applications including, approximate querying, similarity searching and data mining in most application domains, rely on such good quality approximations. Histogram based approximation is a very popular method in database theory and practice to succinctly represent a data distribution in a space efficient manner. In this paper, we place the problem of histogram construction into perspective and we generalize it by raising the requirement of a finite data set and/or known data set size. We consider the case of an infinite data set on which data arrive continuously forming an infinite data stream. In this context, we present the first single pass algorithms capable of constructing histograms of provable good quality. We present algorithms for the fixed window variant of the basic histogram construction problem, supporting incremental maintenance of the histograms. The proposed algorithms trade accuracy for speed and allow for a graceful tradeoff between the two, based on application requirements. In the case of approximate queries on infinite data streams, we present a detailed experimental evaluation comparing our algorithms with other applicable techniques using real data sets, demonstrating the superiority of our proposal. 1
95|A robust, optimization-based approach for approximate answering of aggregate queries|The ability to approximately answer aggregation queries accurately and efficiently is of great benefit for decision support and data mining tools. In contrast to previous sampling-based studies, we treat the problem as an optimization problem whose goal is to minimize the error in answering queries in the given workload. A key novelty of our approach is that we can tailor the choice of samples to be robust even for workloads that are “similar ” but not necessarily identical to the given workload. Finally, our techniques recognize the importance of taking into account the variance in the data distribution in a principled manner. We show how our solution can be implemented on a database system, and present results of extensive experiments on Microsoft SQL Server 2000 that demonstrate the superior quality of our method compared to previous work. 1
96|Online Dynamic Reordering for Interactive Data Processing|Abstract We present a pipelining, dynamically user-controllable reorder operator, for use in data-intensive applications. Allowing the user to reorder the data delivery on the fly increases the interactivity in several contexts such as online aggregation and large-scale spreadsheets; it allows the user to control the processing of data by dynamically specifying preferences for different data items based on prior feedback, so that data of interest is prioritized for early processing.
98|On Sampling and Relational Operators|A major bottleneck in implementing sampling as a primitive relational operation is the inefficiency of sampling the output of a query. We highlight the primary difficulties, summarize the results of some recent work in this area, and indicate directions for future work.   
99|Database-friendly Random Projections|A classic result of Johnson and Lindenstrauss asserts that any set of n points in d-dimensional Euclidean space can be embedded into k-dimensional Euclidean space | where k is logarithmic in n and independent of d | so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the n points onto a random k-dimensional hyperplane. We give a novel construction of the embedding, suitable for database applications, which amounts to computing a simple aggregate over k random attribute partitions.
100| Synopsis Data Structures for Massive Data Sets |Abstract. Massive data sets with terabytes of data are becoming commonplace. There is an increasing demand for algorithms and data structures that provide fast response times to queries on such data sets. In this paper, we describe a context for algorithmic work relevant to massive data sets and a framework for evaluating such work. We consider the use of &#034;synopsis&#034; data structures, which use very little space and provide fast (typically approximated) answers to queries. The design and analysis of effective synopsis data structures o er many algorithmic challenges. We discuss a number of concrete examples of synopsis data structures, and describe fast algorithms for keeping them up-to-date in the presence of online updates to the data sets.  
101|Locality in Search Engine Queries and Its Implications for Caching|Caching is a popular technique for reducing both server load and user response time in distributed systems. In this paper, we consider the question of whether caching might be effective for search engines as well. We study two real search engine traces by examining query locality and its implications for caching. Our trace analysis results show that: (1) Queries have significant locality, with query frequency following a Zipf distribution. Very popular queries are shared among different users and can be cached at servers or proxies, while 16% to 22% of the queries are from the same users and should be cached at the user side. Multiple-word queries are shared less and should be cached mainly at the user side. (2) If caching is to be done at the user side, short-term caching for hours will be enough to cover query temporal locality, while server/proxy caching should use longer periods, such as days. (3) Most users have small lexicons when submitting queries. Frequent users who submit many search requests tend to reuse a small subset of words to form queries. Thus, with proxy or user side caching, prefetching based on user lexicon looks promising.
102|PROBABILITY INEQUALITIES FOR SUMS OF BOUNDED RANDOM VARIABLES|Upper bounds are derived for the probability that the sum S of n independent random variables exceeds its mean ES by a positive number nt. It is assumed that the range of each summand of S is bounded or bounded above. The bounds for Pr(S-ES&gt; nt) depend only on the endpoints of the ranges of the smumands and the mean, or the mean and the variance of S. These results are then used to obtain analogous inequalities for certain sums of dependent random variables such as U statistics and the sum of a random sample without replacement from a finite population. 
103|Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm|learning Boolean functions, linear-threshold algorithms Abstract. Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space. 1.
104|Sampling Large Databases for Association Rules|Discovery of association rules is an important database mining problem. Current algorithms for nding association rules require several passes over the analyzed database, and obviously the role of I/O overhead is very signi cant for very large databases. We present new algorithms that reduce the database activity considerably. Theidea is to pick a random sample, to ndusingthis sample all association rules that probably hold in the whole database, and then to verify the results with the restofthe database. The algorithms thus produce exact association rules, not approximations based on a sample. The approach is, however, probabilistic, and inthose rare cases where our sampling method does not produce all association rules, the missing rules can be found inasecond pass. Our experiments show that the proposed algorithms can nd association rules very e ciently in only onedatabase pass. 1
105|SPRINT: A scalable parallel classifier for data mining|Classification is an important data mining problem. Although classification is a well-studied problem, most of the current classi-fication algorithms require that all or a por-tion of the the entire dataset remain perma-nently in memory. This limits their suitability for mining over large databases. We present a new decision-tree-based classification algo-rithm, called SPRINT that removes all of the memory restrictions, and is fast and scalable. The algorithm has also been designed to be easily parallelized, allowing many processors to work together to build a single consistent model. This parallelization, also presented here, exhibits excellent scalability as well. The combination of these characteristics makes the proposed algorithm an ideal tool for data min-ing. 1
106|SLIQ: A Fast Scalable Classifier for Data Mining|. Classification is an important problem in the emerging field of data mining. Although classification has been studied extensively in the past, most of the classification algorithms are designed only for memory-resident data, thus limiting their suitability for data mining large data sets. This paper discusses issues in building a scalable classifier and presents the design of SLIQ  1  , a new classifier. SLIQ is a decision tree classifier that can handle both numeric and categorical attributes. It uses a novel pre-sorting technique in the tree-growth phase. This sorting procedure is integrated with a breadth-first tree growing strategy to enable classification of disk-resident datasets. SLIQ also uses a new tree-pruning algorithm that is inexpensive, and results in compact and accurate trees. The combination of these techniques enables SLIQ to scale for large data sets and classify data sets irrespective of the number of classes, attributes, and examples (records), thus making it an ...
107|Incremental Induction of Decision Trees|This article presents an incremental algorithm for inducing decision trees  equivalent to those formed by Quinlan&#039;s nonincremental ID3 algorithm, given the  same training instances. The new algorithm, named ID5R, lets one apply the ID3  induction process to learning tasks in which training instances are presented serially.
108|Efficient algorithms for minimizing cross validation error|Model selection is important in many areas of supervised learning. Given a dataset and a set of models for predicting with that dataset, we must choose the model which is expected to best predict future data. In some situations, such as online learning for control of robots or factories, data is cheap and human expertise costly. Cross validation can then be a highly effective method for automatic model selection. Large scale cross validation search can, however, be computationally expensive. This paper introduces new algorithms to reduce the computational burden of such searches. We show how experimental design methods can achieve this, using a technique similar to a Bayesian version of Kaelbling’s Interval Estimation. Several improvements are then given, including (1) the use of blocking to quickly spot near-identical models, and (2) schemata search: a new method for quickly finding families of relevant features. Experiments are presented for robot data and noisy synthetic datasets. The new algorithms speed up computation without sacrificing reliability, and in some cases are more reliable than conventional techniques. 1
109|Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation|Selecting a good model of a set of input points by cross validation is a computationally intensive process, especially if the number of possible models or the number of training points is high. Techniques such as gradient descent are helpful in searching through the space of models, but problems such as local minima, and more importantly, lack of a distance metric between various models reduce the applicability of these search methods. Hoeffding Races is a technique for finding a good model for the data by quickly discarding bad models, and concentrating the computational effort at differentiating between the better ones. This paper focuses on the special case of leave-one-out cross validation applied to memorybased learning algorithms, but we also argue that it is applicable to any class of model selection problems. 1 Introduction  Model selection addresses &#034;high level&#034; decisions about how best to tune learning algorithm architectures for particular tasks. Such decisions include which...
110|BOAT -- Optimistic Decision Tree Construction|Classification is an important data mining problem. Given a training database of records, each tagged with a class label, the goal of classification is to build a concise model that can be used to predict the class label of future, unlabeled records. A very popular class of classifiers are decision trees. All current algorithms to construct decision trees, including all main-memory algorithms, make one scan over the training database per level of the tree.  We introduce a new algorithm (BOAT) for decision tree construction that improves upon earlier algorithms in both performance and functionality. BOAT constructs several levels of the tree in only two scans over the training database, resulting in an average performance gain of 300% over previous work. The key to this performance improvement is a novel optimistic approach to tree construction in which we construct an initial tree using a small subset of the data and refine it to arrive at the final tree. We guarantee that any differen...
111|Efficient Progressive Sampling|Having access to massiveamounts of data does not necessarily imply that induction  algorithms must use them all. Samples often provide the same accuracy with far less  computational cost. However, the correct sample size is rarely obvious. We analyze  methods for progressive sampling---starting with small samples and progressively increasing  them as long as model accuracy improves. We show that a simple, geometric  sampling schedule is efficient in an asymptotic sense. We then explore the notion of  optimal efficiency: what is the absolute best sampling schedule? We describe the issues  involved in instantiating an &#034;optimally efficient&#034; progressive sampler. Finally,we  provide empirical results comparing a variety of progressive sampling methods. We  conclude that progressive sampling often is preferable to analyzing all data instances.
112|Organization-Based Analysis of Web-Object Sharing and Caching|Performance-enhancing mechanisms in the World Wide Web primarily exploit repeated requests to Web documents by multiple clients. However, little is known about patterns of shared document access, particularly from diverse client populations. The principal goal of this paper is to examine the sharing of Web documents from an organizational point of view. An organizational analysis of sharing is important, because caching is often performed on an organizational basis; i.e., proxies are typically placed in front of large and small companies, universities, departments, and so on. Unfortunately, simultaneous multi-organizational traces do not currently exist and are difficult to obtain in practice.
113|OPUS: An efficient admissible algorithm for unordered search|OPUS is a branch and bound search algorithm that enables efficient admissible search through spaces for which the order of search operator application is not significant. The algorithm’s search efficiency is demonstrated with respect to very large machine learning search spaces. The use of admissible search is of potential value to the machine learning community as it means that the exact learning biases to be employed for complex learning tasks can be precisely specified and manipulated. OPUS also has potential for application in other areas of artificial intelligence, notably, truth maintenance. 1.
114|Oversearching and Layered Search in Empirical Learning|When learning classifiers, more extensive search for rules is shown to lead to lower predictive accuracy on many of the real-world domains investigated. This counter-intuitive result is particularly relevant to recent systematic search methods that use risk-free pruning to achieve the same outcome as exhaustive search. We propose an iterated search method that commences with greedy search, extending its scope at each iteration until a stopping criterion is satisfied. This layered search is often found to produce theories that are more accurate than those obtained with either greedy search or moderately extensive beam search. 1 Introduction  Mitchell [1982] observes that the generalization implicit in learning from examples can be viewed as a search over the space of possible theories. From this perspective, most machine learning methods carry out a series of local searches in the vicinity of the current theory, selecting at each step the most promising improvement. Covering algorithms ...
115|An Improved Algorithm for Incremental Induction of Decision Trees|This paper presents an algorithm for incremental induction of decision trees that is able to handle both numeric and symbolic variables. In order to handle numeric variables, a new tree revision operator called `slewing&#039; is introduced. Finally, a non-incremental method is given for finding a decision tree based on a direct metric of a candidate tree.  Contents  1 Introduction 1 2 Design Goals 1 3 An Improved Algorithm 2  3.1 Incorporating a Training Instance : : : : : : : : : : : : : : : : : : : : : : : : 2 3.2 Ensuring a Best Test at Each Decision Node : : : : : : : : : : : : : : : : : : 3 3.3 Information Kept at a Decision Node : : : : : : : : : : : : : : : : : : : : : : 3 3.4 Tree Transposition : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 4 3.5 Slewing a Cutpoint : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 4 3.6 How to Ensure a Best Test Everywhere : : : : : : : : : : : : : : : : : : : : : 5  4 Incremental Training Cost 5 5 Error-Correction Mo...
116|Overfitting and Undercomputing in Machine Learning| suggests a reasonable line of research: find algorithms that can search the hypothesis class better. Hence, there is been extensive research in applying second-order methods to fit neural networks and in conducting much more thorough searches in learning decision trees and rule sets. Ironically, when these algorithms were tested on real datasets, it was found that their performance was often worse than simple gradient descent or greedy search [3, 5]. In short: it appears to be better not to optimize! One of the other important trends in machine learning research has been the establishment and nurturing of connections between various previously-disparate fields including computational learning theory, connectionist learning, symbolic learning, and statistics. The connection to statistics was crucial in resolving this paradox. The key problem arises from the structure of the machine learning task. A learning algorithm is trained on a set of training data, but then it is applied to make 
117|Sequential Inductive Learning|In this paper I advocate a new model for inductive learning. Called sequential induction, this model bridges classical fixed-sample learning techniques (which are efficient but ad hoc), and worst-case approaches (which provide strong statistical guarantees but are too inefficient for practical use). According to the sequential inductive model, learning is a sequence of decisions which are informed by training data. By analyzing induction at the level of these decisions, and by utilizing the minimum data necessary to make each decision, sequential inductive techniques can provide the strong statistical guarantees of worst-case methods, but with substantially less data than those methods require. The sequential inductive model is also useful as a method for determining a sufficient sample size for inductive learning and as such, is relevant to megainduction,where the preponderance of data introduces problems of scale. The peepholing and decision-theoretic subsampling approaches of Catlet...
118|Query evaluation techniques for large databases|Database management systems will continue to manage large data volumes. Thus, efficient algorithms for accessing and manipulating large sets and sequences will be required to provide acceptable performance. The advent of object-oriented and extensible database systems will not solve this problem. On the contrary, modern data models exacerbate it: In order to manipulate large sets of complex objects as efficiently as today’s database systems manipulate simple records, query processing algorithms and software will become more complex, and a solid understanding of algorithm and architectural issues is essential for the designer of database management software. This survey provides a foundation for the design and implementation of query execution facilities in new database management systems. It describes a wide array of practical query evaluation techniques for both relational and post-relational database systems, including iterative execution of complex query evaluation plans, the duality of sort- and hash-based set matching algorithms, types of parallel query execution and their implementation, and special operators for emerging database application domains.
119|Maintenance of Materialized Views: Problems, Techniques, and Applications|In this paper we motivate and describe materialized views, their applications, and the problems  and techniques for their maintenance. We present a taxonomy of view maintenanceproblems  basedupon the class of views considered, upon the resources used to maintain the view, upon the types of modi#cations to the base data that areconsidered during maintenance, and whether the technique works for all instances of databases and modi#cations. We describe some of the view maintenancetechniques proposed in the literature in terms of our taxonomy. Finally, we consider new and promising application domains that are likely to drive work in materialized  views and view maintenance.  1 Introduction  What is a view? A view is a derived relation de#ned in terms of base #stored# relations. A view thus de#nes a function from a set of base tables to a derived table; this function is typically recomputed every time the view is referenced.  What is a materialized view? A view can be materialized by storin...
120|Dataflow query execution in a parallel main-memory environment|Abstract. In this paper, the performance and characteristics of the execution of various join-trees on a parallel DBMS are studied. The results of this study are a step into the direction of the design of a query optimization strategy that is fit for parallel execution of complex queries. Among others, synchronization issues are identified to limit the performance gain from parallelism. A new hash-join algorithm is introduced that has fewer synchronization constraints han the known hash-join algorithms. Also, the behavior of individual join operations in a join-tree is studied in a simulation experiment. The results how that the introduced Pipelining hash-join algorithm yields a better performance for multi-join queries. The format of the optimal join-tree appears to depend on the size of the operands of the join: A multi-join between small operands performs best with a bushy schedule; larger operands are better off with a linear schedule. The results from the simulation study are confirmed with an analytic model for dataflow query execution. Ke~,ords: parallel query processing, multi-join queries, simulation, analytical modeling 1.
121| Ripple Joins for Online Aggregation |We present a new family of join algorithms, called ripple joins, for online processing of multi-table aggregation queries in a relational database management system (dbms). Such queries arise naturally in interactive exploratory decision-support applications. Traditional offline join algorithms are designed to minimize the time to completion of the query. In contrast, ripple joins are designed to minimize the time until an acceptably precise estimate of the query result is available, as measured by the length of a confidence interval. Ripple joins are adaptive, adjusting their behavior during processing in accordance with the statistical properties of the data. Ripple joins also permit the user to dynamically trade off the two key performance factors of online aggregation: the time between successive updates of the running aggregate, and the amount by which the confidence-interval length decreases at each update. We show how ripple joins can be implemented in an existing dbms using iterators, and we give an overview of the methods used to compute confidence intervals and to adaptively optimize the ripple join &#034;aspect-ratio&#034; parameters. In experiments with an initial implementation of our algorithms in the postgres dbms, the time required to produce reasonably precise online estimates was up to two orders of magnitude smaller than the time required for the best offline join algorithms to produce exact answers. 
122|Online Association Rule Mining|We present anovel algorithm to compute large itemsets online. The user is free to change the support threshold any time during the rst scan of the transaction sequence. The algorithm maintains a superset of all large itemsets and for each itemset a shrinking, deterministic interval on its support. After at most 2 scans the algorithm terminates with the precise support for each large itemset. Typically our algorithm is by an order of magnitude more memory e cient than Apriori or DIC. 1
123|Online Data Mining for Co-Evolving Time Sequences|In many applications, the data of interest comprises multiple sequences that evolve over time. Examples include currency exchange rates, network traffic data. We develop a fast method to analyze such co-evolving time sequences  jointly to allow (a) estimation/forecasting of missing /delayed/future values, (b) quantitative data mining,and (c) outlier detection. Our method, MUSCLES, adapts to changing correlations among time sequences. It can handle indefinitely long sequences efficiently using an incremental algorithm and requires only small amount of storage and less I/O operations. To make it scale for a large number of sequences, we present a variation, the Selective MUSCLES method and propose an efficient algorithm to reduce the problem size. Experiments on real datasets show that MUSCLES outperforms popular competitors in prediction accuracy up to 10 times, and discovers interesting correlations. Moreover, Selective MUSCLES scales up very well for large numbers of sequences, reducing response time up to 110 times over MUSCLES, and sometimes even improves the prediction quality.
124|Dynamic Pipeline Scheduling for Improving Interactive Query Performance|Interactive query performance is becoming an  important criterion for online systems where  delivering query results in a timely fashion  is critical. Pipelined execution is a promising  query execution style that can produce  the initial portion of the result early and in  a continuous fashion. In this paper we propose  techniques for delivering results faster in  a pipelined query plan. We distinguish between  two cases. For cases where the tuples  in the query result are of the same importance  we propose a dynamic rate-based  pipeline scheduling policy that produces more  results during the early stages of query execution.
125|An Overview of Real-Time Database Systems|Introduction  Traditionally, real-time systems manage their data (e.g., chamber temperature, aircraft locations) in application-dependent structures. As real-time systems evolve, their applications become more complex and require access to more data. It thus becomes necessary to manage the data in a systematic and organized fashion. Database management systems provide tools for such organization, so in recent years there has been interest in &#034;merging&#034; database and real-time technology. The resulting integrated system, which provides database operations with real-time constraints, is generally called a real-time database system (RTDBS) [1]. Like a conventional database system, a RTDBS functions as a repository of data, provides efficient storage, and performs retrieval and manipulation of information. However, as a part of a real-time system, whose &#034;tasks&#034; are associated with time constraints, a RTDBS has the added burden of ensuring some degree of 1  This chapte
126|Fast Algorithms for Mining Association Rules|We consider the problem of discovering association rules between items in a large database of sales transactions. We present two new algorithms for solving this problem that are fundamentally different from the known algorithms. Empirical evaluation shows that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. We also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called AprioriHybrid. Scale-up experiments show that AprioriHybrid scales linearly with the number of transactions. AprioriHybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database. 
127|Term-weighting approaches in automatic text retrieval|The experimental evidence accumulated over the past 20 years indicates that text indexing systems based on the assignment of appropriately weighted single terms produce retrieval results that are superior to those obtainable with other more elaborate text representations. These results depend crucially on the choice of effective term-weighting systems. This article summarizes the insights gained in automatic term weighting, and provides baseline single-term-indexing models with which other more elaborate content analysis procedures can be compared.  
128|Mining Frequent Patterns  without Candidate Generation: A Frequent-Pattern Tree Approach|Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist a large number of patterns and/or long patterns. In this study,  we propose a novel
frequent-pattern tree
(FP-tree) structure, which is an extended prefix-tree
structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-
based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth.
Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a condensed,
smaller data structure, FP-tree which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts
a pattern-fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a
partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for
mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance
study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns,
and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported
new frequent-pattern mining methods
129|An efficient algorithm for mining association rules in large databases|Mining for a.ssociation rules between items in a large database of sales transactions has been described as an important database mining problem. In this paper we present an effi-cient algorithm for mining association rules that is fundamentally different from known al-gorithms. Compared to previous algorithms, our algorithm not only reduces the I/O over-head significantly but also has lower CPU overhead for most cases. We have performed extensive experiments and compared the per-formance of our algorithm with one of the best existing algorithms. It was found that for large databases, the CPU overhead was re-duced by as much as a factor of four and I/O was reduced by almost an order of magnitude. Hence this algorithm is especially suitable for very large size databases. 1
130|Bottom-up computation of sparse and Iceberg CUBE|We introduce the Iceberg-CUBE problem as a reformulation of the datacube (CUBE) problem. The Iceberg-CUBE problem is to compute only those group-by partitions with an aggregate value (e.g., count) above some minimum support threshold. The result of Iceberg-CUBE can be used (1) to answer group-by queries with a clause such as HAVING COUNT(*)&gt; = X, where X is greater than the threshold, (2) for mining multidimensional association rules, and (3) to complement existing strategies for identifying interesting subsets of the CUBE for precomputation. We present a new algorithm (BUC) for Iceberg-CUBE computation. BUC builds the CUBE bottom-up; i.e., it builds the CUBE by starting from a group-by on a single attribute, then a group-by on a pair of attributes, then a group-by on three attributes, and so on. This is the opposite of all techniques proposed earlier for computing the CUBE, and has an important practical advantage: BUC avoids computing the larger group-bys that do not meet minimum support. The pruning in BUC is similar to the pruning in the Apriori algorithm for association rules, except that BUC trades some pruning for locality of reference and reduced memory requirements. BUC uses the same pruning strategy when computing sparse, complete CUBES. We present a thorough performance evaluation over a broad range of workloads. Our evaluation demonstrates that (in contrast to earlier assumptions) minimizing the aggregations or the number of sorts is not the most important aspect of the sparse CUBE problem. The pruning in BUC, combined with an efficient sort method, enables BUC to outperform all previous algorithms for sparse CUBES, even for computing entire CUBES, and to dramatically improve Iceberg-CUBE computation. 1
131|WebBase : A repository of web pages|In this paper, we study the problem of constructing and maintaining a large shared repository of web pages. We discuss the unique characteristics of such a repository, propose an architecture, and identify its functional modules. We focus on the storage manager module, and illustrate how traditional techniques for storage and indexing can be tailored to meet the requirements of a web repository. To evaluate design alternatives, we also present experimental results from a prototype repository called WebBase, that is currently being developed at Stanford University.
132|A Framework for Clustering Evolving Data Streams|The clustering problem is a difficult problem for the data stream domain. This is because the large volumes of data arriving in a stream renders most traditional algorithms too inefficient. In recent years, a...
133|Efficient and Effective Clustering Methods for Spatial Data Mining|Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. In this paper, we explore whether clustering methods have a role to play in spatial data mining. To this end, we develop a new clustering method called CLARANS which is based on randomized search. We also de- velop two spatial data mining algorithms that use CLARANS. Our analysis and experiments show that with the assistance of CLARANS, these two algorithms are very effective and can lead to discoveries that are difficult to find with current spatial data mining algorithms.
134|Scaling Clustering Algorithms to Large Databases|Practical clustering algorithms require multiple data scans to achieve convergence. For large databases, these scans become prohibitively expensive. We present a scalable clustering framework applicable to a wide class of iterative clustering. We require at most one scan of the database. In this work, the framework is instantiated and numerically justified with the popular K-Means clustering algorithm. The method is based on identifying regions of the data that are compressible, regions that must be maintained in memory, and regions that are discardable. The algorithm operates within the confines of a limited memory buffer. Empirical results demonstrate that the scalable scheme outperforms a sampling-based approach. In our scheme, data resolution is preserved to the extent possible based upon the size of the allocated memory buffer and the fit of current clustering model to the data. The framework is naturally extended to update multiple clustering models simultaneously. We empirically evaluate on synthetic and publicly available data sets.
135|A Framework for Diagnosing Changes in Evolving Data Streams|In recent years, the progress in hardware technology has made it possible for organizations to store and record large streams of transactional data. This results in databases which grow without limit at a rapid rate. This data can often show important changes in trends over time. In such cases, it is useful to understand, visualize and diagnose the evolution of these trends. When the data streams are fast and continuous, it becomes important to analyze and predict the trends quickly in online fashion. In this paper, we discuss the concept of velocity density estimation, a technique used to understand, visualize and determine trends in the evolution of fast data streams. We show how to use velocity density estimation in order to create both temporal velocity profiles and spatial velocity profiles at periodic instants in time. These profiles are then used in order to predict three kinds of data evolution: dissolution, coagulation and shift. Methods are proposed to visualize the changing data trends in a single online scan of the data stream, and a computational requirement which is linear in the number of data points. In addition, batch processing techniques are proposed in order to identify combinations of dimensions which show the greatest amount of global evolution. The techniques discussed in this paper can be easily extended to spatio-temporal data, changes in data snapshots at fixed instances in time, or any other data which has a temporal component during its evolution.
136|Learning in the Presence of Concept Drift and Hidden Contexts|. On-line learning in domains where the target concept depends on some hidden context poses serious problems. A changing context can induce changes in the target concepts, producing what is known as concept drift. We describe a family of learning algorithms that flexibly react to concept drift and can take advantage of situations where contexts reappear. The general approach underlying all these algorithms consists of (1) keeping only a window of currently trusted examples and hypotheses; (2) storing concept descriptions and re-using them when a previous context reappears; and (3) controlling both of these functions by a heuristic that constantly monitors the system&#039;s behavior. The paper reports on experiments that test the systems&#039; performance under various conditions such as different levels of noise and different extent and rate of concept drift.  Keywords: Incremental concept learning, on-line learning, context dependence, concept drift, forgetting  1. Introduction  The work presen...
137|Maintenance of Discovered Association Rules in Large Databases: An Incremental Updating Technique|An incremental updating technique is developed for maintenance of the association rules discovered by database mining. There have been many studies on efficient discovery of association rules in large databases. However, it is nontrivial to maintain such discovered rules in large databases because a database may allow frequent or occasional updates and such updates may not only invalidate some existing strong association rules but also turn some weak rules into strong ones. In this study, an incremental updating technique is proposed for efficient maintenance of dis- covered association rules when new transaction data are added to a transaction database.
138|Activity Monitoring: Noticing interesting changes in behavior|We introduce a problem class which we term activity monitoring. Such problems involve monitoring the behavior of a large population of entities for interesting events requiring action. We present a framework within which each of the individual problems has a natural expression, as well as a methodology for evaluating performance of activity monitoring techniques. We show that two superficially different tasks, news story monitoring and intrusion detection, can be expressed naturally within the framework, and show that key differences in solution methods can be compared.  1 Introduction  In this paper we introduce a problem class which we term activity monitoring. Such problems typically involve monitoring the behavior of a large population of entities for interesting events requiring action. Examples include the tasks of fraud detection, computer intrusion detection, network performance monitoring, crisis monitoring, some forms of fault detection, and news story monitoring. These appli...
139|DEMON: Mining and Monitoring Evolving Data|Data mining algorithms have been the focus of much research recently. In practice, the input data to  a data mining process resides in a large data warehouse whose data is kept up-to-date through periodic  or occasional addition and deletion of blocks of data. Most data mining algorithms have either assumed  that the input data is static, or have been designed for arbitrary insertions and deletions of data records.
140|Mining Surprising Patterns Using Temporal Description Length|We propose a new notion of surprising temporal patterns in market basket data, and algorithms to find such patterns. This is distinct from finding frequent patterns as addressed in the common mining literature. We argue that once the analyst is already familiar with prevalent patterns in the data, the greatest incremental benefit is likely to be from changes in the relationship between item frequencies over time.  A simple measure of surprise is the extent of departure from a model, estimated using standard multivariate time series analysis. Unfortunately, such estimation involves models, smoothing windows and parameters whose optimal choices can vary dramatically from one application to another. In contrast, we propose a precise characterization of surprise based on the number of bits in which a basket sequence can be encoded under a carefully chosen coding scheme. In this scheme it is inexpensive to encode sequences of itemsets that have steady, hence likely to be well-known, correla...
141| 	 Active Data Mining   |We introduce an active data mining paradigm that combines the recent work in data mining with the rich literature on active database systems. In this paradigm, data is continuously mined at a desired frequency. As rules are discovered, they are added to a rulebase, and if they already exist, the history of the statistical parameters associated with the rules is updated. When the history starts exhibiting certain trends, specified as shape queries in the user-speci ed triggers, the triggers are red and appropriate actions are initiated. To be able to specify shape queries, we describe the constructs for de ning shapes, and discuss how the shape predicates are used in a query construct to retrieve rules whose histories exhibit the desired trends. We describe how this query capability is integrated into a trigger system to realize an active mining system. The system presented here has been validated using two sets of customer data.
142|Density-adaptive learning and forgetting|We describe a density-adaptive reinforcement learning and a density-adaptive forgetting algorithm. This learning algorithm uses hybrid k-D/2k-trees to allow foravariable resolution partitioning and labelling of the input space. The density adaptive forgetting algorithm deletes observations from the learning set depending on whether subsequent evidence is available in a local region of the parameter space. The algorithms are demonstrated in a simulation for learning feasible robotic grasp approach directions and orientations and then adapting to subsequent mechanical failures in the gripper. 1
143|Learning Changing Concepts by Exploiting the Structure of Change|This paper examines learning problems in which the target function is allowed to change. The learner sees a sequence of random examples, labelled according to a sequence of functions, and must provide an accurate estimate of the target function sequence. We consider a variety of restrictions on how the target function is allowed to change, including infrequent but arbitrary changes, sequences that correspond to slow walks on a graph whose nodes are functions, and changes that are small on average, as measured by the probability of disagreements between consecutive functions. We first study estimation, in which the learner sees a batch of examples and is then required to give an accurate estimate of the function sequence. Our results provide bounds on the sample complexity and allowable drift rate for these problems. We also study prediction, in which the learner must produce online a hypothesis after each labelled example and the average misclassification probability over this hypothes...
145|A constant-factor approximation algorithm for the k-median problem|We present the first constant-factor approximation algorithm for the metric k-median problem. The k-median problem is one of the most well-studied clustering problems, i.e., those problems in which the aim is to partition a given set of points into clusters so that the points within a cluster are relatively close with respect to some measure. For the metric k-median problem, we are given n points in a metric space. We select k of these to be cluster centers, and then assign each point to its closest selected center. If point j is assigned to a center i, the cost incurred is proportional to the distance between i and j. The goal is to select the k centers that minimize the sum of the assignment costs. We give a 6 2 3-approximation algorithm for this problem. This improves upon the best previously known result of O(log k log log k), which was obtained by refining and derandomizing a randomized O(log n log log n)-approximation algorithm of Bartal. 1
146|Improved Combinatorial Algorithms for the Facility Location and k-Median Problems|We present improved combinatorial approximation algorithms for the uncapacitated facility location and k-median problems. Two central ideas in most of our results are cost scaling and greedy improvement. We present a simple greedy local search algorithm which achieves an approximation ratio of 2:414 +  in ~ O(n 2 =) time. This also yields a bicriteria approximation tradeoff of (1 +; 1+ 2=) for facility cost versus service cost which is better than previously known tradeoffs and close to the best possible. Combining greedy improvement and cost scaling with a recent primal dual algorithm for facility location due to Jain and Vazirani, we get an approximation ratio of 1.853 in ~ O(n 3 ) time. This is already very close to the approximation guarantee of the best known algorithm which is LP-based. Further, combined with the best known LP-based algorithm for facility location, we get a very slight improvement in the approximation factor for facility location, achieving 1.728....
147|Incremental Clustering and Dynamic Information Retrieval|Motivated by applications such as document and image classification in information retrieval, we consider the problem of clustering dynamic point sets in a metric space. We propose a model called incremental clustering which is based on a careful analysis of the requirements of the information retrieval application, and which should also be useful in other applications. The goal is to efficiently maintain clusters of small diameter as new points are inserted. We analyze several natural greedy algorithms and demonstrate that they perform poorly. We propose new deterministic and randomized incremental clustering algorithms which have a provably good performance. We complement our positive results with lower bounds on the performance of incremental algorithms. Finally, we consider the dual clustering problem where the clusters are of fixed diameter, and the goal is to minimize the number of clusters.  
148|Analysis of a local search heuristic for facility location problems|In this paper, we study approximation algorithms for several NP-hard facility location problems. We prove that a simple local search heuristic yields polynomial-time constant-factor approximation bounds for the metric versions of the uncapacitated k-median problem and the uncapacitated facility location problem. (For the k-median problem, our algorithms require a constant-factor blowup in the parameter k.) This local search heuristic was rst proposed several decades ago, and has been shown to exhibit good practical performance in empirical studies. We also extend the above results to obtain constant-factor approximation bounds for the metric versions of capacitated k-median and facility location problems.  
149|A Constant-Factor Approximation Algorithm for the Multicommodity Rent-or-Buy Problem |... Recent work on buy-at-bulk network design has concentrated on the special case where all sinks are identical; existing constant-factor approximation algorithms for this special case make crucial use of the assumption that all commodities ship flow to the same sink vertex and do not obviously extend to the multicommodity rent-or-buy problem. Prior to our work, the best heuristics for the multi-commodity rent-or-buy problem achieved only logarithmic performance guarantees and relied on the machinery of relaxed metrical task systems or of metric embeddings. By contrast, we solve the network design problem directly via a novel primal-dual algorithm.
150|Sublinear Time Algorithms for Metric Space Problems|In this paper we give approximation algorithms for the following problems on metric spaces: Furthest Pair, k-  median, Minimum Routing Cost Spanning Tree, Multiple Sequence Alignment, Maximum Traveling Salesman Problem, Maximum Spanning Tree and Average Distance. The key property of our algorithms is that their running time is linear in the number of metric space points. As the full specification o`f an n-point metric space is of size \Theta(n  2  ), the complexity of our algorithms is sublinear with respect to the input size. All previous algorithms (exact or approximate) for the problems we consider have running time\Omega\Gamma  n  2  ). We believe that our techniques can be applied to get similar bounds for other problems.  1 Introduction  In recent years there has been a dramatic growth of interest in algorithms operating on massive data sets. This poses new challenges for algorithm design, as algorithms quite efficient on small inputs (for example, having quadratic running time) ...
151|Randomized Query Processing in Robot Path Planning (Extended Abstract)  (1995) |The subject of this paper is the analysis of a randomized preprocessing scheme that has been used for query processing in robot path planning. The attractiveness of the scheme stems from its general applicability to virtually any path-planning problem, and its empirically observed success. In this paper we initiate a theoretical basis for explaining this empirical success. Under a simple assumption about the configuration space, we show that it is possible to perform preprocessing following which queries can be answered quickly. En route, we consider related problems on graph connectivity in the evasiveness model, and art-gallery theorems.
152|On the Hardness of Approximating MAX k-CUT and its Dual|We study the Max k-Cut problem and its dual, the Min k-Partition problem: given G = (V; E) and w : E ! R  +  , find an edge set of minimum weight whose removal makes  G k-colorable. For the Max k-Cut problem we show that, if P 6= NP, no polynomial time approximation algorithm can achieve a relative error of 1=oek, where oe = 132. This should be compared to the well-known fact that a naive randomized heuristics delivers approximations whose relative error is 1=k. For the Min k-Partition problem, we show that for k ? 2 and for every ffl ? 0, there exists a constant ff such that the problem cannot be approximated within ffjV j  2\Gammaffl  , even for dense graphs. Both problems are directly related to the frequency allocation problem for cellular (mobile) telephones, an industrial application of increasing relevance. 
153|An improved data stream summary: The Count-Min sketch and its applications|Abstract. We introduce a new sublinear space data structure—the Count-Min Sketch — for summarizing data streams. Our sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly; in addition, it can be applied to solve several important problems in data streams such as finding quantiles, frequent items, etc. The time and space bounds we show for using the CM sketch to solve these problems significantly improve those previously known — typically from 1/e 2 to 1/e in factor. 1
154|Counting Distinct Elements in a Data Stream|We present three algorithms to count the number of distinct elements in a data stream to within a factor of 1 &amp;plusmn; epsilon. Our algorithms improve upon known algorithms for this problem, and offer a spectrum of time/space tradeoffs.
155|What&#039;s New: Finding Significant Differences in Network Data Streams|Monitoring and analyzing network traffic usage patterns is vital for managing IP Networks. An important problem is to provide network managers with information about changes in traffic, informing them about &#034;what&#039;s new&#034;. Specifically, we focus on the challenge of finding significantly large differences in traffic: over time, between interfaces and between routers. We introduce the idea of a deltoid: an item that has a large difference, whether the difference is absolute, relative or variational. We present novel...
156|Optimal space lower bounds for all frequency moments|Abstract We prove that any one-pass streaming algorithm which (ffl, ffi)-approximates the kth frequency moment Fk, for any real k 6 = 1 and any ffl = \Omega i 1pm j, must use \Omega \Gamma 1ffl2 \Delta bits of space, where m is the size of the universe. This is optimal in terms of ffl, resolves the open questions of BarYossef et al in [3, 4], and extends the \Omega \Gamma 1ffl2 \Delta lower bound for F0 in [11] to much smaller ffl by applying novel techniques. Along the way we lower bound the one-way communication complexity of approximating the Hamming distance and the number of bipartite graphs with minimum/maximum degree constraints. 1 Introduction Computing statistics on massive data sets is increasinglyimportant these days. Advances in communication and storage technology enable large bodies of raw datato be generated daily, and consequently, there is a rising demand to process this data efficiently. Sinceit is impractical for an algorithm to store even a small fraction of the data stream, its performance istypically measured by the amount of space it uses. In many scenarios, such as internet routing, once a streamelement is examined it is lost forever unless explicitly saved by the processing algorithm. This, along with thesheer size of the data, makes multiple passes over the data infeasible. In this paper we restrict our attention toone-pass streaming algorithms and we investigate their space complexity.Let a =
157|Finding hierarchical heavy hitters in data streams|Aggregation along hierarchies is a critical summary technique in a large variety of online applications including decision support, and network management (e.g., IP clustering, denial-of-service attack monitoring). Despite the amount of recent study that has been dedicated to online aggregation on sets (e.g., quantiles, hot items), surprisingly little attention has been paid to summarizing hierarchical structure in stream data. The problem we study in this paper is that of finding Hierarchical Heavy Hitters (HHH): given a hierarchy and a fraction f, we want to find all HHH nodes that have a total number of descendants in the data stream larger than f of the total number of elements in the data stream, after discounting the descendant nodes that are HHH nodes. The resulting summary gives a topological “cartogram ” of the hierarchical data. We present deterministic and randomized algorithms for finding HHHs, which builds upon existing techniques by incorporating the hierarchy into the algorithms. Our experiments demonstrate several factors of improvement in accuracy over
158|Detecting Change in Data Streams|Detecting changes in a data stream is an important  area of research with many applications.
159|Testing that distributions are close|Given two distributions over an n element set, we wish to check whether these distributions are statistically close by only sampling. We give a sublinear algorithm which uses O(n 2/3 ? -4 log n) independent samples from each distribution, runs in time linear in the sample size, makes no assumptions about the structure of the distributions, and distinguishes the cases ? when the distance between the distributions is small (less than max ( 2 32 3 v n, ? 4 v)) or large (more n than ?) in L1-distance. We also give an ?(n 2/3 ? -2/3) lower bound. Our algorithm has applications to the problem of checking whether a given Markov process is rapidly mixing. We develop sublinear algorithms for this problem as well.
160|A result of vapnik with applications|A new proof of a result due to Vapnik is given. Its implications for the theory of PAC learnability are discussed, with particular reference to the learnability of functions taking values in a countable set. An application to the theory of artificial neural networks is then given. 1 1
161|Aurora: a new model and architecture for data stream management|This paper describes the basic processing model and architecture of Aurora, a new system to manage data streams for monitoring applications. Monitoring applications differ substantially from conventional business data processing. The fact that a software system must process and react to continual inputs from many sources (e.g., sensors) rather than from human operators requires one to rethink the fundamental architecture of a DBMS for this application area. In this paper, we present Aurora, a new DBMS currently under construction at Brandeis University, Brown University, and M.I.T. We first provide an overview of the basic Aurora model and architecture and then describe in detail a stream-oriented set of operators.
162|The Design, Implementation and Evaluation of SMART: A Scheduler for Multimedia Applications|This paper argues for the need to design a new processor scheduling algorithm that can handle the mix of applications we see today. We present a scheduling algorithm which we have implemented in the Solaris UNIX operating system [Eykholt et al. 1992], and demonstrate its improved performance over existing schedulers in research and practice on real applications. In particular, we have quantitatively compared against the popular weighted fair queueing and UNIX SVR4 schedulers in supporting multimedia applications in a realistic workstation environment...
163|Main memory database systems: An overview|Abstract-Memory resident database systems (MMDB’s) store their data in main physical memory and provide very high-speed access. Conventional database systems are optimized for the particular characteristics of disk storage mechanisms. Memory resident systems, on the other hand, use different optimizations to structure and organize data, as well as to make it reliable. This paper surveys the major memory residence optimizations and briefly discusses some of the memory resident systems that have been designed or implemented. Index Terms- Access methods, application programming in-terface, commit processing, concurrency control, data clustering, data representation, main memory database system (MMDB), query processing, recovery. Invited Paper I.
164|Temporal and Real-Time Databases: A Survey|A temporal database contains time-varying data. In a real-time database transactions have deadlines or timing constraints. In this paper we review the substantial research in these two heretofore separate research areas. We first characterize the time domain, then investigate temporal and real-time data models. We evaluate temporal and real-time query languages along several dimensions. Temporal and real-time DBMS implementation is examined. We conclude with a summary of the major accomplishments of the research to date, and list several research questions that should be addressed next. Keywords: object-oriented database, relational databases, query language, temporal data model, time-constrained database, transaction time, user-defined time, valid time 1 Introduction  Time is an important aspect of all real-world phenomena. Events occur at specific points in time; objects and the relationships among objects exist over time. The ability to model this temporal dimension of the real worl...
165|Active Database Systems|, Exception, Clock, Externalg Granularity ae fMember, Subset, Setg Type ae fPrimitive, Composite g Operators ae for, and, seq, closure, times, not g Consumption mode ae fRecent, Chronicle, Cumulative, Continuous g Role 2 fMandatory, Optional, Noneg Condition Role 2 fMandatory, Optional, Noneg Context ae fDB T , BindE , DBE , DBC g Action Options ae fStructure Operation, Behavior Invocation, Update-Rules, Abort Inform, External, Do Instead g Context ae fDB T , BindE , BindC , DBE , DBC , DBA g ---behavior invocation, in which case the event is raised by the execution of some user-defined operation (e.g. the message display is sent to an object of type widget). It is common for event languages to allow events to be raised before or after an operation has been executed. ---transaction, in which case the event is raised by transaction commands (e.g. abort, commit, begin-transaction) ---abstract or user-defined, in which case a programming mechanism is used that allows an appli...
166|Query Processing, Approximation, and Resource Management In a Data Stream Management System|This paper describes our ongoing work developing the Stanford Stream Data Manager (STREAM), a system for executing continuous queries over multiple continuous data streams. The STREAM system supports a declarative query language, and it copes with high data rates and query workloads by providing approximate answers when resources are limited. This paper describes specific contributions made so far and enumerates our next steps in developing a general-purpose Data Stream Management System.
168|Lore: A database management system for semistructured data|Lore (for Lightweight Object Repository) is a DBMS designed specifically for managing semistructured information. Implementing Lore has required rethinking all aspects of a DBMS, including storage management, indexing, query processing and optimization, and user interfaces. This paper provides an overview of these aspects of the Lore system, as well as other novel features such as dynamic structural summaries and seamless access to data from external sources. 
169|Improved Histograms for Selectivity Estimation of Range Predicates|Many commercial database systems maintain histograms to summarize the contents of relations and permit efficient estimation of query result sizes and access plan costs. Although several types of histograms have been proposed in the past, there has never been a systematic study of all histogram aspects, the available choices for each aspect, and the impact of such choices on histogram effectiveness. In this paper, we provide a taxonomy of histograms that captures all previously proposed histogram types and indicates many new possibilities. We introduce novel choices for several of the taxonomy dimensions, and derive new histogram types by combining choices in effective ways. We also show how sampling techniques can be used to reduce the cost of histogram construction. Finally, we present results from an empirical study of the proposed histogram types used in selectivity estimation of range predicates and identify the histogram types that have the best overall performance. 1 Introduction...
170|Querying the World Wide Web|The World Wide Web is a large, heterogeneous, distributed collection of documents connected by hypertext links. The most common technology currently used for searching the Web depends on sending information retrieval requests to &#034;index servers&#034; that index as many documents as they can find by navigating the network. One problem with this is that users must be aware of the various index servers (over a dozen of them are currently deployed on the Web), of their strengths and weaknesses, and of the peculiarities of their query interfaces. A more serious problem is that these queries cannot exploit the structure and topology of the document network. In this paper we propose a query language, WebSQL, that takes advantage of multiple index servers without requiring users to know about them, and that integrates textual retrieval with structure and topology-based queries. We give a formal semantics for WebSQL using a calculus based on a novel &#034;virtual graph&#034; model of a document network. We propose a new theory of query cost based on the idea of &#034;query locality,&#034; that is, how much of the network must be visited to answer a particular query. We give an algorithm for characterizing WebSQL queries with respect to query locality. Finally, we describe a prototype implementation of WebSQL written in Java.
172|Applications of a Web Query Language|In this paper we report on our experience using WebSQL, a high level declarative query language for extracting information from the Web. WebSQL takes advantage of multiple index servers without requiring users to know about them, and integrates full-text with topology-based queries. The WebSQL query engine is a library of Java classes, and WebSQL queries can be embedded into Java programs much in the same way as SQL queries are embedded in C programs. This allows us to access the Web from Java at a much higher level of abstraction than bare HTTP requests. We illustrate the use of WebSQL for application development by describing two applications we are experimenting with: Web site maintenance and specialized index construction. We also sketch several other possible applications. Using the library, we have also implemented a client-server architecture that allows us to perform interactive intelligent searches on the Web from an applet running on a browser. 1 Introduction  Developing data...
173|Making Commitments in the Face of Uncertainty: How to Pick a Winner Almost Every Time (Extended Abstract)  (1996) |In this paper, we formulate and provide optimal solutions for a broad class of problems in which a decision-maker is required to select from among numerous competing options. The goal of the decision-maker is to select the option that will have the best future performance. This task is made difficult by the constraint that the decision-maker has no way to predict the future performance of any of the options. Somewhat surprisingly, we find that the decision-maker can still (at least in several important scenarios) pick a winner with high probability. Our result has several applications. For example, consider the problem of scheduling background jobs on a network of workstations (NOW) when very little is known about the future speed or availability of each workstation. In this problem, the goal is to schedule each job on a workstation which will have enough idle capacity to complete the job within a reasonable or ...
174|A One-Pass Algorithm for Accurately Estimating Quantiles for Disk-Resident Data|The &#039;-quantile of an ordered sequence of data values is the element with rank &#039; \Theta n, where  n is the total number of values. Accurate estimates of quantiles are required for the solution of many practical applications. In this paper, we present a new algorithm for estimating the quantile values for disk-resident data. Our algorithm has the following characteristics: (1) It requires only one pass over the data; (2) It is deterministic; (3) It produces good lower and upper bounds of the true values of the quantiles; (4) It requires no a priori knowledge of the distribution of the data set; (5) It has a scalable parallel formulation; (6) Extra time and memory for computing additional quantiles (beyond the first one) is constant per quantile. We present experimental results on the IBM SP-2. The experimental results show that the algorithm is indeed robust and does not depend on the distribution of the data sets.   A large part of this work was done while Khaled Alsabti and Vineet Sing...
175|A One-Pass Space-Efficient Algorithm for Finding Quantiles|We present an algorithm for finding the quantile values of a large unordered dataset with unknown distribution. The algorithm has the following features: i) it requires only one pass over the data; ii) it is space efficient -- it uses a small bounded amount of memory independent of the number of values in the dataset; and iii) the true quantile is guaranteed to lie within the lower and upper bounds produced by the algorithm. Empirical evaluation using synthetic data with various distributions as well as real data show that the bounds obtained are quite tight. The algorithm has several applications in database systems, for example in database governors, query optimization, load balancing in multiprocessor database systems, and data mining.
176|Online Processing Redux|The term &#034;online&#034; has become an all-too-common addendum to database system names of the day. In this article we reexamine the notion of processing queries online. We distinguish between online processing and preprocessing, and argue that online processing for large queries requires redesigning major portions of a database system. We highlight pressing applications for truly online processing, and sketch ongoing research in these applications at Berkeley. We also outline basic techniques for running long queries online. We close by reevaluating the typical measurements of cost/performance for online systems, and propose a mass-market approach for designing and measuring data-intensive processing. 1 Introduction  In the parlance of today&#039;s database systems, &#034;online&#034; signifies &#034;interactive&#034;, &#034;within the bounds of patience.&#034; Online processing is the opposite of &#034;batch&#034; processing. In the dark days of computing, all serious work was done in batch mode --- the COBOL or FORTRAN programmer sub...
177|Issues in Data Stream Management|Traditional databases store sets of relatively static records with no pre-defined notion of time, unless timestamp attributes are explicitly added. While this model adequately represents commercial catalogues or repositories of personal information, many current and emerging applications require support for online analysis of rapidly changing data streams. Limitations of traditional DBMSs in supporting streaming applications have been recognized, prompting research to augment existing technologies and build new systems to manage streaming data. The purpose of this paper is to review recent work in data stream management systems, with an emphasis on application requirements, data models, continuous query languages, and query evaluation.
179|The design of an acquisitional query processor for sensor networks|We discuss the design of an acquisitional query processor for data collection in sensor networks. Acquisitional issues are those that pertain to where, when, and how often data is physically acquired (sampled) and delivered to query processing operators. By focusing on the locations and costs of acquiring data, we are able to significantly reduce power consumption over traditional passive systems that assume the a priori existence of data. We discuss simple extensions to SQL for controlling data acquisition, and show how acquisitional issues influence query optimization, dissemination, and execution. We evaluate these issues in the context of TinyDB, a distributed query processor for smart sensor devices, and show how acquisitional techniques can provide significant reductions in power consumption on our sensor devices. 1.
180|TelegraphCQ: Continuous Dataflow Processing for an Uncertan World|Increasingly pervasive networks are leading towards a world where data is constantly in motion. In such a world, conventional techniques for query processing, which were developed under the assumption of a far more static and predictable computational environment, will not be sufficient. Instead, query processors based on adaptive dataflow will be necessary. The Telegraph project has developed a suite of novel technologies for continuously adaptive query processing. The next generation Telegraph system, called TelegraphCQ, is focused on meeting the challenges that arise in handling large streams of continuous queries over high-volume, highly-variable data streams. In this paper, we describe the system architecture and its underlying technology, and report on our ongoing implementation effort, which leverages the PostgreSQL open source code base. We also discuss open issues and our research agenda.
181|Query Processing for Sensor Networks|Hardware for sensor nodes that combine physical sensors, actuators, embedded processors, and communication components has advanced significantly over the last decade, and made the large-scale deployment of such sensors a reality. Applications range from monitoring applications such as inventory maintenance over health care to military applications.
182|Adaptive Filters for Continuous Queries over Distributed Data Streams|We consider an environment where distributed  data sources continuously stream updates to a  centralized processor that monitors continuous  queries over the distributed data. Significant communication  overhead is incurred in the presence of  rapid update streams, and we propose a new technique  for reducing the overhead. Users register  continuous queries with precision requirements at  the central stream processor, which installs filters  at remote data sources. The filters adapt to changing  conditions to minimize stream rates while  guaranteeing that all continuous queries still receive  the updates necessary to provide answers of  adequate precision at all times. Our approach enables  applications to trade precision for communication  overhead at a fine granularity by individually  adjusting the precision constraints of continuous  queries over streams in a multi-query workload.
183|Supporting Aggregate Queries over Ad-Hoc Wireless Sensor Networks|We show how the database community&#039;s notion of a generic query interface for data aggregation can be applied to ad-hoc networks of sensor devices. As has been noted in the sensor network literature, aggregation is important as a data-reduction tool; networking approaches, however, have focused on application specific solutions, whereas our innetwork aggregation approach is driven by a general purpose, SQL-style interface that can execute queries over any type of sensor data while providing opportunities for significant optimization. We present a variety of techniques to improve the reliability and performance of our solution. We also show how grouped aggregates can be efficiently computed and offer a comparison to related systems and database projects.
184|Frequency estimation of internet packet streams with limited space| We consider a router on the Internet analyzing the statistical properties of a TCP/IP packet stream. A fundamental difficulty with measuring traffic behavior on the Internet is that there is simply too much data to be recorded for later analysis, on the order of gigabytes a second. As a result, network routers can collect only relatively few statistics about the data. The central problem addressed here is to use the limited memory of routers to determine essential features of the network traffic stream. A particularly difficult and representative subproblem is to determine the top k categories to which the most packets belong, for a desired value of k and for a given notion of categorization such as the destination IP address. We present an algorithm that deterministically finds (in particular) all categories having a frequency above 1/(m + 1) using m counters, which we prove is best possible in the worst case. We also present a sampling-based algorithm for the case that packet categories follow an arbitrary distribution, but their order over time is permuted uniformly at random. Under this model, our algorithm identifies flows above a frequency threshold of roughly 1 /  v nm with high probability, where m is the number of counters and n is the number of packets observed. This guarantee is not far off from the ideal of identifying all flows (probability 1/n), and we prove that it is best possible up to a logarithmic factor. We show that the algorithm ranks the identified flows according to frequency within any desired constant factor of accuracy. 
185|Streaming Queries over Streaming Data|Recent work on querying data streams has focused  on systems where newly arriving data is  processed and continuously streamed to the user  in real-time. In many emerging applications, however,  ad hoc queries and/or intermittent connectivity  also require the processing of data that arrives  prior to query submission or during a period of  disconnection. For such applications, we have developed  PSoup, a system that combines the processing  of ad-hoc and continuous queries by treating  data and queries symmetrically, allowing new  queries to be applied to old data and new data to  be applied to old queries. PSoup also supports intermittent  connectivity by separating the computation  of query results from the delivery of those  results. PSoup builds on adaptive query processing  techniques developed in the Telegraph project  at UC Berkeley. In this paper, we describe PSoup  and present experiments that demonstrate the effectiveness  of our approach.
186|Multi-Dimensional Regression Analysis of Time-Series Data Streams|Real-time production systems and other dynamic environments often generate tremendous (potentially infinite) amount of stream data; the volume of data is too huge to be stored on disks or scanned multiple times. Can we perform on-line, multi-dimensional analysis and data mining of such data to alert people about dramatic changes of situations and to initiate timely, high-quality responses? This is a challenging task. In this paper,
187|Processing sliding window multi-joins in continuous queries over data streams|We study sliding window multi-join processing in continuous queries over data streams. Several algorithms are reported for performing continuous, incremental joins, under the assumption that all the sliding windows fit in main memory. The algorithms include multiway incremental nested loop joins (NLJs) and multi-way incremental hash joins. We also propose join ordering heuristics to minimize the processing cost per unit time. We test a possible implementation of these algorithms and show that, as expected, hash joins are faster than NLJs for performing equi-joins, and that the overall processing cost is influenced by the strategies used to remove expired tuples from the sliding windows. 1
188|Maintaining Variance and k-Medians over Data Stream Windows|The sliding window model is useful for discounting stale data in data stream applications. In this model, data elements arrive continually and only the most recent N elements are used when answering queries. We present a novel technique for solving two important and related problems in the sliding window model --- maintaining variance and maintaining a k-- median clustering. Our solution to the problem of maintaining variance provides a continually updated estimate of the variance of the last N values in a data stream with relative error of at most # using O(    # 2 log N) memory. We present a constant-factor approximation algorithm which maintains an approximate k--median solution for the last N data points using O(      N) memory, where # &lt; 1/2 is a parameter which trades o# the space bound with the approximation factor of O(2    ).
189|Tribeca: A System for Managing Large Databases of Network Traffic|The engineers who analyze traffic on high bandwidth networks must filter and aggregate either recorded traces of network packets or live traffic from the network itself. These engineers perform operations similar to database queries, but cannot use conventional data managers because of performance concerns and a semantic mismatch between the analysis operations and the operations supported by commercial DBMSs. Traffic analysis does not require fast random access, transactional update, or relational joins. Rather, it needs fast sequential access to a stream of traffic records and the ability to filter, aggregate, define windows, demultiplex, and remultiplex the stream. Tribeca is an extensible, stream-oriented DBMS designed to support network traffic analysis. It combines ideas from temporal and sequence databases with an implementation optimized for databases stored on high speed ID-1 tapes or arriving in real time from the network. The paper describes Tribeca&#039;s query language, executo...
190|Chain: Operator Scheduling for Memory Minimization in Data Stream Systems|In many applications involving continuous data streams, data arrival is bursty and data rate fluctuates over time. Systems that seek to give rapid or real-time query responses in such an environment must be prepared to deal gracefully with bursts in data arrival without compromising system performance. We discuss one strategy for processing bursty streams — adaptive, load-aware scheduling of query operators to minimize resource consumption during times of peak load. We show that the choice of an operator scheduling strategy can have significant impact on the run-time system memory usage. We then present Chain scheduling, an operator scheduling strategy for data stream systems that is near-optimal in minimizing run-time memory usage for any collection of singlestream queries involving selections, projections, and foreign-key joins with stored relations. Chain scheduling also performs well for queries with sliding-window joins over multiple streams, and multiple queries of the above types. A thorough experimental evaluation is provided where we demonstrate the potential benefits of Chain scheduling, compare it with competing scheduling strategies, and validate our analytical conclusions. 1.
191|Wavelet synopses with error guarantees|ABSTRACT Recent work has demonstrated the effectiveness of the wavelet de-composition in reducing large amounts of data to compact sets of
192|Scheduling for Shared Window Joins Over Data Streams|Continuous Ouery (CO) systems typically exploit  commonality among query expressions to achieve  improved efficiency through shared processing. Recently  proposed CO systems have introduced window  specifications in order to support unbounded  data streams. There has been, however, little investigation  of sharing for windowed query operators.
193|Using State Modules for Adaptive Query Processing|We present a query architecture in which join operators are decomposed into their constituent data structures (State Modules, or SteMs), and dataflow among these SteMs is managed adaptively by an Eddy routing operator. Breaking the encapsulation of joins serves two purposes. First, it allows the Eddy to observe multiple physical operations embedded in a join algorithm, allowing for better calibration and control of these operations. Second, the SteM on a relation serves as a shared materialization point, enabling multiple competing access methods to share results, which can be leveraged by multiple competing join algorithms. Our architecture extends prior work significantly, allowing continuously adaptive decisions for most major aspects of traditional query optimization: choice of access methods and join algorithms, ordering of operators, and choice of a query spanning tree. SteMs introduce...
194|Distributed streams algorithms for sliding windows|Massive data sets often arise as physically distributed, parallel data streams, and it is important to estimate various aggregates and statistics on the union of these streams. This paper presents algorithms for estimating aggregate functions over a “sliding window ” of the N most recent data items in one or more streams. Our results include: 1. For a single stream, we present the first ?-approximation scheme for the number of 1’s in a sliding window that is optimal in both worst case time and space. We also present the first ?-approximation scheme for the sum of integers in [0..R] in a sliding window that is optimal in both worst case time and space (assuming R is at most polynomial in N). Both algorithms are deterministic and use only logarithmic memory words. 2. In contrast, we show that any deterministic algorithm that estimates, to within a small constant relative error, the number of 1’s (or the sum of integers) in a sliding window on the union of distributed streams requires ?(N) space.
195| An Abstract Semantics and Concrete Language for Continuous Queries over Streams and Relations |Despite the recent surge of research in query processing over data streams, little attention has been devoted to defining precise semantics for continuous queries over streams. We first present an abstract semantics based on several building blocks: formal definitions for streams and relations, mappings among them, and any relational query language. From these basics we define a precise interpretation for continuous queries over streams and relations. We then propose a concrete language, CQL (for Continuous semantics using SQL as the relational query language and window specifications derived from SQL-99 to map from streams to relations. We identify some equivalences that can be used to rewrite CQL queries for optimization, and we discuss some additional implementation issues arising from the language and its semantics. We are implementing CQL as part of a general-purpose Data Stream Management System at Stanford.  
196|Exploiting k-Constraints to Reduce Memory Overhead in Continuous Queries over Data Streams|We consider the problem of efficiently processing continuous queries over multiple continuous data streams inthe presence of constraints on the datastreams. We specify several types of constraints, and for each constrainttype we identify an “ adherence parameter ” that captures how closely a given stream or joining pair of streams adheres to a constraint of that type. We then present a query execution algorithm that takes-constraints over streams into account in order to reduce memory overhead. In general, the tighter the adherence parameters are in the-constraints, the less memory required. Furthermore, if input streams do not adhere to constraints within the specified adherence parameters, our algorithm automatically degrades gracefully to provide continuous approximate answers. We have implemented our approach in a testbed continuous query processor and preliminary experimental results are reported. 1
197|Data Stream Management Issues – A Survey|Traditional databases store sets of relatively static records with no pre-defined notion of time, unless timestamp attributes are explicitly added. While this model adequately represents commercial catalogues or repositories of personal information, many current and emerging applications require support for on-line analysis of rapidly changing data streams. Limitations of traditional DBMSs in supporting streaming applications have been recognized, prompting research to augment existing technologies and build new systems to manage streaming data. The purpose of this paper is to review recent work in data stream management systems, with an emphasis on data models, continuous query languages, and query evaluation and optimization techniques. We also give examples of streaming queries in various applications and review related work in modeling lists and sequences. 1
198|ATLaS: A Native Extension of SQL for Data Mining and Stream Computations|A lack of power and extensibility in their query languages has seriously limited the generality of DBMSs and hampered their ability to support new application domains. Considerable efforts by database researchers and commercial DBMS vendors have led to major extensions; yet there remain important applications---particularly data mining---that are not supported well in SQL-3. Thus, there is a pressing need for more general mechanisms for extending SQL and dealing with new application areas, particularly database-centric data mining. To satisfy this need, we allow database users to add new table functions and stream-oriented aggregate functions by defining them in SQL---rather than in external procedural languages as O-R DBMSs currently do. This simple extension turns SQL into a powerful database language, which can express a wide range of applications, including recursive queries, ROLAP aggregates, time-series queries, stream-oriented processing, and data mining functions. In addition to adding great power and flexibility to SQL, these extensions are conducive to performance and data independence. The paper also discusses the system we have developed to support these SQL extensions, and the architecture and techniques used in its realization.
199|Selectivity Estimation Without the Attribute Value Independence Assumption|The result size of a query that involves multiple attributes from the same relation depends on these attributes’joinr data distribution, i.e., the frequencies of all combinations of attribute values. To simplify the estimation of that size, most commercial systems make the artribute value independenceassumption and maintain statistics (typically histograms) on individual attributes only. In reality, this assumption is almost always wrong and the resulting estimations tend to be highly inaccurate. In this paper, we propose two main alternatives to effectively approximate (multi-dimensional) joint data distributions. (a) Using a multi-dimensional histogram, (b) Using the Singular Value Decomposition (SVD) technique from linear algebra. An extensive set of experiments demonstrates the advantages and disadvantages of the two approaches and the benefits of both compared to the independence assumption. 1
200|Universality of Serial Histograms|Many current relational database systems use some form of histograms to approximate the frequency distribution of values in the attributes of relations and based on them estimate query result sizes and access plan costs. The errors that exist in the histogram approximations directly or transitively affect many estimates derived by the database system. We identify the class of serial histograms and demonstrate that they are optimal for reducing the query result size error for several classes of queries when the actual query result size (and hence the value of that error) reaches some extreme. Specifically, serial histograms are shown to be optimal for arbitrary tree equality-join queries when the query result size is maximized, whether or not the attribute independence assumption holds, and when the query result size is minimized and the attribute independence assumption holds. We also show that the expected error for any such query is always zero under all histograms, and thus argue that histograms should be chosen based on the reduction of the extreme-cases error, since reduction of the expected error is meaningless. 
201|Optimal histograms for hierarchical range queries|Now there is tremendous interest in data warehousing and OLAP applications. OLAP applications typically view data as having multiple logical dimensions (e.g., product, location) with natural hierarchies de ned on
202|Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing|Many commercial database systems use some form of statistics, typically histograms, to summarize the contents of relations and permit efficient estimation of required quantities. While there has been considerable work done on identifying good histograms for the estimation of query-result sizes, little attention has been paid to the estimation of the data distribution of the result, which is of importance in query optimization. In this paper, we prove that the optimal histogram for estimating the size of the result of a join operator is optimal for estimating its data distribution as well. We also study the effectiveness of these optimal histograms in the context of an important application that requires estimates for the data distribution of a query result: load-balancing for parallel Hybrid hash joins. We derive a cost formula to capture the effect of data skew in both the input and output relations on the load and use the optimal histograms to estimate this cost most accurately. We h...
203|Clustering data streams: Theory and practice|Abstract—The data stream model has recently attracted attention for its applicability to numerous types of data, including telephone records, Web documents, and clickstreams. For analysis of such data, the ability to process the data in a single pass, or a small number of passes, while using little memory, is crucial. We describe such a streaming algorithm that effectively clusters large data streams. We also provide empirical evidence of the algorithm’s performance on synthetic and real data streams. Index Terms—Clustering, data streams, approximation algorithms. 1
204|A density-based algorithm for discovering clusters in large spatial databases with noise|Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.
205|Automatic Subspace Clustering of High Dimensional Data|Data mining applications place special requirements on clustering algorithms including: the ability to find clusters embedded in subspaces of high dimensional data, scalability, end-user comprehensibility of the results, non-presumption of any canonical data distribution, and insensitivity to the order of input records. We present CLIQUE, a clustering algorithm that satisfies each of these requirements. CLIQUE identifies dense clusters in subspaces of maximum dimensionality. It generates cluster descriptions in the form of DNF expressions that are minimized for ease of comprehension. It produces identical results irrespective of the order in which input records are presented and does not presume any specific mathematical form for data distribution. Through experiments, we show that CLIQUE efficiently finds accurate clusters in large high dimensional datasets.
206|BIRCH: an efficient data clustering method for very large databases|Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely st,udied problems in this area is the identification of clusters, or deusel y populated regions, in a multi-dir nensional clataset. Prior work does not adequately address the problem of large datasets and minimization of 1/0 costs. This paper presents a data clustering method named Bfll (;”H (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and clynamicall y clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i. e., available memory and time constraints). BIRCH can typically find a goocl clustering with a single scan of the data, and improve the quality further with a few aclditioual scans. BIRCH is also the first clustering algorithm proposerl in the database area to handle “noise) ’ (data points that are not part of the underlying pattern) effectively. We evaluate BIRCH’S time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIR (;’H versus CLARA NS, a clustering method proposed recently for large datasets, and S11OW that BIRCH is consistently 1
207|OPTICS: Ordering Points To Identify the Clustering Structure|Cluster analysis is a primary method for database mining. It is either used as a stand-alone tool to get insight into the distribution of a data set, e.g. to focus further analysis and data processing, or as a preprocessing step for other algorithms operating on the detected clusters. Almost all of the well-known clustering algorithms require input parameters which are hard to determine but have a significant influence on the clustering result. Furthermore, for many real-data sets there does not even exist a global parameter setting for which the result of the clustering algorithm describes the intrinsic clustering structure accurately. We introduce a new algorithm for the purpose of cluster analysis which does not produce a clustering of a data set explicitly; but instead creates an augmented ordering of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings. It is a versatile basis for both automatic and interactive cluster analysis. We show how to automatically and efficiently extract not only ‘traditional ’ clustering information (e.g. representative points, arbitrary shaped clusters), but also the intrinsic clustering structure. For medium sized data sets, the cluster-ordering can be represented graphically and for very large data sets, we introduce an appropriate visualization technique. Both are suitable for interactive exploration of the intrinsic clustering structure offering additional insights into the distribution and correlation of the data.
208|Probabilistic Counting Algorithms for Data Base Applications|This paper introduces a class of probabilistic counting lgorithms with which one can  estimate the number of distinct elements in a large collection of data (typically a large file  stored on disk) in a single pass using only a small additional storage (typically less than a  hundred binary words) and only a few operations per element scanned. The algorithms are  based on statistical observations made on bits of hashed values of records. They are by con-  struction totally insensitive to the replicafive structure of elements in the file; they can be used  in the context of distributed systems without any degradation of performances and prove  especially useful in the context of data bases query optimisation. ; 1985 Academic Press, Inc
209|On Clusterings: Good, Bad and Spectral| We motivate and develop a natural bicriteria measure for assessing the quality of a clustering which avoids the drawbacks of existing measures. A simple recursive heuristic is shown to have poly-logarithmic worst-case guarantees under the new measure. The main result of the paper is the analysis of a popular spectral algorithm. One variant of spectral clustering turns out to have effective worst-case guarantees; another finds a &#034;good&#034; clustering, if one exists.
211|Approximation Algorithms for Projective Clustering|We consider the following two instances of the projective clustering problem: Given a set S  of n points in R  d  and an integer k ? 0; cover S by k hyper-strips (resp. hyper-cylinders) so that the maximum width of a hyper-strip (resp., the maximum diameter of a hyper-cylinder) is minimized. Let w    be the smallest value so that S can be covered by k hyper-strips (resp. hyper-cylinders), each of width (resp. diameter) at most w    : In the plane, the two problems are equivalent. It is NP-Hard to compute k planar strips of width even at most Cw    ; for any constant C ? 0 [50]. This paper contains four main results related to projective clustering: (i) For d = 2, we present a randomized algorithm that computes O(k log k) strips of width at most 6w    that cover S. Its expected running time is O(nk  2  log  4  n) if k  2  log k  n; it also works for larger values of k, but then the expected running time is O(n  2=3  k  8=3  log  4  n). We also propose another algorithm that computes a c...
213|STING: A statistical information grid approach to spatial data mining|Spatial data mining, i.e., discovery of interesting characteristics and patterns that may implicitly exist in spatial databases, is a challenging task due to the huge amounts of spatial data and to the new conceptual nature of the problems which must account for spatial distance. Clustering and region oriented queries are common problems in this domain. Several approaches have been presented in recent years, all of which require at least one scan of all individual objects (points). Consequently, the computational complexity is at least linearly proportional to the number of objects to answer each query. In this paper, we propose a hierarchical statistical information grid based approach for spatial data mining to reduce the cost further. The idea is to capture statistical information associated with spatial cells in such a manner that whole classes of queries and clustering problems can be answered without recourse to the individual objects. In theory, and confirmed by empirical studies, this approach outperforms the best previous method by at least an order of magnitude, especially when the data set is very large.
214|An Efficient Approach to Clustering in Large Multimedia Databases with Noise|Several clustering algorithms can be applied to clustering in large multimedia databases. The effectiveness and efficiency of the existing algorithms, however, is somewhat limited, since clustering in multimedia databases requires clustering high-dimensional feature vectors and since multimedia databases often contain large amounts of noise. In this paper, we therefore introduce a new algorithm to clustering in large multimedia databases called DENCLUE (DENsitybased CLUstEring). The basic idea of our new approachis  to model the overall point density analytically as the sum of influence functions of the data points. Clusters can then be identified by determining density-attractors and clusters of arbitrary shape can be easily described by a simple equation based on the overall density function. The advantages of our new approach are (1) it has a firm mathematical basis, (2) it has good clustering properties in data sets with large amounts of noise, (3) it allows a compact mathematical ...
215|Fast Monte-Carlo algorithms for finding low-rank approximations|We consider the problem of approximating a given m * n matrix A by another matrix of specified rank k, which is smaller than m and n. The Singular Value Decomposition (SVD) can be used to find the &amp;quot;best &amp;quot; such approximation. However, it takes time polynomial in m, n which is prohibitive for some modern applications. In this paper, we develop an algorithm which is qualitatively faster, provided we may sample the entries of the matrix according to a natural probability distribution. In many applications such sampling can be done efficiently. Our main result is a randomized algorithm to find the description of a matrix D * of rank at most k so that ||A- D*||2F &lt; = min D,rank(D)&lt;=k ||A- D||
216|Greedy strikes back: Improved facility location algorithms|A fundamental facility location problem is to choose the location of facilities, such as industrial plants and warehouses, to minimize the cost of satisfying the demand for some commodity. There are associated costs for locating the facilities, as well as transportation costs for distributing the commodities. We assume that the transportation costs form a metric. This problem is commonly referred to as the uncapacitated facility location (UFL) problem. Applications to bank account location and clustering, as well as many related pieces of work, are discussed by Cornuejols, Nemhauser and Wolsey [2]. Recently, the first constant factor approximation algorithm for this problem was obtained by Shmoys, Tardos and Aardal [16]. We show that a simple greedy heuristic combined with the algorithm by Shmoys, Tardos and Aardal, can be used to obtain an approximation guarantee of 2.408. We discuss a few variants of the problem, demonstrating better approximation factors for restricted versions of the problem. We also show that the problem is Max SNP-hard. However, the inapproximability constants derived from the Max SNP hardness are very close to one. By relating this problem to Set Cover, we prove a lower bound of 1.463 on the best possible approximation ratio assuming NP / ? DT IME[n O(log log n)]. 1
217|Wavecluster: A multi-resolution clustering approach for very large spatial databases|Many applications require the management of spatial data. Clustering large spatial databases is an important problem which tries to find the densely populated regions in the feature space to be used in data mining, knowledge discovery, or efficient information retrieval. A good clustering approach should be efficient and detect clusters of arbitrary shape. It must be insensitive to the outliers (noise) and the order of input data. We pro-pose WaveCluster, a novel clustering approach based on wavelet transforms, which satisfies all the above requirements. Using multi-resolution property of wavelet transforms, we can effectively identify arbitrary shape clus-ters at different degrees of accuracy. We also demonstrate that WaveCluster is highly effi-cient in terms of time complexity. Experi-mental results on very large data sets are pre-sented which show the efficiency and effective-ness of the proposed approach compared to the other recent clustering methods.
219|A new greedy approach for facility location problems |We present a simple and natural greedy algorithm for the metric uncapacitated facility location problem achieving an approximation guarantee of 1.61 whereas the best previously known was 1.73. Furthermore, we will show that our algorithm has a property which allows us to apply the technique of Lagrangian relaxation. Using this property, we can nd better approximation algorithms for many variants of the facility location problem, such as the capacitated facility location problem with soft capacities and a common generalization of the k-median and facility location problem. We will also prove a lower bound on the approximability of the k-median problem.
220|Approximation schemes for Euclidean k-Medians And Related Problems|In the k-median problem we are given a set S of n points in a metric space and a positive integer k. We desire to locate k medians in space, such that the sum of the distances from each of the points of S to the nearest median is minimized. This paper gives an approximation scheme for the plane that for any c &gt; 0 produces a solution of cost at most 1 + 1/c times the optimum and runs in time O(n  O(c+1)  ). The approximation scheme also generalizes to some problems related to k-median.  Our methodology is to extend Arora&#039;s [1, 2] techniques for the TSP, which hitherto seemed inapplicable to problems such as the k-median problem.  1 Introduction  In the k-median problem we are given a set S of n points in a metric space and a positive integer  k. We desire to locate k medians in the space, such that the sum of the distances from each of the points of S to the nearest median is minimized. Besides its intrinsic appeal as a cleanly-stated, basic unsolved problem in combinatorial optimizatio...
221|Clustering in Large Graphs and Matrices|We consider the problem of dividing a set of m points in Euclidean n\Gammaspace into k clusters (m; n are variable while k is fixed), so as to minimize the sum of distance squared of each point to its &#034;cluster center&#034;. This formulation differs in two ways from the most frequently considered clustering problems in the literature, namely, here we have k fixed and m;n variable and we use the sum of squared distances as our measure; we will argue that our problem is natural in many contexts. We consider a relaxation of the discrete problem : find the k\Gammadimensional subspace V so that the sum of distances squared to V (of the m points) is minimized. We show : (i) The relaxation can be solved by Singular Value Decomposition (SVD) of Linear Algebra. (ii) The solution of the relaxation can be used to get a 2-approximation algorithm for the original problem. More importantly, (iii) we argue that in fact the relaxation provides a generalized clustering which is useful in its own right. Final...
222|Optimal Grid-Clustering: Towards Breaking the Curse of Dimensionality in High-Dimensional Clustering|Many applications require the clustering of large amounts of high-dimensional data. Most clustering algorithms, however, do not work effectively and efficiently in high-dimensional space, which is due to the so-called &#034;curse of dimensionality&#034;. In addition, the high-dimensional data often contains a significant amount of noise which causes additional effectiveness problems. In this paper, we review and compare the existing algorithms for clustering high-dimensional data and show the impact of the curse of dimensionality on their effectiveness and efficiency. The comparison  reveals that condensation-based approaches (such as BIRCH or STING) are the most promising candidates for achieving the necessary efficiency, but it also shows that basically all condensation-based approaches have severe  weaknesses with respect to their effectiveness in high-dimensional space. To overcome these problems, we develop a new clustering technique called OptiGrid which is based on constructing an optimal grid-...
223|Near-optimal sparse Fourier representations via sampling|We give an algorithm for nding a Fourier representation R ofBterms for a given discrete signal A of lengthN, such thatkA,Rk 2 2 is within the factor (1 +) of best possible kA,Roptk 2 2. Our algorithm can access A by reading its values on a sample setT [0;N), chosen randomly from a (non-product) distribution of our choice, independent of A. That is, we sample non-adaptively. The total time cost of the algorithm is polynomial inB log(N) log(M) = (where M is the ratio of largest to smallest numerical quantity encountered), which implies a similar bound for the number of samples. 1.
224|A monte carlo algorithm for fast projective clustering|We propose a mathematical formulation for the notion of optimal projective cluster, starting from natural requirements on the density of points in subspaces. This allows us to develop a Monte Carlo algorithm for iteratively computing projective clusters. We prove that the computed clusters are good with high probability. We implemented a modified version of the algorithm, using heuristics to speed up computation. Our extensive experiments show that our method is significantly more accurate than previous approaches. In particular, we use our techniques to build a classifier for detecting rotated human faces in cluttered images. 1. PROJECTIVE CLUSTERING Clustering is a widely used technique for data mining, indexing, and classification. Many practical methods proposed in the last few years, such as CLARANS [11], BIRCH [15], DBSCAN [5, 6], and
225|Streaming-Data Algorithms for High-Quality Clustering| As data gathering grows easier, and as researchers discover new ways to interpret data, streamingdata algorithms have become essential in many fields. Data stream computation precludes algorithms that require random access or large memory. In this paper, we consider the problem of clustering data streams, which is important in the analysis a variety of sources of data streams, such as routing data, telephone records, web documents, and clickstreams. We provide a new clustering algorithms with theoretical guarantees on its performance. We give empirical evidence of its superiority over the commonly-used k-Means algorithm. We then adapt our algorithm to be able to operate on data streams and experimentally demonstrate its superior performance in this context.
226|Approximation Algorithms for Geometric Median Problems|In this paper we present approximation algorithms for median problems in  metric spaces and fixed-dimensional Euclidean space. Our algorithms use a new  method for transforming an optimal solution of the linear program relaxation  of the s-median problem into a provably good integral solution. This transformation  technique is fundamentally different from the methods of randomized  and deterministic rounding [Rag, RaT] and the methods proposed in [LiV] in  the following way: Previous techniques never set variables with zero values in  the fractional solution to 1. This departure from previous methods is crucial  for the success of our algorithms.
227|Online Facility Location  |We consider the online variant of facility location, in which demand points arrive one at a time and we must maintain a set of facilities to service these points. We provide a randomized online O(1)-competitive algorithm in the case where points arrive in random order. If points are ordered adversarially, we show that no algorithm can be constant-competitive, and provide an O(log n)-competitive algorithm. Our algorithms are randomized and the analysis depends heavily on the concept of expected waiting time. We also combine our techniques with those of Charikar and Guha to provide a linear-time constant approximation for the offline facility location problem.  
229|A Sublinear Time Approximation Scheme for Clustering in Metric Spaces|The metric 2-clustering problem is defined as follows: given a metric (X; d), partition X into two sets S 1 and S 2 in order to minimize the value of  X  i  X  fu;vgaeS i  d(u; v) In this paper we show an approximation scheme for this problem. 1 Introduction  In this paper we consider the following k-  clustering problem: given a weighted graph G = (X; d) on N vertices, where d(\Delta; \Delta) is a weight function, partition X into k sets S 1 : : : S k such that the value of  X  i  X  fu;vgaeS i  d(u; v) is minimized. This problem was first formally posed by Sahni and Gonzalez [7]. They observed that the problem is NP-complete (for k  2) and by reduction from k-coloring showed that it cannot be approximated up to any constant (for k  3). Instead, they proposed a 1=k-approximation algorithm for the dual version of this problem where the goal is to maximize the weight of edges which do not belong to any cluster (i.e. k-max cut). Unfortunately, the latter result does not (and cannot) impl...
230|Polynomial Time Approximation Schemes for Geometric k-Clustering|The Johnson-Lindenstrauss lemma states that n points in a high dimensional Hilbert space can be embedded with small distortion of the distances into an O(log n) dimensional space by applying a random linear transformation. We show that similar (though weaker) properties hold for certain random linear transformations over the Hamming cube. We use these transformations to solve NP-hard clustering problems in the cube as well as in geometric settings. More specifically, we address the following clustering problem. Given n points in a larger set (for example, R^d) endowed with a distance function (for example, L² distance), we would like to partition the data set into k disjoint clusters, each with a &#034;cluster center&#034;, so as to minimize the sum over all data points of the distance between the point and the center of the cluster containing the point. The problem is provably NP-hard in some high dimensional geometric settings, even for k = 2. We give polynomial time approximation schemes for this problem in several settings, including the binary cube {0, 1}^d with Hamming distance, and R^d either with L¹ distance, or with L² distance, or with the square of L&amp;sup2; distance. In all these settings, the best previous results were constant factor approximation guarantees. We note that our problem is similar in flavor to the k-median problem (and the related facility location problem), which has been considered in graph-theoretic and fixed dimensional geometric settings, where it becomes hard when k is part of the input. In contrast, we study the problem when k is fixed, but the dimension is part of the input.
231|A statistical method for profiling network traffic|Rights to individual papers remain with the author or the author&#039;s employer. Permission is granted for noncommercial reproduction of the work for educational or research purposes. This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein. For more information about the USENIX Association:
232|Optimal Time Bounds for Approximate Clustering|Clusteringisafundamentalprobleminunsuper-vised learning, andhasbeenstudiedwidelyboth asaproblemoflearningmixture modelsandasanoptimizationproblem. Inthispaper, we studyclusteringwithrespectthe k-median objectivefunction, anaturalformulationofclusteringin whichweattempttominimize the average distancetoclustercenters. Oneofthe maincontributionsofthispaperisasimplebutpowerful samplingtechniquethatwecall successivesampling thatcouldbeofindependentinterest. Weshowthatoursamplingprocedurecan rapidlyidentify asmallsetofpoints(ofsizejust O(k log n/k))thatsummarizetheinputpoints forthepurposeofclustering. Usingsuccessive sampling, we develop analgorithmforthe k-medianproblemthatrunsin O(nk) timeforawiderangeof valuesof k andisguaranteed, with high probability, to return a solution with cost at most a constant factor times optimal. We also establish a lower bound of \Omega ( nk) onanyrandom-izedconstant-factorapproximation algorithm for the k-median problem that succeeds with even a negligible (say
233|Subquadratic Approximation Algorithms For Clustering Problems in High Dimensional Spaces|One of the central problems in information retrieval, data mining, computational biology, statistical analysis, computer vision, geographic analysis, pattern recognition, distributed protocols is the question of classification of data according to some clustering rule. Often the data is noisy and even approximate classification is of extreme importance. The difficulty of such classification stems from the fact that usually the data has many incomparable attributes, and often results in the question of clustering problems in high dimensional spaces. Since they require measuring distance between every pair of data points, standard algorithms for computing the exact clustering solutions use quadratic or &#034;nearly quadratic&#034; running time; i.e., O(dn  2\Gammaff(d)  ) time where n is the number of data points, d is the dimen-    Computer Science Department, University of Toronto. Part of this work was done while visiting Bell Communications Research.  y  Bell Communications Research, MCC-1C365...
234|Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality|The nearest neighbor problem is the following: Given a set of n points P = fp 1 ; : : : ; png in  some metric space X, preprocess P so as to efficiently answer queries which require finding the  point in P closest to a query point q 2 X. We focus on the particularly interesting case of the  d-dimensional Euclidean space where X = !  d  under some l p norm. Despite decades of effort,  the current solutions are far from satisfactory; in fact, for large d, in theory or in practice, they  provide little improvement over the brute-force algorithm which compares the query point to  each data point. Of late, there has been some interest in the approximate nearest neighbors  problem, which is: Find a point p 2 P that is an ffl-approximate nearest neighbor of the query  q in that for all p  0  2 P , d(p; q)  (1 + ffl)d(p  0  ; q).  We present two algorithmic results for the approximate version that significantly improve the  known bounds: (a) preprocessing cost polynomial in n and d, and a trul...
235|The geometry of graphs and some of its algorithmic applications|In this paper we explore some implications of view-ing graphs as geometric objects. This approach of-fers a new perspective on a number of graph-theoretic and algorithmic problems. There are several ways to model graphs geometrically and our main concern here is with geometric representations that respect the met-ric of the (possibly weighted) graph. Given a graph G we map its vertices to a normed space in an attempt to (i) Keep down the dimension of the host space and (ii) Guarantee a small distortion, i.e., make sure that distances between vertices in G closely match the dis-tances between their geometric images. In this paper we develop efficient algorithms for em-bedding graphs low-dimensionally with a small distor-tion. Further algorithmic applications include: 0 A simple, unified approach to a number of prob-lems on multicommodity flows, including the Leighton-Rae Theorem [29] and some of its ex-tensions. 0 For graphs embeddable in low-dimensional spaces with a small distortion, we can find low-diameter decompositions (in the sense of [4] and [34]). The parameters of the decomposition depend only on the dimension and the distortion and not on the size of the graph. 0 In graphs embedded this way, small balanced separators can be found efficiently. Faithful low-dimensional representations of statisti-cal data allow for meaningful and efficient cluster-ing, which is one of the most basic tasks in pattern-recognition. For the (mostly heuristic) methods used
236|Pseudorandom generators for space-bounded computation|Pseudorandom generators are constructed which convert O(SlogR) truly random bits to R bits that appear random to any algorithm that runs in SPACE(S). In particular, any randomized polynomial time algorithm that runs in space S can be simulated using only O(Slogn) random bits. An application of these generators is an explicit construction of universal traversal sequences (for arbitrary graphs) of length n O(l~ The generators constructed are technically stronger than just appearing random to spacebounded machines, and have several other applications. In particular, applications are given for &#034;deterministic amplification &#034; (i.e. reducing the probability of error of randomized algorithms), as well as generalizations of it. 1.
237|Finding interesting associations without support pruning|Abstract Association-rule mining has heretofore relied on the condition of high support to do its work efficiently. In particular, the well-known a-priori algorithm is only effective when the only rules of interest are relationships that occur very frequently. However, there are a number of applications, such as data mining, identification of similar web documents, clustering, and collaborative filtering, where the rules of interest have comparatively few instances in the data. In these cases, we must look for highly correlated items, or possibly even causal relationships between infrequent items. We develop a family of algorithms for solving this problem, employing a combination of random sampling and hashing techniques. We provide analysis of the algorithms developed, and conduct experiments on real and synthetic data to obtain a comparative performance analysis.
238|Filtering near-duplicate documents|Abstract. The mathematical concept of document resemblance captures well the informal notion of syntactic similarity. The resemblance can be estimated using a fixed size “sketch ” for each document. For a large collection of documents (say hundreds of millions) the size of this sketch is of the order of a few hundred bytes per document. However, for efficient large scale web indexing it is not necessary to determine the actual resemblance value: it suffices to determine whether newly encountered documents are duplicates or near-duplicates of documents already indexed. In other words, it suffices to determine whether the resemblance is above a certain threshold. In this talk we show how this determination can be made using a ”sample ” of less than 50 bytes per document. The basic approach for computing resemblance has two aspects: first, resemblance is expressed as a set (of strings) intersection problem, and second, the relative size of intersections is evaluated by a process of random sampling that can be done independently for each document. The process of estimating the relative size of intersection of sets and the thresholdtestdiscussedabovecanbeappliedtoarbitrarysets,andthus might be of independent interest. The algorithm for filtering near-duplicate documents discussed here has been successfully implemented and has been used for the last three years in the context of the AltaVista search engine. 1
239|The dimension of almost spherical sections of convex bodies|The well-known theorem of Dvoretzky [1] states that convex bodies of high dimension have low dimensional sections which are almost spherical. More precisely, the theorem states that for every integer k and every e&gt; 0 there is an integer n(k, e) such that any Banach space X with dimension&gt; n(k, e) has a subspace Y of dimension k with d{Y,l\) &lt; 1 + e. Here d(Y, l£) denotes the Banach Mazur distance coefficient between Y and the k dimensional Hubert space l\ i.e. inflim \\T ~ X \ \ taken over all operators T from Y onto l\. The estimate for n(k, e) given in [1] was improved in [5] to n(k, e) = ec(e)k In other words (considering the dependence of n(k, e) on k for fixed e) the dimension of the almost spherical section (of the unit ball) given by Dvoretzky&#039;s theorem is about the log of the dimension of the space. This estimate is in general the best possible, since as observed in [10] it is easy to verify that if X = Z ~ any subspace Y of X whose Banach Mazur distance from a Hubert space is &lt; 2 say, must be of dimension at most C log n. It turns out however that if
240|Fast Hierarchical Clustering and Other Applications of Dynamic Closest Pairs|We develop data structures for dynamic closest pair problems with arbitrary distance functions, that do not necessarily come from any geometric structure on the objects. Based on a technique previously used by the author for Euclidean closest pairs, we show how to insert and delete objects from an n-object set, maintaining the closest pair, in O(nlog² n) time per update and O(n) space. With quadratic space, we can instead use a quadtree-like structure to achieve an optimal time bound, O(n) per update. We apply these data structures to hierarchical clustering, greedy matching, and TSP heuristics, and discuss other potential applications in machine learning, Gröbner bases, and local improvement algorithms for partition and placement problems. Experiments show our new methods to be faster in practice than previously used heuristics.
241|On the Impossibility of Dimension Reduction in l_1|The Johnson-Lindenstrauss Lemma shows that any n points in Euclidean space (with distances measured by the L2 norm) may be mapped down to O((log n)/ep^2) dimensions such that no pairwise distance is distorted by more than a (1 ep) factor. Determining whether such dimension reduction is possible in L1 has been an intriguing open question. Charikar and Sahai [7] recently showed lower bounds for dimension reduction in L1 that can be achieved by linear projections, and positive results for shortest path metrics of restricted graph families. However the question of general dimension reduction in L1 was still open. For example, it was not known whether it is possible to reduce the number of dimensions to O(log n) with 1 ep distortion. We show strong lower bounds for general dimension reduction in L1. We give an explicity family of n points in L1 such that any embedding with distortion d requires n^Omega(1/d^2) dimensions. This proves that there is no analog of the Johnson-Lindenstrauss Lemma for L1
242|Dynamic Euclidean Minimum Spanning Trees and Extrema of Binary Functions|We maintain the minimum spanning tree of a point set in the plane, subject to point insertions and deletions, in amortized time O(n 1/2 log 2 n) per update operation. We reduce the problem to maintaining bichromatic closest pairs, which we solve in time O(n # ) per update. Our algorithm uses a novel construction, the ordered nearest neighbor path of a set of points. Our results generalize to higher dimensions, and to fully dynamic algorithms for maintaining minima of binary functions, including the diameter of a point set and the bichromatic farthest pair. 1 Introduction A dynamic geometric data structure is one that maintains the solution to some problem, defined on a geometric input such as a point set, as the input undergoes update operations such as insertions or deletions of single points. Dynamic algorithms have been studied for many geometric optimization problems, including closest pairs [7, 23, 25, 26], diameter [7, 26], width [4], convex hulls [15, 22], linear ...
243|Reductions Among High Dimensional Proximity Problems|We present improved running times for a wide range of approximate high dimensional proximity  problems. We obtain subquadratic running time for each of these problems. These improved  running times are obtained by reduction to Nearest Neighbour queries. The problems we consider  in this paper are Approximate Diameter, Approximate Furthest Neighbours, Approximate  Discrete Center, Approximate Line Center, Approximate Metric Facility Location, Approximate  Bottleneck Matching, and Approximate Minimum Weight Matching.  University of Southern California. Email: agoel@cs.usc.edu .  y  Stanford University. Email: indyk@cs.stanford.edu .  z  University of Iowa. Email: kvaradar@cs.uiowa.edu .  0  Problem Ref Approx. Time Comments  Diameter [10]  p  3 O(dn)  [12] 1 + ffl O(dn log n + n  2  )  [2] 1 + ffl  ~  O(n  2\GammaO(ffl  2  )  + dn)  [18] 1 + ffl  ~  O(n  1+1=(1+ffl=6)  + dn)  here 1 + ffl ~ O(n  1+1=(1+ffl)  + dn) ~ O(n) (1 + ffl)-NNS queries  here  p  2 ~ O(dn) see Section 3 for some  e...
244|Derandomized Dimensionality Reduction with Applications|The Johnson-Lindenstrauss lemma provides a way to map a number of points in high-dimensional space into a low-dimensional space, with only a small distortion of the distances between the points. The proofs of the lemma are non-constructive: they show that a random mapping induces small distortions with high probability, but they do not construct the actual mapping. In this paper, we provide a procedure that constructs such a mapping deterministically in time almost linear in the number of distances to preserve times the dimension of the original space. We then use that result (together with Nisan&#039;s pseudorandom generator) to obtain an efficient derandomization of several approximation algorithms based on semidefinite programming.
246|Checking Approximate Computations over the Reals|The idea of program result checking was first introduced by Blum [2] and Blum and Kannan [3]. Given a program and an instance of a problem, we&#039;d like to make sure that the program is correct on that instance without using very much computation time. While checkers have been developed for a wide variety of problems, most of those problems involve exact solutions, primarily over finite fields.
247|Fast small-space algorithms for approximate histogram maintenance |Avector A of lengthN is de ned implicitly, via a stream of updates of the form \add 5 to A3. &amp;quot; We give asketching algorithm, that constructs a small sketch from the stream of updates, and a reconstruction algorithm, that produces aBbucket piecewise-constant representation (histogram) H for A from the sketch, such thatkA,Hk (1+)kA,Hoptk, where the errorkA,Hk is either`1 (absolute) or`2 (rootmean-square) error. The time to process a single update, time to reconstruct the histogram, and size of the sketch are each bounded by poly(B;log(N); logkAk;1 =). Our result is obtained in two steps. First we obtain what we call a robust histogram approximation for A, a histogram such that adding a small number of buckets does not help improve the representation quality signi cantly. From the robust histogram, we cull a histogram of desired accruacy andB buckets in the second step. This technique also provides similar results for Haar wavelet representations, under`2 error. Our results have applications in summarizing data distributions fast and succinctly even in distributed settings. 1.
248|Stable distributions for stream computations: It’s as easy as 0,1,2|-1. Introduction A surprising number of data stream problems are solved bymethods involving computations with stable distributions. This
249|On Demand Classification of Data Streams|Current models of the classification problem do not effectively handle bursts of particular classes coming in at different times. In fact, the current model of the classification problem simply concentrates on methods for one-pass classification modeling of very large data sets. Our model for data stream classification views the data stream classification problem from the point of view of a dynamic approach in which simultaneous training and testing streams are used for dynamic classification of data sets. This model reflects real life situations effectively, since it is desirable to classify test streams in real time over an evolving training and test stream. The aim here is to create a classification system in which the training model can adapt quickly to the changes of the underlying data stream. In order to achieve this goal, we propose an on-demand classification process which can dynamically select the appropriate window of past training data to build the classifier. The empirical results indicate that the system maintains a high classification accuracy in an evolving data stream, while providing an efficient solution to the classification task.
250| Requirements for Clustering Data Streams |Scientific and industrial examples of data streams abound in astronomy, telecommunication operations, banking and stock-market applications, e-commerce and other fields. A challenge imposed by continuously arriving data streams is to analyze them and to modify the models that explain them as new data arrives. In this paper, we analyze the requirements needed for clustering data streams. We review some of the latest algorithms in the literature and assess if they meet these requirements.
251|Iterative Optimization and Simplification of Hierarchical Clusterings|Clustering is often used for discovering structure in data. Clustering systems differ in  the objective function used to evaluate clustering quality and the control strategy used to  search the space of clusterings. Ideally, the search strategy should consistently construct  clusterings of high quality, but be computationally inexpensive as well. In general, we  cannot have it both ways, but we can partition the search so that a system inexpensively  constructs a `tentative&#039; clustering for initial examination, followed by iterative optimization,  which continues to search in background for improved clusterings. Given this motivation,  we evaluate an inexpensive strategy for creating initial clusterings, coupled with several  control strategies for iterative optimization, each of which repeatedly modifies an initial  clustering in search of a better one. One of these methods appears novel as an iterative  optimization strategy in clustering contexts. Once a clustering has been construct...
252|Using the Fractal Dimension to Cluster Datasets|Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. The clustering of large data sets has received a lot of attention in recent years, however, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the data set and the number of dimensions that describe the points, or in finding arbitrary shapes of clusters, or dealing effectively with the presence of noise. In this paper, we present a new clustering algorithm, based in the fractal properties of the data sets. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same cluster have a great degree of self-similarity among them (and much less self-similarity with respect to points in other clusters). FC requires one scan of the data, is suspendable at will, providing the best answer possible at that point, and is incremental. We show via experiments that FC effectively deals with large data sets, high-dimensionality and noise and is capable of recognizing clusters of arbitrary shape.  
254|Tri-Plots: Scalable Tools for Multidimensional Data Mining|We focus on the problem of finding patterns across two large, multidimensional datasets. For example, given feature vectors of healthy and of non-healthy patients, we want to answer the following questions: Are the two clouds of points separable? What is the smallest/largest pair-wise distance across the two datasets? Which of the two clouds does a new point (feature vector) come from? We propose a new tool, the tri-plot, and its generalization, the pq-plot, which help us answer the above questions. We provide a set of rules on how to interpret a tri-plot, and we apply these rules on synthetic and real datasets. We also show how to use our tool for classification, when traditional methods (nearest neighbor, classification trees) may fail.
255|Size-estimation framework with applications to transitive closure and reachability|Computing the transitive closure in directed graphs is a fundamental graph problem. We consider the more restricted problem of computing the number of nodes reachable from every node and the size of the transitive closure. The fastest known transitive closure algorithms run in O(min{mn, n2.38}) time, where n is the number of nodes and m the number of edges in the graph. We present an O(m) time randomized (Monte Carlo) algorithm that estimates, with small relative error, the sizes of all reachability sets and the transitive closure. Another ramification of our estimation scheme is a Õ(m) time algorithm for estimating sizes of neighborhoods in directed graphs with nonnegative edge lengths. Our size-estimation algorithms are much faster than performing the respective explicit computations. 1
256|A linear-time probabilistic counting algorithm for database applications|We present a probabilistic algorithm for counting the number of unique values in the presence of duplicates. This algorithm has O(q) time complexity, where q is the number of values including duplicates, and produces an estimation with an arbitrary accuracy prespecified by the user using only a small amount of space. Traditionally, accurate counts of unique values were obtained by sorting, which has O(q log q) time complexity. Our technique, called linear counting, is based on hashing. We present a comprehensive theoretical and experimental analysis of linear counting. The analysis reveals an interesting result: A load factor (number of unique values/hash table size) much larger than 1.0 (e.g., 12) can be used for accurate estimation (e.g., 1 % of error). We present this technique with two important applications to database problems: namely, (1) obtaining the column cardinality (the number of unique values in a column of a relation) and (2) obtaining the join selectivity (the number of unique values in the join column resulting from an unconditional join divided by the number of unique join column values in the relation to he joined). These two parameters are important statistics that are used in relational query optimization and physical database design.
257|Mining Concept-Drifting Data Streams Using Ensemble Classifiers|Recently, mining data streams with concept drifts for actionable insights has become an important and challenging task for a wide range of applications including credit card fraud protection, target marketing, network intrusion detection, etc. Conventional knowledge discovery tools are facing two challenges, the overwhelming volume of the streaming data, and the concept drifts. In this paper, we propose a general framework for mining concept-drifting data streams using weighted ensemble classifiers. We train an ensemble of classification models, such as C4.5, RIPPER, naive Bayesian, etc., from sequential chunks of the data stream. The classifiers in the ensemble are judiciously weighted based on their expected classification accuracy on the test data under the time-evolving environment. Thus, the ensemble approach improves both the efficiency in learning the model and the accuracy in performing classification. Our empirical study shows that the proposed methods have substantial advantage over single-classifier approaches in prediction accuracy, and the ensemble framework is effective for a variety of classification models.
258|Experiments with a New Boosting Algorithm|In an earlier paper, we introduced a new “boosting” algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a “pseudo-loss ” which is a method for forcing a learning algorithm of multi-label conceptsto concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman’s “bagging ” method when used to aggregate various classifiers (including decision trees and single attribute-value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem. 
259|Fast Effective Rule Induction|Many existing rule learning systems are computationally expensive on large noisy datasets. In this paper we evaluate the recently-proposed rule learning algorithm IREP on a large and diverse collection of benchmark problems. We show that while IREP is extremely efficient, it frequently gives error rates higher than those of C4.5 and C4.5rules. We then propose a number of modifications resulting in an algorithm RIPPERk that is very competitive with C4.5rules with respect to error rates, but much more efficient on large samples. RIPPERk obtains error rates lower than or equivalent to C4.5rules on 22 of 37 benchmark problems, scales nearly linearly with the number of training examples, and can efficiently process noisy datasets containing hundreds of thousands of examples. 
260|An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants|Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets.  We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer.

The purpose of the study is to improve our understanding of why and
  when these algorithms, which use perturbation, reweighting, and
  combination techniques, affect classification error.  We provide a
  bias and variance decomposition of the error to show how different
  methods and variants influence these two terms.  This allowed us to
  determine that Bagging reduced variance of unstable methods, while
  boosting methods (AdaBoost and Arc-x4) reduced both the bias and
  variance of unstable methods but increased the variance for Naive-Bayes,
  which was very stable.  We observed that Arc-x4 behaves differently
  than AdaBoost if reweighting is used instead of resampling,
  indicating a fundamental difference.  Voting variants, some of which
  are introduced in this paper, include: pruning versus no pruning,
  use of probabilistic estimates, weight perturbations (Wagging), and
  backfitting of data.  We found that Bagging improves when
  probabilistic estimates in conjunction with no-pruning are used, as
  well as when the data was backfit.  We measure tree sizes and show
  an interesting positive correlation between the increase in the
  average tree size in AdaBoost trials and its success in reducing the
  error.  We compare the mean-squared error of voting methods to
  non-voting methods and show that the voting methods lead to large
  and significant reductions in the mean-squared errors.  Practical
  problems that arise in implementing boosting algorithms are
  explored, including numerical instabilities and underflows.  We use
  scatterplots that graphically show how AdaBoost reweights instances,
  emphasizing not only &#034;hard&#034; areas but also outliers and noise.

261|Bias plus variance decomposition for zero-one loss functions|We present a bias-variance decomposition of expected misclassi cation rate, the most commonly used loss function in supervised classi cation learning. The bias-variance decomposition for quadratic loss functions is well known and serves as an important tool for analyzing learning algorithms, yet no decomposition was o ered for the more commonly used zero-one (misclassi cation) loss functions until the recent work of Kong &amp; Dietterich (1995) and Breiman (1996). Their decomposition su ers from some major shortcomings though (e.g., potentially negative variance), which our decomposition avoids. We show that, in practice, the naive frequency-based estimation of the decomposition terms is by itself biased and show how to correct for this bias. We illustrate the decomposition on various algorithms and datasets from the UCI repository. 1
262|Error Correlation And Error Reduction In Ensemble Classifiers|Using an ensemble of classifiers, instead of a single classifier, can lead to improved generalization.  The gains obtained by combining however, are often affected more by the selection  of what is presented to the combiner, than by the actual combining method that is chosen.  In this paper we focus on data selection and classifier training methods, in order to &#034;prepare&#034;  classifiers for combining. We review a combining framework for classification problems that  quantifies the need for reducing the correlation among individual classifiers. Then, we discuss  several methods that make the classifiers in an ensemble more complementary. Experimental  results are provided to illustrate the benefits and pitfalls of reducing the correlation among  classifiers, especially when the training data is in limited supply.  2  1 Introduction  A classifier&#039;s ability to meaningfully respond to novel patterns, or generalize, is perhaps its most important property (Levin et al., 1990; Wolpert, 1990). In...
263|A streaming ensemble algorithm (SEA) for large-scale classification  (2001) |Classification
264|RainForest - a Framework for Fast Decision Tree Construction of Large Datasets|Classification of large datasets is an important data mining problem. Many classification algorithms have been proposed in the literature, but studies have shown that so far no algorithm uniformly outperforms all other algorithms in terms of quality. In this paper, we present a unifying framework for decision tree classifiers that separates the scalability aspects of algorithms for constructing a decision tree from the central features that determine the quality of the tree. This generic algorithm is easy to instantiate with specific algorithms from the literature (including C4.5, CART,
265|A Unified Bias-Variance Decomposition and its Applications|This paper presents a unified bias-variance  decomposition that is applicable to squared  loss, zero-one loss, variable misclassification  costs, and other loss functions. The unified  decomposition sheds light on a number of significant  issues: the relation between some of  the previously-proposed decompositions for  zero-one loss and the original one for squared  loss, the relation between bias, variance and  Schapire et al.&#039;s (1997) notion of margin, and  the nature of the trade-o# between bias and  variance in classification. While the biasvariance  behavior of zero-one loss and variable  misclassification costs is quite di#erent  from that of squared loss, this di#erence derives  directly from the di#erent definitions of  loss. We have applied the proposed decomposition  to decision tree learning, instancebased  learning and boosting on a large suite  of benchmark data sets, and made several significant  observations.  1. Introduction  The bias-variance decomposition is a key too...
266|Pasting Bites Together For Prediction In Large Data Sets And On-Line|The size of many data bases have grown to the point where they cannot fit into the fast memory of even large memory machines, to say nothing of current workstations. If what we want to do is to use these data bases to construct predictions of various characteristics, then since the usual methods require that all data be held in fast memory, various work-arounds have to be used. This paper studies one such class of methods which give accuracy comparable to that which could have been obtained if all data could have been held in core and which are computationally fast. The procedure takes small bites of the data, grows a predictor on each small bite and then pastes these predictors together. The methods are also applicable to on-line learning. *Partially supported by NSF Grant 1-444063-21445 1. Introduction.  Suppose that the data base D is a large collection of examples (y n ,x n ) where the x n are input vectors and the y n are class labels. What we want to do is use this data to constr...
267|Progressive Modeling|Presently, inductive learning is still performed in a frustrating batch process. The user has little interaction with the system and no control over the final accuracy and training time. If the accuracy of the produced model is too low, all the computing resources are misspent. In this paper, we propose a progressive modeling framework. In progressive modeling, the learning algorithm estimates online both the accuracy of the final model and remaining training time. If the estimated accuracy is far below expectation, the user can terminate training prior to completion without wasting further resources. If the user chooses to complete the learning process, progressive modeling will compute a model with expected accuracy in expected time. We describe one implementation of progressive modeling using ensemble of classifiers.
268|Distributed Learning on Very Large Data Sets|One approach to learning from intractably large data sets is to utilize all the training data by learning models on tractably sized subsets of the data. The subsets of data may be disjoint or partially overlapping. The individual learned models may be combined into a single model or a voting approachmay be used to combine the classi#cations of a set of models. An approach to learning models in parallel from arbitrarily large training data sets and combining them into a classi#er is described. The training sets are disjoint in the work described here. A parallel implementation on the DOE&#039;s ASCI Red parallel supercomputer is described. Results with data sets small enough to be handled by a single processor show that data sets can be divided into a moderate number of distinct subsets without degrading classi#er accuracy. Speedup results are shown for a parallel implementation on the ASCI Red with data sets too large to be handled on a single processor. Training sets of size 3 to 50 millio...
269|Pruning and dynamic scheduling of cost-sensitive ensembles|Previous research has shown that averaging ensemble can scale up learning over very large cost-sensitive datasets with linear speedup independent of the learning algorithms. At the same time, it achieves the same or even better accuracy than a single model computed from the entire dataset. However, one major drawback is its inefficiency in prediction since every base model in the ensemble has to be consulted in order to produce a final prediction. In this paper, we propose several approaches to reduce the number of base classifiers. Among various methods explored, our empirical studies have shown that the benefit-based greedy approach can safely remove more than 90 % of the base models while maintaining or even exceeding the prediction accuracy of the original ensemble. Assuming that each base classifier consumes one unit of prediction time, the removal of 90 % of base classifiers translates to a prediction speedup of 10 times. On top of pruning, we propose a novel dynamic scheduling approach to further reduce the “expected ” number of classifiers employed in prediction. It measures the confidence of a prediction by a subset of classifiers in the pruned ensemble. This confidence is used to decide if more classifiers are needed in order to produce a prediction that is the same as the original unpruned ensemble. This approach reduces the “expected ” number of classifiers by another 25 % to 75 % without loss of accuracy.
270|Active mining of data streams |Most previously proposed mining methods on data streams make an unrealistic assumption that “labelled ” data stream is readily available and can be mined at anytime. However, in most real-world problems, labelled data streams are rarely immediately available. Due to this reason, models are refreshed periodically, that is usually synchronized with data availability schedule. There are several undesirable consequences of this “passive periodic refresh”. In this paper, we propose a new concept of demand-driven active data mining. It estimates the error of the model on the new data stream without knowing the true class labels. When significantly higher error is suspected, it investigates the true class labels of a selected number of examples in the most recent data stream to verify the suspected higher error.
271|Online learning Data streams|tree-based ensembles and option trees for regression on evolving data streams
273|Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy|Diversity among the members of a team of classifiers is deemed to be a key issue in classifier combination. However, measuring diversity is not straightforward because there is no generally accepted formal definition. We have found and studied ten statistics which can measure diversity among binary classifier outputs (correct or incorrect vote for the class label): four averaged pairwise measures (the Q statistic, the correlation, the disagreement and the double fault) and six non-pairwise measures (the entropy of the votes, the difficulty index, the Kohavi-Wolpert variance, the interrater agreement, the generalized diversity, and the coincident failure diversity). Four experiments have been designed to examine the relationship between the accuracy of the team and the measures of diversity, and among the measures themselves. Although there are proven connections between diversity and accuracy in some special cases, our results raise some doubts about the usefulness of diversity measures in building classifier ensembles in real-life pattern recognition problems.
274|Issues in Stacked Generalization|Stacked generalization is a general method of using a high-level model to combine lower-level models to achieve greater predictive accuracy. In this paper we address two crucial issues which have been considered to be a `black art&#039; in classification tasks ever since the introduction of stacked generalization in 1992 by Wolpert: the type of generalizer that is suitable to derive the higher-level model, and the kind of attributes that should be used as its input. We find that best results are obtained when the higher-level model combines the confidence (and not just the predictions) of the lower-level ones.
275|New Ensemble Methods For Evolving Data Streams |Advanced analysis of data streams is quickly becoming a key area of data mining research as the number of applications demanding such processing increases. Online mining when such data streams evolve over time, that is when concepts drift or change completely, is becoming one of the core issues. When tackling non-stationary concepts, ensembles of classifiers have several advantages over single classifier methods: they are easy to scale and parallelize, they can adapt to change quickly by pruning under-performing parts of the ensemble, and they therefore usually also generate more accurate concept descriptions. This paper proposes a new experimental data stream framework for studying concept drift, and two new variants of Bagging: ADWIN Bagging and Adaptive-Size Hoeffding Tree (ASHT) Bagging. Using the new experimental framework, an evaluation study on synthetic and real-world datasets comprising up to ten million examples shows that the new ensemble methods perform very well compared to several known methods.
277|Learning from time-changing data with adaptive windowing|We present a new approach for dealing with distribution change and concept drift when learning from data sequences that may vary with time. We use sliding windows whose size, instead of being fixed a priori, is recomputed online according to the rate of change observed from the data in the window itself. This delivers the user or programmer from having to guess a time-scale for change. Contrary to many related works, we provide rigorous guarantees of performance, as bounds on the rates of false positives and false negatives. Using ideas from data stream algorithmics, we develop a time- and memory-efficient version of this algorithm, called ADWIN2. We show how to combine ADWIN2 with the Naïve Bayes (NB) predictor, in two ways: one, using it to monitor the error rate of the current model and declare when revision is necessary and, two, putting it inside the NB predictor to maintain up-to-date estimations of conditional probabilities in the data. We test our approach using synthetic and real data streams and compare them to both fixed-size and variable-size window strategies with good results.
278|Accurate decision trees for mining high-speed data streams|In this paper we study the problem of constructing accurate decision tree models from data streams. Data streams are incremental tasks that require incremental, online, and any-time learning algorithms. One of the most successful algorithms for mining data streams is VFDT. In this paper we extend the VFDT system in two directions: the ability to deal with continuous data and the use of more powerful classification techniques at tree leaves. The proposed system, VFDTc, can incorporate and classify new information online, with a single scan of the data, in time constant per example. The most relevant property of our system is the ability to obtain a performance similar to a standard decision tree algorithm even for medium size datasets. This is relevant due to the any-time property. We study the behaviour of VFDTc in different problems and demonstrate its utility in large and medium data sets. Under a bias-variance analysis we observe that VFDTc in comparison to C4.5 is able to reduce the variance component.
279|Option Decision Trees with Majority Votes|We describe an experimental study of Option  Decision Trees with majority votes. Option  Decision Trees generalize regular decision  trees by allowing option nodes in addition  to decision nodes; such nodes allow for  several possible tests to be conducted instead  of the commonly used single test. Our goal  was to explore when option nodes are most  useful and to control the growth of the trees  so that additional complexity of little utility  is limited. Option Decision Trees can reduce  the error of decision trees on real-world problems  by combining multiple options, with the  motivation similar to that of voting algorithms  that learn multiple models and combine  the predictions. However, unlikevoting  algorithms, an Option Decision Tree provides  a single structured classifier (one decision  tree), which can be interpreted more easily  by humans. Our results show that for the  tested problems, we can achieve significant  reduction in error rates for trees restricted to  two levels of o...
280|Boosting Classifiers for Drifting Concepts|This paper proposes a boosting-like method to train a classifier ensemble from data streams. It naturally adapts to concept drift and allows to quantify the drift in terms of its base learners. The algorithm is empirically shown to outperform learning algorithms that ignore concept drift. It performs no worse than advanced adaptive time window and example selection strategies that store all the data and are thus not suited for mining massive streams.
281|Leveraging bagging for evolving data streams |Abstract. Bagging, boosting and Random Forests are classical ensemble methods used to improve the performance of single classifiers. They obtain superior performance by increasing the accuracy and diversity of the single classifiers. Attempts have been made to reproduce these methods in the more challenging context of evolving data streams. In this paper, we propose a new variant of bagging, called leveraging bagging. This method combines the simplicity of bagging with adding more randomization to the input, and output of the classifiers. We test our method by performing an evaluation study on synthetic and real-world datasets comprising up to ten million examples. 1
282|Learning decision trees from dynamic data streams|Abstract: This paper presents a system for induction of forest of functional trees from data streams able to detect concept drift. The Ultra Fast Forest of Trees (UFFT) is an incremental algorithm, which works online, processing each example in constant time, and performing a single scan over the training examples. It uses analytical techniques to choose the splitting criteria, and the information gain to estimate the merit of each possible splitting-test. For multi-class problems the algorithm builds a binary tree for each possible pair of classes, leading to a forest of trees. Decision nodes and leaves contain naive-Bayes classifiers playing different roles during the induction process. Naive-Bayes in leaves are used to classify test examples. Naive-Bayes in inner nodes play two different roles. They can be used as multivariate splitting-tests if chosen by the splitting criteria, and used to detect changes in the class-distribution of the examples that traverse the node. When a change in the class-distribution is detected, all the sub-tree rooted at that node will be pruned. The use of naive-Bayes classifiers at leaves to classify test examples, the use of splitting-tests based on the outcome of naive-Bayes, and the use of naive-Bayes classifiers at decision nodes to detect changes in the distribution of the examples are directly obtained from the sufficient statistics required to compute the splitting criteria, without no additional computations. This aspect is a main advantage in the context of high-speed data streams. This methodology was tested with artificial and real-world data sets. The experimental results show a very good performance in comparison to a batch decision tree learner, and high capacity to detect drift in the distribution of the examples.
283|An Automatic Construction and Organization Strategy for Ensemble Learning on Data Streams |As data streams are gaining prominence in a growing number of emerging application domains, classification on data streams is becoming an active research area. Currently, the typical approach to this problem is based on ensemble learning, which learns basic classifiers from training data stream and forms the global predictor by organizing these basic ones. While this approach seems successful to some extent, its performance usually suffers from two contradictory elements existing naturally within many application scenarios: firstly, the need for gathering sufficient training data for basic classifiers and engaging enough basic learners in voting for bias-variance reduction; and secondly, the requirement for significant sensitivity to concept-drifts, which places emphasis on using recent training data and up-to-date individual classifiers. It results in such a dilemma that some algorithms are not sensitive enough to concept-drifts while others, although sensitive enough, suffer from unsatisfactory classification accuracy. In this paper, we propose an ensemble learning algorithm, which: (1) furnishes training data for basic classifiers, starting from the up-to-date data chunk and searching for complement from past chunks while ruling out the data inconsistent with current concept; (2) provides effective voting by adaptively distinguishing sensible classifiers from the else and engaging sensible ones as voters. Experimental results justify the superiority of this strategy in terms of both accuracy and sensitivity, especially in severe circumstances where training data is extremely insufficient or concepts are evolving frequently and significantly. 1.
284|Online coordinate boosting|We present a new online boosting algorithm for adapting the weights of a boosted classifier, which yields a closer approximation to Freund and Schapire’s AdaBoost algorithm than previous online boosting algorithms. We also contribute a new way of deriving the online algorithm that ties together previous online boosting work. We assume that the weak hypotheses were selected beforehand, and only their weights are updated during online boosting. The update rule is derived by minimizing AdaBoost’s loss when viewed in an incremental form. The equations show that optimization is computationally expensive. However, a fast online approximation is possible. We compare approximation error to batch AdaBoost on synthetic datasets and generalization error on face datasets and the MNIST dataset. 1
285|An Information Statistics Approach to Data Stream and Communication Complexity|We present a new method for proving strong lower bounds in communication complexity.
286|Graph-Based Algorithms for Boolean Function Manipulation|In this paper we present a new data structure for representing Boolean functions and an associated set of manipulation algorithms. Functions are represented by directed, acyclic graphs in a manner similar to the representations introduced by Lee [1] and Akers [2], but with further restrictions on the ordering of decision variables in the graph. Although a function requires, in the worst case, a graph of size exponential in the number of arguments, many of the functions encountered in typical applications have a more reasonable representation. Our algorithms have time complexity proportional to the sizes of the graphs being operated on, and hence are quite efficient as long as the graphs do not grow too large. We present experimental results from applying these algorithms to problems in logic design verification that demonstrate the practicality of our approach.
287|Monotone Complexity|We give a general complexity classification scheme for monotone  computation, including monotone space-bounded and Turing machine  models not previously considered. We propose monotone complexity  classes including mAC  i  , mNC  i  , mLOGCFL, mBWBP , mL, mNL, mP ,  mBPP and mNP . We define a simple notion of monotone reducibility  and exhibit complete problems. This provides a framework for stating  existing results and asking new questions.  We show that mNL (monotone nondeterministic log-space) is not  closed under complementation, in contrast to Immerman&#039;s and Szelepcs  &#039;enyi&#039;s nonmonotone result [Imm88, Sze87] that NL = co-NL; this  is a simple extension of the monotone circuit depth lower bound of  Karchmer and Wigderson [KW90] for st-connectivity.  We also consider mBWBP (monotone bounded width branching  programs) and study the question of whether mBWBP is properly  contained in mNC  1  , motivated by Barrington&#039;s result [Bar89] that  BWBP = NC  1  . Although we cannot answer t...
288|Divergence measures based on the Shannon entropy|Abstract-A new class of information-theoretic divergence measures based on the Shannon entropy is introduced. Unlike the well-known Kullback divergences, the new measures do not require the condition of absolute continuity to be satisfied by the probability distributions in-volved. More importantly, their close relationship with the variational distance and the probability of misclassification error are established in terms of bounds. These bounds are crucial in many applications of divergence measures. The new measures are also well characterized by the properties of nonnegativity, finiteness, semiboundedness, and boundedness. Index Terms-Divergence, dissimilarity measure, discrimination in-formation, entropy, probability of error bounds. I.
290|A Parallel Repetition Theorem|We show that a parallel repetition of any two-prover one-round proof system (MIP(2, 1)) decreases the probability of error at an exponential rate. No constructive bound was previously known. The constant in the exponent (in our analysis) depends only on the original probability of error and on the total number of possible answers of the two provers. The dependency on the total number of possible answers is logarithmic, which was recently proved to be almost the best possible [U. Feige and O. Verbitsky, Proc. 11th Annual IEEE Conference on Computational Complexity, IEEE Computer Society Press, Los Alamitos, CA, 1996, pp. 70--76].
291|Informational Complexity and the Direct Sum Problem for Simultaneous Message Complexity|Given m copies of the same problem, does it take m times the amount of resources to solve these m problems? This is the direct sum problem, a fundamental question that has been studied in many computational models. We study this question in the simultaneous message (SM) model of communication introduced by Yao [Y79].  The equality problem for n-bit strings is well known to have SM complexity (  p  n). We prove that solving m copies of the problem has  complexity m  p  n); the best lower bound provable using previously known techniques is  p  mn). We also prove similar lower bounds on certain Boolean combinations of multiple copies of the equality function. These results can be generalized to a broader class of functions.  We introduce a new notion of informational complexity which is related to SM complexity and has nice direct sum properties. This notion is used as a tool to prove the above results; it appears to be quite powerful and may be of independent interest.  1 
292|Near-optimal lower bounds on the multi-party communication complexity of set disjointness|We study the communication complexity of the set disjointness problem in the general multi-party model. For t players, each holding a subset of a universe of size n, we establish a near-optimal lower bound of ?(n/(t log t)) on the communication complexity of the problem of determining whether their sets are disjoint. In the more restrictive one-way communication model, in which the players are required to speak in a predetermined order, we improve our bound to an optimal ?(n/t). These results improve upon the earlier bounds of ?(n/t 2) in the general model, and ?(e 2 n/t 1+e) in the one-way model, due to Bar-Yossef, Jayram, Kumar, and Sivakumar [5]. As in the case of earlier results, our bounds apply to the unique intersection promise problem. This communication problem is known to have connections with the space complexity of approximating frequency moments in the data stream model. Our results lead to an improved space complexity lower bound of ?(n 1-2/k / log n) for approximating the k th frequency moment with a constant number of passes over the input, and a technical improvement to ?(n 1-2/k) if only one pass over the input is permitted. Our proofs rely on the information theoretic direct sum decomposition paradigm of Bar-Yossef et al [5]. Our improvements stem from novel analytical tech-
293|On Randomized One-Round Communication Complexity|We present several results regarding randomized one-round communication complexity. Our results include a connection to the VCdimension, a study of the problem of computing the inner product of two real valued vectors, and a relation between \simultaneous&#034; protocols and one-round protocols.  Key words. Communication Complexity; One-round and simultaneous protocols; VC-dimension;  Subject classications. 68Q25. 1. 
294|Super-Logarithmic Depth Lower Bounds Via The Direct Sum In Communication Complexity| Is it easier to solve two communication problems together than separately? This question is related to the complexity of the composition of boolean functions. Based on this relationship, an approach to separating NC 1 from P is outlined. Furthermore, it is shown that the approach provides a new proof of the separation of monotone NC 1 from monotone P. 
295|The Communication Complexity of Efficient Allocation Problems|We analyze the communication complexity of surplus-maximizing allocations. We study both the continuous and discrete models of communication, measuring its complexity with the dimensionality of the message space and the number of transmitted bits, respectively. In both cases, we offer a lower bound on the amount of communication. This bound is applied to the problem of allocating L heterogeneous objects among N agents, whose valuations are (i) unrestricted, (ii) submodular, or (iii) homogeneous in objects. In cases (i) and (ii), efficiency requires exponential communication in L. Furthermore, in case (i), polynomial communication in L cannot achieve a higher surplus than selling all objects as a bundle. On the other hand, in case (iii), exact efficiency requires the transmission of L numbers, but arbitrarily close approximation is achieved with only O(log L) bits. When a Walrasian equilibrium with per-item prices exists, efficiency is achieved with deterministic communication that is polynomial in L.
296|Two Applications of Information Complexity|We show the following new lower bounds in two concrete complexity models:  (1) In the two-party communication complexity model, we show that the tribes function on n inputs [6] has two-sided error randomized complexity # n), while its nondeterminstic complexity and co-nondeterministic complexity are both #( # n). This separation between randomized and nondeterministic complexity is the best possible and it settles an open problem in Kushilevitz and Nisan [17], which was also posed by Beame and Lawry [5].
297|Information Theory Methods in Communication Complexity|We use tools and techniques from information theory to study communication complexity problems in the one-way and simultaneous communication models. Our results include: (1) A tight characterization of multi-party one-way communication complexity for product distributions in terms of VC-dimension and shatter coefficients; (2) An equivalence of multi-party one-way and simultaneous communication models for product distributions; (3) A suite of lower bounds for specific functions in the simultaneous communication model, most notably an optimal lower bound for the multi-party set disjointness problem of Alon et al. [AMS99] and for the generalized addressing function problem of Babai et al. [BGKL96] for arbitrary groups. Methodologically, our main contribution is rendering communication complexity problems in the framework of information theory. This allows us access to the powerful calculus of information theory and the use of fundamental principles such as Fano&#039;s inequality and the Maximum Likelihood Estimate Principle.
298|A lower bound for the bounded round quantum communication complexity of set disjointness | We show lower bounds in the multi-party quantum communication complexity model. In this model, there are t parties where the ith party has input Xi ? [n]. These parties communicate with each other by transmitting qubits to determine with high probability the value of some function F of their combined input (X1,...,Xt). We consider the class of Boolean valued functions whose value depends only on X1 n...n Xt; that is, for each F in this class there is an fF : 2[n] ? {0,1}, such that F(X1,...,Xt) = fF(X1 n...n Xt). We show that the t-party k-round communication complexity of F is O(sm(fF)/(k2)), where sm(fF) stands for the monotone sensitivity of fF&#039; and is defined by sm(fF) = &amp;utri; maxS?[n] |{i : fF(S ? {i}) ? fF(S)}|. For two-party quantum communication protocols for the set disjointness problem, this implies that the two parties must exchange O(n/k2) qubits. An upper bound of O(n/k) can be derived from the O(vn) upper bound due to S. Aaronson and A. Ambainis (2003). For k = 1, our lower bound matches the O(n) lower bound observed by H. Buhrman and R. de Wolf (2001) (based on a result of A. Nayak (1999)), and for 2 = k &amp;Lt; n14 /, improves the lower bound of O(vn) shown by A. Razborov (2002). For protocols with no restrictions on the number of rounds, we can conclude that the two parties must exchange O(n13/) qubits. This, however, falls short of the optimal O (vn) lower bound shown by A. Razborov (2002). Our result is obtained by adapting to the quantum setting the elegant information-theoretic arguments of Z. Bar-Yossef et al. (2002). Using this method we can show similar lower bounds for the L8 function considered in Z. Bar-Yossef et al. (2002).
299|Privacy, Additional Information, and Communication|Two parties, each holding one input of a two-variable function, communicate in order to determine the value of the function. Each party wants to expose as little of its input as possible to the other party. We prove tight bounds on the minimum amount of information about the individual inputs that must be revealed in the computation of most functions and of some specific ones, and show that a computation that reveals little information about the individual inputs may require many more message exchanges than a more revealing computation.  Key words: Private distributed protocols, additional-information, communication-complexity, rounds-complexity. 1 Introduction  Let f be a function of two n-bit inputs, x and y. Two honest parties, PX holding x and P Y having  y, each with unlimited computing power, communicate to determine f(x; y). Each party wants to keep as much of its input secret from the other party. For some privately computable functions this can be done without revealing any mo...
300|StatStream: Statistical Monitoring of Thousands of Data Streams in Real Time|Consider the problem of monitoring tens of thousands of time series data streams in an online fashion and making decisions based on them. In addition to single stream statistics such as average and standard deviation, we also want to find high correlations among all pairs of streams. A stock market trader might use such a tool to spot arbitrage opportunities.
301|Efficient similarity search in sequence databases|We propose an indexing method for time sequences for processing similarity queries. We use the Discrete Fourier Transform (DFT) to map time sequences to the frequency domain, the crucial observation being that, for most sequences of practical interest, only the first few frequencies are strong. Another important observation is Parseval&#039;s theorem, which specifies that the Fourier transform preserves the Euclidean distance in the time or frequency domain. Having thus mapped sequences to a lower-dimensionality space by using only the first few Fourier coe cients, we use R-trees to index the sequences and e ciently answer similarity queries. We provide experimental results which show that our method is superior to search based on sequential scanning. Our experiments show that a few coefficients (1-3) are adequate to provide good performance. The performance gain of our method increases with the number and length of sequences. 
302|Locally Adaptive Dimensionality Reduction for Indexing Large Time Series Databases|Similarity search in large time series databases has attracted much research interest recently. It is a difficult problem because of the typically high dimensionality of the data.. The most promising solutions&#039; involve performing dimensionality reduction on the data, then indexing the reduced data with a multidimensional index structure. Many dimensionality reduction techniques have been proposed, including Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), and the Discrete Wavelet Transform (DWT). In this work we introduce a new dimensionality reduction technique which we call Adaptive Piecewise Constant Approximation (APCA). While previous techniques (e.g., SVD, DFT and DWT) choose a common representation for all the items in the database that minimizes the global reconstruction error, APCA approximates each time series by a set of constant value segments&#039; of varying lengths&#039; such that their individual reconstruction errors&#039; are minimal. We show how APCA can be indexed using a multidimensional index structure. We propose two distance measures in the indexed space that exploit the high fidelity of APCA for fast searching: a lower bounding Euclidean distance approximation, and a non-lower bounding, but very tight Euclidean distance approximation and show how they can support fast exact searchin&amp; and even faster approximate searching on the same index structure. We theoretically and empirically compare APCA to all the other techniques and demonstrate its&#039; superiority.
303|Efficient time series matching by wavelets|Time series stored as feature vectors can be indexed by multidimensional index trees like R-Trees for fast retrieval. Due to the dimensionality curse problem, transformations are applied to time series to reduce the number of dimensions of the feature vectors. Different transformations like Discrete Fourier Transform (DFT), Discrete Wavelet Transform (DWT), Karhunen-Loeve (K-L) transform or Singular Value Decomposition (SVD) can be applied. While the use of DFT and K-L transform or SVD have been studied in the literature, to our knowledge, there is no in-depth study on the application of DWT. In this paper, we propose to use Haar Wavelet Transform for time series indexing. The major contributions are: (1) we show that Euclidean distance is preserved in the Haar transformed domain and no false dismissal will occur, (2) we show that Haar transform can outperform DFT through experiments, (3) a new similarity model is suggested to accommodate vertical shift of time series, and (4) a two-phase method is proposed for efficient-nearest neighbor query in time series databases. 1.
304|Similarity-Based Queries for Time Series Data|We study a set of linear transformations on the Fourier series representation of a sequence that can be used as the basis for similarity queries on time-series data. We show that our set of transformations is rich enough to formulate operations such as moving average and time warping. We present a query processing algorithm that uses the underlying R-tree index of a multidimensional data set to answer similarity queries efficiently. Our experiments show that the performance of this algorithm is competitive to that of processing ordinary (exact match) queries using the index, and much faster than sequential scanning. We relate our transformations to the general framework for similarity queries of Jagadish et al. 1
305|Efficiently Supporting Ad Hoc Queries in Large Datasets of Time Sequences|Ad hoc querying is difficult on very large datasets, since it is usually not possible to have the entire dataset on disk. While compression can be used to decrease the size of the dataset, compressed data is notoriously difficult to index or access. In this paper we consider a very large dataaet comprising multiple distinct time sequences. Each point in the sequence is a numerical value. We show how to compress such a dataset into a format that supports ad hoc querying, provided that a small error can be tolerated when the data is uncompressed. Experiments on large, real world datasets (AT&amp;T customer calling patterns) show that the proposed method achieves an average of less thau 5% error in any data value after compressing to a mere 2.5% of the original space (i. e., a 40:1 compression ratio), with these numbers not very sensitive to dataset size. Experiments on aggregate queries achieved a 0.5% reconstruction error with a space requirement under 2%.  
306|On Similarity Queries for Time-Series Data: Constraint Specification and Implementation|Constraints are a natural mechanism for the specification of similarity queries on time-series data. However, to realize the expressive power of constraint programming in this context, one must provide the matching implementation technology for efficient indexing of very large data sets. In this paper, we formalize the intuitive notions of exact and approximate similarity between time-series patterns and data. Our definition of similarity extends the distance metric used in [2, 7] with invariance under a group of transformations. Our main observation is that the resulting, more expressive, set of constraint queries can be supported by a new indexing technique, which preserves all the desirable properties of the indexing scheme proposed in [2, 7].
307|Optimal expected-time algorithms for closest point problems|Geometric closest potnt problems deal with the proxLmity relationships in k-dimensional point sets. Examples of closest point problems include building minimum spanning trees, nearest neighbor searching, and triangulation constructmn Shamos and Hoey [17] have shown how the Voronoi dtagram can be used to solve a number of planar closest point problems in optimal worst case tune. In this paper we extend thmr work by giving optimal expected.trine algorithms for solving a number of closest point problems in k-space, including nearest neighbor searching, finding all nearest neighbors, and computing planar minimum spanning trees. In addition to establishing theoretical bounds, the algorithms in this paper can be implemented to solve practical problems very efficiently. Key Words and Phrases &#039; computational geometry, closest point problems, minunum spanning trees, nearest neighbor searching, optimal algorithms, probabfllstm analysis of algorithms, Voronoi diagrams CR Categories: 3.74, 5 25, 5.31, 5.32 1.
308|Similarity search over time series data using wavelets|We consider the use of wavelet transformations as a dimensionality reduction technique to permit efficient similarity search over high-dimensional time-series data. While numerous transformations have been proposed and studied, the only wavelet that has been shown to be effective for this application is the Haar wavelet. In this work, we observe that a large class of wavelet transformations (not only orthonormal wavelets but also bi-orthonormal wavelets)can be used to support similarity search. This class includes the most popular and most effective wavelets being used in image compression. We present a detailed performance study of the effects of using different wavelets on the performance of similarity search for time-series data. We include several wavelets that outperform both the Haar wavelet and the best known non-wavelet transformations for this application. To ensure our results are usable by an application engineer, we also show how to configure an indexing strategy for the best performing transformations. Finally, we identify classes of data that can be indexed efficiently using these wavelet transformations. 1.
309|Efficient Retrieval of Similar Time Sequences Using DFT|We propose an improvement of the known DFTbased indexing technique for fast retrieval of similar time sequences. We use the last few Fourier coefficients in the distance computation without storing them in the index since every coefficient at the end is the complex conjugate of a coefficient at the beginning and as strong as its counterpart. We show analytically that this observation can accelerate the search time of the index by more than a factor of two. This result was confirmed by our experiments, which were carried out on real stock prices and synthetic data. Keywords similarity retrieval, time series indexing 1
310|XTream: personal data streams|The real usability of data stream systems depends on the practical aspect of building applications on data streams. In this demo we show two possible applications on data streams implemented on our prototype platform XTream. One application integrates VoIP and E-Mail, the other one incorporates streams in a Smart Home setting. Using these applications we try to identify and discuss the functional-ity that data stream management systems should provide. Those attending the demo will be able to compose their own applications.
311|Concierge: A Service Platform for Resource-Constrained Devices|As mobile and embedded devices become widespread, the management and configuration of the software in the devices is increasingly turning into a critical issue. OSGi is a business standard for the life cycle management of Java software components. It is based on a service oriented architecture where functional units are decoupled and components can be managed independently of each other. However, the focus continuously shifts from the originally intended area of small and embedded devices towards large-scaled enterprise systems. As a result, implementations of the OSGi framework are increasingly becoming more heavyweight and less suitable for smaller computing devices. In this paper, we describe the experience gathered during the design of Concierge, an implementation of the OSGi specification tailored to resource-constrained devices. Comprehensive benchmarks show that Concierge performs better than existing implementations and consumes less resources.
312|Stream Control Transmission Protocol|This document is an Internet-Draft and is in full conformance with all provisions of Section 10 of RFC 2026. Internet-Drafts are working documents of the Internet Engineering Task Force (IETF), its areas, and its working groups. Note that other groups may also distribute working documents as Internet-Drafts. Internet-Drafts are draft documents valid for a maximum of six months and may be updated, replaced, or obsoleted by other documents at any time. It is inappropriate to use Internet- Drafts as reference material or to cite them other than as ‘‘work in progress.’’ The list of current Internet-Drafts can be accessed at
313|On Estimating End-to-End Network Path Properties|The more information about current network conditions available to a transport protocol, the more efficiently it can use the network to transfer its data. In networks such as the Internet, the transport protocol must often form its own estimates of network properties based on measurements performed by the connection endpoints. We consider two basic transport estimation problems: determining the setting of the retransmission timer (RTO) for a reliable protocol, and estimating the bandwidth available to a connection as it begins. We look at both of these problems in the context of TCP, using a large TCP measurement set [Pax97b] for trace-driven simulations. For RTO estimation, we evaluate a number of different algorithms, finding that the performance of the estimators is dominated by their minimum values, and to a lesser extent, the timer granularity, while being virtually unaffected by how often round-trip time measurements are made or the settings of the parameters in the exponentially-weighted moving average estimators commonly used. For bandwidth estimation, we explore techniques previously sketched in the literature [Hoe96, AD98] and find that in practice they perform less well than anticipated. We then develop a receiver-side algorithm that performs significantly better. 1
315|TCP congestion control with a misbehaving receiver|In this paper, we explore the operation of TCP congestion control when the receiver can misbehave, as might occur with a greedy Web client. We first demonstrate that there are simple attacks that allow a misbehaving receiver to drive a standard TCP sender arbitrarily fast, without losing end-to-end reliability. These attacks are widely applicable because they stem from the sender behavior specified in RFC 2581 rather than implementation bugs. We then show that it is possible to modify TCP to eliminate this undesirable behavior entirely, without requiring assumptions of any kind about receiver behavior. This is a strong result: with our solution a receiver can only reduce the data transfer rate by misbehaving, thereby eliminating the incentive to do so. 1
316|Randomness Requirements for Security|This document is intended to become a Best Current Practice. Comments should be sent to the authors. Distribution is unlimited. This document is an Internet-Draft and is in full conformance with all provisions of Section 10 of RFC 2026. Internet-Drafts are working documents of the Internet Engineering Task Force (IETF), its areas, and its working groups. Note that other groups may also distribute working documents as Internet-Drafts. Internet-Drafts are draft documents valid for a maximum of six months and may be updated, replaced, or obsoleted by other documents at any time. It is inappropriate to use Internet-Drafts as reference material or to cite them other than as &#034;work in progress. &#034; The list of current Internet-Drafts can be accessed at http://www.ietf.org/ietf/1id-abstracts.txt The list of Internet-Draft Shadow Directories can be accessed at
317|Mining Data Streams|Abstract: Mining data streams has raised a number of research challenges for the data mining community. These challenges include the limitations of computational resources, especially because mining streams of data most likely be done on a mobile device with limited resources. Also due to the continuality of data streams, the algorithm should have only one pass or less over the incoming data records. In this article, our Algorithm Output Granularity (AOG) approach in mining data streams is discussed. AOG is a novel adaptable approach that can cope with the challenging inherent features of data streams. We also show the results for AOG based clustering in a resource constrained environment.
318|Clustering of Time Series Subsequences is Meaningless: Implications for Past and Future Research|Time series data is perhaps the most frequently encountered type of data examined by the data mining community. Clustering is perhaps the most frequently used data mining algorithm, being useful in it’s own right as an exploratory technique, and also as a subroutine in more complex data mining algorithms such as rule discovery, indexing, summarization, anomaly detection, and classification. Given these two facts, it is hardly surprising that time series clustering has attracted much attention. The data to be clustered can be in one of two formats: many individual time series, or a single time series, from which individual time series are extracted with a sliding window. Given the recent explosion of interest in streaming data and online algorithms, the latter case has received much attention. In this work we make a surprising claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature. We can justify calling our claim surprising, since it invalidates the contribution of dozens of previously published papers. We will justify our claim with a theorem, illustrative examples, and a comprehensive set of experiments on reimplementations of previous work. Although the primary contribution of our work is to draw attention to the fact that an apparent solution to an important problem is incorrect and should no longer be used, we also introduce a novel method which, based on the concept of time series motifs, is able to meaningfully cluster some streaming time series datasets.
319|A General Method for Scaling Up Machine Learning Algorithms and its Application to Clustering|We propose to scale learning algorithms to  arbitrarily large databases by the following  method. First derive an upper bound for  the learner&#039;s loss as a function of the number  of examples used in each step of the algorithm.
320|Adaptive, hands-off stream mining|Sensor devices and embedded processors are becoming ubiquitous, especially in measurement and monitoring applications. Automatic discovery of patterns and trends in the large volumes of such data is of paramount importance. The combination of relatively limited resources (CPU, memory and/or communication bandwidth and power) poses some interesting challenges. We need both powerful and concise “languages ” to represent the important features of the data, which can (a) adapt and handle arbitrary periodic components, including bursts, and (b) require little memory and a single pass over the data. This allows sensors to automatically (a) discover interesting patterns and trends in the data, and (b) perform outlier detection to alert users. We need a way so that a sensor can discover something like “the hourly phone call volume so far follows a daily and a weekly periodicity, with bursts roughly every year, ” which a human might recognize as, e.g., the Mother’s day surge. When possible and if desired, the user can then issue explicit queries to further investigate the reported patterns. In this work we propose AWSOM (Arbitrary Window Stream mOdeling Method), which allows sensors operating in remote or hostile environments to discover patterns efficiently and
322|Onboard Detection of Snow, Ice, Clouds and Other Geophysical Processes Using Kernel Methods|The detection of clouds within a satellite image  is essential for retrieving surface geophysical  parameters from optical and thermal imagery.
323|Adaptive Mining Techniques for Data Streams Using Algorithm Output Granularity Mohamed|Mining data streams is an emerging area of research given the potentially large number of business and scientific applications. A significant challenge in analyzing /mining data streams is the high data rate of the stream. In this paper, we propose a novel approach to cope with the high data rate of incoming data streams. We termed our approach &#034;algorithm output granularity&#034;. It is a resource-aware approach that is adaptable to available memory, time constraints, and data stream rate. The approach is generic and applicable to clustering, classification and counting frequent items mining techniques. We have developed a data stream clustering algorithm based on the algorithm output granularity approach. We present this algorithm and discuss its implementation and empirical evaluation. The experiments show acceptable accuracy accompanied with run-time efficiency. They show that the proposed algorithm outperforms the K-means in terms of running time while preserving the accuracy that our algorithm can achieve.
324|Data Stream Management Systems  |In many application fields, such as production lines or stock analysis, it is substantial to create and process high amounts of data at high rates. Such continuous data flows with unknown size and end are also called data streams. The processing and analysis of data streams are a challenge for common data management systems as they have to operate and deliver results in real time. Data Stream Management Systems (DSMS), as an advancement of database management systems, have been implemented to deal with these issues. DSMS have to adapt to the notion of data streams on various levels, such as query languages, processing or optimization. In this chapter we give an overview of the basics of data streams, architecture principles of DSMS and the used query languages. Furthermore, we specifically detail data quality aspects in DSMS as these play an important role for various applications based on data streams. Finally, the chapter also includes a list of research and commercial DSMS and their key properties.
325|The CQL Continuous Query Language: Semantic Foundations and Query Execution|CQL, a Continuous Query Language, is supported by the STREAM prototype Data Stream  Management System at Stanford. CQL is an expressive SQL-based declarative language for  registering continuous queries against streams and updatable relations. We begin by presenting  an abstract semantics that relies only on &#034;black box&#034; mappings among streams and relations.
326|Graphscope: parameter-free mining of large time-evolving graphs|How can we find communities in dynamic networks of social interactions, such as who calls whom, who emails whom, or who sells to whom? How can we spot discontinuity time-points in such streams of graphs, in an on-line, any-time fashion? We propose GraphScope, that addresses both prob-lems, using information theoretic principles. Contrary to the majority of earlier methods, it needs no user-defined param-eters. Moreover, it is designed to operate on large graphs, in a streaming fashion. We demonstrate the efficiency and effectiveness of our GraphScope on real datasets from sev-eral diverse domains. In all cases it produces meaningful time-evolving patterns that agree with human intuition.
327|On graph problems in a semi-streaming model|Abstract. We formalize a potentially rich new streaming model, the semi-streaming model, that we believe is necessary for the fruitful study of efficient algorithms for solving problems on massive graphs whose edge sets cannot be stored in memory. In this model, the input graph, G = (V, E), is presented as a stream of edges (in adversarial order), and the storage space of an algorithm is bounded by O(n · polylog n), where n = |V |. We are particularly interested in algorithms that use only one pass over the input, but, for problems where this is provably insufficient, we also look at algorithms using constant or, in some cases, logarithmically many passes. In the course of this general study, we give semi-streaming constant approximation algorithms for the unweighted and weighted matching problems, along with a further algorithm improvement for the bipartite case. We also exhibit log n / log log n semistreaming approximations to the diameter and the problem of computing the distance between specified vertices in a weighted graph. These are complemented by ?(log (1-?) n) lower bounds. 1
328|Exploiting punctuation semantics in continuous data streams|Abstract—As most current query processing architectures are already pipelined, it seems logical to apply them to data streams. However, two classes of query operators are impractical for processing long or infinite data streams. Unbounded stateful operators maintain state with no upper bound in size and, so, run out of memory. Blocking operators read an entire input before emitting a single output and, so, might never produce a result. We believe that a priori knowledge of a data stream can permit the use of such operators in some cases. We discuss a kind of stream semantics called punctuated streams. Punctuations in a stream mark the end of substreams allowing us to view an infinite stream as a mixture of finite streams. We introduce three kinds of invariants to specify the proper behavior of operators in the presence of punctuation. Pass invariants define when results can be passed on. Keep invariants define what must be kept in local state to continue successful operation. Propagation invariants define when punctuation can be passed on. We report on our initial implementation and show a strategy for proving implementations of these invariants are faithful to their relational counterparts. Index Terms—Continuous queries, stream semantics, continuous data streams, query operators, stream iterators. 1
329|A Middleware for Fast and Flexible Sensor Network Deployment|A key problem in current sensor network technology is the heterogeneity of the available software and hardware platforms which makes deployment and application development a tedious and time consuming task. To minimize the unnecessary and repetitive implementation of identical functionalities for different platforms, we present our Global Sensor Networks (GSN) middleware which supports the flexible integration and discovery of sensor networks and sensor data, enables fast deployment and addition of new platforms, provides distributed querying, filtering, and combination of sensor data, and supports the dynamic adaption of the system configuration during operation. GSN’s central concept is the virtual sensor abstraction which enables the user to declaratively specify XML-based deployment descriptors in combination with the possibility to integrate sensor network data through plain SQL queries over local and remote sensor data sources. In this demonstration, we specifically focus on the deployment aspects and allow users to dynamically reconfigure the running system, to add new sensor networks on the fly, and to monitor the effects of the changes via a graphical interface. The GSN implementation is available from
330|Stream: The stanford data stream management system|Traditional database management systems are best equipped to run onetime queries over finite stored data sets. However, many modern applications such as network monitoring, financial analysis, manufacturing, and sensor networks require long-running, or continuous, queries over continuous unbounded
331|Processing flows of information: from data stream to complex event processing|A large number of distributed applications requires continuous and timely processing of information as it flows from the periphery to the center of the system. Examples include intrusion detection systems which analyze network traffic in real-time to identify possible attacks; environmental monitoring applications which process raw data coming from sensor networks to identify critical situations; or applications performing online analysis of stock prices to identify trends and forecast future values. Traditional DBMSs, which need to store and index data before processing it, can hardly fulfill the requirements of timeliness coming from such domains. Accordingly, during the last decade, different research communities developed a number of tools, which we collectively call Information flow processing (IFP) systems, to support these scenarios. They differ in their system architecture, data model, rule model, and rule language. In this article, we survey these systems to help researchers, who often come from different backgrounds, in understanding how the various approaches they adopt may complement each other. In particular, we propose a general, unifying model to capture the different aspects of an IFP system and use it to provide a complete and precise classification of the systems and mechanisms proposed so far.
332|The 8 requirements of real-time stream processing|Applications that require real-time processing of high-volume data steams are pushing the limits of traditional data processing infrastructures. These stream-based applications include market feed processing and electronic trading on Wall Street, network and infrastructure monitoring, fraud detection, and command and control in military environments. Furthermore, as the “sea change ” caused by cheap micro-sensor technology takes hold, we expect to see everything of material significance on the planet get “sensor-tagged ” and report its state or location in real time. This sensorization of the real world will lead to a “green field ” of novel monitoring and control applications with high-volume and low-latency processing requirements. Recently, several technologies have emerged—including off-theshelf stream processing engines—specifically to address the challenges of processing high-volume, real-time data without requiring the use of custom code. At the same time, some existing software technologies, such as main memory DBMSs and rule engines, are also being “repurposed ” by marketing departments to address these applications. In this paper, we outline eight requirements that a system software should meet to excel at a variety of real-time stream processing applications. Our goal is to provide high-level guidance to information technologists so that they will know what to look for when evaluation alternative stream processing solutions. As such, this paper serves a purpose comparable to the requirements papers in relational DBMSs and on-line analytical processing. We also briefly review alternative system software technologies in the context of our requirements. The paper attempts to be vendor neutral, so no specific commercial products are mentioned. 1.
333|Semantics and evaluation techniques for window aggregates in data streams|A windowed query operator breaks a data stream into possibly overlapping subsets of data and computes a result over each. Many stream systems can evaluate window aggregate queries. However, current stream systems suffer from a lack of an explicit definition of window semantics. As a result, their implementations unnecessarily confuse window definition with physical stream properties. This confusion complicates the stream system, and even worse, can hurt performance both in terms of memory usage and execution time. To address this problem, we propose a framework for defining window semantics, which can be used to express almost all types of windows of which we are aware, and which is easily extensible to other types of windows that may occur in the future. Based on this definition, we explore a one-pass query evaluation strategy, the Window-ID (WID) approach, for various types of window aggregate queries. WID significantly reduces both required memory space and execution time for a large class of window definitions. In addition, WID can leverage punctuations to gracefully handle disorder. Our experimental study shows that WID has better execution-time performance than existing window aggregate query evaluation options that retain and reprocess tuples, and has better latency-accuracy tradeoffs for disordered input streams compared to using a fixed delay for handling disorder. 1.
334|Staying FIT: Efficient Load Shedding Techniques for Distributed Stream Processing|In distributed stream processing environments, large numbers of continuous queries are distributed onto multiple servers. When one or more of these servers become overloaded due to bursty data arrival, excessive load needs to be shed in order to preserve low latency for the query results. Because of the load dependencies among the servers, load shedding decisions on these servers must be well-coordinated to achieve end-to-end control on the output quality. In this paper, we model the distributed load shedding problem as a linear optimization problem, for which we propose two alternative solution approaches: a solver-based centralized approach, and a distributed approach based on metadata aggregation and propagation, whose centralized implementation is also available. Both of our solutions are based on generating a series of load shedding plans in advance, to be used under certain input load conditions. We have implemented our techniques as part of the Borealis distributed stream processing system. We present experimental results from our prototype implementation showing the performance of these techniques under different input and query workloads. 1.
335|XSQ: A streaming XPath engine|We have implemented and released the XSQ system for evaluating XPath queries on streaming XML data. XSQ supports XPath features such as multiple predicates, closures, and aggregation, which pose interesting challenges for streaming evaluation. Our implementation is based on using a hierarchical arrangement of augmented finite state automata. A design goal of XSQ is buffering data for the least amount of time possible. We present a detailed experimental study that characterizes the performance of XSQ and related systems, and that illustrates the performance implications of XPath features such as closures.
336|Dense Subgraph Maintenance under Streaming Edge Weight Updates for Realtime Story Identification|Recent years have witnessed an unprecedented proliferation of social media. People around the globe author, every day, millions of blog posts, micro-blog posts, social network status updates, etc. This rich stream of information can be used to identify, on an ongoing basis, emerging stories, and events that capture popular attention. Stories can be identified via groups of tightly-coupled realworld entities, namely the people, locations, products, etc., that are involved in the story. The sheer scale, and rapid evolution of the data involved necessitate highly efficient techniques for identifying important stories at every point of time. The main challenge in real-time story identification is the maintenance of dense subgraphs (corresponding to groups of tightlycoupled entities) under streaming edge weight updates (resulting from a stream of user-generated content). This is the first work to study the efficient maintenance of dense subgraphs under such streaming edge weight updates. For a wide range of definitions of density, we derive theoretical results regarding the magnitude of change that a single edge weight update can cause. Based on these, we propose a novel algorithm, DYNDENS, which outperforms adaptations of existing techniques to this setting, and yields meaningful results. Our approach is validated by a thorough experimental evaluation on large-scale real and synthetic datasets. 
337|Exploiting PredicateWindow Semantics over Data Streams |The continuous sliding-window query model is used widely in data stream management systems where the focus of a continuous query is limited to a set of the most recent tuples. In this paper, we show that an interesting and important class of queries over data streams cannot be answered using the sliding-window query model. Thus, we introduce a new model for continuous window queries, termed the predicatewindow query model that limits the focus of a continuous query to the stream tuples that qualify a certain predicate. Predicate-window queries have some distinguishing characteristics, e.g., (1) The window predicate can be defined over any attribute in the stream tuple (ordered or unordered). (2) Stream tuples qualify and disqualify the window predicate in an out-of-order manner. In this paper, we discuss the applicability of the predicate-window query model. We will show how the existing sliding-window query models fail to answer some of the predicate-window queries. Finally, we discuss the challenges in supporting the predicate-window query model in data stream management systems. 1.
338| Extending XQuery with Window Functions |This paper presents two extensions for XQuery. The first extension allows the definition and processing of different kinds of windows over an input sequence; i.e., tumbling, sliding, and landmark windows. The second extension extends the XQuery data model (XDM) to support infinite sequences. This extension makes it possible to use XQuery as a language for continuous queries. Both extensions have been integrated into a Java-based open source XQuery engine. This paper gives details of this implementation and presents the results of running the Linear Road benchmark on the extended XQuery engine. 
339|AN OVERVIEW OF THE APPLICATIONS OF MULTISETS|  This paper presents a systemization of representation of multisets and basic operations under multisets, and an overview of the applications of multisets in mathematics, computer science and related areas.
340|PODS: a new model and processing algorithms for uncertain data streams|Uncertain data streams, where data is incomplete, imprecise, and even misleading, have been observed in a variety of environments. Feeding uncertain data streams to existing stream systems can produce results of unknown quality, which is of paramount concern to monitoring applications. In this paper, we present the Pods system that supports uncertain data stream processing for data that is naturally captured using continuous random variables. The Pods system employs a unique data model that is flexible and allows efficient computation. Built on this model, we develop evaluation techniques for complex relational operators, including aggregates and joins, by exploring advanced statistical theory and approximation techniques. Our evaluation results show that our techniques can achieve high performance in stream processing while satisfying accuracy requirements, and these techniques significantly outperform a state-of-the-art sampling-based method. Furthermore, initial results of a case study show that our modeling and aggregation techniques can allow a tornado detection system to produce better quality results yet with lower execution time. 1.
341|Logical Foundations of Continuous Query Languages for Data Streams |Abstract. Data Stream Management Systems (DSMS) have attracted much interest from the database community, and extensions of relational database languages were proposed for expressing continuous queries on data streams. However, while relational databases were built on the solid bedrock of logic, the same cannot be said for DSMS. Thus, a logic-based reconstruction of DSMS languages and their unique computational model is long overdue. Indeed, the banning of blocking queries and the fact that stream data are ordered by their arrival timestamps represent major new aspects that have yet to be characterized by simple theories. In this paper, we show that these new requirements can be modeled using the familiar deductive database concepts of closed-world assumption and explicit local stratification. Besides its obvious theoretical interest, this approach leads to the design of a powerful version of Datalog for data streams. This language is called Streamlog and takes the query and application languages of DSMS to new levels of expressive power, by removing the unnecessary limitations that severely impair current commercial systems and research prototypes. 1
342|A general algebra and implementation for monitoring event streams|Recently there has been considerable research on Data Stream Management Systems (DSMS) to support analysis of data that arrives rapidly in high-speed streams. Most of these systems have very expressive query languages in order to address a wide range of applications. In this paper, we take a different approach. Instead of starting with a very powerful data stream query language, we begin with a well-known class of languages — event languages. Through the addition of several simple, but powerful language constructs (namely parameterization and aggregates), we add pieces that extend their expressiveness towards full-fledged languages for processing data streams. Our resulting contributions are a novel algebra for expressing data stream queries, and a corresponding transformation of algebra expressions into finite state automata that can be implemented very efficiently. Our language is simple and natural, and it can express surprisingly powerful data stream queries. We formally introduce the language including a formal mapping of algebra expressions to finite state automata. Furthermore, we show the efficacy of our approach via an initial performance evaluation, including a comparison with the Stanford STREAM System. 1
343|Relational Languages and Data Models for Continuous Queries on Sequences and Data Streams|Most data stream management systems are based on extensions of the relational data model and query languages, but rigorous analyses of the problems and limitations of this approach, and how to overcome them, are still wanting. In this article, we elucidate the interaction between stream-oriented extensions of the relational model and continuous query language constructs, and show that the resulting expressive power problems are even more serious for data streams than for databases. In particular, we study the loss of expressive power caused by the loss of blocking query operators, and characterize nonblocking queries as monotonic functions on the database. Thus we introduce the notion of N B-completeness to assure that a query language is as suitable for continuous queries as it is for traditional database queries. We show that neither RA nor SQL are N B-complete on unordered sets of tuples, and the problem is even more serious when the data model is extended to support order—a sine-qua-non in data stream applications. The new limitations of SQL, compounded with well-known problems in applications such as sequence queries and data mining, motivate our proposal of extending the language with user-defined aggregates (UDAs). These can be natively coded in SQL, according to simple syntactic rules that set nonblocking aggregates apart from blocking ones. We first prove that SQL with UDAs is Turing complete. We then prove that SQL with monotonic UDAs and union operators can express all monotonic set functions computable by a Turing machine (N B-completeness) and
344|Designing an Inductive Data Stream Management System: the Stream Mill Experience |There has been much recent interest in on-line data mining. Existing mining algorithms designed for stored data are either not applicable or not effective on data streams, where real-time response is often needed and data characteristics change frequently. Therefore, researchers have been focusing on designing new and improved algorithms for on-line mining tasks, such as classification, clustering, frequent itemsets mining, pattern matching, etc. Relatively little attention has been paid to designing DSMSs, which facilitate and integrate the task of mining data streams—i.e., stream systems that provide Inductive functionalities analogous to those provided by Weka and MS OLE DB for stored data. In this paper, we propose the notion of an Inductive DSMS—a system that besides providing a rich library of inter-operable functions to support the whole mining process, also supports the essentials of DSMS, including optimization of continuous queries, load shedding, synoptic constructs, and non-stop computing. Ease-of-use and extensibility are additional desiderata for the proposed Inductive DSMS. We first review the many challenges involved in realizing such a system and then present our approach of extending the Stream Mill DSMS toward that goal. Our system features (i) a powerful query language where mining methods are expressed via aggregates for generic streams and arbitrary windows, (ii) a library of fast and light mining algorithms, and (iii) an architecture that makes it easy to customize and extend existing mining methods and introduce new ones. 1.
345|constitutive expression|IFNg is a pro-in¯ammatory cytokine that potentiates p53-independent apoptosis in a variety of cell types. STAT1 is the primary mediator of IFNg action. ZBP-89 is a transcription factor that binds to the G/C-rich elements and mediates p53-independent apoptosis. In this study, site-directed mutagenesis revealed that a G-rich element from +171 to +179 within the ®rst intron of the STAT1 gene is critical for optimal STAT1 promoter activity. Electrophoretic mobility shift assays and promoter analysis revealed that ZBP-89 binds directly to this STAT1 G-rich element along with Sp1 and Sp3. Reduction of ZBP-89 with siRNA attenuated both basal and IFNg-induced STAT1 expression and subsequently diminished the activation of apoptotic markers, e.g. caspase-3 and PARP. Taken together, we conclude that ZBP-89 is required for constitutive STAT1 expression and in this way contributes to the ability of cells to be activated by IFNg.
346|A flexible framework for multisensor data fusion using data stream management technologies |Many applications use sensors to capture an image of the real world, which is needed for automatical processes. E. g. fu-ture driver assistance systems will be based on dynamic in-formation about the car’s environment, the car’s state and the driver’s state. Since there exists no single sensor that can sense the required information, different sensors like radar, video and eye-tracker are used. Typically some provide re-dundant information about the same real world entity, while others measure different things. Thus, the fusion of infor-mation from different sensors is necessary to get a consistant image of the real world. In most sensor fusion systems the sensor configuration is known a priori and the fusion algo-rithms are adapted for these sensor configurations. Thus, changing a sensor fusion system to enable it to process sensor readings from another sensor configuration is hardly possible or completely impossible. Since in development processes of automotive applications different sensor equipment and en-vironmental requirements exist and change frequently a new approach for adapting sensor fusion systems is necessary. Hence, in this work a framework for sensor fusion systems will be developed that allows a flexible adaption of fusion mechanisms. Due to realtime requirements of automotive applications and the flexibility of query processing technolo-gies, data stream management technology will be used to develop a flexible framework for multisensor data fusion.
347|Annotations in Data Streams|The central goal of data stream algorithms is to process massive streams of data using sublinear storage space. Motivated by work in the database community on outsourcing database and data stream processing, we ask whether the space usage of such algorithms be further reduced by enlisting a more powerful “helper ” who can annotate the stream as it is read. We do not wish to blindly trust the helper, so we require that the algorithm be convinced of having computed a correct answer. We show upper bounds that achieve a non-trivial tradeoff between the amount of annotation used and the space required to verify it. We also prove lower bounds on such tradeoffs, often nearly matching the upper bounds, via notions related to Merlin-Arthur communication complexity. Our results cover the classic data stream problems of selection, frequency moments, and fundamental graph problems such as triangle-freeness and connectivity. Our work is also part of a growing trend — including recent studies of multi-pass streaming, read/write streams and randomly ordered streams — of asking more complexity-theoretic questions about data stream processing. It is a recognition that, in addition to practical relevance, the data stream model raises many interesting theoretical questions in its own right. 1
348|Algebraic Methods for Interactive Proof Systems|We present a new algebraic technique for the construc-tion of interactive proof systems. We use our technique to prove that every language in the polynomial-time hierarchy has an interactive proof system. This tech-nique played a pivotal role in the recent proofs that IP=PSPACE (Shamir) and that MIP=NEXP (Babai, Fortnow and Lund). 
349|Delegating computation: interactive proofs for muggles|In this work we study interactive proofs for tractable languages. The (honest) prover should be efficient and run in polynomial time, or in other words a “muggle”. 1 The verifier should be super-efficient and run in nearly-linear time. These proof systems can be used for delegating computation: a server can run a computation for a client and interactively prove the correctness of the result. The client can verify the result’s correctness in nearly-linear time (instead of running the entire computation itself). Previously, related questions were considered in the Holographic Proof setting by Babai, Fortnow, Levin and Szegedy, in the argument setting under computational assumptions by Kilian, and in the random oracle model by Micali. Our focus, however, is on the original interactive proof model where no assumptions are made on the computational power or adaptiveness of dishonest provers. Our main technical theorem gives a public coin interactive proof for any language computable by a log-space uniform boolean circuit with depth d and input length n. The verifier runs in time (n+d)·polylog(n) and space O(log(n)), the communication complexity is d · polylog(n), and the prover runs in time poly(n). In particular, for languages computable by log-space uniform N C (circuits of polylog(n) depth), the prover is efficient, the verifier runs in time n · polylog(n) and space O(log(n)), and the communication complexity is polylog(n).
350|Counting Triangles in Data Streams|We present two space bounded random sampling algorithms that compute an approximation of the number of triangles in an undirected graph given as a stream of edges. Our first algorithm does not make any assumptions on the order of edges in the stream. It uses space that is inversely related to the ratio between the number of triangles and the number of triples with at least one edge in the induced subgraph, and constant expected update time per edge. Our second algorithm is designed for incidence streams (all edges incident to the same vertex appear consecutively). It uses space that is inversely related to the ratio between the number of triangles and length 2 paths in the graph and expected update time O(log |V |·(1+s·|V |/|E|)), where s is the space requirement of the algorithm. These results significantly improve over previous work [20, 8]. Since the space complexity depends only on the structure of the input graph and not on the number of nodes, our algorithms scale very well with increasing graph size and so they provide a basic tool to analyze the structure of large graphs. They have many applications, for example, in the discovery of Web communities, the computa- 
351|New streaming algorithms for counting triangles in graphs|Abstract. We present three streaming algorithms that (?, d) - approximate 1 the number of triangles in graphs. Similar to the previous algorithms [3], the space usage of presented algorithms are inversely proportional to the number of triangles while, for some families of graphs, the space usage is improved. We also prove a lower bound, based on the number of triangles, which indicates that our first algorithm behaves almost optimally on graphs with constant degrees. 1
352|Algebrization: A new barrier in complexity theory|Any proof of P ? = NP will have to overcome two barriers: relativization and natural proofs. Yet over the last decade, we have seen circuit lower bounds (for example, that PP does not have linear-size circuits) that overcome both barriers simultaneously. So the question arises of whether there is a third barrier to progress on the central questions in complexity theory. In this paper we present such a barrier, which we call algebraic relativization or algebrization. The idea is that, when we relativize some complexity class inclusion, we should give the simulating machine access not only to an oracle A, but also to a low-degree extension of A over a finite field or ring. We systematically go through basic results and open problems in complexity theory to delineate the power of the new algebrization barrier. First, we show that all known non-relativizing results based on arithmetization—both inclusions such as IP = PSPACE and MIP = NEXP, and separations such as MAEXP ? ? P/poly —do indeed algebrize. Second, we show that almost all of the major open problems—including P versus NP, P versus RP, and NEXP versus P/poly—will require non-algebrizing techniques. In some cases algebrization seems to explain exactly why progress stopped where it did: for example, why we have superlinear circuit lower bounds for PromiseMA but not for NP. Our second set of results follows from lower bounds in a new model of algebraic query complexity, which we introduce in this paper and which is interesting in its own right. Some of our lower bounds use direct combinatorial and algebraic arguments, while others stem from a surprising connection between our model and communication complexity. Using this connection, we are also able to give an MA-protocol for the Inner Product function with O (  v n log n) communication (essentially matching a lower bound of Klauck), as well as a communication complexity conjecture whose truth would imply NL ? = NP. 1
353|Estimating Rarity and Similarity over Data Stream Windows|In the windowed data stream model, we observe items coming in over time. At any time t, we consider the window of the last N observations a t\Gamma(N \Gamma1) ; a t\Gamma(N \Gamma2) ; : : : ; a t , each a i 2 f1; : : : ; ug; we are allowed to ask queries about the data in the window, say, we wish to compute the minimum or the median of the items in the window. A crucial restriction is that we are only allowed o(N) (often polylogarithmic in N) storage space, that is, space smaller than the window size, so the items within the window can not be archived. Window data stream model arose out of the need to formally reason about the underlying data analyses problems in applications like inter-networking and transactions processing.
354|Practical Verified Computation with Streaming Interactive Proofs |When delegating computation to a service provider, as in the cloud computing paradigm, we seek some reassurance that the output is correct and complete. Yet recomputing the output as a check is inefficient and expensive, and it may not even be feasible to store all the data locally. We are therefore interested in what can be validated by a streaming (sublinear space) user, who cannot store the full input, or perform the full computation herself. Our aim in this work is to advance a recent line of work on “proof systems ” in which the service provider proves the correctness of its output to a user. The goal is to minimize the time and space costs of both parties in generating and checking the proof. Only very recently have there been attempts to implement such proof systems, and thus far these have been quite limited in
355|Trading off space for passes in graph streaming problems|Data stream processing has recently received increasing attention as a computational paradigm for dealing with massive data sets. Surprisingly, no algorithm with both sublinear space and passes is known for natural graph problems in classical read-only streaming. Motivated by technological factors of modern storage systems, some authors have recently started to investigate the computational power of less restrictive models where writing streams is allowed. In this paper, we show that the use of intermediate temporary streams is powerful enough to provide effective spacepasses tradeoffs for natural graph problems. In particular, for any space restriction of s bits, we show that single-source shortest paths in directed graphs with small positive integer edge weights can be solved in O((n log 3/2 n) /  v s) passes. The result can be generalized to deal with multiple sources within the same bounds. This is the first known streaming algorithm for shortest paths in directed graphs. For undirected connectivity, we devise an O((n log n)/s) passes algorithm. Both problems require ?(n/s) passes under the restrictions we consider. We also show that the model where intermediate temporary streams are allowed can be strictly more powerful than classical streaming for some problems, while maintaining all of its hardness for others.
356|GRAPH DISTANCES IN THE DATA-STREAM MODEL| We explore problems related to computing graph distances in the data-stream model. The goal is to design algorithms that can process the edges of a graph in an arbitrary order given only a limited amount of working memory. We are motivated by both the practical challenge of processing massive graphs such as the web graph and the desire for a better theoretical understanding of the datastream model. In particular, we are interested in the trade-offs between model parameters such as perdata-item processing time, total space, and the number of passes that may be taken over the stream. These trade-offs are more apparent when considering graph problems than they were in previous streaming work that solved problems of a statistical nature. Our results include the following: (1) Spanner construction: There exists a single-pass, Õ(tn1+1/t)-space, Õ(t2n1/t)-time-per-edge algorithm that constructs a (2t + 1)-spanner. For t =O(logn/log log n), the algorithm satisfies the semistreaming space restriction of O(n polylog n) and has per-edge processing time O(polylog n). This resolves an open question from [J. Feigenbaum et al., Theoret. Comput. Sci., 348 (2005), pp. 207–216]. (2) Breadth-first-search (BFS) trees: For any even constant k, we show that any algorithm that computes the first k layers of a BFS tree from a prescribed node with probability at least 2/3 requires either greater than k/2 passes or ˜O(n1+1/k) space. Since constructing BFS trees is
357|Robust lower bounds for communication and stream computation|We study the communication complexity of evaluating functions when the input data is randomly allocated (according to some known distribution) amongst two or more players, possibly with information overlap. This naturally extends previously studied variable partition models such as the best-case and worst-case partition models [32, 29]. We aim to understand whether the hardness of a communication problem holds for almost every allocation of the input, as opposed to holding for perhaps just a few atypical partitions. A key application is to the heavily studied data stream model. There is a strong connection between our communication lower bounds and lower bounds in the data stream model that are “robust” to the ordering of the data. That is, we prove lower bounds for when the order of the items in the stream is chosen not adversarially but rather uniformly (or near-uniformly) from the set of all permuations. This random-order data stream model has attracted recent interest, since lower bounds here give stronger evidence for the inherent hardness of streaming problems. Our results include the first random-partition communication lower bounds for problems including multi-party set disjointness and gap-Hamming-distance. Both are tight. We also extend and improve previous results [19, 7] for a form of pointer jumping that is relevant to the problem of selection (in particular, median finding). Collectively, these results yield lower bounds for a variety of problems in the random-order data stream model, including estimating the number of distinct elements, approximating frequency moments, and quantile estimation.
358|Verifying computations with streaming interactive proofs|When computation is outsourced, the data owner would like to be assured that the desired computation has been performed correctly by the service provider. In theory, proof systems can give the necessary assurance, but prior work is not sufficiently scalable or practical. In this paper, we develop new proof protocols for verifying computations which are streaming in nature: the verifier (data owner) needs only logarithmic space and a single pass over the input, and after observing the input follows a simple protocol with a prover (service provider) that takes logarithmic communication spread over a logarithmic number of rounds. These ensure that the computation is performed correctly: that the service provider has not made any errors or missed out some data. The guarantee is very strong: even if the service provider deliberately tries to cheat, there is only vanishingly small probability of doing so undetected, while a correct computation is always accepted. We first observe that some theoretical results can be modified to work with streaming verifiers, showing that there are efficient protocols for problems in the complexity classes NP and NC. Our main results then seek to bridge the gap between theory and practice by developing usable protocols for a variety of problems of central importance in streaming and database processing. All these problems require linear space in the traditional streaming model, and therefore our protocols demonstrate that adding a prover can exponentially reduce the effort needed by the verifier. Our experimental results show that our protocols are practical and scalable. 1.
359|Lower bounds for randomized read/write stream algorithms|Motivated by the capabilities of modern storage architectures, we consider the following generalization of the data stream model where the algorithm has sequential access to multiple streams. Unlike the data stream model, where the stream is read only, in this new model (introduced in [8, 9]) the algorithms can also write onto streams. There is no limit on the size of the streams but the number of passes made on the streams is restricted. On the other hand, the amount of internal memory used by the algorithm is scarce, similar to data stream model. We resolve the main open problem in [7] of proving lower bounds in this model for algorithms that are allowed to have 2-sided error. Previously, such lower bounds were shown only for deterministic and 1-sided error randomized algorithms [9, 7]. We consider the classical set disjointness problem that has proved to be invaluable for deriving lower bounds for many other problems involving data streams and other randomized models of computation. For this problem, we show a near-linear lower bound on the size of the internal memory used by a randomized algorithm with 2-sided error that is allowed to have o(log N / log log N) passes over the streams. This bound is almost optimal since there is a simple algorithm that can solve this problem using logarithmic memory if the number of passes over the streams is allowed to be O(log N). Applications include near-linear lower bounds on the internal memory for well-known problems in the literature: (1) approximately counting the number of distinct elements in the input (F0); (2) approximating the frequency of the mode of an input sequence (F * 8); (3) computing the join of two relations; and (4) deciding if some node of an XML document matches an XQuery (or XPath) query.
360|CADS: Continuous authentication on data streams|We study processing and authentication of long-running queries on outsourced data streams. In this scenario, a data owner (DO) constantly transmits its data to a service provider (SP), together with additional authentication information. Clients register continuous range queries to the SP. Whenever the data change, the SP must update the results of all affected queries and inform the clients accordingly. The clients can verify the correctness of the results using the authentication information provided by the DO. Compared to conventional databases, stream environments pose new challenges such as the need for fast structure updating, support for continuous query processing and authentication, and provision for temporal completeness. Specifically, in addition to the correctness of individual results, the client must be able to verify that there are no missing results in between updates. We face these challenges through several contributions. Since there is no previous work, we first present a technique, called REF, that achieves correctness and temporal completeness but incurs false transmissions, i.e., the SP has to inform clients whenever there is a data update, even if their results are not affected. Then, we propose CADS, which minimizes the processing and transmission overhead through an elaborate indexing scheme and a virtual caching mechanism. Finally, we extend CADS to the case where multiple owners outsource their data to the same SP. The SP integrates all data in a single authentication process, independently of the number of DOs. 
361|On the Value of Multiple Read/Write Streams for Approximating Frequency Moments |We consider the read/write streams model, an extension of the standard data stream model in which an algorithm can create and manipulate multiple read/write streams in addition to its input data stream. We show that any randomized read/write stream algorithm with a fixed number of streams and a sublogarithmic number of passes that produces a constant factor approximation of the k-th frequency moment Fk of an input sequence of length of at most N from {1,..., N} requires space ?(N 1-4/k-d) for any d&gt; 0. For comparison, it is known that with a single read-only data stream there is a randomized constantfactor approximation for Fk using Õ(N 1-2/k) space and that there is a deterministic algorithm computing Fk exactly using 3 read/write streams, O(log N) passes, and O(log N) space. Therefore, although the ability to manipulate multiple read/write streams can add substantial power to the data stream model, with a sub-logarithmic number of passes this does not significantly improve the ability to approximate higher frequency moments efficiently. Our lower bounds also apply to (1 + ?)-approximations of Fk for ? = 1/N.  
362|Streaming graph computations with a helpful advisor  | Motivated by the trend to outsource work to commercial cloud computing services, we consider a variation of the streaming paradigm where a streaming algorithm can be assisted by a powerful helper that can provide annotations to the data stream. We extend previous work on such annotation models by considering a number of graph streaming problems. Without annotations, streaming algorithms for graph problems generally require significant memory; we show that for many standard problems, including all graph problems that can be expressed with totally unimodular integer programming formulations, only constant memory is needed for single-pass algorithms given linear-sized annotations. We also obtain a protocol achieving optimal tradeoffs between annotation length and memory usage for matrix-vector multiplication; this result contributes to a trend of recent research on numerical linear algebra in streaming models.  
363|WEIGHTED MATCHING IN THE SEMI-STREAMING MODEL| We reduce the best known approximation ratio for finding a weighted matching of a graph using a one-pass semi-streaming algorithm from 5.828 to 5.585. The semi-streaming model forbids random access to the input and restricts the memory to O(n · polylog n) bits. It was introduced by Muthukrishnan in 2003 and is appropriate when dealing with massive graphs.  
364|Zero-One Frequency Laws |Data streams emerged as a critical model for multiple applications that handle vast amounts of data. One of the most influential and celebrated papers in streaming is the “AMS ” paper on computing frequency moments by Alon, Matias and Szegedy. The main question left open (and explicitly asked) by AMS in 1996 is to give the precise characterization for which functions G on frequency vectors mi (1 = i = n) can ? i?[n] G(mi) be approximated efficiently, where “efficiently ” means by a single pass over data stream and poly-logarithmic memory. No such characterization was known despite a tremendous amount of research on frequency-based functions in streaming literature. In this paper we finally resolve the AMS main question and give a precise characterization (in fact, a zero-one law) for all monotonically increasing functions on frequencies that are zero at the origin. That is, we consider all monotonic functions G: R ? ? R such that G(0)  = 0 and G can be computed in poly-logarithmic time and space and ask, for which G in this class is there an (1±?)-approximation algorithm for computing ? i?[n] G(mi) for any polylogarithmic ?? We give an algebraic characterization for all such G so that: • For all functions G in our class that satisfy our algebraic condition, we provide a very general and constructive way to derive an efficient (1±?)-approximation algorithm for computing ? i?[n] G(mi) with polylogarithmic memory and a single pass over data stream; while • For all functions G in our class that do not satisfy our algebraic characterization, we show a lower bound
365|Randomized Synopses for Query Assurance on Data Streams |Due to the overwhelming flow of information in many data stream applications, many companies may not be willing to acquire the necessary resources for deploying a Data Stream Management System (DSMS), choosing, alternatively, to outsource the data stream and the desired computations to a third-party. But data outsourcing and remote computations intrinsically raise issues of trust, making outsourced query assurance on data streams a problem with important practical implications. Consider a setting where a continuous “GROUP BY, SUM ” query is processed using a remote, untrusted server. A client with limited processing capabilities observing exactly the same stream as the server, registers the query on the server’s DSMS and receives results upon request. The client wants to verify the integrity of the results using significantly fewer resources than evaluating the query locally. Towards that goal, we propose a probabilistic verification algorithm for selection and aggregate/group-by queries, that uses constant space irrespective of the result-set size, has low update cost per stream element, and can have arbitrarily small probability of failure. We generalize this algorithm to allow some tolerance on the number of erroneous groups detected, in order to support semantic load shedding on the server. We also discuss the hardness of supporting random load shedding. Finally, we implement our techniques and perform an empirical evaluation using live network traffic. 1
366|Punctuated Data Streams|As most current query processing architectures are already pipelined, it seems logical to apply them to data streams. However, two classes of query operators are impractical
for processing long or unbounded data streams. Unbounded stateful operators maintain state with no upper bound on its size, and so eventually run out of memory. Blocking
operators read the entire input before emitting a single output, and so might never produce a result. We believe that a priori semantic knowledge of a data stream can permit the use of such operators in some cases. We explore a kind of stream semantics called punctuated streams. Punctuations in a stream mark the end of substreams, allowing us to view a non-terminating stream as a mixture of terminating streams. We introduce three kinds of
invariants to specify the proper behavior of query operators in the presence of punctuation. Pass invariants unblock blocking operators by defining when such an operator can pass results on. Keep invariants define what must be kept in local state to continue successful operation. Propagation invariants define when an operator can pass punctuation on. We then present a strategy for proving that implementations of these invariants are faithful to their finite table counterparts.

In practice, it is important to answer the following question: &#034;How much additional overhead is required when using punctuations?&#034; We use the scenario of a monitoring
system for an online auction. Streams of bids, new items, and new users are sent to an online auction system. There are many interesting queries that can be posed over these
auction streams. We define queries for this scenario, and execute them with different kinds and amounts of punctuations embedded in the input streams. We show that, for a reasonable ratio of punctuations to data items, the overhead is minimal. Additionally, we compare the behavior of a query using punctuations with the behavior of the same query using slack over data streams with disorder.

Clearly, not all punctuations are useful to a particular query, and it would be useful to make a determination of when they are. That is, we would like to answer the question
“Can stream query Q benefit from a particular set of punctuations?” To that end, we first define punctuation schemes to specify the collection of punctuations that will be presented to a query on a particular data stream. We show how both punctuations and query operators induce groupings over the items in the domain of the input(s). We show that a query benefits from an input punctuation scheme (in terms of being able to produce a given output scheme), if each set in the groupings induced by the operators of the query is covered by a finite number of punctuations in the scheme — a kind of compactness.

We conclude with discussion on possible future directions of research related to punctuations and data streams. These directions focus on a variety of questions, ranging
from issues in query optimization to other possible semantics that can be expressed using punctuations.
367|Data Stream Sharing|Abstract. Recent research efforts in the fields of data stream processing and data stream management systems (DSMSs) show the increasing importance of processing data streams, e. g., in the e-science domain. Together with the advent of peer-to-peer (P2P) networks and grid computing, this leads to the necessity of developing new techniques for distributing and processing continuous queries over data streams in such networks. In this paper, we present a novel approach for optimizing the integration, distribution, and execution of newly registered continuous queries over data streams in grid-based P2P networks. We introduce Windowed XQuery (WXQuery), our XQuery-based subscription language for continuous queries over XML data streams supporting window-based operators. Concentrating on filtering and window-based aggregation, we present our stream sharing algorithms as well as experimental evaluation results from the astrophysics application domain to assess our approach. 1
368|The physiology of the grid: An open grid services architecture for distributed systems integration|In both e-business and e-science, we often need to integrate services across distributed, heterogeneous, dynamic “virtual organizations ” formed from the disparate resources within a single enterprise and/or from external resource sharing and service provider relationships. This integration can be technically challenging because of the need to achieve various qualities of service when running on top of different native platforms. We present an Open Grid Services Architecture that addresses these challenges. Building on concepts and technologies from the Grid and Web services communities, this architecture defines a uniform exposed service semantics (the Grid service); defines standard mechanisms for creating, naming, and discovering transient Grid service instances; provides location transparency and multiple protocol bindings for service instances; and supports integration with underlying native platform facilities. The Open Grid Services Architecture also defines, in terms of Web Services Description Language (WSDL) interfaces and associated conventions, mechanisms required for creating and composing sophisticated distributed systems, including lifetime management, change management, and notification. Service bindings can support reliable invocation, authentication, authorization, and delegation, if required. Our presentation complements an earlier foundational article, “The Anatomy of the Grid, ” by describing how Grid mechanisms can implement a service-oriented architecture, explaining how Grid functionality can be incorporated into a Web services framework, and illustrating how our architecture can be applied within commercial computing as a basis for distributed system integration—within and across organizational domains. This is a DRAFT document and continues to be revised. The latest version can be found at
369|A Survey of Approaches to Automatic Schema Matching|Schema matching is a basic problem in many database application domains, such as data integration, E-business, data warehousing, and semantic query processing. In current implementations, schema matching is typically performed manually, which has significant limitations. On the other hand, previous research papers have proposed many techniques to achieve a partial automation of the match operation for specific application domains. We present a taxonomy that covers many of these existing approaches, and we describe the approaches in some detail. In particular, we distinguish between schema-level and instance-level, element-level and structure-level, and language-based and constraint-based matchers. Based on our classification we review some previous match implementations thereby indicating which part of the solution space they cover. We intend our taxonomy and review of past work to be useful when comparing different approaches to schema matching, when developing a new match algorithm, and when implementing a schema matching component.
370|Multicast Routing in Datagram Internetworks and Extended LANs|Multicasting, the transmission of a packet to a group of hosts, is an important service for improving the efficiency and robustness of distributed systems and applications. Although multicast capability is available and widely used in local area networks, when those LANs are interconnected by store-and-forward routers, the multicast service is usually not offered across the resulting internetwork. To address this limitation, we specify extensions to two common internetwork routing algorithms-distance-vector routing and link-state routing-to support low-delay datagram multicasting beyond a single LAN. We also describe modifications to the single-spanning-tree routing algorithm commonly used by link-layer bridges, to reduce the costs of multicasting in large extended LANs. Finally, we discuss how the use of multicast scope control and hierarchical multicast routing allows the multicast service to scale up to large internetworks.
371|The Cougar Approach to In-Network Query Processing in Sensor Networks|The widespread distribution and availability of smallscale sensors, actuators, and embedded processors is transforming the physical world into a computing platform. One such example is a sensor network consisting of a large number of sensor nodes that combine physical sensing capabilities such as temperature, light, or seismic sensors with networking and computation capabilities. Applications range from environmental control, warehouse inventory, and health care to military environments. Existing sensor networks assume that the sensors are preprogrammed and send data to a central frontend where the data is aggregated and stored for offline querying and analysis. This approach has two major drawbacks. First, the user cannot change the behavior of the system on the fly. Second, conservation of battery power is a major design factor, but a central system cannot make use of in-network programming, which trades costly communication for cheap local computation.
372|Designing a Super-peer Network|Despite their growing popularity, the behavior of super-peernetworks is not well understood. For example, what are the potential drawbacks of super-peer networks? How can super-peers be made more reliable? How many clients should a superpeer take on to maximize efficiency? In this paper we examinesuper-peer networks in detail, gaining an understanding of their fundamental characteristics and performance tradeoffs. We alsopresent practical guidelines and a general procedure for the design of an efficient super-peer network.
373|Topologically-aware overlay construction and server selection|  A number of large-scale distributed Internet applications could potentially benefit from some level of knowledge about the relative proximity between its participating host nodes. For example, the performance of large overlay networks could be improved if the application-level connectivity between the nodes in these networks is congruent with the underlying IP-level topology. Similarly, in the case of replicated web content, client nodes could use topological information in selecting one of multiple available servers. For such applications, one need not find the optimal solution in order to achieve significant practical benefits. Thus, these applications, and presumably others like them, do not require exact topological information and can instead use sufficiently informative hints about the relative positions of Internet hosts. In this paper, we present a binning scheme whereby nodes partition themselves into bins such that nodes that fall within a given bin are relatively close to one another in terms of network latency. Our binning strategy is simple (requiring minimal support from any measurement infrastructure), scalable (requiring no form of global knowledge, each node only needs knowledge of a small number of well-known landmark nodes) and completely distributed (requiring no communication or cooperation between the nodes being binned). We apply this binning strategy to the two applications mentioned above: overlay network construction and server selection. We test our binning strategy and its application using simulation and Internet measurement traces. Our results indicate that the performance of these applications can be significantly improved by even the rather coarse-grained knowledge of topology offered by our binning scheme.
374|Semantic Data Caching and Replacement|We propose a semantic model for client-side caching and replacement in a client-server database system and compare this approach to page caching and tuple caching strategies. Our caching model is based on, and derives its advantages from, three key ideas. First, the client maintains a semantic description of the data in its cache,which allows for a compact specification, as a remainder query, of the tuples needed to answer a query that are not available in the cache. Second, usage information for replacement policies is maintained in an adaptive fashion for semantic regions, which are associated with collections of tuples. This avoids the high overheads of tuple caching and, unlike page caching, is insensitive to bad clustering. Third, maintaining a semantic description of cached data enables the use of sophisticated value functions that incorporate semantic notions of locality, not just LRU or MRU, for cache replacement. We validate these ideas with a detailed performance study that i...
375|iMAP: discovering complex semantic matches between database schemas|Creating semantic matches between disparate data sources is fundamental to numerous data sharing efforts. Manually creating matches is extremely tedious and error-prone. Hence many recent works have focused on automating the matching process. To date, however, virtually all of these works deal only with one-to-one (1-1) matches, such as address = location. They do not consider the important class of more complex matches, such as address = concat(city,state) and room-price = room-rate * (1 + tax-rate). We describe the iMAP system which semi-automatically discovers both 1-1 and complex matches. iMAP reformulates schema matching as a search in an often very large or infinite match space. To search effectively, it employs a set of searchers, each discovering specific types of complex matches. To further improve matching accuracy, iMAP exploits a variety of domain knowledge, including past complex matches, domain integrity constraints, and overlap data. Finally, iMAP introduces a novel feature that generates explanation of predicted matches, to provide insights into the matching process and suggest actions to converge on correct matches quickly. We apply iMAP to several real-world domains to match relational tables, and show that it discovers both 1-1 and complex matches with high accuracy. 1.
376|Efficient Query Reformulation in Peer Data Management Systems|Peer data management systems (PDMS) offer a flexible architecture for decentralized data sharing. In a PDMS, every peer is associated with a schema that represents the peer&#039;s domain of interest, and semantic relationships between peers are provided locally between pairs (or small sets) of peers. By traversing semantic paths of mappings, a query over one peer can obtain relevant data from any reachable peer in the network. Semantic paths are traversed by reformulating queries at a peer into queries on its neighbors. Naively following semantic paths...
377|Towards an Internet-Scale XML Dissemination Service|Publish/subscribe systems have demonstrated the ability  to scale to large numbers of users and high data rates  when providing content-based data dissemination services  on the Internet. However, their services are limited  by the data semantics and query expressiveness that they  support. On the other hand, the recent work on selective  dissemination of XML data has made significant progress  in moving from XML filtering to the richer functionality  of transformation for result customization, but in general  has ignored the challenges of deploying such XML-based  services on an Internet-scale. In this paper, we address  these challenges in the context of incorporating the rich  functionality of XML data dissemination in a highly  scalable system. We present the architectural design of  ONYX, a system based on an overlay network. We identify  the salient technical challenges in supporting XML  filtering and transformation in this environment and propose  techniques for solving them.
378|The bea/xqrl streaming xquery processor|In this paper, we describe the design, implementation, and performance characteristics of a complete, industrial-strength XQuery engine, the BEA streaming XQuery processor. The engine was designed to provide very high performance for message processing applications, i.e., for transforming XML data streams, and it is a central component of the 8.1 release of BEA’s WebLogic Integration (WLI) product. This XQuery engine is fully compliant with the August 2002 draft of the W3C XML Query Language specification. A goal of this paper is to describe how an efficient, fully compliant XQuery engine can be built from a few relatively simple components and well-understood technologies.
379|Design Considerations for High Fan-in Systems: The HiFi Approach|Advances in data acquisition and sensor technologies are leading towards the development of “high fan-in ” architectures: widely distributed systems whose edges consist of numerous receptors such as sensor networks, RFID readers, or probes, and whose interior nodes are traditional host computers organized using the principles of cascading streams and successive aggregation. Examples include RFID-enabled supply chain management, largescale environmental monitoring, and various types of network and computing infrastructure monitoring. In this paper, we identify the key characteristics and data management challenges presented by high fan-in systems, and argue for a uniform, query-based approach towards addressing them. We then present our initial design concepts behind HiFi, the system we are building to embody these ideas, and describe a proof-of-concept prototype. 1.
380|Resource Sharing in Continuous Sliding-Window Aggregates|We consider the problem of resource sharing  when processing large numbers of continuous  queries. We specifically address sliding-window  aggregates over data streams, an important class  of continuous operators for which sharing has not  been addressed. We present a suite of sharing  techniques that cover a wide range of possible scenarios:  different classes of aggregation functions  (algebraic, distributive, holistic), different window  types (time-based, tuple-based, suffix, historical)  , and different input models (single stream,  multiple substreams). We provide precise theoretical  performance guarantees for our techniques,  and show their practical effectiveness through experimental  study.
381|Learning Source Descriptions for Data Integration |To build a data-integration system, the application designer must specify a mediated schema and supply the descriptions of data sources. A source description contains a source schema that describes the content of the source, and a mapping between the corresponding elements of the source schema and the mediated schema. Manually constructing these mappings is both labor-intensive and error-prone, and has proven to be a major bottleneck in deploying large-scale data integration systems in practice. In this paper we report on our initial work toward automatically learning mappings between source schemas and the mediated schema. Specifically, we investigate finding one-to-one mappings for the leaf elements of source schemas. We describe LSD, a system that automatically finds such mappings. LSD consults a set of learner modules – where each module looks at the problem from a different perspective, then combines the predictions of the modules using a meta-learner. We report on experimental results of applying LSD to five sources in the real-estate domain.  
382|Schema-based Scheduling of Event Processors and Buffer Minimization for Queries on Structured Data Streams|We introduce an extension of the XQuery language, FluX, that supports event-based query processing and the conscious handling of main memory buffers. Purely event-based queries of this language can be executed on streaming XML data in a very direct way. We then develop an algorithm that allows to efficiently rewrite XQueries into the event-based FluX language. This algorithm uses order constraints from a DTD to schedule event handlers and to thus minimize the amount of buffering required for evaluating a query. We discuss the various technical aspects of query optimization and query evaluation within our framework. This is complemented with an experimental evaluation of our approach.
383|GridDB: A Data-Centric Overlay for Scientific Grids|We present GridDB, a data-centric overlay for scientific  grid data analysis. In contrast to currently deployed  process-centric middleware, GridDB manages  data entities rather than processes. GridDB provides  a suite of services important to data analysis:  a declarative interface, type-checking, interactive  query processing, and memoization. We discuss  several elements of GridDB: workflow/data model,  query language, software architecture and query processing;  and a prototype implementation. We validate  GridDB by showing its modeling of real-world  physics and astronomy analyses, and measurements  on our prototype.
384|Containment of Nested XML Queries|Query containment is the most fundamental relationship between a pair of database queries: a query Q is said to be contained in a query Q    if the answer for Q is always a subset of the answer for Q    , independent of the current state of the database. Query containment is an important problem in a wide variety of data management applications, including verification of integrity constraints, reasoning about contents of data sources in data integration, semantic caching, verification of knowledge bases, determining queries independent of updates, and most recently, in query reformulation for peer data management systems. Query containment has been studied extensively in the relational context and for XPath queries, but not for XML queries with nesting.
385|The Case for Precision Sharing|Sharing has emerged as a key idea of static and  adaptive stream query processing systems. Inherent  in these systems is a tension between sharing  common work and avoiding unnecessary work.
386|StreamGlobe: Adaptive query processing and optimization in streaming P2P environments|Recent research and development efforts show the increasing importance of processing data streams, not only in the context of sensor networks, but also in information retrieval networks. With the advent of various mobile devices being able to participate in ubiquitous (wireless) networks, a major challenge is to develop data stream management systems (DSMS) for information retrieval in such networks. In this paper, we present the architecture of our StreamGlobe system, which is focused on meeting the challenges of efficiently querying data streams in an ad-hoc network environment. StreamGlobe is based on a federation of heterogeneous peers ranging from small, possibly mobile devices to stationary servers. On this foundation, self-organizing network optimization and expressive in-network query processing capabilities enable powerful information processing and retrieval. Data streams in StreamGlobe are represented in XML and queried using XQuery. We report on our ongoing implementation effort and briefly show our research agenda. 1
387|Dynamic Data Warehouse Design|A data warehouse (DW) can be seen as a set of materialized views defined over remote base relations. When a query is posed, it is evaluated locally, using the materialized views, without accessing the original information sources. The DWs are dynamic entities that evolve continuously over time. As time passes, new queries need to be answered by them. Some of these queries can be answered using exclusively the materialized views. In general though new views need to be added to the DW. In this paper we investigate the problem of incrementally designing a DW when new queries need to be answered and extra space is allocated for view materialization. Based on an AND/OR dag representation of multiple queries, we model the problem as a state space search problem. We design incremental algorithms for selecting a set of new views to additionally materialize in the DW that fits in the extra space, allows a complete rewriting of the new queries over the materialized views and minim...
388|Testing with hostile data streams|This note describes a method of testing software for response to malicious data streams. Systems that process data streams obtained from an external source such as the Internet are vulnerable to security issues if malicious data is not processed correctly. This note describes a testing method that creates malicious data streams, applies them to a software application and checks the appropriateness of the application response. The note begins with a description of the problem: inadequate testing of software response to malicious data streams. I present a method of testing the response to malicious data streams and introduce the concepts of lexical, syntactic and semantic data stream deformation. I provide a description of a system that produces and applies such tests. This description divides the testing system into components and provides some detail about each component. This system applied to Adobe ® Acrobat® Reader ® version 5.0.1 provides a case study. The study applied 141,306 unique test cases and revealed 11 distinct indications of buffer overrun, numerous program lock-ups, and four steganographic possibilities. Research is on-going in the following areas: generalized buffer overrun exploitation, maliciously testing protocols and testing with encoded or encrypted data streams.
389|Random Testing|this technical sense; however, it is certainly not the most used method.) If the technical meaning contrasts &#034;random&#034; with &#034;systematic,&#034; it is in the sense that fluctuations in physical measurements are random (unpredictable or chaotic) vs. systematic (causal or lawful). Why is it desirable to be &#034;unsystematic&#034; on purpose in selecting test data for a program? (1) Because there are efficient methods of selecting random points algorithmically, by computing pseudorandom numbers; thus a vast number of tests can be easily defined. (2) Because statistical independence among test points allows statistical prediction of significance in the observed results. In the sequel it will be seen that (1) may be compromised because the required result of an easily generated test is not so easy to generate. (2) is the more important quality of random testing, both in practice and for the theory of software testing. To make an analogy with the case of physical measurement, it is only random fluctuations that can be &#034;averaged out&#034; to yield an improved measurement over many trials; systematic fluctuations might in principle be eliminated, but if their cause (or even their existence) is unknown, they forever invalidate the measurement. The analogy is better than it seems: in program testing, with systematic methods we know what we are doing, but not what it means; only by giving up all systematization can the significance of testing be known. Random testing at its best can be illustrated by a simple example. Suppose that a subroutine is written to compute the (floating-point) cube root of an integer parameter. The method to be used has been shown to be accurate to within 2x10
390|Partition Testing versus Random Testing: the Influence of Uncertainty|The paper compares partition testing and random testing on the assumption that program failure rates are not known with certainty before testing and are therefore modeled by random variables. It is shown that under uncertainty, partition testing compares more favorably to random testing than suggested by prior investigations concerning the deterministic case: the restriction to failure rates that are known with certainty systematically favors random testing. In particular, we generalize a result by Weyuker and Jeng stating equal fault detection probabilities for partition testing and random testing in the case where the failure rates in the subdomains defined by the partition are equal. It turns out that for independent random failure rates with equal expectation, the case above is a boundary case (the worst case for partition testing), and the fault detection probability of partition testing can be up to k times higher than that of random testing, where k is the number of subdomains. ...
391|Semantics of data streams and operators |Abstract. What does a data stream mean? Much of the extensive work on query operators and query processing for data streams has proceeded without the benefit of an answer to this question. While such imprecision may be tolerable when dealing with simple cases, such as flat data, guaranteed physical order and element-wise operations, it can lead to ambiguities when dealing with nested data, disordered streams and windowed operators. We propose reconstitution functions to make the denotation and representation of data streams more precise, and use these functions to investigate the connection between monotonicity and nonblocking behavior of stream operators. We also touch on a reconstitution function for XML data. Other aspects of data stream semantics we consider are the use of punctuation to delineate finite subsets of a stream, adequacy of descriptions of stream disorder, and the formal specification of windowed operators. 1
392|Broadcast Disks: Data Management for Asymmetric Communications Environments|This paper proposes the use of repetitive broadcast as a way of augmenting the memory hierarchy of clients in an asymmetric communication environment. We describe a new technique called “Broadcast Disks” for structuring the broadcast in a way that provides improved performance for non-uniformly accessed data. The Broadcast Disk superimposes multiple disks spinning at different speeds on a single broadcast channel — in effect creating an arbitrarily fine-grained memory hierarchy. In addition to proposing and defining the mechanism, a main result of this work is that exploiting the potential of the broadcast structure requires a reevaluation of basic cache management policies. We examine several “pure ” cache management policies and develop and measure implementable approximations to these policies. These results and others are presented in a set of simulation studies that substantiates the basic idea and develops some of the intuitions required to design a particular broadcast program.
393|Stream Window Join: Tracking Moving Objects in Sensor-Network Databases|The widespread use of sensor networks presents revolutionary opportunities for life and environmental science applications. Many of these applications involve continuous queries that require the tracking, monitoring, and correlation of multi-sensor data that represent moving objects. We propose to answer these queries using a multi-way stream window join operator. This form of join over multisensor data must cope with the infinite nature of sensor data streams and the delays in network transmission. This paper introduces a class of join algorithms, termed W-join, for joining multiple infinite data streams. W-join addresses the infinite nature of the data streams by joining stream data items that lie within a sliding window and that match a certain join condition. W-join can be used to track the motion of a moving object or detect the propagation of clouds of hazardous material or pollution spills over time in a sensor network environment. We describe two new algorithms for W-join, and address variations and local/global optimizations related to specifying the nature of the window constraints to fulfill the posed queries. The performance of the proposed algorithms are studied experimentally in a prototype stream database system, using synthetic data streams and real time-series data. Tradeoffs of the proposed algorithms and their advantages and disadvantages are highlighted, given variations in the aggregate arrival rates of the input data streams and the desired response times per query.
394|Holistic UDAFs at streaming speeds|Many algorithms have been proposed to approximate holistic aggregates, such as quantiles and heavy hitters, over data streams. However, little work has been done to explore what techniques are required to incorporate these algorithms in a data stream query processor, and to make them useful in practice. In this paper, we study the performance implications of using user-defined aggregate functions (UDAFs) to incorporate selectionbased and sketch-based algorithms for holistic aggregates into a data stream management system’s query processing architecture. We identify key performance bottlenecks and tradeoffs, and propose novel techniques to make these holistic UDAFs fast and spaceefficient for use in high-speed data stream applications. We evaluate performance using generated and actual IP packet data, focusing on approximating quantiles and heavy hitters. The best of our current implementations can process streaming queries at OC48 speeds (2x 2.4Gbps).
395|How to Query Network Traffic Data Using Data Streams|In this paper, we show how ad-hoc queries can be made in real time on network traffic data using a data stream model. We define a rich class of ordering properties and use them to label the attributes of a stream. The attribute ordering properties can be used to optimize data stream queries, enabling the efficient evaluation of complex ad-hoc queries. The rich set of ordering properties allows the output of many operators on data streams to also be labeled with ordering properties, allowing the composability of data stream queries. We show how an SQL-like language can express many network analysis query, and be translated into data stream operators. We use the data stream model described in this paper as the query processing architecture for Gigascope, a fast and flexible network
396|Simulation data as data streams |Computational or scientific simulations are increasingly being applied to solve a variety of scientific problems. Domains such as astrophysics, engineering, chemistry, biology, and environmental studies are benefiting from this important capability. Simulations, however, produce enormous amounts of data that need to be analyzed and understood. In this overview paper, we describe scientific simulation data, its characteristics, and the way scientists generate and use the data. We then compare and contrast simulation data to data streams. Finally, we describe our approach to analyzing simulation data, present the AQSim (Ad-hoc Queries for Simulation data) system, and discuss some of the challenges that result from handling this kind of data. 1-
397|Real-Time Analysis, Visualization, and Steering of Microtomography Experiments at Photon Sources|A new generation of specialized scientific instruments called synchrotron light  sources allow the imaging of materials at very fine scales. However, in contrast to  a traditional microscope, interactive use has not previously been possible because  of the large amounts of data generated and the considerable computation required  translating this data into a useful image. We describe a new software architecture  that uses high-speed networks and supercomputers to enable quasi-real-time and hence  interactive analysis of synchrotron light source data. This architecture uses technologies  provided by the Globus &#034;computational grid&#034; toolkit to allow dynamic creation of a  reconstruction pipeline that transfers data from a synchrotron source beamline to a  preprocessing station, next to a parallel reconstruction system, and then to multiple  visualization stations. Collaborative analysis tools allow multiple users to control data  visualization. As a result, local and remote scientists can...
398|Practical lessons in supporting large-scale computational science|Business needs have driven the development of commercial database systems since their inception. As a result, there has been a strong focus on supporting many users, minimizing the potential corruption or loss
399|Approximate ad-hoc query engine for simulation data|In this paper, we describe AQSim, an ongoing effort to design and implement a system to manage terabytes of scientific simulation data. The project is aimed at reducing data storage requirements and access time while permitting ad-hoc queries using statistical and mathematical models of the data instead of the original data sets. In order to facilitate data exchange between models based on different representations, we are evaluating using the ASCI common data model which is comprised of several layers of increasing semantic complexity. To support queries over the spatial-temporal mesh structured data we are in the process of defining and implementing a grammar for MeshSQL
400|The framework for approximate queries on simulation data|AQSim is a system intended to enable scientists to query and analyze a large volume of scientific simulation data. The system uses the state of the art in approximate query processing techniques to build a novel framework for progressive data analysis. These techniques are used to define a multi-resolution index, where each node contains multiple models of the data. The benefits of these models are two-fold: 1) they are compact representations, reconstructing only the information relevant to the analysis, and 2) the variety of models capture different aspects of the data which may be of interest to the user but are not readily apparent in their raw form. To be able to deal with the data interactively, AQSim allows the scientist to make an informed tradeoff between query response accuracy and time. In this paper, we present the framework of AQSim with a focus on its architectural design. We also show the results from an initial proof-of-concept prototype developed at LLNL. The presented framework is generic enough to handle more than just simulation data.
401|Statistical modeling of large-scale simulation data|With the advent of fast computer systems, scientists are now able to generate terabytes of simulation data. Unfortunately, the sheer size of these data sets has made efficient exploration of them impossible. To aid scientists in gleaning insight from their simulation data, we have developed an ad-hoc query infrastructure. Our system, called AQSim (short for Ad-hoc Queries for Simulation) reduces the data storage requirements and query access times in two stages. First, it creates and stores mathematical and statistical models of the data at multiple resolutions. Second, it evaluates queries on the models of the data instead of on the entire data set. In this paper, we present two simple but effective statistical modeling techniques for simulation data. Our first modeling technique computes the “true” (unbiased) mean of systematic partitions of the data. It makes no
402|Pushing Constraints into Data Streams |One important challenge in data mining is the ability to deal with complex, voluminous and dynamic data. Indeed, due to the great advances in technology, in many real world appli-cations data appear in the form of continuous data streams, as opposed to traditional static datasets. Several techniques have been proposed to explore data streams, in particular for the discovery of frequent co-occurrences in data. How-ever, one of the common criticisms pointed out to frequent pattern mining is the fact that it generates a huge number of patterns, independent of user expertise, making it very hard to analyze and use the results. These bottlenecks are even more evident when dealing with data streams, since new data are continuously and endlessly arriving, and many intermediate results must be kept in memory. The use of constraints to filter the results is the most common and used approach to focus the discovery on what is really interest-ing. In this sense, there is a need for the integration of data stream mining with constrained mining. In this work we describe a set of strategies for pushing constraints into data stream mining, through the use of a pattern tree structure that captures a summary of the current possible patterns. We also propose an algorithm that discovers patterns in data streams that satisfy any user defined constraint.
403|Knowledge Discovery in Databases: an Overview|this article.  0738-4602/92/$4.00 1992 AAAI  58 AI MAGAZINE  for the 1990s (Silberschatz,  Stonebraker,  and Ullman 1990)
404|Exploratory Mining and Pruning Optimizations of Constrained Associations Rules|From the standpoint of supporting human-centered discovery of knowledge, the present-day model of mining association rules suffers from the following serious shortcom- ings: (i) lack of user exploration and control, (ii) lack of focus, and (iii) rigid notion of relationships. In effect, this model functions as a black-box, admitting little user interaction in between. We propose, in this paper, an architecture that opens up the black-box, and supports constraintbased, human-centered exploratory mining of associations. The foundation of this architecture is a rich set of con- straint constructs, including domain, class, and $QL-style aggregate constraints, which enable users to clearly specify what associations are to be mined. We propose constrained association queries as a means of specifying the constraints to be satisfied by the antecedent and consequent of a mined association.
405|Mining Association Rules with Item Constraints|The problem of discovering association rules has received considerable research attention and several fast algorithms for mining association rules have been developed. In practice, users are often interested in a subset of association rules. For example, they may only want rules that contain a specific item or rules that contain children of a specific item in a hierarchy. While such constraints can be applied as a postprocessing step, integrating them into the mining algorithm can dramatically reduce the execution time. We consider the problem of integrating constraints that are boolean expressions over the presence or absence of items into the association discovery algorithm. We present three integrated algorithms for mining association rules with item constraints and discuss their tradeoffs. 1. Introduction The problem of discovering association rules was introduced in (Agrawal, Imielinski, &amp; Swami 1993). Given a set of transactions, where each transaction is a set of literals (call...
406|Mining Frequent Patterns in Data Streams at Multiple Time Granularities|Although frequent-pattern mining has been widely studied and used, it is challenging to extend it to data streams. Compared to mining from a static transaction data set, the streaming case has far more information to track and far greater complexity to manage. Infrequent items can become frequent later on and hence cannot be ignored. The storage structure needs to be dynamically adjusted to reflect the evolution of itemset frequencies over time.
407|Mining Frequent Itemsets with Convertible Constraints|Recent work has highlighted the importance of the constraint-based mining paradigm in the context of frequent itemsets, associations, correlations, sequential patterns, and many other interesting patterns in large databases. In this paper, we study constraints which cannot be handled with existing theory and techniques. For example,, ,  ( can contain items of arbitrary values) &#034;!$ # %&#039;&amp;) ( , are customarily regarded as “tough ” constraints in that they cannot be pushed inside an algorithm such as Apriori. We develop a notion of convertible constraints and systematically analyze, classify, and characterize this class. We also develop techniques which enable them to be readily pushed deep inside the recently developed FP-growth algorithm for frequent itemset mining. Results from our detailed experiments show the effectiveness of the techniques developed. 1.
408|SplitStream: High-Bandwidth Multicast in Cooperative Environments|In tree-based multicast systems, a relatively small number of interior nodes carry the load of forwarding multicast messages. This works well when the interior nodes are highly available, d d cated infrastructure routers but it poses a problem for application-level multicast in peer-to-peer systems. SplitStreamadV esses this problem by striping the content across a forest of interior-nodno# sjoint multicast trees that d stributes the forward ng load among all participating peers. For example, it is possible to construct efficient SplitStream forests in which each peer contributes only as much forwarding bandH d th as it receives. Furthermore, with appropriate content encod ngs, SplitStream is highly robust to failures because a nod e fai ure causes the oss of a single stripe on average. We present thed#&#039; gnand implementation of SplitStream and show experimental results obtained on an Internet testbed and via large-scale network simulation. The results show that SplitStreamd istributes the forward ing load among all peers and can accommod&#039;9 peers with different band0 d capacities while imposing low overhead for forest constructionand maintenance. 
409|Chord: A Scalable Peer-to-Peer Lookup Service for Internet Applications|A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.
410|SCRIBE: A large-scale and decentralized application-level multicast infrastructure|This paper presents Scribe, a scalable application-level multicast infrastructure. Scribe supports large numbers of groups, with a potentially large number of members per group. Scribe is built on top of Pastry, a generic peer-to-peer object location and routing substrate overlayed on the Internet, and leverages Pastry&#039;s reliability, self-organization, and locality properties. Pastry is used to create and manage groups and to build efficient multicast trees for the dissemination of messages to each group. Scribe provides best-effort reliability guarantees, but we outline how an application can extend Scribe to provide stronger reliability. Simulation results, based on a realistic network topology model, show that Scribe scales across a wide range of groups and group sizes. Also, it balances the load on the nodes while achieving acceptable delay and link stress when compared to IP multicast.
411|Overcast: Reliable Multicasting with an Overlay Network|Overcast is an application-level multicasting system that can be incrementally deployed using today&#039;s Internet infrastructure. These properties stem from Overcast&#039;s implementation as an overlay network. An overlay network consists of a collection of nodes placed at strategic locations in an existing network fabric. These nodes implement a network abstraction on top of the network provided by the underlying substrate network. Overcast  provides
412|Bayeux: An architecture for scalable and fault-tolerant wide-area data dissemination|The demand for streaming multimedia applications is growing at an incredible rate. In this paper, we propose Bayeux, an efficient application-level multicast system that scales to arbitrarily large receiver groups while tolerating failures in routers and network links. Bayeux also includes specific mechanisms for load-balancing across replicate root nodes and more efficient bandwidth consumption. Our simulation results indicate that Bayeux maintains these properties while keeping transmission overhead low. To achieve these properties, Bayeux leverages the architecture of Tapestry, a fault-tolerant, wide-area overlay routing and location network.
413|Distributing Streaming Media Content Using Cooperative Networking|In this paper, we discuss the problem of distributing streaming media content, both live and on-demand, to a large number of hosts in a scalable way. Our work is set in the context of the traditional client-server framework. Specifically, we consider the problem that arises when the server is overwhelmed by the volume of requests from its clients. As a solution, we propose Cooperative Networking (CoopNet), where clients cooperate to distribute content, thereby alleviating the load on the server. We discuss the proposed solution in some detail, pointing out the interesting research issues that arise, and present a preliminary evaluation using traces gathered at a busy news site during the flash crowd that occurred on September 11, 2001.
414|Application-Level Multicast Using Content-Addressable Networks|Most currently proposed solutions to application-level multicast organize  the group members into an application-level mesh over which a DistanceVector  routing protocol, or a similar algorithm, is used to construct source-rooted  distribution trees. The use of a global routing protocol limits the scalability of  these systems. Other proposed solutions that scale to larger numbers of receivers  do so by restricting the multicast service model to be single-sourced. In this paper,  we propose an application-level multicast scheme capable of scaling to large  group sizes without restricting the service model to a single source. Our scheme  builds on recent work on Content-Addressable Networks (CANs). Extending the  CAN framework to support multicast comes at trivial additional cost and, because  of the structured nature of CAN topologies, obviates the need for a multicast  routing algorithm. Given the deployment of a distributed infrastructure such as a  CAN, we believe our CAN-based multicast scheme offers the dual advantages of  simplicity and scalability.
415|Informed content delivery across adaptive overlay networks|Abstract—Overlay networks have emerged as a powerful and highly flexible method for delivering content. We study how to optimize throughput of large transfers across richly connected, adaptive overlay networks, focusing on the potential of collaborative transfers between peers to supplement ongoing downloads. First, we make the case for an erasure-resilient encoding of the content. Using the digital fountain encoding approach, end hosts can efficiently reconstruct the original content of size from a subset of any symbols drawn from a large universe of encoding symbols. Such an approach affords reliability and a substantial degree of application-level flexibility, as it seamlessly accommodates connection migration and parallel transfers while providing resilience to packet loss. However, since the sets of encoding symbols acquired by peers during downloads may overlap substantially, care must be taken to enable them to collaborate effectively. Our main contribution is a collection of useful algorithmic tools for efficient summarization and approximate reconciliation of sets of symbols between pairs of collaborating peers, all of which keep message complexity and computation to a minimum. Through simulations and experiments on a prototype implementation, we demonstrate the performance benefits of our informed content-delivery mechanisms and how they complement existing overlay network architectures. Index Terms—Bloom filter, content delivery, digital fountain, erasure code, min-wise sketch, overlay, peer-to-peer, reconciliation. I.
416|An Evaluation of Scalable Application-Level Multicast Built Using Peer-to-Peer Overlays|Structured peer-erg163 overlay networks such as CAN, Chord, Pastry, and Tapestry can be used to implement Internet-g683 application-3 vel multicast. There are two general approaches to accomplishingthis: tree buildingand flooding. This paper evaluates these two approaches usingtwo different types of structured overlay: 1) overlays which use a form of generalized hypercube routing, e.g., Chord, Pastry and Tapestry, and 2) overlays which use a numerical distance metric to route through a Cartesian hyper-erg15 e.g., CAN. Pastry and CAN are chosen as the representatives of each type of overlay. To the best of our knowledge, this paper reports the firstheadto -d- comparison ofCAN-B91g versus Pastry-gZ4B overlay networks, usingmulticast communication workloads runningon an identical simulation infrastructure. The two approaches to multicast are independent of overlay network choice, and we provide a comparison of floodingversus tree-2696 multicast on both overlays. Results show that the tree-2613 approach consistently outperforms the floodingapproach. Finally, for treebased multicast, we show that Pastry provides better performance than CAN.
417|Exploiting network proximity in peer-to-peer overlay networks|In CAN, each node measures its network delay to a set of
418|Distributed Video Streaming with Forward Error Correction|With the explosive growth of video applications over the Internet, many approaches have been proposed to stream video effectively over packet switched, best-effort networks. Many use techniques from source and channel coding, or implement transport protocols, or modify system architectures in order to deal with delay, loss, and time-varying nature of the Internet. In our previous work, we proposed a framework with a receiver driven protocol to coordinate simultaneous video streaming from multiple senders to a single receiver in order to achieve higher throughput, and to increase tolerance to packet loss and delay due to network congestion. The receiver-driven protocol employs two algorithms: rate allocation and packet partition. The rate allocation algorithm determines the sending rate for each sender; the packet partition algorithm ensures no senders send the same packets, and at the same time, minimizes the probability of late packets. In this paper, we propose a novel rate allocation scheme to be used with Forward Error Correction (FEC) in order to minimize the probability of packet loss in bursty loss environments such as those caused by network congestion. Using both simulations and actual Internet experiments, we demonstrate the effectiveness of our rate allocation scheme in reducing packet loss, and hence, achieving higher visual quality for the streamed video.
419|Using Random Subsets to Build Scalable Network Services|In this paper, we argue that a broad range of large-scale network services would benefit from a scalable mechanism for delivering state about a random subset of global participants. Key to this approach is ensuring that membership in the subset changes periodically and with uniform representation over all participants. Random subsets could help overcome inherent scaling limitations to services that maintain global state and perform global network probing. It could further improve the routing performance of peer-to-peer distributed hash tables by locating topologically-close nodes. This paper presents the design, implementation, and evaluation of RanSub, a scalable protocol for delivering such state.
420|Unbalanced Multiple Description Video Communication Using Path Diversity|Multiple description (MD) coders provide important error resilience  properties. Specifically, MD coders are designed to provide good performance when the loss is limited to a single description, but it is not known in advance which description. In [1], we combined MD video coding with a path diversity transmission system for packet networks such as the Internet, where different descriptions are explicitly transmitted through different network paths, to improve the effectiveness of MD coding over a packet network by increasing the likelihood that the loss probabilities for each description are independent. The available bandwidth in each path may be similar or different, resulting in the requirement of balanced or unbalanced operation, where the bit rate of each description may differ based on the available bandwidth along its path. We design a MD video communication system that is effective in both balanced and unbalanced operation. Specifically, unbalanced MD streams are created by carefully adjusting the frame rate of each description, thereby achieving unbalanced rates of almost 2:1 while preserving MD&#039;s effectiveness and error recovery capability.  
421|Proximity neighbor selection in tree-based structured peer-to-peer overlays|Structured peer-to-peer (p2p) overlay networks provide a useful substrate for building distributed applications. They assign object keys to overlay nodes and provide a primitive to route a message to the node responsible for a key. Proximity neighbor selection (PNS) can be used to achieve both low delay routes and low bandwidth usage but it introduces high overhead. This paper presents a detailed evaluation of PNS and heuristic approximations. We describe a new heuristic called constrained gossiping (PNS-CG) and show that it achieves performance similar to perfect PNS with low overhead. We also compare constrained gossiping with previous heuristics and show that it achieves better performance with lower overhead.
422|Scalable Application-Level Anycast for Highly Dynamic Groups|We present an application-level implementation of anycast  for highly dynamic groups. The implementation can handle group sizes  varying from one to the whole Internet, and membership maintenance  is e#cient enough to allow members to join for the purpose of receiving  a single message. Key to this e#ciency is the use of a proximity-aware  peer-to-peer overlay network for decentralized, lightweight group maintenance;  nodes join the overlay once and can join and leave many groups  many times to amortize the cost of maintaining the overlay. An anycast  implementation with these properties provides a key building block  for distributed applications. In particular, it enables management and  location of dynamic resources in large scale peer-to-peer systems. We  present several resource management applications that are enabled by  our implementation.
423|Fcast Multicast File Distribution|Reliable data multicast is problematic. ACK/NACK schemes do not scale to large audiences, and simple data replication wastes network bandwidth. Fcast, &#034;file multicasting&#034;, combines multicast with Forward Error Correction (FEC) to address both these problems. Like classic multicast, Fcast scales to large audiences, and like other FEC schemes, it uses bandwidth very efficiently. Some of the benefits of this combination were known previously, but Fcast contributes new caching methods that improve disk throughput, and new optimizations for small file transfers. This paper describes Fcast&#039;s design, implementation, and API.
424|Data stream management and mining |Abstract. This paper provides an introduction to the field of data stream management and mining. The increase of data production in operational information systems prevents from monitoring these systems with the old paradigm of storing data before analyzing it. New approaches have been developed recently to process data ‘on the fly ’ considering they are produced in the form of structured data streams. These approaches cover both querying and mining data.
425|Gigascope: a stream database for network applications|We have developed Gigascope, a stream database for network ap-plications including traffic analysis, intrusion detection, router con-figuration analysis, network research, network monitoring, and and performance monitoring and debugging. Gigascope is undergoing installation at many sites within the AT&amp;T network, including at OC48 routers, for detailed monitoring. In this paper we describe our motivation for and constraints in developing Gigascope, the Gigascope architecture and query language, and performance is-sues. We conclude with a discussion of stream database research problems we have found in our application. 1.
426|SASE: Complex event processing over streams|RFID technology is gaining adoption on an increasing scale for tracking and monitoring purposes. Wide deployments of RFID devices will soon generate an unprecedented volume of data. Emerging applications require the RFID data to be filtered and correlated for complex pattern detection and transformed to events that provide meaningful, actionable information to end applications. In this work, we design and develop SASE, a com-plex event processing system that performs such data-information transformations over real-time streams. We design a complex event language for specifying application logic for such transformation, devise new query processing techniques to effi-ciently implement the language,  and develop a comprehensive system that collects, cleans, and processes RFID data for deliv-ery of relevant, timely information as well as storing necessary data for future querying. We demonstrate an initial prototype of SASE through a real-world retail management scenario. 1.
427|Using Data Stream Management Systems to analyze Electric Power Consumption Data |Abstract. With the development of AMM (Automatic Metering Management), it will be possible for electric power suppliers to acquire from the customers their electric power consumption up to every second. This will generate data arriving in multiple, continuous, rapid, and time-varying data streams. Data Stream Management Systems (DSMS)- currently available as prototypes- aim at facilitating the management of such data streams. This paper describes an experimental study which analyzes the advantages and limitations of using a DSMS for the management of electric power consumption data.
428|Online clustering of data streams|We consider the problem of clustering data streams. A data stream can roughly be thought of as a transient, continuously increasing sequence of time-stamped data. In order to maintain an up-to-date clustering structure, it is necessary to analyze the incoming data in an online manner, tolerating but a constant time delay. For this purpose, we develop an efficient online version of the classical K-means method. Our algorithm’s efficiency is mainly due to a (discrete) Fourier transform of the original data, resulting both in a smoothing as well as a compression of these data. 1
429|Estimating the number of clusters in a dataset via the Gap statistic|We propose a method (the \Gap statistic&#034;) for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. k-means or hierarchical), comparing the change in within cluster dispersion to that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study that shows that the Gap statistic usually outperforms other methods that have been proposed in the literature. We also briey explore application of the same technique to the problem for estimating the number of linear principal components. 1 Introduction  Cluster analysis is an important tool for \unsupervised&#034; learning| the problem of nding groups in data without the help of a response variable. A major challenge in cluster analysis is estimation of the optimal number of \clusters&#034;. Figure 1 (top right) shows a typical plot of an error measure W k (the within cluster dispersion dened below) for a clustering pr...
430|Estimating Data Stream . . .  |Object-detection applications rely on streams of data gathered from sensors, RFID readers, and image recognition systems, among others. These raw data streams tend to be noisy, including both false positives (erroneous readings) and false negatives (missed readings). Techniques exist for general-purpose cleaning of these types of data streams, based on temporal and/or spatial correlations, as well as properties of the physical world. Cleaning is effective at improving the quality of the data, however no cleaning procedures can eliminate all errors. In this paper we identify and address the problem of quality estimation as object-detection data streams are cleaned. We provide techniques for estimating both confidence and coverage as streams are processed by cleaning modules. Detailed experimental results based on an RFID application demonstrate the accuracy and effectiveness of our approach. 
431|Energy-Efficient Computing for Wildlife Tracking: Design Tradeoffs and Early Experiences with ZebraNet|Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The  eld of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scienti  c and commercial purposes. This paper examines the research decisions and design tradeos that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.
432|Trio: a system for integrated management of data, accuracy, and lineage|Trio is a new database system that manages not only data, butalsotheaccuracy and lineage of the data. Inexact (uncertain, probabilistic, fuzzy, approximate, incomplete, and imprecise!) databases have been proposed in the past, and the lineage problem also has been studied. The goals of the Trio project are to combine and distill previous work into a simple and usable model, design a query language as an understandable extension to SQL, and most importantly build a working system—a system that augments conventional data management with both accuracy and lineage as an integral part of the data. This paper provides numerous motivating applications for Trio and lays out preliminary plans for the data model, query language, and prototype system.
433|ProbView: A Flexible Probabilistic Database System|... In this article, we characterize, using postulates, whole classes of strategies for conjunction, disjunction, and negation, meaningful from the viewpoint of probability theory. (1) We propose a probabilistic relational data model and a generic probabilistic relational algebra that neatly captures various strategies satisfying the postulates, within a single unified framework. (2) We show that as long as the chosen strategies can be computed in polynomial time, queries in the positive fragment of the probabilistic relational algebra have essentially the same data complexity as classical relational algebra. (3) We establish various containments and equivalences between algebraic expressions, similar in spirit to those in classical algebra. (4) We develop algorithms for maintaining materialized probabilistic views. (5) Based on these ideas, we have developed  
434|Automated ranking of database query results|We investigate the problem of ranking answers to a database query when many tuples are returned. We adapt and apply principles of probabilistic models from Information Retrieval for structured data. Our proposed solution is domain independent. It leverages data and workload statistics and correlations. Our ranking functions can be further customized for different applications. We present results of preliminary experiments which demonstrate the efficiency as well as the quality of our ranking system. 1.
435|Temporal management of RFID data|RFID technology can be used to significantly im-prove the efficiency of business processes by pro-viding the capability of automatic identification and data capture. This technology poses many new challenges on current data management sys-tems. RFID data are time-dependent, dynamically changing, in large volumes, and carry implicit se-mantics. RFID data management systems need to effectively support such large scale temporal data created by RFID applications. These sys-tems need to have an explicit temporal data model for RFID data to support tracking and monitor-ing queries. In addition, they need to have an automatic method to transform the primitive ob-servations from RFID readers into derived data used in RFID-enabled applications. In this pa-per, we present an integrated RFID data manage-ment system – Siemens RFID Middleware – based on an expressive temporal data model for RFID data. Our system enables semantic RFID data filtering and automatic data transformation based on declarative rules, provides powerful query sup-port of RFID object tracking and monitoring, and can be adapted to different RFID-enabled applica-tions.
436|A probabilistic framework for vague queries and imprecise information in databases|A probabilistic learning model for vague queries and missing or imprecise information in databases is described. Instead of retrieving only a set of answers, our approach yields a ranking of objects from the database in response to a query. By using relevance judgements from the user about the objects retrieved, the ranking for the actual query as well as the overall retrieval quality of the system can be further improved. For specifying different kinds of conditions in vague queries, the notion of vague pred-icates is introduced. Based on the underlying probabilistic model, also imprecise or missing attribute values can be treated easily. In addition, the corresponding formulas can be applied in combination with standard predicates (from two-valued logic), thus extending standard database systems for coping with missing or imprecise data. 
437|Cleaning and Querying Noisy Sensors|Sensor networks have become an important source of data with numerous applications in monitoring various real-life phenomena as well as industrial applications and traffic control. Unfortunately, sensor data is subject to several sources of errors such as noise from external sources, hardware noise, inaccuracies and imprecision, and various environmental effects. Such errors may seriously impact the answer to any query posed to the sensors. In particular, they may yield imprecise or even incorrect and misleading answers which can be very significant if they result in immediate critical decisions or activation of actuators. In this paper, we present a framework for cleaning and querying noisy sensors. Specifically, we present a Bayesian approach for reducing the uncertainty associated with the data, that arise due to random noise, in an online fashion. Our approach combines prior knowledge of the true sensor reading, the noise characteristics of this sensor, and the observed noisy reading in order to obtain a more accurate estimate of the reading. This cleaning step can be performed either at the sensor level or at the base-station. Based on our proposed uncertainty models and using a statistical approach, we introduce several algorithms for answering traditional database queries over uncertain sensor readings. Finally, we present a preliminary evaluation of our proposed approach using synthetic data and highlight some exciting research directions in this area.
438|Swarm Coordination for Pursuit Evasion Games Using Sensor Networks|Abstract — In this work we consider the problem of pursuit evasion games (PEGs) where a group of pursuers is required to detect, chase and capture a group of evaders with the aid of a sensor network in minimum time. Differently from standards PEGs where the environment and the location of evaders is unknown and a probabilistic map is built based on the pursuer onboard sensors, here we consider a scenario where a sensor network, previously deployed in the region of concern, can detect the presence of moving vehicles and can relay this information to the pursuers. Here we propose a general framework for the design of a hierarchical control architecture that exploit the advantages of a sensor networks by combining both centralized and decentralized real-time control algorithms. We also propose a coordination scheme for the pursuers to minimize the time-to-capture of all evaders. In particular, we focus on PEGs with sensor networks orbiting in space for artificial space debris detection and removal. Index Terms — Sensor networks, pursuit evasion games, vehicle coordination, space vehicles, space debris over the area of interest. This constraint makes designing a cooperative pursuit algorithm harder because lack of complete observability only allows for suboptimal pursuit policies. See Figure 1(left). Furthermore, a smart evaders makes the map-building process dynamic since their location changes over time. The map-learning phase is, by itself, time-consuming and computationally intensive even for simple two-dimensional rectilinear environments [5]. Moreover, inaccurate sensors complicate this process and a probabilistic approach is often required [21]. I.
439|Answering Queries from Statistics and Probabilistic Views|this paper, require complex correlations between tuples, for which the query semantics has not been previously studied
440|GADT: A Probability Space ADT for Representing and Querying the Physical World|Large sensor networks are being widely deployed for measurement, detection, and monitoring applications. Many of these applications involve database systems to store and process data from the physical world. This data has inherent measurement uncertainties that are properly represented by continuous probability distribution functions (pdf&#039;s). We introduce a new object-relational data type, the Gaussian ADT GADT, that models physical data as gaussian pdf&#039;s, and we show that existing index structures can be used as fast access methods for GADT data. We also present a measure-theoretic model of probabilistic data and evaluate GADT in its light.
441|Accessing Imprecise Data: An Approach Based on Intervals|In many real world applications (even in banking), imprecise data is a matter of fact. However, classic database management systems provide little if any help in the management of imprecise data. We are applying methods from interval arithmetic, epsilon serializability, and other related areas to help the application designers in the management of naturally imprecise data. Our approach includes operators on imprecise data that give bounds on the result imprecision and algorithms that constrain the imprecision propagation in the database. 1 Introduction  Traditional database management systems provide support only for precise data, though in the physical world data is often imprecise. An important class of examples is the scientific data such as incomplete recording of data, instrument noise, measurement error, computational model imprecision, and data aggregation of one kind or another. Another example is the &#034;fuzzy&#034; data managed by Epsilon Serializability algorithms [PL91, DP93]. In t...
442|Mapping and Localization with RFID Technology|In this paper we analyze whether recent Radio Frequency Identification (RFID) technology can be used to improve the localization of mobile robots and persons in their environment. In particular we study the problem of localizing RFID tags with a mobile platform that is equipped with a pair of RFID antennas. We present a probabilistic measurement model for RFID readers that allow us to accurately localize RFID tags in the environment. We also demonstrate how such maps can be used to localize a robot and persons in their environment. Finally, we present experiments illustrating that the computational requirements for global robot localization can be seriously reduced by fusing RFID information with laser data.  
443|Structuring Protocols with Data Streams |This paper describes a new approach to integrating data-handling protocol functions while preserving modularity. Our overall objective is a software architecture for protocols that provides high conceptual performance for developers and results in high-performance code in execution. Our approach to data-handling function integration is based on the data stream abstraction. A data stream is a finite FIFO queue of bytes. The protocol developer writes a series of stream functions, each of which performs some operations on its input and may generate output. Each stream function accepts some number of data stream ends --- either input or output ends --- and performs arbitrary computations on the data in-between. The developer builds protocols by connecting stream functions output-to-input. A number of characteristics make data streams an attractive paradigm for data-handling protocol functions. First, data streams seem to be a natural match to the structure of many of the problems arising in protocol development. Second, they admit many powerful data-stream operations, yet they are simple to apply. Finally, for all their descriptive and operational power, data-stream computations have a regular structure that can be expected to lend itself to well-known compiler optimization techniques such as loop fusion. The work described here is part of the Tau project. Tau (&#034;Transport and up&#034;) is a framework and protocol for composition of upper-level protocol functions without layering. As such, Tau supports the separation of protocol control functions (e.g. acknowledgement)  from data-manipulation protocol functions (e.g. encryption, checksums) that is necessary for the approach described here to be feasible. In particular, Tau enables data-manipulation functions to be described and ...
444|The x-Kernel: An Architecture for Implementing Network Protocols|This paper describes a new operating system kernel, called the x-kernel, that provides an  explicit architecture for constructing and composing network protocols. Our experience  implementing and evaluating several protocols in the x-kernel shows that this architecture  is both general enough to accommodate a wide range of protocols, yet efficient enough to  perform competitively with less structured operating systems.  1 Introduction  Network software is at the heart of any distributed system. It manages the communication hardware that connects the processors in the system and it defines abstractions through which processes running on those processors exchange messages. Network software is extremely complex: it must hide the details of the underlying hardware, recover from transmission failures, ensure that messages are delivered to the application processes in the appropriate order, and manage the encoding and decoding of data. To help manage this complexity, network software is divi...
445|A Stream Input-Output System|In a new version of the Unix operating system, a flexible coroutine-based design replaces the traditional rigid connection between processes and terminals or networks. Processing modules may be inserted dynamically into the stream that connects a user&#039;s program to a device. Programs may also connect directly to programs, providing interprocess communication. Introduction  The part of the Unix operating system that deals with terminals and other character devices has always been complicated. In recent versions of the system it has become even more so, for two reasons. 1) Network connections require protocols more ornate than are easily accommodated in the existing structure. A notion of &#034;line disciplines&#034; was only partially successful, mostly because in the traditional system only one line discipline can be active at a time. 2) The fundamental data structure of the traditional character I/O system, a queue of individual characters (the &#034;clist&#034;), is costly because it accepts and dispense...
446|Increasing Network Throughput by Integrating Protocol Layers|Integrating protocol data manipulations is a strategy for increasing the throughput of network protocols. The idea is to combine a series of protocol layers into a pipeline so as to access message data more efficiently. This paper introduces a widely-applicable technique for integrating protocols. This technique not only improves performance, but also preserves the modularity of protocol layers by automatically integrating independently expressed protocols. The paper also describes a prototype integration tool, and studies the performance limits and scalability of protocol integration. Department of Computer Science The University of Arizona Tucson, AZ 85721 1 This research was sponsored in part by DARPA Contract DABT63-91-C-0030. 1 Introduction Data manipulation---e.g., encryption, presentation formatting, compression, computing checksums---is one of the costliest aspects of data transfer [3, 4, 6]. This is because reading, and possibly writing, each byte of data in a message invo...
447|A System for Constructing Configurable High-Level|New distributed computing applications are driving the development of more specialized protocols, as well as demanding greater control over the communication substrate. Here, a network subsystem that supports modular, finegrained construction of high-level protocols such as atomic multicast and group RPC is described. The approach is based on extending the standard hierarchical model of the x-kernel with composite protocols in which micro-protocol objects are composed within a standard runtime framework. Each micro-protocol realizes a separate semantic property, leading to a highly modular and configurable implementation. In contrast with similar systems, this approach provides finer granularity and more flexible inter-object communication. The design and prototype implementation runing on Mach are described. Performance results are also given for a micro-protocol suite implementing variants of group RPC. 1
448|A Language-Based Approach To Protocol Implementation|: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 15 CHAPTER 1: INTRODUCTION : : : : : : : : : : : : : : : : : : : : : : : : : : 17 1.1 Introduction to Network Software : : : : : : : : : : : : : : : : : : : : : 17 1.2 Network Software is Evolving : : : : : : : : : : : : : : : : : : : : : : : 20 1.3 Existing Support for Network Software Development : : : : : : : : : : : 21 1.3.1 Protocol Frameworks : : : : : : : : : : : : : : : : : : : : : : 21 1.3.2 Formal Techniques : : : : : : : : : : : : : : : : : : : : : : : : 22 1.4 New Strategies for Supporting Protocol Development : : : : : : : : : : : 23 1.4.1 Simplifying Protocol Development by Imposing Constraints : : 24 1.4.2 Language Support for Protocol Development : : : : : : : : : : 25 1.5 Morpheus : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 26 1.5.1 Abstraction : : : : : : : : : : : : : : : : : : : : : : : : : : : : 26 1.5.2 Modularity : : : : : : : : : : : : : : : : : : : : : : : : : : : : ...
449|Protocol Implementation Using Integrated Layer Processing|Integrated Layer Processing (ILP) is an implementation concept which &amp;quot;permit[s] the implementor the option of performing all the [data] manipulation steps in one or two integrated processing loops &amp;quot; [1]. To estimate the achievable benefits of ILP, a file transfer application with an encryption function on top of a user-level TCP has been implemented and the performance of the application in terms of throughput and packet processing times has been measured. The results show that it is possible to obtain performance benefits by integrating marshalling, encryption and TCP checksum calculation. They also show that the benefits are smaller than in simple experiments, where ILP effects have not been evaluated in a complete protocol environment. Simulations of memory access and cache hit rate show that the main benefit of ILP is reduced memory accesses rather than an improved cache hit rate. The results further show that data manipulation characteristics may significantly influence the cache behavior and the achievable performance gain of ILP. 1
450|The Fox Project: Advanced Development of Systems Software|The Fox project will use an advanced programming language to build software such as operating systems, network protocols, and distributed systems. The goals of the project are to improve the design and construction of real systems software and to further the development of advanced programming languages. We will base our work on Standard ML, a modern functional programming language that provides polymorphism, first-class functions, exception handling, garbage collection, a parameterized module system, static typing, and formal semantics. The Fox project spans a wide range of research interests, from experimental systems building to type theory, and involves several faculty members. This research was sponsored by the Air Force Systems Command and the Defense Advanced Research Projects Agency (DARPA) under Contract F19628-91-C-0128. The views and conclusionscontained in this document are those of the authors and should not be interpreted as representing the official policies, either expr...
451|Implementing communication protocols using object-oriented techniques|Appropriate use of object-oriented programming mechanisms in the implementation of communication architectures results in a type structure that reflects the architectural model and increases the run-time performance of the protocol machines at each layer. This result is important since it contradicts the assertion by some that layered protocol architectures, such as the ISO Reference Model, necessarily suffer in performance because of layering, thus forcing implementors to violate the layering principle in search of efficiency. The result substantiates the experience of others, notably Clark, that sound network programming methodology leads to efficient implementations that are also understandable. In this paper, elements of an object-oriented implementation of the upper layer OSI protocols are presented. The purpose of the paper is two-fold: first, to communicate to software engineers, particularly those developing systems software, that object-oriented programing techniques facilitate and enhance the implementation of layered architectures; second, to convey to language designers that object-oriented language features are useful in building communication protocols. The focus is on the requirements for the upper layer OSI protocols and how inheritance, subtyping, and polymorphic functions effect their implementation. 1
452|Clustering geometric data streams |Using recent knowledge in data stream clustering we present a modified approach to the facility location problem in the context of geometric data streams. We give insight to the existing algorithm from a less mathematical point of view, focusing on understanding and practical use, namely by computer graphics experts. We propose a modification of the original data stream k-median clustering to solve facility location which is the case when we a priori do not know the number of clusters in the input data. Like the original, the modified version is capable of processing millions of points while using rather small amount of memory. Based on our experiments with clustering geometric data we present suggestions on how to set processing parameters. We also describe how the algorithm handles various distributions of input data within the stream. These findings may be applied back to the original algorithm.
454|Out-of-Core Simplification of Large Polygonal Models|We present an algorithm for out-of-core simplification of large polygonal datasets that are too complex to fit in main memory. The algorithm extends the vertex clustering scheme of Rossignac and Borrel [13] by using error quadric information for the placement of each cluster&#039;s representative vertex, which better preserves fine details and results in a low mean geometric error. The use of quadrics instead of the vertex grading approach in [13] has the additional benefits of requiring less disk space and only a single pass over the model rather than two. The resulting linear time algorithm allows simplification of datasets of arbitrary complexity. In order
455|Algorithms for Facility Location Problems with Outliers (Extended Abstract)  (2000) |) Moses Charikar Samir Khuller y David M. Mount z Giri Narasimhan x Abstract Facility location problems are traditionally investigated with the assumption that all the clients are to be provided service. A significant shortcoming of this formulation is that a few very distant clients, called outliers, can exert a disproportionately strong influence over the final solution. In this paper we explore a generalization of various facility location problems (K-center, K-median, uncapacitated facility location etc) to the case when only a specified fraction of the customers are to be served. What makes the problems harder is that we have to also select the subset that should get service. We provide generalizations of various approximation algorithms to deal with this added constraint. 1 Introduction The facility location problem and the related clustering problems, k-median and k-center, are widely studied in operations research and computer science [3, 7, 22, 24, 32]. Typically in...
456|Streaming Meshes|Recent years have seen an immense increase in the complexity of geometric data sets. Today&#039;s gigabyte-sized polygon models can no longer be completely loaded into the main memory of common desktop PCs. Unfortunately, current mesh formats do not account for this. They were designed years ago when meshes were orders of magnitudes smaller. Using such formats to store large meshes is inefficient and unduly complicates all subsequent processing.
457|Out-of-Core Compression for Gigantic Polygon Meshes|Polygonal models acquired with emerging 3D scanning technology or from large scale CAD applications easily reach sizes of several gigabytes and do not fit in the address space of common 32-bit desktop PCs. In this paper we propose an out-of-core mesh compression technique that converts such gigantic meshes into a streamable, highly compressed representation. During decompression only a small portion of the mesh needs to be kept in memory at any time. As full connectivity information is available along the decompression boundaries, this provides seamless mesh access for incremental in-core processing on gigantic meshes. Decompression speeds are CPU-limited and exceed one million vertices and two million triangles per second on a 1.8 GHz Athlon processor.
458|Coresets in Dynamic Geometric Data Streams|A dynamic geometric data stream consists of a sequence of m insert/delete operations of points from the discrete space {1,..., ?} d [26]. We develop streaming (1 + ?)-approximation algorithms for k-median, k-means, MaxCut, maximum weighted matching (MaxWM), maximum travelling salesperson (MaxTSP), maximum spanning tree (MaxST), and average distance over dynamic geometric data streams. Our algorithms maintain a small weighted set of points (a coreset) that approximates with probability 2/3 the current point set with respect to the considered problem during the m insert/delete operations of the data stream. They use poly(? -1, log m, log ?) space and update time per insert/delete operation for constant k and dimension d. Having a coreset one only needs a fast approximation algorithm for the weighted problem to compute a solution quickly. In fact, even an exponential algorithm is sometimes feasible as its running time may still be polynomial in n. For example one can compute in poly(log n, exp(O((1+log(1/?)/?) d-1))) time a solution to k-median and k-means [21] where n is the size of the current point set and k and d are constants. Finding an implicit solution to MaxCut can be done in poly(log n, exp((1/?) O(1))) time. For MaxST and average distance we require poly(log n, ? -1) time and for MaxWM we require O(n 3) time to do this.
459|Streaming Compression of Triangle Meshes|Current mesh compression schemes encode triangles and vertices in an order derived from systematically traversing the connectivity graph. These schemes struggle with gigabyte-sized mesh input where the construction and the usage of the data structures that support topological traversal queries become I/O-inefficient and require large amounts of temporary disk space. Furthermore they expect the entire mesh as input. Since meshes cannot be compressed until their generation is complete, they have to be stored at least once in uncompressed form. We radically depart from the traditional approach to mesh compression and propose a scheme that incrementally encodes a mesh in the order it is given to the compressor using only minimal memory resources. This makes the compression process essentially transparent to the user and practically independent of the mesh size. This is especially beneficial for compressing large meshes, where previous approaches spend significant memory, disk, and I/O resources on pre-processing, whereas our scheme starts compressing after receiving the first few triangles. 
460|Efficient Mining of Emerging Patterns: Discovering Trends and Differences|We introduce a new kind of patterns, called emerging patterns (EPs), for knowledge discovery from databases. EPs are defined as itemsets whose supports increase significantly  from one dataset to another. EPs can capture emerging trends in timestamped databases, or useful contrasts between data classes. EPs have been proven useful: we have used them to build very powerful classifiers, which are more accurate than C4.5 and CBA, for many datasets. We believe that EPs with low to medium support, such as 1%-- 20%, can give useful new insights and guidance to experts, in even &#034;well understood&#034; applications.  The efficient mining of EPs is a challenging problem, since (i) the Apriori property no longer holds for EPs, and (ii) there are usually too many candidates for high dimensional databases or for small support thresholds such as 0.5%. Naive algorithms are too costly. To solve this problem, (a) we promote the description of large collections of itemsets using their concise borders (the pa...
461|A Simple Algorithm For Finding Frequent Elements In Streams And Bags|We present a simple, exact algorithm for identifying in a multiset the items with frequency more than a threshold ?. The algorithm requires two passes, linear time, and space 1/?. The first pass is an on-line algorithm, generalizing a well-known algorithm for finding a majority element, for identifying a set of at most 1/? items that includes, possibly among others, all items with frequency greater than ?.
462|Dynamic Weighted Majority: A New Ensemble Method for Tracking Concept Drift|Algorithms for tracking concept drift are important for many applications. We present a general method based on the Weighted Majority algorithm for using any on-line learner for concept drift. Dynamic Weighted Majority (DWM) maintains an ensemble of base learners, predicts using a weighted-majority vote of these &#034;experts&#034;, and dynamically creates and deletes experts in response to changes in performance. We empirically evaluated two experimental systems based on the method using incremental naive Bayes and Incremental Tree Inducer (ITI) as experts.
463|Efcient elastic burst detection in data streams|Burst detection is the activity of finding abnormal aggre-gates in data streams. Such aggregates are based on sliding windows over data streams. In some applications, we want to monitor many sliding window sizes simultaneously and to report those windows with aggregates significantly different from other periods. We will present a general data struc-ture for detecting interesting aggregates over such elastic windows in near linear time. We present applications of the algorithm for detecting Gamma Ray Bursts in large-scale astrophysical data. Detection of periods with high volumes of trading activities and high stock price volatility is also demonstrated using real time Trade and Quote (TAQ) data from the New York Stock Exchange (NYSE). Our algorithm beats the direct computation approach by several orders of magnitude.
464|A Framework for Measuring Changes in Data Characteristics|A data mining algorithm builds a model that captures interesting aspects of the underlying data. We develop a framework for quantifying the difference, called the deviation, between two datasets in terms of the models they induce. Our framework covers a wide variety of models including frequent itemsets, decision tree classifiers, and clusters, and captures standard measures of deviation such as the misclassification rate and the chi-squared metric as special cases. We also show how statistical techniques can be applied to the deviation measure to assess whether the difference between two models is meaningful (i.e., whether the underlying datasets have statistically significant differences in their characteristics), and discuss several practical applications.
465|Sliding-Window Filtering: An Efficient Algorithm for Incremental Mining|We explore in this paper an e#ective sliding-window filtering (abbreviatedly as SWF) algorithm for incremental mining of association rules. In essence, by partitioning a transaction database into several partitions, algorithm SWF employs a filtering threshold in each partition to deal with the candidate itemset generation. Under SWF, the cumulative information of mining previous partitions is selectively carried over toward the generation of candidate itemsets for the subsequent partitions. Algorithm SWF not only significantly reduces I/O and CPU cost by the concepts of cumulative filtering and scan reduction techniques but also effectively controls memory utilization by the technique of sliding-window partition. Algorithm SWF is particularly powerful for efficient incremental mining for an ongoing time-variant transaction database. By utilizing proper scan reduction techniques, only one scan of the incremented dataset is needed by algorithm SWF. The I/O cost of SWF is, in orders of magnitude, smaller than those required by prior methods, thus resolving the performance bottleneck. Experimental studies are performed to evaluate performance of algorithm SWF. It is noted that the improvement achieved by algorithm SWF is even more prominent as the incremented portion of the dataset increases and also as the size of the database increases.
466|An Algorithm for In-Core Frequent Itemset Mining on Streaming Data|has been extensively studied over the last decade. This paper takes a new approach for this problem and makes two major contributions. First, we present a one pass algorithm for frequent itemset mining, which has deterministic bounds on the accuracy, and does not require any out-of-core summary structure. Second, because our one pass algorithm does not produce any false negatives, it can be easily extended to a two pass accurate algorithm. Our two pass algorithm is very memory efficient, and allows mining of datasets with large number of distinct items and/or very low support levels.
467|Interpreting an Arbitrary Data Stream |Abstract: This paper describes a new method that can interpret and extract information from a machine-level binary data stream. This method has two major components: one is a Data Format Scripting Language (DFSL); the other is generic Data Parsing Application Software. The DFSL is a scripting language that specifies the physical layout and semantic constraints for an associated binary data stream. This language can be used to parse a data stream with a specified data format and convert the data into meaningful data structure with text notation. The Data Parsing Application Software is a generic program used to parse the script and its associated raw data. Depending on the script, this program can interpret the meaning of individual data fields and their values. This language and the developed system can be used in the electrical engineering area, especially where the demand for manipulation of real machine-level binary digits is high.
468|DataScript - A Specification and Scripting Language for Binary Data|Abstract. DataScript is a language to describe and manipulate binary data formats as types. DataScript consists of two components: a constraint-based specification language that uses DataScript types to describe the physical layout of data and a language binding that provides a simple programming interface to script binary data. A DataScript compiler generates Java libraries that are linked with DataScript scripts. DataScript specifications can be used to describe formats in a programmatic way, eliminating the vagaries and ambiguities often associated with prosaic format descriptions. The libraries generated by the DataScript compiler free the programmer from the tedious task of coding input and output routines. More importantly, they assure correctness and safety by validating both the input read and the output generated. We show examples that demonstrate that DataScript is simple, yet powerful enough to describe many commonly used formats. Similar to how scripting languages such as Perl allow the manipulation of text files, the libraries generated by the DataScript compiler can be used to quickly write scripts that safely manipulate binary files. 1
469|Approximate Join Processing Over Data Streams|We consider the problem of approximating sliding window joins over data streams in a data stream processing system with limited resources. In our model, we deal with resource constraints by shedding load in the form of dropping tuples from the data streams. We first discuss alternate architectural models for data stream join processing, and we survey suitable measures for the quality of an approximation of a set-valued query result. We then consider the number of generated result tuples as the quality measure, and we give optimal offline and fast online algorithms for it. In a thorough experimental study with synthetic and real data we show the efficacy of our solutions. For applications with demand for exact results we introduce a new Archive-metric which captures the amount of work needed to complete the join in case the streams are archived for later processing.
470|A metric for distributions with applications to image databases|We introduce a new distance between two distributions that we call the Earth Mover’s Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distributioninto the other by moving “distribution mass ” around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search. 1
471|An Efficient Implementation Of A Scaling Minimum-Cost Flow Algorithm|. The scaling push-relabel method is an important theoretical development in the area of minimum-cost flow algorithms. We study practical implementations of this method. We are especially interested in heuristics which improve real-life performance of the method. Our implementation works very well over a wide range of problem classes. In our experiments, it was always competitive with the established codes, and usually outperformed these codes by a wide margin. Some heuristics we develop may apply to other network algorithms. Our experimental work on the minimum-cost flow problem motivated theoretical work on related problems. Supported in part by ONR Young Investigator Award N00014-91-J-1855, NSF Presidential Young Investigator Grant CCR-8858097 with matching funds from AT&amp;T and DEC, Stanford University Office of Technology Licensing, and a grant form the Powell Foundation.  1  1. Introduction.  Significant theoretical progress has been made recently in the area of minimum-cost flow ...
472|Adaptive Query Processing: Technology in Evolution|As query engines are scaled and federated, they must cope with highly unpredictable and changeable environments. In the Telegraph project, we are attempting to architect and implement a continuously adaptive query engine suitable for global-area systems, massive parallelism, and sensor networks. To set the stage for our research, we present a survey of prior work on adaptive query processing, focusing on three characterizations of adaptivity: the frequency of adaptivity, the effects of adaptivity, and the extent of adaptivity. Given this survey, we sketch directions for research in the Telegraph project.  
473|CoolStreaming/DONet: A Data-driven Overlay Network for Peer-to-Peer Live Media Streaming|This paper presents DONet, a Data-driven Overlay Network for live media streaming. The core operations in DONet are very simple: every node periodically exchanges data availability information with a set of partners, and retrieves unavailable data from one or more partners, or supplies available data to partners. We emphasize three salient features of this data-driven design: 1) easy to implement, as it does not have to construct and maintain a complex global structure; 2) efficient, as data forwarding is dynamically determined according to data availability while not restricted by specific directions; and 3) robust and resilient, as the partnerships enable adaptive and quick switching among multi-suppliers. We show through analysis that DONet is scalable with bounded delay. We also address a set of practical challenges for realizing DONet, and propose an efficient member- and partnership management algorithm, together with an intelligent scheduling algorithm that achieves real-time and continuous distribution of streaming contents.
474|A Case for End System Multicast|Abstract — The conventional wisdom has been that IP is the natural protocol layer for implementing multicast related functionality. However, more than a decade after its initial proposal, IP Multicast is still plagued with concerns pertaining to scalability, network management, deployment and support for higher layer functionality such as error, flow and congestion control. In this paper, we explore an alternative architecture that we term End System Multicast, where end systems implement all multicast related functionality including membership management and packet replication. This shifting of multicast support from routers to end systems has the potential to address most problems associated with IP Multicast. However, the key concern is the performance penalty associated with such a model. In particular, End System Multicast introduces duplicate packets on physical links and incurs larger end-to-end delays than IP Multicast. In this paper, we study these performance concerns in the context of the Narada protocol. In Narada, end systems selforganize into an overlay structure using a fully distributed protocol. Further, end systems attempt to optimize the efficiency of the overlay by adapting to network dynamics and by considering application level performance. We present details of Narada and evaluate it using both simulation and Internet experiments. Our results indicate that the performance penalties are low both from the application and the network perspectives. We believe the potential benefits of transferring multicast functionality from end systems to routers significantly outweigh the performance penalty incurred. I.
475|Scalable Application Layer Multicast|We describe a new scalable application-layer multicast protocol, specifically designed for low-bandwidth, data streaming applications with large receiver sets. Our scheme is based upon a hierarchical clustering of the application-layer multicast peers and can support a number of different data delivery trees with desirable properties. We present extensive simulations of both our protocol and the Narada application-layer multicast protocol over Internet-like topologies. Our results show that for groups of size 32 or more, our protocol has lower link stress (by about 25%), improved or similar endto-end latencies and similar failure recovery properties. More importantly, it is able to achieve these results by using orders of magnitude lower control traffic. Finally, we present results from our wide-area testbed in which we experimented with 32-100 member groups distributed over 8 different sites. In our experiments, averagegroup members established and maintained low-latency paths and incurred a maximum packet loss rate of less than 1 % as members randomly joined and left the multicast group. The average control overhead during our experiments was less than 1 Kbps for groups of size 100.
476|Bullet: High Bandwidth Data Dissemination Using an Overlay Mesh|In recent years, overlay networks have become an effective alternative to IP multicast for efficient point to multipoint communication across the Internet. Typically, nodes self-organize with the goal of forming an efficient overlay tree, one that meets performance targets without placing undue burden on the underlying network. In this paper, we target high-bandwidth data distribution from a single source to a large number of receivers. Applications include large-file transfers and real-time multimedia streaming. For these applications, we argue that an overlay mesh, rather than a tree, can deliver fundamentally higher bandwidth and reliability relative to typical tree structures. This paper presents Bullet, a scalable and distributed algorithm that enables nodes spread across the Internet to self-organize into a high bandwidth overlay mesh. We construct Bullet around the insight that data should be distributed in a disjoint manner to strategic points in the network. Individual Bullet receivers are then responsible for locating and retrieving the data from multiple points in parallel. Key contributions of this work include: i) an algorithm that sends data to di#erent points in the overlay such that any data object is equally likely to appear at any node, ii) a scalable and decentralized algorithm that allows nodes to locate and recover missing data items, and iii) a complete implementation and evaluation of Bullet running across the Internet and in a large-scale emulation environment reveals up to a factor two bandwidth improvements under a variety of circumstances. In addition, we find that, relative to tree-based solutions, Bullet reduces the need to perform expensive bandwidth probing.
477|Peer-to-Peer Membership Management for Gossip-Based Protocols|Gossip-based protocols for group communication have attractive scalability and reliability properties. The probabilistic  gossip schemes studied so far typically assume that each group member has full knowledge of the global membership and chooses  gossip targets uniformly at random. The requirement of global knowledge impairs their applicability to very large-scale groups. In this  paper, we present SCAMP (Scalable Membership protocol), a novel peer-to-peer membership protocol which operates in a fully  decentralized manner and provides each member with a partial view of the group membership. Our protocol is self-organizing in the  sense that the size of partial views naturally converges to the value required to support a gossip algorithm reliably. This value is a  function of the group size, but is achieved without any node knowing the group size. We propose additional mechanisms to achieve  balanced view sizes even with highly unbalanced subscription patterns. We present the design, theoretical analysis, and a detailed  evaluation of the basic protocol and its refinements. Simulation results show that the reliability guarantees provided by SCAMP are  comparable to previous schemes based on global knowledge. The scale of the experiments attests to the scalability of the protocol.
478|PROMISE: Peer-to-Peer Media Streaming Using CollectCast|We present the design, implementation, and evaluation of PROMISE,  a novel peer-to-peer media streaming system encompassing the key functions of peer lookup, peer-based aggregated streaming, and dynamic adaptations to network and peer conditions. Particularly, PROMISE is based on a new application level P2P service called CollectCast. CollectCast performs three main functions: (1) inferring and leveraging the underlying network topology and performance information for the selection of senders; (2) monitoring the status of peers and connections and reacting to peer/connection failure or degradation with low overhead; (3) dynamically switching active senders and standby senders, so that the collective network performance out of the active senders remains satisfactory. Based on both real-world measurement and simulation, we evaluate the performance of PROMISE, and discuss lessons learned from our experience with respect to the practicality and further optimization of PROMISE.
479|Video Multicast over the Internet|Multicast (multipoint) distribution of video is an important component of many existing and  future networked services. Today&#039;s Internet lacks support for quality of service (QoS) assurance  which makes the transmission of real-time traffic (such as video) challenging. In addition,  the heterogeneity of the Internet&#039;s transmission resources and end-systems makes it extremely  difficult, if not impossible, to agree on acceptable traffic characteristics among multiple receivers  of the same video stream. In this paper we survey techniques that have been proposed for  transmitting video in this environment. These techniques generally involve adaptation of the  video traffic carried over the network to match receiver requirements and network conditions.  In addition to their applicability to the near-term capabilities of the Internet, they also are of  relevance to a future, QoS-aware Internet environment because of the inevitable inaccuracies  in traffic and resource reservation specifica...
480|Resilient Multicast using Overlays|(PRM): a multicast data recovery scheme that improves data delivery ratios while maintaining low end-to-end latencies. PRM has both a proactive and a reactive components; in this paper we describe how PRM can be used to improve the performance of application-layer multicast protocols especially when there are high packet losses and host failures. Through detailed analysis in this paper, we show that this loss recovery technique has efficient scaling properties—the overheads at each overlay node asymptotically decrease to zero with increasing group sizes. As a detailed case study, we show how PRM can be applied to the NICE application-layer multicast protocol. We present detailed simulations of the PRM-enhanced NICE protocol for 10 000 node Internet-like topologies. Simulations show that PRM achieves a high delivery ratio ( 97%) with a low latency bound (600 ms) for environments with high end-to-end network losses (1%–5%) and high topology change rates (5 changes per second) while incurring very low overheads ( 5%). Index Terms—Multicast, networks, overlays, probabilistic forwarding, protocols, resilience. I.
481|Routing in Overlay Multicast Networks|Multicast services can be provided either as a basic network service or as an application-layer service. Higher level multicast implementations often provide more sophisticated features, and can provide multicast services, where no network layer support is available. Overlay multicast networks offer an intermediate option, potentially combining the flexibility and advanced features of application layer multicast with the greater efficiency of network layer multicast. Overlay multicast networks play an important role in the Internet. Indeed, since Internet Service Providers have been slow to enable IP multicast in their networks, Internet multicast is only widely available as an overlay service. This paper introduces several routing algorithms that are suitable for overlay multicast networks and evaluates their performance. The algorithms seek to optimize the endto -end delay and the interface bandwidth usage at the routing sites within the overlay network. The interface bandwidth is typically a key resource for an overlay network provider, and needs to be carefully managed in order to maximize the number of sessions that can be served. The simultaneous optimization of both delay and bandwidth is an NP-hard problem. We propose several heuristic algorithms and simulate their performance under various traffic conditions and on various network topologies.
482|A Peer-to-Peer Architecture for Media Streaming|We have witnessed the success of peer-to-peer (P2P) applications in both commercial and research fields. However, a practical application has received little attention to date: media streaming. Given the fact that the current Internet does not support IP Multicast while content-distribution-networks technologies are costly, P2P could be a promising start for enabling large-scale streaming systems. In our so-called Zigzag approach, we propose a method for clustering peers into a hierarchy called the administrative organization for easy management, and a method for building the multicast tree atop this hierarchy for efficient content transmission. In Zigzag, the multicast tree has a height logarithmic with the number of clients, and a node degree bounded by a constant. This helps reduce the number of processing hops on the delivery path to a client while avoiding network bottleneck. Consequently, the end-to-end delay is kept small. Although one could build a tree satisfying such properties easily, an efficient control protocol between the nodes must be in place to maintain the tree under the effects of network dynamics. Zigzag handles such situations gracefully requiring a constant amortized worst-case control overhead. Especially, failure recovery is done regionally with impact on at most a constant number of existing clients and with mostly no burden on the server.
483|oStream: Asynchronous Streaming Multicast in Application-Layer Overlay Networks|Although initially proposed as the deployable alternative to IP multicast, application-layer overlay network actually revolutionizes the way network applications can be built, since each overlay node is an end host, which is able to carry out more functionalities than simply forwarding packets. This paper addresses the on-demand media distribution problem in the context of overlay network. We take advantage of the strong...
484|On Peer-to-Peer Media Streaming  |In this paper, we study a peer-to-peer media streaming system with the following characteristics: (1) its streaming capacity grows dynamically; (2) peers do not exhibit serverlike behavior; (3) peers are heterogeneous in their bandwidth contribution; and (4) each streaming session may involve multiple supplying peers. Based on these characteristics, we investigate two problems: (1) how to assign media data to multiple supplying peers in one streaming session and (2) how to fast amplify the system’s total streaming capacity. Our solution to the first problem is an optimal media data assignment algorithm ÇÌËÔ Ô, which results in minimum buffering delay in the consequent streaming session. Our solution to the second problem is a distributed differentiated admission control protocol ???Ô Ô. By differentiating between requesting peers with different outbound bandwidth, ???Ô Ô achieves fast system capacity amplification; benefits all requesting peers in admission rate, waiting time, and buffering delay; and creates an incentive for peers to offer their truly available out-bound bandwidth. 
485|P2Cast: peer-to-peer patching scheme for VoD service|Providing video on demand (VoD) service over the Internet in a scalable way is a challenging problem. In this paper, we propose P2Cast- an architecture that uses a peer-to-peer approach to cooperatively stream video using patching techniques, while only relying on unicast connections among peers. We address the following two key technical issues in P2Cast: (1) constructing an application overlay appropriate for streaming; and (2) providing continuous stream playback (without glitches) in the face of disruption from an early departing client. Our simulation experiments show that P2Cast can serve many more clients than traditional client-server unicast service, and that it generally out-performs multicast-based patching if clients can cache more than ¡£¢¥¤ of a stream’s initial portion. We handle disruptions by delaying the start of playback and applying the shifted forwarding technique. A threshold on the length of time during which arriving clients are served in a single session in P2Cast serves as a knob to adjust the balance between the scalability and the clients ’ viewing quality in P2Cast.
486|From Epidemics to Distributed Computing |Abstract — Epidemic algorithms have been recently recognized as robust and scalable means to disseminate information in large-scale settings. Information is disseminated reliably in a distributed system the same way an epidemic would be propagated throughout a group of individuals: each process of the system chooses random peers to whom it relays the information it has received. The underlying peer-to-peer communication paradigm is the key to the scalability of the dissemination scheme. Epidemic algorithms have been studied theoretically and their analysis is built on sound mathematical foundations. Although promising, their general applicability to large scale distributed systems has yet to go through addressing many issues. These constitute an exciting research agenda. Index Terms — Scalability, peer-to-peer, epidemics, information
487|An Architecture for Internet Content Distribution as an Infrastructure Service|The IP Multicast service model extends the traditional best effort Internet datagram delivery service for efficient multi-point packet delivery. However, in spite of a decade of research on multicast protocols and applications, a globally deployed multicast service is nowhere in sight, hindered by multitudes of problems such as manageability, lack of a robust inter-domain multicast routing protocol, scalability, and heterogeneity. In this work, we propose a new model for Internet multicast where we view multi-point delivery not as a network primitive but rather as an application-level infrastructure service. Our architecture relies on a collection of strategically placed network agents that collaboratively provides the multicast service for a session. Clients locate a nearby agent and tap into the session via that agent. Agents organize themselves into an overlay network of unicast connections and build data distribution trees on top of this overlay structure. This model effectively pa...
488|Layered Peer-to-Peer Streaming|In this paper, we propose a peer-to-peer streaming solution to address the on-demand media distribution problem. We identify two issues, namely the asynchrony of user requests and heterogeneity of peer network bandwidth. Our key techniques to address these two issues are cache-andrelay and layer-encoded streaming. A unique challenge of layered peer-to-peer streaming is that the bandwidth and data availability (number of layers received) of each receiving peer are constrained and heterogeneous, which further limits the bandwidth and data availability of its downstream node when it acts as the supplying peer. This challenge distinguishes our work from existing studies on layered multicast. Our experiments show that our solution is e#cient at utilizing bandwidth resource of supplying peers, scalable at saving server bandwidth consumption, and optimal at maximizing streaming qualities of all peers.
489|Cache-and-Relay Streaming Media Delivery for Asynchronous Clients|We consider the problem of delivering popular streaming media to a large number of asynchronous clients. We propose and evaluate a cache-and-relay end-system multicast approach, whereby a client joining a multicast session caches the stream, and if needed, relays that stream to neighboring clients which may join the multicast session at some later time. This cache-and-relay approach is fully distributed, scalable, and efficient in terms of network link cost. In this paper we analytically derive bounds on the network link cost of our cache-and-relay approach, and we evaluate its performance under assumptions of limited client bandwidth and limited client cache capacity. When client bandwidth is limited, we show that although finding an optimal solution is NP-hard, a simple greedy algorithm performs surprisingly well in that it incurs network link costs that are very close to a theoretical lower bound. When client cache capacity is limited, we show that our cache-and-relay approach can still significantly reduce network link cost. We have evaluated our cache-and-relay approach using simulations over large, synthetic random networks, power-law degree networks, and small-world networks, as well as over large real router-level Internet maps.
490|  A Comparative Study of Application Layer Multicast Protocols | Due to the sparse deployment of IP multicast in the Internet today, some researchers have proposed application layer multicast as a new approach to implement widearea multicast services. In this approach multicast functionality is implemented at the end-hosts instead of network routers. Unlike network-layer multicast, application layer multicast requires no infrastructure support and can be easily deployed in the Internet. In this paper, we describe a set of application layer multicast protocols that have been proposed in recent literature, classify them based on some properties and present a comparison of performance and applicability of these schemes.
491|A Proactive Approach to Reconstructing Overlay Multicast Trees|Overlay multicast constructs a multicast delivery tree among end hosts. Unlike traditional IP multicast, the nonleaf nodes in the tree are normal end hosts, which are potentially more susceptible to failures than routers and may leave the multicast group voluntarily. In these cases, all downstream nodes will be affected. Thus an important problem in overlay multicast is how to recover from node departures in order to minimize the disruption of service to those affected nodes. In this paper, we propose a proactive approach to restore overlay multicast trees. Rather than letting downstream nodes try to find a new parent after a node departure, each non-leaf node precalculates a parent-to-be for each of its children. When this nonleaf node is gone, all its children can find their respective new parents immediately. The salient feature of the approach is that each non-leaf node can compute a rescue plan for its children independently, and in most cases, rescue plans from multiple non-leaf nodes can work together for their children when they fail or leave at the same time. We develop a protocol for nodes to communicate with new parents so that the delivery tree can be quickly restored. Extensive simulations demonstrate that our proactive approach can recover from node departures 5 times faster than reactive methods in some cases, and 2 times faster on average.
492|PROP: a Scalable and Reliable P2P Assisted Proxy Streaming System|The demand of delivering streaming media content in the Internet has become increasingly high for scientific, educational, and commercial applications. Three representative technologies have been developed for this purpose, each of which has its merits and serious limitations. Infrastructurebased CDNs with dedicated network bandwidths and powerful media replicas can provide high quality streaming services but at a high cost. Server-based proxies are costeffective but not scalable due to the limited proxy capacity and its centralized control. Client-based P2P networks are scalable but do not guarantee high quality streaming service due to the transient nature of peers. To address these limitations, we present a novel and efficient design of a scalable and reliable media proxy system supported by P2P networks. This system is called PROP abbreviated from our technical theme of &#034;collaborating and coordinating PROxy and its P2P clients&#034;. Our objective is to address both scalability and reliability issues of streaming media delivery in a costeffective way. In the PROP system, the clients&#039; machines in an intranet are self-organized into a structured P2P system to provide a large media storage and to actively participate in the streaming media delivery, where the proxy is also embedded as an important member to ensure quality of streaming service. The coordination and collaboration in the system are efficiently conducted by our P2P management structure and replacement policies. We have comparatively evaluated our system by trace-driven simulations with synthetic workloads and with a real-life workload trace extracted from the media server logs in an enterprise network. The results show that our design significantly improves the quality of media streaming and the system scalabil...
493|A hybrid architecture for cost-effective on-demand media streaming|We propose a new architecture for on-demand media streaming centered around the peer-to-peer (P2P) paradigm. The key idea of the architecture is that peers share some of their resources with the system. As peers contribute resources to the system, the overall system capacity increases and more clients can be served. The proposed ar-chitecture employs several novel techniques to: (1) use the often-underutilized peers ’ resources, which makes the proposed architecture both deployable and cost-effective, (2) aggregate contributions from multiple peers to serve a requesting peer so that supplying peers are not overloaded, (3) make a good use of peer heterogeneity by as-signing relatively more work to the powerful peers, and (4) organize peers in a network-aware fashion, such that nearby peers are grouped into a logical entity called a cluster. The network-aware peer organization is validated by statistics collected and analyzed from real Internet data. The main benefit of the network-aware peer organization is that it allows to develop efficient searching (to locate nearby suppliers) and dispersion (to disseminate new files into the system) algorithms. We present network-aware searching and dispersion algorithms that result in: (i) fast dissemination of new media files, (ii) reduction of the load on the underlying network, and (iii) better streaming service. We demonstrate the potential of the proposed architecture for a large-scale on-demand media streaming service through an extensive simulation study on large, Internet-like, topologies. Starting with a limited streaming capacity
494|Processing Distributed Compound-Data Streams |Abstract. In the environment of distribute data stream systems, the available communica-tion bandwidth is a bottleneck resource. It is significant to reduce the communication overhead as possible for improving the availability of communication bandwidth with the constraint of the precision of queries. In this paper, we propose a new method for transfer-ring data streams in distributed data stream systems, named as compound-data streams. The idea is that raw data streams are grouped and merged into compound-data streams, and then compound-data streams, instead of raw data streams, are transferred to the central processor node. By this way, the communication overhead can be reduced greatly. 1
495|Wide-Area Traffic: The Failure of Poisson Modeling|Network arrivals are often modeled as Poisson processes for analytic simplicity, even though a number of traffic studies have shown that packet interarrivals are not exponentially distributed. We evaluate 24 wide-area traces, investigating a number of wide-area TCP arrival processes (session and connection arrivals, FTP data connection arrivals within FTP sessions, and TELNET packet arrivals) to determine the error introduced by modeling them using Poisson processes. We find that user-initiated TCP session arrivals, such as remotelogin and file-transfer, are well-modeled as Poisson processes with fixed hourly rates, but that other connection arrivals deviate considerably from Poisson; that modeling TELNET packet interarrivals as exponential grievously underestimates the burstiness of TELNET traffic, but using the empirical Tcplib [Danzig et al, 1992] interarrivals preserves burstiness over many time scales; and that FTP data connection arrivals within FTP sessions come bunched into “connection bursts,” the largest of which are so large that they completely dominate FTP data traffic. Finally, we offer some results regarding how our findings relate to the possible self-similarity of widearea traffic.  
496|Scalable distributed stream processing|Stream processing fits a large class of new applications for which conventional DBMSs fall short. Because many stream-oriented systems are inherently geographically distributed and because distribution offers scalable load management and higher availability, future stream processing systems will operate in a distributed fashion. They will run across the Internet on computers typically owned by multiple cooperating administrative domains. This paper describes the architectural challenges facing the design of large-scale distributed stream processing systems, and discusses novel approaches for addressing load management, high availability, and federated operation issues. We describe two stream processing systems, Aurora * and Medusa, which are being designed to explore complementary solutions to these challenges. 1
497|Maximizing the output rate of multi-way join queries over streaming information sources|Recently there has been a growing interest in join query evaluation for scenarios in which inputs arrive at highly variable and unpredictable rates. In such scenarios, the focus shifts from completing the computation as soon as possible to producing a prefix of the output as soon as possible. To handle this shift in focus, most solutions to date rely upon some combination of streaming binary operators and “on-the-fly” execution plan reorganization. In contrast, we consider the alternative of extending existing symmetric binary join operators to handle more than two inputs. Toward this end, we have completed a prototype implementation of a multi-way join operator, which we term the “MJoin ” operator, and explored its performance. Our results show that in many instances the MJoin produces outputs sooner than any tree of binary operators. Additionally, since MJoins are completely symmetric with respect to their inputs, they can reduce the need for expensive runtime plan reorganization. This suggests that supporting multi-way joins in a single, symmetric, streaming operator may be a useful addition to systems that support queries over input streams from remote sites. 1
498|Using hddt to avoid instances propagation in unbalanced and evolving data streams|data streams
499|The WEKA Data Mining Software: An Update |More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003. 1.
500|The CN2 Induction Algorithm|Systems for inducing concept descriptions from examples are valuable tools for  assisting in the task of knowledge acquisition for expert systems. This paper presents  a description and empirical evaluation of a new induction system, cn2, designed for  the efficient induction of simple, comprehensible production rules in domains where  problems of poor description language and/or noise may be present. Implementations  of the cn2, id3 and aq algorithms are compared on three medical classification tasks.   
501|The class imbalance problem: A systematic study|Abstract In machine learning problems, dierences in prior class probabilities|or class imbalances|have been reported to hinder the performance of some standard classi ers, such as decision trees. This paper presents a systematic study aimed at answering three dierent questions. First, we attempt to understand what the class imbalance problem is by establishing a relationship between concept complexity, size of the training set and class imbalance level. Second, we discuss several basic re-sampling or cost-modifying methods previously proposed to deal with class imbalances and compare their eectiveness. Finally, we investigate the assumption that the class imbalance problem does not only aect decision tree systems but also aects other classi cation systems such as Neural Networks and Support Vector Machines.
502|Editorial: special issue on learning from imbalanced data sets|The class imbalance problem is one of the (relatively) new problems that emerged when machine learning matured from an embryonic science to an applied technology, amply used in the worlds of business, industry and scientific research.
503|DATA MINING FOR IMBALANCED DATASETS: AN OVERVIEW| A dataset is imbalanced if the classification categories are not approximately equally represented. Recent years brought increased interest in applying machine learning techniques to difficult &#034;real-world&#034; problems, many of which are characterized by imbalanced data. Additionally the distribution of the testing data may differ from that of the training data, and the true misclassification costs may be unknown at learning time. Predictive accuracy, a popular choice for evaluating performance of a classifier, might not be appropriate when the data is imbalanced and/or the costs of different errors vary markedly. In this Chapter, we discuss some of the sampling techniques used for balancing the datasets, and the performance measures more appropriate for mining imbalanced datasets. 
504|A general framework for mining concept-drifting data streams with skewed distributions|In recent years, there have been some interesting studies on predictive modeling in data streams. However, most such studies assume relatively balanced and stable data streams but cannot handle well rather skewed (e.g., few positives but lots of negatives) and stochastic distributions, which are typical in many data stream applications. In this paper, we propose a new approach to mine data streams by estimating reliable posterior probabilities using an ensemble of models to match the distribution over under-samples of negatives and repeated samples of positives. We formally show some interesting and important properties of the proposed framework, e.g., reliability of estimated probabilities on skewed positive class, accuracy of estimated probabilities, efficiency and scalability. Experiments are performed on several synthetic as well as real-world datasets with skewed distributions, and they demonstrate that our framework has substantial advantages over existing approaches in estimation reliability and predication accuracy. 1
505|MOA: Massive Online Analysis |Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA includes a collection of offline and online methods as well as tools for evaluation. In particular, it implements boosting, bagging, and Hoeffding Trees, all with and without Naïve Bayes classifiers at the leaves. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis, and is released under the GNU GPL license.
506|Learning Decision Trees for Unbalanced Data|Abstract. Learning from unbalanced datasets presents a convoluted problem in which traditional learning algorithms may perform poorly. The objective functions used for learning the classifiers typically tend to favor the larger, less important classes in such problems. This paper compares the performance of several popular decision tree splitting criteria – information gain, Gini measure, and DKM – and identifies a new skew insensitive measure in Hellinger distance. We outline the strengths of Hellinger distance in class imbalance, propose its application in forming decision trees, and perform a comprehensive comparative analysis between each decision tree construction method. In addition, we consider the performance of each tree within a powerful sampling wrapper framework to capture the interaction of the splitting metric and sampling. We evaluate over this wide range of datasets and determine which operate best under class imbalance. 1
507|Incremental learning of variable rate concept drift |Abstract. We have recently introduced an incremental learning algorithm, Learn ++.NSE, for Non-Stationary Environments, where the data distribution changes over time due to concept drift. Learn ++.NSE is an ensemble of classifiers approach, training a new classifier on each consecutive batch of data that become available, and combining them through an age-adjusted dynamic error based weighted majority voting. Prior work has shown the algorithm’s ability to track gradually changing environments as well as its ability to retain former knowledge in cases of cyclical or recurring data by retaining and appropriately weighting all classifiers generated thus far. In this contribution, we extend the analysis of the algorithm to more challenging environments experiencing varying drift rates; but more importantly we present preliminary results on the ability of the algorithm to accommodate addition or subtraction of classes over time. Furthermore, we also present comparative results of a variation of the algorithm that employs an error-based pruning in cyclical environments.
508|N.V.: Adaptive methods for classification in arbitrarily imbalanced and drifting data streams|Abstract. Streaming data is pervasive in a multitude of data mining applications. One fundamental problem in the task of mining streaming data is distributional drift over time. Streams may also exhibit high and varying degrees of class imbalance, which can further complicate the task. In scenarios like these, class imbalance is particularly difficult to overcome and has not been as thoroughly studied. In this paper, we comprehensively consider the issues of changing distributions in conjunction with high degrees of class imbalance in streaming data. We propose new approaches based on distributional divergence and meta-classification that improve several performance metrics often applied in the study of imbalanced classification. We also propose a new distance measure for detecting distributional drift and examine its utility in weighting ensemble base classifiers. We employ a sequential validation framework, which we believe is the most meaningful option in the context of streaming imbalanced data.
509|Detecting Fractures in Classifier Performance |A fundamental tenet assumed by many classification algorithms is the presumption that both training and testing samples are drawn from the same distribution of data – this is the stationary distribution assumption. This entails that the past is strongly indicative of the future. However, in real world applications, many factors may alter the One True Model responsible for generating the data distribution both significantly and subtly. In circumstances violating the stationary distribution assumption, traditional validation schemes such as ten-folds and hold-out become poor performance predictors and classifier rankers. Thus, it becomes critical to discover the fracture points in classifier performance by discovering the divergence between populations. In this paper, we implement a comprehensive evaluation framework to identify bias, enabling selection of a ”correct ” classifier given the sample bias. To thoroughly evaluate the performance of classifiers within biased distributions, we consider the following three scenarios: missing completely at random (akin to stationary); missing at random; and missing not at random. The latter reflects the canonical sample selection bias problem. 1
510|Heuristic Updatable Weighted Random Subspaces for Non-stationary Environments |Abstract—Learning in non-stationary environments is an increasingly important problem in a wide variety of real-world applications. In non-stationary environments data arrives incrementally, however the underlying generating function may change over time. While there is a variety of research into such environments, the research mainly consists of detecting concept drift (and then relearning the model), or developing classifiers which adapt to drift incrementally. We introduce Heuristic Updatable Weighted Random Subspaces (HUWRS), a new technique based on the Random Subspace Method that detects drift in individual features via the use of Hellinger distance, a distributional divergence metric. Through the use of subspaces, HUWRS allows for a more finegrained approach to dealing with concept drift which is robust to feature drift even without class labels. We then compare our approach to two state of the art algorithms, concluding that for a wide range of datasets and window sizes HUWRS outperforms the other methods.
511|Learning in Non-stationary Environments with Class Imbalance ABSTRACT |Learning in non-stationary environments is an increasingly important problem in a wide variety of real-world applications. In non-stationary environments data arrives incrementally, however the underlying generating function may change over time. In addition to the environments being non-stationary, they also often exhibit class imbalance. That is one class (the majority class) vastly outnumbers the other class (the minority class). This combination of class imbalance with non-stationary environments poses significant and interesting practical problems for classification. To overcome these issues, we introduce a novel instance selection mechanism, as well as provide a modification to the Heuristic Updatable Weighted Random Subspaces (HUWRS) method for the class imbalance problem. We then compare our modifications of HUWRS (called HUWRS.IP) to other state of the art algorithms, concluding that HUWRS.IP often achieves vastly superior performance.
512|Racing for unbalanced methods selection|Abstract. State-of-the-art classification algorithms suffer when the data is skewed towards one class. This led to the development of a number of techniques to cope with unbalanced data. However, as confirmed by our experimental comparison, no technique appears to work consistently better in all conditions. We propose to use a racing method to select adaptively the most appropriate strategy for a given unbalanced task. The results show that racing is able to adapt the choice of the strategy to the specific nature of the unbalanced problem and to select rapidly the most appropriate strategy without compromising the accuracy.
513|An Ensemble Based Incremental Learning Framework for Concept Drift and Class Imbalance |Abstract—We have recently introduced an incremental learning algorithm, Learn ++.NSE, designed to learn in nonstationary environments, and has been shown to provide an attractive solution to a number of concept drift problems under different drift scenarios. However, Learn ++.NSE relies on error to weigh the classifiers in the ensemble on the most recent data. For balanced class distributions, this approach works very well, but when faced with imbalanced data, error is no longer an acceptable measure of performance. On the other hand, the well-established SMOTE algorithm can address the class imbalance issue, however, it cannot learn in nonstationary environments. While there is some literature available for learning in nonstationary environments and imbalanced data separately, the combined problem of learning from imbalanced data coming from nonstationary environments is underexplored. Therefore, in this work we propose two modified frameworks for an algorithm that can be used to incrementally learn from imbalanced data coming from a nonstationary environment. Index Terms—concept drift, imbalanced data, ensemble of classifiers, incremental learning in nonstationary environments I.
514|Data Stream Mining |which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. This research aims to describe a new design of data streammining system that can analyze medical data stream and make real-time prediction. The motivation of the research is due to a growing concern of combining software technology and medical functions for the development of software application that can be used in medical field of chronic disease prognosis and diagnosis, children healthcare, diabetes diagnosis, and so forth. Most of the existing software technologies are case-based data mining systems. They only can analyze finite and structured data set and can only work well in their early years and can hardly meet today’s medical requirement. In this paper, we describe a clinical-support-system based data stream mining technology; the design has taken into account all the shortcomings of the existing clinical support systems. 1.
515|M.: Computing semantic similarity using ontologies |networks
516|References for Data Stream Algorithms|Many scenarios, such as network analysis, utility monitoring, and financial applications, generate massive streams of data. These streams consist of millions or billions of simple updates every hour, and must be processed to extract the information described in tiny pieces. These notes provide an introduction to (and set of references for) data stream algorithms, and some of the techniques that have been developed over recent years to help mine the data while avoiding drowning in these massive flows of information. 1
517|Routing in a delay tolerant network|We formulate the delay-tolerant networking routing problem, where messages are to be moved end-to-end across a connectivity graph that is time-varying but whose dynamics may be known in advance. The problem has the added constraints of finite buffers at each node and the general property that no contemporaneous end-to-end path may ever exist. This situation limits the applicability of traditional routing approaches that tend to treat outages as failures and seek to find an existing end-to-end path. We propose a framework for evaluating routing algorithms in such environments. We then develop several algorithms and use simulations to compare their performance with respect to the amount of knowledge they require about network topology. We find that, as expected, the algorithms using the least knowledge tend to perform poorly. We also find that with limited additional knowledge, far less than complete global knowledge, efficient algorithms can be constructed for routing in such environments. To the best of our knowledge this is the first such investigation of routing issues in DTNs.
518|Efficient Query Evaluation on Probabilistic Databases|We describe a system that supports arbitrarily complex SQL queries with ”uncertain” predicates. The query semantics is based on a probabilistic model and the results are ranked, much like in Information Retrieval. Our main focus is efficient query evaluation, a problem that has not received attention in the past. We describe an optimization algorithm that can compute efficiently most queries. We show, however, that the data complexity of some queries is #P-complete, which implies that these queries do not admit any efficient evaluation methods. For these queries we describe both an approximation algorithm and a Monte-Carlo simulation algorithm.
519|Distributed top-k monitoring|The querying and analysis of data streams has been a topic of much recent interest, motivated by applications from the fields of networking, web usage analysis, sensor instrumentation, telecommunications, and others. Many of these applications involve monitoring answers to continuous queries over data streams produced at physically distributed locations, and most previous approaches require streams to be transmitted to a single location for centralized processing. Unfortunately, the continual transmission of a large number of rapid data streams to a central location can be impractical or expensive. We study a useful class of queries that continuously report the k largest values obtained from distributed data streams (“top-k monitoring queries”), which are of particular interest because they can be used to reduce the overhead incurred while running other types of monitoring queries. We show that transmitting entire data streams is unnecessary to support these queries and present an alternative approach that reduces communication significantly. In our approach, arithmetic constraints are maintained at remote stream sources to ensure that the most recently provided top-k answer remains valid to within a userspecified error tolerance. Distributed communication is only necessary on occasion, when constraints are violated, and we show empirically through extensive simulation on real-world data that our approach reduces overall communication cost by an order of magnitude compared with alternatives that offer the same error guarantees. 1
520|Strong regularities in World Wide Web surfing|One of the most common modes of accessing information in the World Wide Web (WWW) is surfing from one document to another along hyperlinks. Several large empirical studies have revealed common patterns of surfing behavior. A model which assumes that users make a sequence of decisions to proceed to another page, continuing as long as the value of the current page exceeds some threshold, yields the probability distribution for the number of pages, or depth, that a user visits within a Web site. This model was verified by comparing its predictions with detailed measurements of surfing patterns. It also explains the observed Zipf-like distributions in page hits observed at WWW sites. Huberman et al 1The exponential growth of World Wide Web (WWW) is making it the standard information system for an increasing segment of the world&#039;s population. From electronic commerce and information resource to entertainment, the Web allows inexpensive and fast access to unique and novel services provided by individuals and institutions scattered throughout the world (1).
521|Holistic Aggregates in a Networked World: Distributed Tracking of Approximate Quantiles|While traditional database systems optimize for performance on one-shot queries, emerging large-scale monitoring applications require continuous tracking of complex aggregates and data-distribution summaries over collections of physically-distributed streams. Thus, effective solutions have to be simultaneously space efficient (at each remote site), communication efficient (across the underlying communication network), and provide continuous, guaranteedquality estimates. In this paper, we propose novel algorithmic solutions for the problem of continuously tracking complex holistic aggregates in such a distributed-streams setting — our primary focus is on approximate quantile summaries, but our approach is more broadly applicable and can handle other holistic-aggregate functions (e.g., “heavy-hitters ” queries). We present the first known distributed-tracking schemes for maintaining accurate quantile estimates with provable approximation guarantees, while simultaneously optimizing the storage space at each remote site as well as the communication cost across the network. In a nutshell, our algorithms employ a combination of local tracking at remote sites and simple prediction models for local site behavior in order to produce highly communication- and space-efficient solutions. We perform extensive experiments with real and synthetic data to explore the various tradeoffs and understand the role of prediction models in our schemes. The results clearly validate our approach, revealing significant savings over naive solutions as well as our analytical worst-case guarantees. 1.
522|Faster Core-Set Constructions and Data Stream Algorithms in Fixed Dimensions|We speed up previous (1 + &#034;)-factor approximation algorithms for a number of geometric  optimization problems in  xed dimensions: diameter, width, minimum-radius enclosing cylinder,  minimum-width annulus, minimum-volume bounding box, minimum-width cylindrical shell, etc.
523|Graph distances in the streaming model: the value of space|We investigate the importance of space when solving problems based on graph distance in the streaming model. In this model, the input graph is presented as a stream of edges in an arbitrary order. The main computational restriction of the model is that we have limited space and therefore cannot store all the streamed data; we are forced to make space-efficient summaries of the data as we go along. For a graph of n vertices and m edges, we show that testing many graph properties, including connectivity (ergo any reasonable decision problem about distances) and bipartiteness, requires ?(n) bits of space. Given this, we then investigate how the power of the model increases as we relax our space restriction. Our main result is an efficient randomized algorithm that constructs a (2t + 1)-spanner in one pass. With high probability, it uses O(t · n 1+1/t log 2 n) bits of space and processes each edge in the stream in O(t 2 · n 1/t log n) time. We find approximations to diameter and girth via the log n constructed spanner. For t = ? (), the space log log n requirement of the algorithm is O(n·polylog n), and the per-edge processing time is O(polylog n). We also show a corresponding lower bound of t for the approximation ratio achievable when the space restriction is O(t · n1+1/t log 2 n). We then consider the scenario in which we are allowed multiple passes over the input stream. Here, we investigate whether allowing these extra passes will compensate for a given space restriction. We show that *This work was supported by the DoD University Research Initiative (URI) administered by the Office of Naval Research
524|Streaming and sublinear approximation of entropy and information distances|In most algorithmic applications which compare two distributions, information theoretic distances are more natural than standard lp norms. In this paper we design streaming and sublinear time property testing algorithms for entropy and various information theoretic distances. Batu et al posed the problem of property testing with respect to the Jensen-Shannon distance. We present optimal algorithms for estimating bounded, symmetric f-divergences (including the Jensen-Shannon divergence and the Hellinger distance) between distributions in various property testing frameworks. Along the way, we close a (log n)/H gap between the upper and lower bounds for estimating entropy H, yielding an optimal algorithm over all values of the entropy. In a data stream setting (sublinear space), we give the first algorithm for estimating the entropy of a distribution. Our algorithm runs in polylogarithmic space and yields an asymptotic constant factor approximation scheme. An integral part of the algorithm is an interesting use of an F0 (the number of distinct elements in a set) estimation algorithm; we also provide other results along the space/time/approximation tradeoff curve. Our results have interesting structural implications that connect sublinear time and space constrained algorithms. The mediating model is the random order streaming model, which assumes the input is a random permutation of a multiset and was first considered by Munro and Paterson in 1980. We show that any property testing algorithm in the combined oracle model for calculating a permutation invariant functions can be simulated in the random order model in a single pass. This addresses a question raised by Feigenbaum et al regarding the relationship between property testing and stream algorithms. Further, we give a polylog-space PTAS for estimating the entropy of a one pass random order stream. This bound cannot be achieved in the combined oracle (generalized property testing) model. 1
525|Algorithms for Distributed Functional Monitoring|We study what we call functional monitoring problems. We have k players each tracking their inputs, say player i tracking a multiset Ai(t) up until time t, and communicating with a central coordinator. The coordinator’s task is to monitor a given function f computed over the union of the inputs ?iAi(t), continuously at all times t. The goal is to minimize the number of bits communicated between the players and the coordinator. A simple example is when f is the sum, and the coordinator is required to alert when the sum of a distributed set of values exceeds a given threshold t. Of interest is the approximate version where the coordinator outputs 1 if f = t and 0 if f = (1 - ?)t. This defines the (k, f, t, ?) distributed, functional monitoring problem. Functional monitoring problems are fundamental in distributed systems, in particular sensor networks, where we must minimize communication; they also connect to problems in communication complexity, communication theory, and signal processing. Yet few formal bounds are known for functional monitoring. We give upper and lower bounds for the (k, f, t, ?) problem for some of the basic f’s. In particular, we study frequency moments (F0, F1, F2). For F0 and F1, we obtain continuously monitoring algorithms with costs almost the same as their one-shot computation algorithms. However, for F2 the monitoring problem seems much harder. We give a carefully constructed multi-round algorithm that uses “sketch summaries ” at multiple levels of detail and solves the (k, F2, t, ?) problem with communication Õ(k2 /?+ (  v k/?) 3). Since frequency moment estimation is central to other problems, our results have immediate applications to histograms, wavelet computations, and others. Our algorithmic techniques are likely to be useful for other functional monitoring problems as well.  
526|Communication-efficient online detection of network-wide anomalies|Abstract—There has been growing interest in building largescale distributed monitoring systems for sensor, enterprise, and ISP networks. Recent work has proposed using Principal Component Analysis (PCA) over global traffic matrix statistics to effectively isolate network-wide anomalies. To allow such a PCAbased anomaly detection scheme to scale, we propose a novel approximation scheme that dramatically reduces the burden on the production network. Our scheme avoids the expensive step of centralizing all the data by performing intelligent filtering at the distributed monitors. This filtering reduces monitoring bandwidth overheads, but can result in the anomaly detector making incorrect decisions based on a perturbed view of the global data set. We employ stochastic matrix perturbation theory to bound such errors. Our algorithm selects the filtering parameters at local monitors such that the errors made by the detector are guaranteed to lie below a user-specified upper bound. Our algorithm thus allows network operators to explicitly balance the tradeoff between detection accuracy and the amount of data communicated over the network. In addition, our approach enables real-time detection because we exploit continuous monitoring at the distributed monitors. Experiments with traffic data from Abilene backbone network demonstrate that our methods yield significant communication benefits while simultaneously achieving high detection accuracy. I.
528|Estimating statistical aggregates on probabilistic data streams|The probabilistic stream model was introduced by Jayram, Kale, and Vee [2007]. It is a generalization of the data stream model that is suited to handling “probabilistic ” data, where each item of the stream represents a probability distribution over a set of possible events. Therefore, a probabilistic stream determines a distribution over a potentially exponential number of classical “deterministic ” streams where each item is deterministically one of the domain values. We present algorithms for computing commonly used aggregates on a probabilistic stream. We present the first one pass streaming algorithms for estimating the expected mean of a probabilistic stream. Next, we consider the problem of estimating frequency moments for probabilistic data. We propose a general approach to obtain unbiased estimators working over probabilistic data by utilizing unbiased estimators designed for standard streams. Applying this approach, we extend a classical data stream algorithm to obtain a one-pass algorithm for estimating F2, the second frequency moment. We present the first known streaming algorithms for estimating F0, the number of distinct items on probabilistic streams. Our work also gives an efficient one-pass algorithm for estimating the median and a two-pass algorithm for estimating the range.
529|Distributed Set-Expression Cardinality Estimation|We consider the problem of estimating set-expression  cardinality in a distributed streaming environment  where rapid update streams originating at remote sites  are continually transmitted to a central processing system.
530|Conquering the divide: Continuous clustering of distributed data streams|Data is often collected over a distributed network, but in many cases, is so voluminous that it is impractical and undesirable to collect it in a central location. Instead, we must perform distributed computations over the data, guaranteeing high quality answers even as new data arrives. In this paper, we formalize and study the problem of maintaining a clustering of such distributed data that is continuously evolving. In particular, our goal is to minimize the communication and computational cost, still providing guaranteed accuracy of the clustering. We focus on the k-center clustering, and provide a suite of algorithms that vary based on which centralized algorithm they derive from, and whether they maintain a single global clustering or many local clusterings that can be merged together. We show that these algorithms can be designed to give accuracy guarantees that are close to the best possible even in the centralized case. In our experiments, we see clear trends among these algorithms, showing that the choice of algorithm is crucial, and that we can achieve a clustering that is as good as the best centralized clustering, with only a small fraction of the communication required to collect all the data in a single location. 1
531|Proof sketches: Verifiable in-network aggregation|Recent work on distributed, in-network aggregation assumes a benign population of participants. Unfortunately, modern distributed systems are plagued by malicious participants. In this paper we present a first step towards verifiable yet efficient distributed, in-network aggregation in adversarial settings. We describe a general framework and threat model for the problem and then present proof sketches, a compact verification mechanism that combines cryptographic signatures and Flajolet-Martin sketches to guarantee acceptable aggregation error bounds with high probability. We derive proof sketches for count aggregates and extend them for random sampling, which can be used to provide verifiable approximations for a broad class of dataanalysis queries, e.g., quantiles and heavy hitters. Finally, we evaluate the practical use of proof sketches, and observe that adversaries can often be reduced to much smaller violations in practice than our worst-case bounds suggest. 1.
532|A Simpler and More Efficient Deterministic Scheme for Finding Frequent Items over Sliding Windows|In this paper, we give a simple scheme for identifying eapproximate frequent items over a sliding window of size n. Our scheme is deterministic and does not make any assumption on the distribution of the item frequencies. It supports O(1/e) update and query time, and uses O(1/e) space. It is very simple; its main data structures are just a few short queues whose entries store the position of some items in the sliding window. We also extend our scheme for variable-size window. This extended scheme uses O(1/e log(en)) space.
533|What’s different: Distributed, continuous monitoring of duplicate-resilient aggregates on data streams|Emerging applications in sensor systems and network-wide IP traffic analysis present many technical challenges. They need distributed monitoring and continuous tracking of events. They have severe resource constraints not only at each site in terms of per-update processing time and archival space for highspeed streams of observations, but also crucially, communication constraints for collaborating on the monitoring task. These elements have been addressed in a series of recent works. A fundamental issue that arises is that one cannot make the “uniqueness ” assumption on observed events which is present in previous works, since widescale monitoring invariably encounters the same events at different points. For example, within the network of an Internet Service Provider packets of the same flow will be observed in different routers; similarly, the same individual will be observed by multiple mobile sensors in monitoring wild animals. Aggregates of interest on such distributed environments must be resilient to duplicate observations. We study such duplicate-resilient aggregates that measure the extent of the duplication—how many unique observations are there, how many observations are unique—as well as standard holistic aggregates such as quantiles and heavy hitters over the unique items. We present accuracy guaranteed, highly communication-efficient algorithms for these aggregates that work within the time and space constraints of high speed streams. We also present results of a detailed experimental study on both real-life and synthetic data. 1
534|Lower bounds for quantile estimation in random-order and multi-pass streaming|Abstract. We present lower bounds on the space required to estimate the quantiles of a stream of numerical values. Quantile estimation is perhaps the most studied problem in the data stream model and it is relatively well understood in the basic single-pass data stream model in which the values are ordered adversarially. Natural extensions of this basic model include the random-order model in which the values are ordered randomly (e.g. [21, 5, 13, 11, 12]) and the multi-pass model in which an algorithm is permitted a limited number of passes over the stream (e.g. [6, 7, 1, 19, 2, 6, 7, 1, 19, 2]). We present lower bounds that complement existing upper bounds [21, 11] in both models. One consequence is an exponential separation between the random-order and adversarialorder models: using ?(polylog n) space, exact selection requires ?(log n) passes in the adversarial-order model while O(log log n) passes are sufficient in the random-order model. 1
535|A deterministic algorithm for summarizing asynchronous streams over a sliding window|We consider the problem of maintaining aggregates over recent elements of a massive data stream. Motivated by applications involving network data, we consider asynchronous data streams, where the observed order of data may be different from the order in which the data was generated. The set of recent elements is modeled as a sliding timestamp window of the stream, whose elements are changing continuously with time. We present the first deterministic algorithms for maintaining a small space summary of elements in a sliding timestamp window of an asynchronous data stream. The summary can return approximate answers for the following fundamental aggregates: basic count, the number of elements within the sliding window, and sum, the sum of all element values within the sliding window. For basic counting, the space taken by our summary is O(log W ·log B·(log W +log B)/?) bits, where B is an upper bound on the value of the basic count, W is an upper bound on the width of the timestamp window, and ? is the desired relative error. Our algorithms are based on a novel data structure called splittable histogram. Prior to this work, randomized algorithms were known for this problem, which provide weaker guarantees than those provided by our deterministic algorithms. 1
536|Time decaying aggregates in out-of-order streams|Processing large data streams is now a major topic in data management. The data involved can be truly massive, and the required analyses complex. In a stream of sequential events such as stock feeds, sensor readings, or IP traffic measurements, data tuples pertaining to recent events are typically more important than older ones. This can be formalized via time-decay functions, which assign weights to data based on the age of data. Decay functions such as sliding windows and exponential decay have been studied under the assumption of well-ordered arrivals, i.e., data arrives in non-decreasing order of time stamps. However, data quality issues are prevalent in massive streams (due to network asynchrony and delays etc.), and correct arrival order is not guaranteed. We focus on the computation of decayed aggregates such as range queries, quantiles, and heavy hitters on out-of-order streams, where elements do not necessarily arrive in increasing order of timestamps. Existing techniques such as Exponential Histograms and Waves are unable to handle out-of-order streams. We give the first deterministic algorithms for approximating these aggregates under popular decay functions such as sliding window and polynomial decay. We study the overhead of allowing out-of-order arrivals when compared to well-ordered arrivals, both analytically and experimentally. Our experiments confirm that these algorithms can be applied in practice, and compare the relative performance of different approaches for handling out-of-order arrivals.
537|Time-Decaying Sketches for Sensor Data Aggregation|We present a new sketch for summarizing network data. The sketch has the following properties which make it useful in communication-efficient aggregation in distributed streaming scenarios, such as sensor networks: the sketch is duplicateinsensitive, i.e. re-insertions of the same data will not affect the sketch, and hence the estimates of aggregates. Unlike previous duplicate-insensitive sketches for sensor data aggregation [26, 12], it is also time-decaying, so that the weight of a data item in the sketch can decrease with time according to a user-specified decay function. The sketch can give provably approximate guarantees for various aggregates of data, including the sum, median, quantiles, and frequent elements. The size of the sketch and the time taken to update it are both polylogarithmic in the size of the relevant data. Further, multiple sketches computed over distributed data can be combined without losing the accuracy guarantees. To our knowledge, this is the first sketch that combines all the above properties.
538|Efficient strategies for continuous distributed tracking tasks|While traditional databases have focused on single query evaluation in a centralized setting, emerging applications require continuous tracking of queries on data that is widely distributed and constantly updated. We describe such scenarios, and describe the challenges involved in designing communication-efficient protocols for the tracking tasks we define. We outline some solutions to these problems, by abstracting a model of the communication system, defining the tracking tasks of interest, and building query-tracking schemes based on three guiding principles of minimizing global information, using summaries to capture whole data streams, and seeking stability of the protocols. 1
539|Exponentially decayed aggregates on data streams|Abstract — In a massive stream of sequential events such as stock feeds, sensor readings, or IP traffic measurements, tuples pertaining to recent events are typically more important than older ones. It is important to compute various aggregates over such streams after applying a decay function which assigns weights to tuples based on their age. We focus on the computation of exponentially decayed aggregates in the form of quantiles and heavy hitters. Our techniques are based on extending existing data stream summaries, such as the q-digest [1] and the “spacesaving” algorithm [2]. Our experiments confirm that our methods can be applied in practice, and have similar space and time costs to the non-decayed aggregate computation. I.
540|Access path selection in a relational database management system|ABSTRACT: In a high level query and data manipulation language such as SQL, requests are stated non-procedurally, without reference to access paths. This paper describes how System R chooses access paths for both simple (single relation) and complex queries (such as joins), given a user specification of desired data as a boolean expression of predicates. System R is an experimental database management system developed to carry out research on the relational model of data. System R was designed and built by members of the IBM San Jose Research&#039;Laboratory. 1.
541|StreamIt: A Language for Streaming Applications|We characterize high-performance streaming applications as  a new and distinct domain of programs that is becoming increasingly important.
542|The Michigan Internet AuctionBot: A configurable auction server for human and software agents|Market mechanisms, such as auctions, will likely represent a common interaction medium for agents on the Internet. The Michigan Internet AuctionBot is a flexible, scalable, and robust auction server that supports both software and human agents. The server manages many simultaneous auctions by separating the interface from the core auction procedures. This design provides a responsive interface and tolerates system and network disruptions, but necessitates careful timekeeping procedures to ensure temporal accuracy. The AuctionBot has been used extensively in classroom exercises, and is available to the general Internet population. Its flexible specification of auctions in terms of orthogonal parameters makes it a useful device for agent researchers exploring the design space of auction mechanisms.
543|Efficient and Extensible Algorithms for Multi Query Optimization|Complex queries are becoming commonplace, with the growing use of decision support systems.  These complex queries often have a lot of common sub-expressions, either within a single query, or  across multiple such queries run as a batch. Multi-query optimization aims at exploiting common subexpressions  to reduce evaluation cost. Multi-query optimization has hither-to been viewed as impractical,  since earlier algorithms were exhaustive, and explore a doubly exponential search space.  In this paper we demonstrate that multi-query optimization using heuristics is practical, and provides  significant benefits. We propose three cost-based heuristic algorithms: Volcano-SH and Volcano-RU,  which are based on simple modifications to the Volcano search strategy, and a greedy heuristic. Our  greedy heuristic incorporates novel optimizations that improve efficiency greatly. Our algorithms are  designed to be easily added to existing optimizers. We present a performance study comparing the  algo...
544|A Survey Of Stream Processing|Stream processing is a term that is used widely in the literature to describe a variety of systems. We present an overview of the historical development of stream processing and a detailed discussion of the different languages and techniques for programming with streams that can be found in the literature. This includes an analysis of dataflow, specialized functional and logic programming with streams, reactive systems, signal processing systems, and the use of streams in the design and verification of hardware. The aim of this survey is an analysis of the development of each of these specialized topics to determine if a general theory of stream processing has emerged. As such, we discuss and classify the different classes of stream processing systems found in the literature from the perspective of programming primitives, implementation techniques, and computability issues, including a comparison of the semantic models that are used to formalize stream based computation.
545|FM96.5 A Java-based Electronic Auction House|We present an implementation of an electronic auction house inspired by the age old institution of the fish market, where both software and human agents may trade. This implementation supports fair, lively and robust bidder interactions. FM96.5 is a Java-based multi-agent environment that allows for a real-time concurrent operation of the complete fish market auction process by making use of multi-threading. Agent interactions in this structured environment are modelled through standardized illocutions implemented upon Java Object Serialization. All market-owned agents are deployed through a simple layered architecture, while buyer and seller agents of arbitrary complexity are confined to the market behavioural conventions through standardized Java agent interface applets. 1 Introduction  Internet is spawning many new markets. One that is particularly attractive for multiagent technologies is network-based trading. But if that market is to become an effective actual market various non-...
546|PSoup: a system for streaming queries over streaming data|Recent work on querying data streams has focused on systems where newly arriving data is processed and continuously streamed to the user in real time. In many emerging applications, however, ad hoc queries and/or intermittent connectivity also require the processing of data that arrives prior to query submission or during a period of disconnection. For such applications, we have developed PSoup, a system that combines the processing of ad hoc and continuous queries by treating data and queries symmetrically, allowing new queries to be applied to old data and new data to be applied to old queries. PSoup also supports intermittent connectivity by separating the computation of query results from the delivery of those results. PSoup builds on adaptive query-processing techniques developed in the Telegraph project at UC Berkeley. In this paper, we describe PSoup and present experiments that demonstrate the effectiveness of our approach.
547|Spidle: A DSL Approach to Specifying Streaming Applications|Multimedia stream processing is a rapidly evolving domain which requires much software development and expects high performance. Developing a streaming application...
548|Sampling algorithms in a stream operator|Complex queries over high speed data streams often need to rely on approximations to keep up with their input. The research community has developed a rich literature on approximate streaming algorithms for this application. Many of these algorithms produce samples of the input stream, providing better properties than conventional random sampling. In this paper, we abstract the stream sampling process and design a new stream sample operator. We show how it can be used to implement a wide variety of algorithms that perform sampling and samplingbased aggregations. Also, we show how to implement the operator in Gigascope- a high speed stream database specialized for IP network monitoring applications. As an example study, we apply the operator within such an enhanced Gigascope to perform subset-sum sampling which is of great interest for IP network management. We evaluate this implemention on a live, high speed internet traffic data stream and find that (a) the operator is a flexible, versatile addition to Gigascope suitable for tuning and algorithm engineering, and (b) the operator imposes only a small evaluation overhead. This is the first operational implementation we know of, for a wide variety of stream sampling algorithms at line speed within a data stream management system. 1.
549|Partial results for online query processing|Traditional query processors generate full, accurate query results, either in batch or in pipelined fashion. We argue that this strict model is too rigid for exploratory queries over diverse and distributed data sources, such as sources on the Internet. Instead, we propose a looser model of querying in which a user submits a broad initial query outline, and the system continually generates partial result tuples that may contain values for only some of the output fields. The user can watch these partial results accumulate at the user interface, and accordingly refine the query by specifying their interest in different kinds of partial results. After describing our querying model and user interface, we present a query processing architecture for this model which is implemented in the Telegraph dataflow system. Our architecture is designed to generate partial results quickly, and to adapt query execution to changing user interests. The crux of this architecture is a dataflow operator that supports two kinds of reorderings: reordering of intermediate tuples within a dataflow, and reordering of query plan operators through which tuples flow. We study reordering policies that optimize for the quality of partial results delivered over time, and experimentally demonstrate the benefits of our architecture in this context. 1.
550|Pipelining in multi-query optimization|Database systems frequently have to execute a set of related queries, which share several common subexpressions. Multi-query optimization exploits this, by finding evaluation plans that share common results. Current approaches to multi-query optimization assume that common subexpressions are materialized. Significant performance benefits can be had if common subexpressions are pipelined to their uses, without being materialized. However, plans with pipelining may not always be realizable with limited buffer space, as we show. We present a general model for schedules with pipelining, and present a necessary and sufficient condition for determining validity of a schedule under our model. We show that finding a valid schedule with minimum cost is NP-hard. We present a greedy heuristic for finding good schedules. Finally, we present a performance study that shows the benefit of our algorithms on batches of queries from the TPCD benchmark. 1.
551|ATLaS: a Small but Complete SQL Extension for Data Mining and Data Streams|Introduction  DBMSs have long suffered from SQL&#039;s lack of power and extensibility. We have implemented ATLaS [1], a powerful database language and system that enables users to develop complete data-intensive applications in SQL---by writing new aggregates and table functions in SQL, rather than in procedural languages as in current Object-Relational systems. As a result, ATLaS&#039; SQL is Turing-complete [7], and is very suitable for advanced data-intensive applications, such as data mining and stream queries. The ATLaS system is now available for download along with a suite of applications [1] including various data mining functions, that have been coded in ATLaS&#039; SQL, and execute with a modest (20--40%) performance overhead with respect to the same applications written in C/C++. Our proposed demo will illustrate the key features and applications of ATLaS. In particular, we will demonstrate:  .  ATLaS&#039; SQL features, including its native support for user-defined aggregates and table functi
552|A Scalable Hash Ripple Join Algorithm|Recently, Haas and Hellerstein proposed the hash ripple join algorithm in the context of online aggregation. Although the algorithm rapidly gives a good estimate for many join-aggregate problem instances, the convergence can be slow if the number of tuples that satisfy the join predicate is small or if there are many groups in the output. Furthermore, if memory overflows (for example, because the user allows the algorithm to run to completion for an exact answer), the algorithm degenerates to block ripple join and performance suffers. In this paper, we build on the work of Haas and Hellerstein and propose a new algorithm that (a) combines parallelism with sampling to speed convergence, and (b) maintains good performance in the presence of memory overflow. Results from a prototype implementation in a parallel DBMS show that its rate of convergence scales with the number of processors, and that when allowed to run to completion, even in the presence of memory overflow, it is competitive with the traditional parallel hybrid hash join algorithm. 1.
553|An Efficient Framework for Order Optimization|Since the introduction of cost-based query optimization, the performance-critical role of interesting orders has been recognized. Some algebraic operators change interesting orders (e.g. sort and select), while others exploit interesting orders (e.g. merge join). The two operations performed by any query optimizer during plan generation are 1) computing the resulting order given an input order and an algebraic operator and 2) determining the compatibility between a given input order and the required order a given algebraic operator can beneficially exploit. Since these two operations are called millions of times during plan generation, they are highly performance-critical. The third crucial parameter is the space requirement for annotating every plan node with its output order.
554|A heartbeat mechanism and its application in Gigascope|Data stream management systems often rely on ordering properties of tuple attributes in order to implement non-blocking operators. However, query operators that work with multiple streams, such as stream merge or join, can often still block if one of the input stream is very slow or bursty. In principle, punctuation and heartbeat mechanisms have been proposed to unblock streaming operators. In practice, it is a challenge to incorporate such mechanisms into a highperformance stream management system that is operational in an industrial application. In this paper, we introduce a system for punctuation-carrying heartbeat generation that we developed for Gigascope, a high-performance streaming database for network monitoring, that is operationally used within AT&amp;T&#039;s IP backbone. We show how heartbeats can be regularly generated by low-level nodes in query execution plans and propagated upward unblocking all streaming operators on its way. Additionally, our heartbeat mechanism can be used for other applications in distributed settings such as detecting node failures, performance monitoring, and query optimization. A performance evaluation using live data feeds shows that our system is capable of working at multiple Gigabit line speeds in a live, industrial deployment and can significantly decrease the query memory utilization.
555|Online Auction Site Management |The successful deployment and operation of an online auction system requires knowledge of mechanism design, system architecture, and successful Internet business practices. Online auctions pose several challenges to Web developers because they are intensely data driven and have temporal behaviors that must be faithfully implemented. This article discusses many of the issues that an auction provider should consider when selecting or developing an auction software system. Auctions can be seen as a mechanism that is precisely defined by sets of rules that govern bidding, quoting, and clearing. These activities will have natural components in the software system, and the choices made in the architecture of the auction system will affect its scalability, temporal integrity, and overall complexity. Complementary features of auction systems, such as catalogs, search tools, and reputation mechanisms, are also discussed.
556|Time, Clocks, and the Ordering of Events in a Distributed System|The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become.  
557|Next Century Challenges: Mobile Networking for “Smart Dust”|Large-scale networks of wireless sensors are becoming an active topic of research. Advances in hardware technology and engineering design have led to dramatic reductions in size, power consumption and cost for digital circuitry, wire-less communications and Micro ElectroMechanical Systems (MEMS). This has enabled very compact, autonomous and mobile nodes, each containing one or more sensors, computation and communication capabilities, and a power supply. The missing ingredient is the networking and applications layers needed to harness this revolutionary capability into a complete system. We review the key elements of the emergent technology of “Smart Dust ” and outline the research challenges they present to the mobile networking and systems community, which must provide coherent connectivity to large numbers of mobile network nodes co-located within a small volume. 
558|Internet time synchronization: The Network Time Protocol|Abstruct- This paper describes the network time protocol (NTP), which is designed to distribute time information in a large, diverse internet system operating at speeds from mundane to lightwave. It uses a symmetric architecture in which a distributed subnet of time servers operating in a self-organizing, hierarchical configuration synchronizes local clocks within the subnet and to national time standards via wire, radio, or calibrated atomic clock. The servers can also redistribute time information within a network via local routing algorithms and time daemons. This paper also discusses the architecture, protocol and algorithms, which were developed over several years of implementation refinement and resulted in the designation of NTP as an Internet Standard protocol. The NTP synchronization system, which has been in regular operation in the Internet for the last several years, is described along with performance data which shows that timekeeping accuracy throughout most portions of the Internet can be ordinarily maintained to within a few milliseconds, even in cases of failure or disruption of clocks, time servers or networks. I.
559|Astrolabe: A Robust and Scalable Technology for Distributed System Monitoring, Management, and Data Mining|this paper, we describe a new information management service called Astrolabe. Astrolabe monitors the dynamically changing state of a collection of distributed resources, reporting summaries of this information to its users. Like DNS, Astrolabe organizes the resources into a hierarchy of domains, which we call zones to avoid confusion, and associates attributes with each zone. Unlike DNS, zones are not bound to specific servers, the attributes may be highly dynamic, and updates propagate quickly; typically, in tens of seconds
560|Instrumenting the world with wireless sensor networks|Pervasive micro-sensing and actuation may revolutionize the way in which we understand and manage complex physical systems: from airplane wings to complex ecosystems. The capabilities for detailed physical monitoring and manipulation offer enormous opportunities for almost every scientific discipline, and it will alter the feasible granularity of engineering. We identify opportunities and challenges for distributed signal processing in networks of these sensing elements and investigate some of the architectural challenges posed by systems that are massively distributed, physically-coupled, wirelessly networked, and energy limited. 
561|Algorithms for Scheduling Imprecise Computations with Timing Constraints to Minimize Maximum Error|We consider here the problem of scheduling tasks in the imprecise computation model to minimize the maximum error. Given a task system and a schedule of it, the maximum error of the task system is equal to the error of the task that has the largest error when the task system is executed according to the schedule. We describe two preemptive algorithms for scheduling on a processor n dependent tasks with rational ready times, deadlines, and processing times. Each schedule found by our algorithms is an optimal schedule with the minimum total error, and according to this schedule the maximum error is minimized. The run times of our algorithms are O ( n  3  ) and O ( n  2  ). 1. Introduction  In a hard real-time system, every ( real-time ) task must complete by its deadline; otherwise, the result produced by it is of little use. For many applications, approximate results are acceptable, but some penalties may apply. The imprecise computation model [1-4] was introduced to characterize these ...
562|Packet audio playout delay adjustment: performance bounds and algorithms|In packet audio applications, packets are buffered at a receiving site and their playout delayed in order to compensate for variable network delays. In this paper, we consider the problem of adaptively adjusting the playout delay in order to keep this delay as small as possible, while at the same time avoiding excessive “loss ” due to the arrival of packets at the receiver after their playout time has already passed. The contributions of this paper are twofold. First, given a trace of packet audio receptions at a receiver, we present efficient algorithms for computing a bound on the achievable performance of any playout delay adjustment algorithm. More precisely, we compute upper and lower bounds (which are shown to be tight for the range of loss and delay values of interest) on the optimum (minimum) average playout delay for a given number of packet losses (due to late arrivals) at the receiver for that trace. Second, we present a new adaptive delay adjustment algorithm that tracks the network delay of recently received packets and efficiently maintains delay percentile information. This information, together with a “delay spike ” detection algorithm based on (but extending) our earlier work [RKTS94], is used to dynamically adjust talkspurt playout delay. We show that this algorithm outperforms existing delay adjustment algorithms over a number of measured audio delay traces and performs close to the theoretical optimum over a range of parameter values of interest.
563|Offering a Precision-Performance Tradeoff for Aggregation Queries over Replicated Data|Strict consistency of replicated data is infeasible or  not required by many distributed applications, so current  systems often permit stale replication,inwhich  cached copies of data values are allowed to become  out of date. Queries over cached data return an answer  quickly, but the stale answer may be unboundedly  imprecise. Alternatively, queries over remote  master data return a precise answer, but with potentially  poor performance. To bridge the gap between  these two extremes, we propose a new class of replication  systems called TRAPP (Tradeoff in Replication  Precision and Performance). TRAPP systems  give each user fine-grained control over the tradeoff  between precision and performance: Caches store  ranges that are guaranteed to bound the current data  values, instead of storing stale exact values. Users  supply a quantitative precision constraint along with  each query. To answer a query, TRAPP systems automatically  select a combination of locally cached  bounds and exact master data stored remotely to deliver  a bounded answer consisting of a range that is  no wider than the specified precision constraint, that  is guaranteed to contain the precise answer, and that  is computed as quickly as possible. This paper defines  the architecture of TRAPP replication systems  and covers some mechanics of caching data ranges. It  then focuses on queries with aggregation, presenting  optimization algorithms for answering queries with  precision constraints, and reporting on performance  experiments that demonstrate the fine-grained control  of the precision-performance tradeoff offered by  TRAPP systems.
564|Query Processing, Resource Management, and Approximation in a Data Stream Management System  –|This paper describes our ongoing work developing the Stanford Stream Data Manager (STREAM), a system for executing continuous queries over multiple continuous data streams. The STREAM system supports a declarative query language, and it copes with high data rates and query workloads by providing approximate answers when resources are limited. This paper describes specific contributions made so far and enumerates our next steps in developing a general-purpose Data Stream Management System.
565|Efficient Reactive Monitoring|Networks are monitored in order to ensure that the system operates within desirable parameters. The increasing complexity of networks and services provided by them increases this need for monitoring. Monitoring consists of measuring properties of the network, and of inferring  an aggregate predicate from these measurements. Conducting such monitoring introduces traffic overhead that may reduce the overall effective throughput.  This paper studies ways to minimize the monitoring communication overhead in IP networks. We develop and analyze several monitoring algorithms that achieve significant reduction in the management overhead while maintaining the functionality. The main idea is to combine global polling with local event driven reporting.  The amount of traffic saving depends on the statistical characterization of the monitored data. We indicate the specific statistical factors that affect the saving and show how to choose the right algorithm for the type of monitored data. In particular our results show that for Internet traffic our algorithms can save more than 90% of the monitoring traffic.  I. 
566|Low-Power Wireless Sensor Networks|Wireless distributed microsensor systems will enable fault tolerant monitoring and control of a variety of applications. Due to the large number of microsensor nodes that may be deployed and the long required system lifetimes, replacing the battery is not an option. Sensor systems must utilize the minimal possible energy while operating over a wide range of operating scenarios. This paper presents an overview of the key technologies required for low-energy distributed microsensors. These include power aware computation/communication component technology, low-energy signaling and networking, system partitioning considering computation and communication trade-offs, and a power aware software infrastructure. I. INTRODUCTION  The designof micropower wireless sensor systems has gained increasing importancefm a varietyof civil and military applications. With recent advances in MEMS technology and its associatedinterf aces, signal processing, and RF circuitry, thefk&#034;&#039; hasshif &#034; awayf rom limi...
567|Local Verification of Global Integrity Constraints in Distributed Databases|We present an optimization for integrity constraint verification in distributed databases. The optimization allows a global constraint, i.e. a constraint spanning multiple databases, to be verified by accessing data at a single database, eliminating the cost of accessing remote data. The optimization is based on an algorithm that takes as input a global constraint and data to be inserted into a local database. The algorithm produces a local condition such that if the local data satisfies this condition then, based on the previous satisfaction of the global constraint, the global constraint is still satisfied. If the local data does not satisfy the condition, then a conventional global verification procedure is required. 1 Introduction  A clear trend in information systems technology is the distribution of related data across multiple sites. Such systems may vary from tightly-coupled parallel databases to federated information systems. In all cases, one benefit of data distribution is t...
568|Efficient Numerical Error Bounding for Replicated Network Services|The goal of this work is to support replicated  network services that accept updates to numerical  records from multiple wide-area locations. Given the 
569|A Traffic Engineering Approach based on Minimum-Delay Routing|Single-path routing provided by today&#039;s Interior Gateway Protocols (IGPs) make extremely inefficient usage of network bandwidth, and is evident in the large end-to-end delays flows experience in single-path routing as compared to minimum-delay routing. Enhancement to OSPF such as optimized multipath have not proved adequate to bridge this large delay gap. Practical implementation of minimum-delay routing, on the other hand, have been largely unsuccessful for reasons such as scalability, slow convergence and out-of-order packet delivery. This paper proposes a traffic engineering solution that adapts the minimum-delay routing for a given traffic matrix in a way that is practical and suitable to implement in the Differential Services framework. A simple and scalable packet forwarding technique is described that offers several improvements over OSPF-OMP.
570|Maintaining Global Integrity Constraints in Distributed Databases|. Given some integrity constraints over a distributed database, we consider the problem of incrementally checking global consistency in response to updates made to the base relations but without accessing all these base relations. In many application areas such as collaborative design, mobile computing and enterprise information systems, total data availability cannot be assumed. Even if all the base data is available, some of it may incur such a high cost that its use should only be considered as a last resort. Without looking at all the relations that participate in the constraint, how can one meaningfully check a constraint for violation? When the constraint is known to be satisfied prior to the update, the state of the relations that are available (aka local) can in principle be used to infer something about the relations that are not available (aka remote). This observation is the basis for the existence of tests that guarantee that global consistency is preserved under a given up...
571|Maintaining Temporal Coherency of Cooperating Dynamic Data Repositories|On-line decision making often involves significant amount of time-varying data. Examples of time-varying data  include financial information such as stock prices and currency exchange rates, real-time traffic and weather information,  and data from industrial process control applications. The coherency requirements associated with time-varying  data depends on the nature of the data and user tolerances. This paper examines techniques to efficiently disseminate  time-varying data from sources to a set of repositories. A particular focus of our work is to examine how such  repositories can cooperate with one another and the source to improve the efficiency of the dissemination process,  while meeting user coherency requirements. We consider two key issues: (i) When should the source and/or the  repositories push changes of interest to other repositories so as to meet all user-specified coherency requirements?  (ii) How should an overlay network of such repositories be organized so as to minimize the overheads of maintaining  temporal coherency of all data items stored in the various repositories? We examine these questions in turn, offer a  set of alternative solutions to address these questions and experimentally evaluate their performance using real-world  traces of dynamically changing data (specifically, stock prices). We show that cooperation helps reduce the systemwide  overheads for maintaining coherency across all repositories. However, contrary to intuition, we also show that  increasing the degree of cooperation beyond a certain point can, in fact, be detrimental to the overall goals of achieving  high fidelity at low overheads. To address this issue, we propose techniques to (i) derive the &#034;optimal&#034; degree of  cooperation among repositories, and (ii) derive the...
572|Sketching sampled data streams|Abstract—Sampling is used as a universal method to reduce the running time of computations – the computation is performed on a much smaller sample and then the result is scaled to compensate for the difference in size. Sketches are a popular approximation method for data streams and they proved to be useful for estimating frequency moments and aggregates over joins. A possibility to further improve the time performance of sketches is to compute the sketch over a sample of the stream rather than the entire data stream. In this paper we analyze the behavior of the sketch estimator when computed over a sample of the stream, not the entire data stream, for the size of join and the self-join size problems. Our analysis is developed for a generic sampling process. We instantiate the results of the analysis for all three major types of sampling – Bernoulli sampling which is used for load shedding, sampling with replacement which is used to generate i.i.d. samples from a distribution, and sampling without replacement which is used by online aggregation engines – and compare these particular results with the results of the basic sketch estimator. Our experimental results show that the accuracy of the sketch computed over a small sample of the data is, in general, close to the accuracy of the sketch estimator computed over the entire data even when the sample size is only 10 % or less of the dataset size. This is equivalent to a speed-up factor of at least 10 when updating the sketch. I.
573|Sketching streams through the net: Distributed approximate query tracking|While traditional database systems optimize for performance on one-shot query processing, emerging large-scale monitoring applications require continuous tracking of complex dataanalysis queries over collections of physically-distributed streams. Thus, effective solutions have to be simultaneously space/time efficient (at each remote monitor site), communication efficient (across the underlying communication network), and provide continuous, guaranteed-quality approximate query answers. In this paper, we propose novel algorithmic solutions for the problem of continuously tracking a broad class of complex aggregate queries in such a distributed-streams setting. Our tracking schemes maintain approximate query answers with provable error guarantees, while simultaneously optimizing the storage space and processing time at each remote site, as well as the communication cost across the network. In a nutshell, our algorithms rely on tracking general-purpose randomized sketch summaries of local streams at remote sites along with concise prediction models of local site behavior in order to produce highly communication- and space/time-efficient solutions. The end result is a powerful approximate query tracking framework that readily incorporates several complex analysis queries (including distributed join and multi-join aggregates, and approximate wavelet representations), thus giving the first known low-overhead tracking solution for such queries in the distributed-streams model. Experiments with real data validate our approach, revealing significant savings over naive solutions as well as our analytical worst-case guarantees. 1
574|Scalable approximate query processing with the DBO engine|This paper describes query processing in the DBO database system. Like other database systems designed for ad-hoc, analytic processing, DBO is able to compute the exact answer to queries over a large relational database in a scalable fashion. Unlike any other system designed for analytic processing, DBO can constantly maintain a guess as to the final answer to an aggregate query throughout execution, along with statistically meaningful bounds for the guess’s accuracy. As DBO gathers more and more information, the guess gets more and more accurate, until it is 100 % accurate as the query is completed. This allows users to stop the execution at any time that they are happy with the query accuracy, and encourages exploratory data analysis.
575|How to (accurately) skip past streams  (2006) |For processing massive data streams, most proposed algorithmic methods look at each new item, perform a small number of operations while keeping a small amount of memory, and still perform much-needed analyses. However, in many situations, the update speed per item is very critical and not every item can be extensively examined. In practice, this has been addressed by sampling only a subset of items (say 1 in N) from the input, but it results in loss of guarantees on the accuracy of the post-hoc analyses. In this paper, we present a technique of skipping past streams. Unlike traditional sampling approaches, our skipping is performed in a principled manner without significant loss of guarantees on post-hoc analyses, while substantially improving the processing rate. Using this technique on top of well-known sketches, we show improvements in the update time as well as guaranteed accuracy for a number of stream processing problems including data summarization, heavy hitters detection and self-join size estimation. We present experimental results of our methods over synthetic data and integrate our methods into Sprint’s Continuous Monitoring (CMON) system for live network traffic analyses. Furthermore, going beyond traditional packet header analyses, we show how the packet contents can be analyzed at streaming speeds, a more challenging task because each packet content can result in many updates. 1.
576|Pseudo-random number generation for sketch-based estimations |The exact computation of aggregate queries, like the size of join of two relations, usually requires large amounts of memory – constrained in data-streaming – or communication – constrained in distributed computation – and large processing times. In this situation, approximation techniques with provable guarantees, like sketches, are one possible solution. The performance of sketches depends crucially on the ability to generate particular pseudo-random numbers. In this paper we investigate both theoretically and empirically the problem of generating k-wise independent pseudo-random numbers and, in particular, that of generating 3 and 4-wise independent pseudorandom numbers that are fast range-summable (i.e., they can be summed-up in sub-linear time). Our specific contributions are: (a) we provide a thorough comparison of the various pseudorandom number generating schemes, (b) we study both theoretically and empirically the fast range-summation property of the 3 and 4-wise independent generating schemes, (c) we provide algorithms for the fast range-summation of two 3-wise independent schemes, BCH and Extended Hamming, (d) we show convincing theoretical and empirical evidence that the Extended Hamming scheme performs as well as any 4-wise independent scheme for estimating the size of join of two relations using AMS-sketches, even though it is only 3-wise independent. We use this scheme to generate estimators that significantly outperform the state-of-the-art solutions for two problems – size of spatial joins and selectivity estimation.
577|A.: Statistical analysis of sketch estimators|Sketching techniques can provide approximate answers to aggregate queries either for data-streaming or distributed computation. Small space summaries that have linearity properties are required for both types of applications. The prevalent method for analyzing sketches uses moment analysis and distribution independent bounds based on moments. This method produces clean, easy to interpret, theoretical bounds that are especially useful for deriving asymptotic results. However, the theoretical bounds obscure fine details of the behavior of various sketches and they are mostly not indicative of which type of sketches should be used in practice. Moreover, no significant empirical comparison between various sketching techniques has been published, which makes the choice even harder. In this paper, we take a close look at the sketching techniques proposed in the literature from a statistical point of view with the goal of determining properties that indicate the actual behavior and producing tighter confidence bounds. Interestingly, the statistical analysis reveals that two of the techniques, Fast-AGMS and Count-Min, provide results that are in some cases orders of magnitude better than the corresponding theoretical predictions. We conduct an extensive empirical study that compares the different sketching techniques in order to corroborate the statistical analysis with the conclusions we draw from it. The study indicates the expected performance of various sketches, which is crucial if the techniques are to be used by practitioners. The overall conclusion of the study is that Fast-AGMS sketches are, for the full spectrum of problems, either the best, or close to the best, sketching technique. This makes Fast-AGMS sketches the preferred choice irrespective of the situation.
578|The sort-merge-shrink join|One of the most common operations in analytic query processing is the application of an aggregate function to the result of a relational join. We describe an algorithm called the Sort-Merge-Shrink (SMS) Join for computing the answer to such a query over large, disk-based input tables. The key innovation of the SMS join is that if the input data are clustered in a statistically random fashion on disk, then at all times, the join provides an online, statistical estimator for the eventual answer to the query as well as probabilistic confidence bounds. Thus, a user can monitor the progress of the join throughout its execution and stop the join when satisfied with the estimate’s accuracy or run the algorithm to completion with a total time requirement that is not much longer than that of other common join algorithms. This contrasts with other online join algorithms, which either do not offer such statistical guarantees or can only offer guarantees so long as the input data can fit into main memory.
579|On String Classification in Data Streams|String data has recently become important because of its use in a number of applications such as computational and molecular biology, protein analysis, and market basket data. In many cases, these strings contain a wide variety of substructures which may have physical significance for that application. For example, such substructures could represent important fragments of a DNA string or an interesting portion of a fraudulent transaction. In such a case, it is desirable to determine the identity, location, and extent of that substructure in the data. This is a much more difficult generalization of the classification problem, since the latter problem labels entire strings rather than deal with the more complex task of determining string fragments with a particular kind of behavior. The problem becomes even more complicated when different kinds of substrings show complicated nesting patterns. Therefore, we define a somewhat different problem which we refer to as the generalized classification problem. We propose a scalable approach based on hidden markov models for this problem. We show how to implement the generalized string classification procedure for very large data bases and data streams. We present experimental results over a number of large data sets and data streams.
580|Hidden Markov models for detecting remote protein homologies|A new hidden Markov model method (SAM-T98) for nding remote homologs of protein sequences is described and evaluated. The method begins with a single target sequence and iteratively builds a hidden Markov model (hmm) from the sequence and homologs found using the hmm for database search. SAM-T98 is also used to construct model libraries automatically from sequences in structural databases. We evaluate the SAM-T98 method with four datasets. Three of the test sets are fold-recognition tests, where the correct answers are determined by structural similarity. The fourth uses a curated database. The method is compared against wu-blastp and against double-blast, a two-step method similar to ISS, but using blast instead of fasta. Results SAM-T98 had the fewest errors in all tests| dramatically so for the fold-recognition tests. At the minimum-error point on the SCOP-domains test, SAM-T98 got 880 true positives and 68 false positives, double-blast got 533 true positives with 71 false positives, and wu-blastp got 353 true positives with 24 false positives. The method is optimized to recognize superfamilies, and would require parameter adjustment to be used to nd family or fold relationships. One key to the performance of the hmm method is a new score-normalization technique that compares the score to the score with a reversed model rather than to a uniform null model. Availability A World Wide Web server, as well as information on obtaining the Sequence Alignment and PREPRINT to appear in Bioinformatics, 1999
581|Automatic Segmentation of Text Into Structured Records|In this paper we present a method for automatically segmenting unformatted text records into structured elements. Several useful data sources today are human-generated as continuous text whereas convenient usage requires the data to be organized as structured records. A prime motivation is the warehouse address cleaning problem of transforming dirty addresses stored in large corporate databases as a single text field into subfields like &#034;City&#034; and &#034;Street&#034;. Existing tools rely on hand-tuned, domain-specific rule-based systems.
582|Protein Modeling using Hidden Markov Models: Analysis of Globins|We apply Hidden Markov Models (HMMs) to the problem of statistical modeling and multiple alignment of protein families. A variant of the Expectation Maximization (EM) algorithm known as the Viterbi algorithm is used to obtain the statistical model from the unaligned sequences. In a detailed series of experiments, we have taken 400 unaligned globin sequences, and produced a statistical model entirely automatically from the primary (unaligned) sequences using no prior knowledge of globin structure. The produced model includes amino acid distributions for all the known positions in the 7 major alpha-helices, as well as the probability of and average length of insertions between these positions, and the probability that each position is not present at all. Using this model, we obtained a multiple alignment of the 400 sequences and 225 other globin sequences, that agrees almost perfectly with a structural alignment by Bashford et al. This model can also discriminate all these 625 globins fr...
583|Evaluation of Techniques for Classifying Biological Sequences   |In recent years we have witnessed an exponential increase in the amount of biological information, either DNA or protein sequences, that has become available in public databases. This has been followed by an increased interest in developing computational techniques to automatically classify these large volumes of sequence data into various categories corresponding to either their role in the chromosomes, their structure, and/or their function. In this paper we evaluate some of the widely-used sequence classification algorithms and develop a framework for modeling sequences in a fashion so that traditional machine learning algorithms, such as support vector machines, can be applied easily. Our detailed experimental evaluation shows that the SVM-based approaches are able to achieve higher classification accuracy compared to the more traditional sequence classification algorithms such as Markov model based techniques and K-nearest neighbor based approaches.
584|On Effective Classification of Strings with Wavelets|In recent years, the technological advances in mapping genes have made it increasingly easy to store and use a wide variety of biological data. Such data are usually in the form of very long strings for which it is difficult to determine the most relevant features for a classification task. For example, a typical DNA string may be millions of characters long, and there may be thousands of such strings in a database. In many cases, the classification behavior of the data maybe hidden in the compositional behavior of certain segments of the string which cannot be easily determined apriori. Another problem which complicates the classification task is that in some cases the classification behavior is reflected in global behavior of the string, whereas in others it is reflected in local patterns. Given the enormous variation in the behavior of the strings over different data sets, it is useful to develop an approach which is sensitive to both the global and local behavior of the strings for the purpose of classi cation. For this purpose, we will exploit the multi-resolution property of wavelet decomposition in order to create a scheme which can mine classification characteristics at different levels of granularity. The resulting scheme turns out to be very effective in practice on a wide range of problems.  
585|Algorithms for data streams|Data stream processing has gained increasing popularity in the last few years as an effective paradigm for processing massive data sets. A wide range of applications in computational sciences generate huge and rapidly changing data streams that need to be continuously monitored in order to support exploratory analyses and to detect correlations, rare events, fraud, intrusion, unusual or anomalous activities. Relevant examples include monitoring network traffic, online auctions, transaction logs, tele-phone call records, automated bank machine operations, atmospheric and astronomical events. Due to the high sequential access rates of modern disks, streaming algorithms can also be effectively deployed for processing massive files on secondary storage, pro-viding new insights into the solution of several computational problems in external memory. Streaming models constrain algorithms to access the input data in one or few se-quential passes, using only a small amount of working memory and processing each input item quickly. Solving computational problems under these restrictions poses sev-
586|External-Memory Graph Algorithms|We present a collection of new techniques for designing and analyzing efficient external-memory algorithms for graph problems and illustrate how these techniques can be applied to a wide variety of specific problems. Our results include:  ffl Proximate-neighboring. We present a simple method for deriving external-memory lower bounds via reductions from a problem we call the &#034;proximate neighbors&#034; problem. We use this technique to derive non-trivial lower bounds for such problems as list ranking, expression tree evaluation, and connected components.  ffl PRAM simulation. We give methods for efficiently simulating PRAM computations in external memory, even for some cases in which the PRAM algorithm is not work-optimal. We apply this to derive a number of optimal (and simple) external-memory graph algorithms.  ffl Time-forward processing. We present a general technique for evaluating circuits (or &#034;circuit-like&#034; computations) in external memory. We also use this in a deterministic list rank...
587|A Functional Approach to External Graph Algorithms|. We present a new approach for designing external graph algorithms  and use it to design simple external algorithms for computing connected components,  minimum spanning trees, bottleneck minimum spanning trees, and maximal  matchings in undirected graphs and multi-graphs. Our I/O bounds compete  with those of previous approaches. Unlike previous approaches, ours is purely  functional---without side effects---and is thus amenable to standard checkpointing  and programming language optimization techniques. This is an important  practical consideration for applications that may take hours to run.  1 Introduction  We present a divide-and-conquer approach for designing external graph algorithms, i.e., algorithms on graphs that are too large to fit in main memory. Our approach is simple to describe and implement: it builds a succession of graph transformations that reduce to sorting, selection, and a recursive bucketing technique. No sophisticated data structures are needed. We apply our t...
588|Efficient Computation of Frequent and Top-k Elements in Data Streams|We propose an approximate integrated approach for solving both problems of finding the most popular k elements, and finding frequent elements in a data stream coming from a large domain. Our solution is space efficient and reports both frequent and top-k elements with tight guarantees on errors. For general data distributions, our top-k algorithm returns k elements that have roughly the highest frequencies; and it uses limited space for calculating frequent elements. For realistic Zipfian data, the space requirement of the proposed algorithm for solving the exact frequent elements problem decreases dramatically with the parameter of the distribution; and for top-k queries, the analysis ensures that only the top-k elements, in the correct order, are reported. The experiments, using real and synthetic data sets, show space reductions with no loss in accuracy. Having proved the effectiveness of the proposed approach through both analysis and experiments, we extend it to be able to answer continuous queries about frequent and top-k elements. Although the problems of incremental reporting of frequent and top-k elements are useful in many applications, to the best of our knowledge, no solution has been proposed.
589|Tight lower bounds for the distinct elements problem|We prove strong lower bounds for the space complexity of ¢¤£¦¥¨§? ©-approximating the number of distinct elements ?? ? in a data stream. Let ? be the size of the universe from which the stream elements are drawn. We show that any one-pass streaming algorithm for ¢¤£¦¥¨§? ©-approximating ?  ? must use ????? space £??????¦???? ? ?????? ? when, for ???? ? any, im-proving upon the known lower bound of ? ??? ?  ? for this range of £. This lower bound is tight up to a factor of ???????????? ?. Our lower bound is derived from a reduction from the one-way communication complexity of approximating a boolean function in Euclidean space. The reduction makes use of a lowdistortion embedding from an ?? ? to an ?  ? norm. 1
590|Space efficient mining of multigraph streams |The challenge of monitoring massive amounts of data gen-erated by communication networks has led to the interest in data stream processing. We study streams of edges in mas-sive communication multigraphs, defined by (source, desti-nation) pairs. The goal is to compute properties of the un-derlying graph while using small space (much smaller than the number of communicants), and to avoid bias introduced because some edges may appear many times, while others are seen only once. We give results for three fundamen-tal problems on multigraph degree sequences: estimating frequency moments of degrees, finding the heavy hitter de-grees, and computing range sums of degree values. In all cases we are able to show space bounds for our summa-rizing algorithms that are significantly smaller than stor-ing complete information. We use a variety of data stream methods: sketches, sampling, hashing and distinct counting, but a common feature is that we use cascaded summaries: nesting multiple estimation techniques within one another. In our experimental study, we see that such summaries are highly effective, enabling massive multigraph streams to be effectively summarized to answer queries of interest with high accuracy using only a small amount of space. 1.
593|Maintenance of multidimensional histograms|1 Introduction Let Aj an N * N dynamic array1 at time j. Input is a series of updates. The jth input is (i, k, cj), which updates Aj-1 to be Aj, where
594|Finding matchings in the streaming model|This report presents algorithms for finding large matchings in the streaming model. In this model, applicable when dealing with massive graphs, edges are streamed-in in some arbitrary order rather than residing in randomly accessible memory. For e&gt; 0, we achieve a 1/(1+e) approximation for maximum cardinality matching and a 1/(2+e) approximation to maximum weighted matching. Both algorithms use a constant number of passes.
595|  Architecture for Accessing Data Streams on the Grid |Data streams are a prevalent and growing source of timely data. Existing systems that handle streaming data are often explicitly designed to serve the data streams. In the future we expect data streams to be viewed as just another input source to be consulted at will and on demand. These on-demand applications are often distributed, and either have significant computational or data access needs. This paper introduces an architecture for flexible access to real-time streaming data on the grid based on the following fundamental observations: Aggregation of data streams as data resource – for a class of data stream systems, a viable view of the data streams they produce is as a data resource, where the canonical data resource is a database. Stream access through database operations – an intuitive view of stream access operations is in terms of database operations, specifically by means of a database query language. The recent burgeoning interest in the database research community on the topic of streams attests to this viability. Grid service-based access to data streams – access to data streams has a natural realization through the proposed Global Grid Forum Grid Data Service specification, which currently specifies access to databases. The primary contributions of this paper are the definition of a data stream resource, an architecture for a data stream resource on the grid, and an identification of open research issues.
597|Autopilot: Adaptive control of distributed applications|With increasing development of applications for heterogeneous, distributed computing grids, the focus of performance analysis has shifted from a posteriori optimization on homogeneous parallel systems to application tuning for heterogeneous resources with time varying availability. This shift has profound implications for performance instrumentation and analysis techniques. Autopilot is a new infrastructure for dynamic performance tuning of heterogeneous computational grids based on closed loop control. This paper describes the Autopilot model of distributed sensors, actuators, and decision procedures, reports preliminary performance benchmarks, and presents a case study in which the Autopilot library is utilized in the development of an adaptive parallel input/output system.  
598|DataCutter: Middleware for Filtering Very Large Scientific Datasets on Archival Storage Systems|In this paper we present a middleware infrastructure, called DataCutter, that enables  processing of scientific datasets stored in archival storage systems across a widearea  network. DataCutter provides support for subsetting of datasets through multidimensional  range queries, and application specific aggregation on scientific datasets  stored in an archival storage system. We also present experimental results from a prototype  implementation.
600|An Event Service to Support Grid Computational Environments|We believe that it is interes) tos)2 thes ys)2 ands) ware architecture of environments which integrate the evolving ideas of computational grids dis)- objects webs ervices peer-topeer  networks and mes oriented middleware. Such peer-to-peer(P2P)Grids s houlds eamles integrate us tothems2 es and to res) which areals linked to each other. We canabs ss h environments as adis)- ss of &#034;clients which cons2 either of&#034;us or &#034;res2)- or proxies thereto.Thes clients mus be linked together in a flexible fault tolerant e#cient high performancefasmanc Inthis paper, wes2 the mes) or events - termed GES or the Grid Event Service -- thatis appropriate to link the clients (bothus andres2) of cours together. For our purp osp (regis)- trans orting and dis vering information), events arejusmes - typically with timesme)22 Themes2) ss GES mus s cale over a wide variety ofdevices - from hand heldcomputers at one end to high performancecomputers ands) at the other extreme. We have analyzed the requirements of s) eral Grids ervices that could be built with this model, including computing and education and incorporatedconsd) ts of collaboration with as hared event model. Wes2 that generalizing the well-knownpublis-)s e modelis an attractive approach and here wes2 s2 of theis to be addres)- if this modelis us in the GES. 1 Introducti  The web in recent years has experienced an explosion in tj number of devices users employt o access services. A single user may access acert&#034;E service using multEQE devices. Most services allow client st o accesst he servicet hrough a broker. The client istjF forcedt intjE&#034;G wit tt service viat his broker tGF--GFjOF tG duratFj tra it is usingt he service. If tj broker fails,t he client is denied servicingtrv suchtQ&#034; t&#034; failed broker recovers. Int he event t hat t his...
601|Database support for data-driven scientific applications|krishnan,kurc,umit,jsaltz¢ In this paper we describe a services oriented software system to provide basic database support for efficient execution of applications that make use of scientific datasets in the Grid. This system supports two core operations: efficient selection of the data of interest from distributed databases and efficient transfer of data from storage nodes to compute nodes for processing. We present its overall architecture and main components and describe preliminary experimental results. 1
602|Software approach to hazard detection using on-line analysis of safety constraints|Hazard situations in safety-critical systems are typically complex, so there is a need for means to detect complex hazards and react in a timely and meaningful way. This paper addresses the problem of hazard detection through the development of an on-line analysis tool. The approach allows the user to specify complex multi-source hazards using a query-like language, uses both synchronous and asynchronous on-line checking approaches to balance efficiency and expressiveness, accommodates dynamic applications through dynamic constraint addition, and supports distributed and parallel applications running in heterogeneous environments. 1
603|Experiences with OGSA-DAI: Portlet Access and Benchmark|Portals have proven to be useful client-side applications for providing user-oriented services for accessing the grid. Grids are increasingly being used for collaborative work within the scientific community. The job processing time for high performance computations can be reduced by the usage of computational grids, with its wide availability to resources. Grid users would similarly benefit from having access to databases, mainly, those involved in collaborative data analysis of large datasets and those requiring sharing of data. OGSA-DAI provides an extension to the OGSA framework by allowing access to and integration of data held in heterogeneous data resources. In this paper, we describe our experiences in designing and building a portlet to OGSA-DAI and in testing the grid services access to a relational database by means of a synthetic database workload.
604|Warping the Time on Data Streams |Abstract. Continuously monitoring through time the correlation/distance of multiple data streams is of interest in a variety of applications, including financial analysis, video surveillance, and mining of biological data. However, distance measures commonly adopted for comparing time series, such as Euclidean and Dynamic Time Warping (DT W), either are known to be inaccurate or are too time-consuming to be applied in a streaming environment. In this paper we propose a novel DT W-like distance measure, called SDT W, which, unlike DT W, can be efficiently updated at each time step and experimentally show that it improves over DT W by orders of magnitude without sacrificing accuracy. For instance, with a sliding window of 512 samples, SDT W is 400 times faster than DT W. 1.
605|Dynamic programming algorithm optimization for spoken word recognition|Abstract-This paper reports on an optimum dynamic programming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using timewarping function. Then, two time-normalized distance definitions, ded symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. AND SEIBI CHIBA vestigations were made, based on the assumption that speech patterns are time-sampled with a common and uniform sam-pling period, as in most general cases. One of the problems discussed in this paper involves the relative superiority of either a symmetric form of DP-matching or an asymmetric one. In the asymmetric form, time-normalization is achieved by trans-forming the time axis of a speech pattern onto that of the other. In the symmetric form, on the other hand, both time axes are transformed onto a temporarily defined common axis. Theoretical and experimental comparisons show that the sym-metric form gives better recognition than the asymmetric one. Another problem discussed concerns slope constraint technique. Since too much of the warping function flexibility sometimes results in poor discrimination between words in different The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimentat comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about twothirds errors, even compared to the best conventional algorithm. categories, a constraint is newly introduced on the warping I.
606|Exact Indexing of Dynamic Time Warping|The problem of indexing time series has attracted  much research interest in the database  community. Most algorithms used to index time  series utilize the Euclidean distance or some  variation thereof. However is has been forcefully  shown that the Euclidean distance is a very  brittle distance measure. Dynamic Time Warping  (DTW) is a much more robust distance measure  for time series, allowing similar shapes to match  even if they are out of phase in the time axis.
607|On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical  Demonstration|... mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made (speed in the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of &#034;improvement&#034; that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details. To illustrate our point
608|Efficient Retrieval of Similar Time Sequences Under Time Warping|Fast similarity searching in large time-sequence databases has attracted a lot of research interest [1, 5, 2, 6, 3, 10]. All of them use the Euclidean distance (L 2 ), or some variation of L p metrics. L p  metrics lead to efficient indexing, thanks to feature extraction (e.g., by keeping the first few DFT coefficients) and subsequent use of fast spatial access methods for the points in feature space. In this work we examine a popular, field-tested dissimilarity function, the &#034;time warping&#034; distance function which permits local accelerations and decelerations in the rate of the signals or sequences. This function is natural and suitable for several applications, like matching of voice, audio and medical signals (e.g., electrocardiograms) However, from the indexing viewpoint it presents two major challenges: (a) it does not lead to any natural &#034;features&#034;, precluding the use of spatial access methods (b) it is quadratic (O(len 1  len 2 )) on the length of the sequences involved. Here we ...
609|Making Time-series Classification More Accurate Using Learned Constraints|It has long been known that Dynamic Time Warping (DTW) is superior to Euclidean distance for classification and clustering of time series. However, until lately, most research has utilized Euclidean distance because it is more efficiently calculated. A recently introduced technique that greatly mitigates DTWs demanding CPU time has sparked a flurry of research activity. However, the technique and its many extensions still only allow DTW to be applied to moderately large datasets. In addition, almost all of the research on DTW has focused exclusively on speeding up its calculation; there has been little work done on improving its accuracy. In this work, we target the accuracy aspect of DTW performance and introduce a new framework that learns arbitrary constraints on the warping path of the DTW calculation. Apart from improving the accuracy of classification, our technique as a side effect speeds up DTW by a wide margin as well. We show the utility of our approach on datasets from diverse domains and demonstrate significant gains in accuracy and efficiency.
610|Indexing large human-motion databases|Data-driven animation has become the industry standard for computer games and many animated movies and special effects. In particular, motion capture data recorded from live actors, is the most promising approach offered thus far for animating realistic human characters. However, the manipulation of such data for general use and re-use is not yet a solved problem. Many of the existing techniques dealing with editing motion rely on indexing for annotation, segmentation, and re-ordering of the data. Euclidean distance is inappropriate for solving these indexing problems because of the inherent variability found in human motion. The limitations of Euclidean distance stems from the fact that it is very sensitive to distortions in the time axis. A partial solution to this problem, Dynamic Time Warping (DTW), aligns the time axis
611|An Index-Based Approach for Similarity Search Supporting Time Warping in Large Sequence Databases|This paper discusses an effective processing of similarity search that supports time warping  in large sequence databases. Time warping enables finding sequences with similar patterns  even when they are of different lengths. Previous methods for processing similarity search that  supports time warping fail to employ multi-dimensional indexes without false dismissal since  the time warping distance does not satisfy the triangular inequality. They have to scan all  the database, thus suffer from serious performance degradation in large databases. Another  method that hires the suffix tree, which does not assume any distance function, also shows poor  performance due to the large tree size.  In this paper, we propose a new novel method for similarity search that supports time  warping. Our primary goal is to innovate on search performance in large databases without  permitting any false dismissal. To attain this goal, we devise a new distance function D tw\Gammalb  that consistently unde...
612|Iterative deepening dynamic time warping for time series|Time series are a ubiquitous form of data occurring in virtually every scientific discipline and business application. There has been much recent work on adapting data mining algorithms to time series databases. For example, Das et al. attempt to show how association rules can be learned from time series [7]. Debregeas and Hebrail [8]
613|Searching in Metric Spaces with User-Defined and Approximate Distances|Metric access methods (MAMs), such as the M-tree, are powerful index structures for supporting similarity queries on metric spaces, which represent a common abstraction forthIj searchrc problems tho arise in many modern application areas, such as multimedia, data mining, decision support, pattern recognition, and genomic databases. As compared to multi-dimensional (spatial) access methods (SAMs), MAMs are more general, yet they are reputed to lose in flexibility, since it is commonly deemed th= th= can only answer queries using th same distance function used to buildth index. In thj paper we sh wth&#034; th&#034; limitation is only apparent -- thus MAMs are far more flexible than believed -- and extend the M-tree so as to be able to support user-defined distance criteria, approximate distance functions to speed up query evaluation, as well as dissimilarity functions whD h are not metrics. The so-extended M-tree, also called QIC-M-tree, can deal with three distinct distances at a time: 1) a query (user-defined) distance,2)anindex distance (used to buildth tree), and 3) a comparison(iso oximate) distance (used to quickly discard from th search uninteresting parts of th tree). We develop an analytical cost model thl accurately characterizes the performance of QIC-M-tree and validate such model thjj&#034;[ extensive experimentation on real metric data sets. In particular, our analysis is able to predict th best evaluation strategy (i.e.whe h distances to use) under a variety of configurations, by properly taking into account relevant factors such as th distribution of distances, th cost of computing distances, and th actual index structure. We also prove thF the overall saving in CPU search costs whj using an approximate distance can be estimated by using information on the data set only -- thus...
614| An Overview of Temporal Data Mining |Temporal Data Mining is a rapidly evolving area of research that is at the intersection of several disciplines, including statistics, temporal pattern recognition, temporal databases, optimisation, visualisation, high-performance computing, and parallel computing. This paper is first intended to serve as an overview of the temporal data mining in research and applications. 
615|Missing data: Our view of the state of the art|Statistical procedures for missing data have vastly improved, yet misconception and unsound practice still abound. The authors frame the missing-data problem, review methods, offer advice, and raise issues that remain unresolved. They clear up common misunderstandings regarding the missing at random (MAR) concept. They summarize the evidence against older procedures and, with few exceptions, dis-courage their use. They present, in both technical and practical language, 2 general approaches that come highly recommended: maximum likelihood (ML) and Bayes-ian multiple imputation (MI). Newer developments are discussed, including some for dealing with missing data that are not MAR. Although not yet in the main-stream, these procedures may eventually extend the ML and MI methods that currently represent the state of the art. Why do missing data create such difficulty in sci-entific research? Because most data analysis proce-dures were not designed for them. Missingness is usu-ally a nuisance, not the main focus of inquiry, but
616|Statistical Analysis with Missing Data|Subsample ignorable likelihood for regression
617|Bayesian Data Analysis|I actually own a copy of Harold Jeffreys’s Theory of Probability but have only read small bits of it, most recently over a decade ago to confirm that, indeed, Jeffreys was not too proud to use a classical chi-squared p-value when he wanted to check the misfit of a model to data (Gelman, Meng and Stern, 2006). I do, however, feel that it is important to understand where our probability models come from, and I welcome the opportunity to use the present article by Robert, Chopin and Rousseau as a platform for further discussion of foundational issues. 2 In this brief discussion I will argue the following: (1) in thinking about prior distributions, we should go beyond Jeffreys’s principles and move toward weakly informative priors; (2) it is natural for those of us who work in social and computational sciences to favor complex models, contra Jeffreys’s preference for simplicity; and (3) a key generalization of Jeffreys’s ideas is to explicitly include model checking in the process of data analysis.
618|Analyzing Incomplete Political Science Data: An Alternative Algorithm for Multiple Imputation|We propose a remedy for the discrepancy between the way political scientists analyze data with missing values and the recommendations of the statistics community. Methodologists and statisticians agree that &#034;multiple imputation&#034; is a superior approach to the problem of missing data scattered through one&#039;s explanatory and dependent variables than the methods currently used in applied data analysis. The reason for this discrepancy lies with the fact that the computational algorithms used to apply the best multiple imputation models have been slow, difficult to implement, impossible to run with existing commercial statistical packages, and demanding of considerable expertise.  In this paper, we adapt an existing algorithm, and use it to implement a generalpurpose, multiple imputation model for missing data. This algorithm is considerably faster and easier to use than the leading method recommended in the statistics literature. We also quantify the risks of current missing data practices, ...
619|Multiple imputation for multivariate missing-data problems: a data analyst&#039;s perspective|Analyses of multivariate data are frequently hampered by missing values. Until re-cently, the only missing-data methods available to most data analysts have been relatively ad hoc practices such as listwise deletion. Recent dramatic advances in theoretical and com-putational statistics, however, have produced a new generation of flexible procedures with a sound statistical basis. These procedures involve multiple imputation (Rubin, 1987), a simu-lation technique that replaces each missing datum with a set of m&gt;1 plausible values. The m versions of the complete data are analyzed by standard complete-data methods, and the results are combined using simple rules to yield estimates, standard errors, and p-values that formally incorporate missing-data uncertainty. New computational algorithms and software described in a recent book (Schafer, 1997) allow us to create proper multiple imputations in complex multivariate settings. This article reviews the key ideas of multiple imputation, discusses the software programs currently available, and demonstrates their use on data from
620|Application of random-effects pattern-mixture models for missing data in longitudinal studies|Random-effects regression models have become increasingly popular for analysis of longitudinal data. A key advantage of the random-effects approach is that it can be applied when subjects are not measured at the same number of timepoints. In this article we describe use of random-effects pattern-mixture models to further handle and describe the influence of missing data in longitudinal studies. For this approach, subjects are first divided into groups depending on their missing-data pattern and then variables based on these groups are used as model covariates. In this way, researchers are able to examine the effect of missing-data patterns on the outcome (or outcomes) of interest. Furthermore, overall estimates can be obtained by averaging over the missing-data patterns. A psychiatric clinical trials data set is used to illustrate the random-effects pattern-mixture approach to longitudinal data analysis with missing data.  
621|Multiple Imputation for Missing Data: A Cautionary Tale|: Two algorithms for producing multiple imputations for missing data are evaluated with simulated data. Software using a propensity score classifier with the approximate Bayesian boostrap produces badly biased estimates of regression coefficients when data on predictor variables are missing at random or missing completely at random. On the other hand, a regression-based method employing the data augmentation algorithm produces estimates with little or no bias.  4 Multiple imputation (MI) appears to be one of the most attractive methods for generalpurpose handling of missing data in multivariate analysis. The basic idea, first proposed by Rubin (1977) and elaborated in his (1987) book, is quite simple: 1. Impute missing values using an appropriate model that incorporates random variation. 2. Do this M times (usually 3-5 times), producing M &#034;complete&#034; data sets. 3. Perform the desired analysis on each data set using standard complete-data methods. 4. Average the values of the parameter ...
622|On Structural Equation Modeling with Data that are not Missing Completely at Random|A general latent variable model is given which includes the specification of a missing data mechanism. This framework allows for an elucidating discussion of existing general multivariate theory bearing on maximum likelihood estimation with missing data. Here, missing completely at random is not a prerequisite for unbiased estimation in large samples, as when using the traditional listwise or pairwise present data approaches. The theory is connected with old and new results in the area of selection and factorial invariance. It is pointed out that in many applications, maximum likelihood estimation with missing data may be carried out by existing structural equation modeling software, such as LISREL and LISCOMP. Several sets of artifical data are generated within the general model framework. The proposed estimator is compared to the two traditional ones and found superior. Key words: maximum likelihood, ignorability, selectivity, factor analysis, factorial invariance,
623|Multiple Imputation in Practice: Comparison of Software Packages for Regression Models With Missing Variables |This article reviews multiple imputation, describes assumptions that it requires, and reviews software packages that implement this procedure. We apply the methods and compare the results using two examples---a child psychopathology dataset with missing outcomes and an artificial dataset with missing covariates. We conclude with some discussion of the strengths and weaknesses of these implementations as well as advantages and limitations of imputation
624|Imputation of the 1989 Survey of Consumer Finances: Stochastic Relaxation and Multiple Imputation” mimeo, Board of Governors of the Federal Reserve System|acknowledges the support for this work by staff in the Division of Research and Statistics including
625|ANALYSIS WITH MISSING DATA IN PREVENTION RESEARCH|Missing data are pervasive in alcohol and drug abuse prevention evaluation efforts: Researchers administer surveys, and some items are left unanswered. Slow readers often leave large portions incomplete at the end of the survey. Researchers administer the surveys at several points in time, and people fail to show up at one or more waves of measurement. Researchers often design their measures to include a certain amount of “missingness”; some measures are so expensive (in money or time) that researchers can afford to administer them only to some respondents. Missing data problems have been around for years. Until recently, researchers have fumbled with partial solutions and put up only the weakest counterarguments to the admonitions of the critics of prevention and applied psychological research. Things have changed, however. Statistically sound solutions are now available for virtually every missing data problem,
626|Inference with Imputed Conditional Means|In this paper, we develop analytic techniques that can be used to produce appropriate inferences from a data set in which imputation for missing values has been carried out using predictive means. Our derivations are based on asymptotic expansions of point estimators and their associated variance estimators, and the resulting formulas can be thought of as first-order approximations to the estimators that would be used with multiple imputation. The procedures developed can be used either for univariate missing data or for multivariate missing data in which the variables are either missing or observed together, and they are designed for situations in which the complete-data estimator is a smooth function of linear statistics. We illustrate properties of our methods in several examples, including abstract problems as well as applications to large data sets from studies carried out by the federal government. Key Words: Linearization; Missing data; Multiple Imputation; Nonresponse; Taylor s...
627|Maximum Likelihood Analysis of Generalized Linear Models with Missing Covariates|Missing data is a common occurrence in most medical research data collection enterprises. There is an extensive literature concerning missing data, much of which has focused on missing outcomes. Covariates in regression models are often missing, particularly if information is being collected from multiple sources. The method of weights is an implementation of the EM algorithm 8 for general maximum-likelihood analysis of regression models, including generalized linear models 32 (GLMs) with incomplete covariates. In this paper, we will describe the method of weights in detail, illustrate its application with several examples, discuss its advantages and limitations, and review extensions and applications of the method.
628|Multiple imputation and posterior simulation for multivariate missing data in longitudinal studies (pp  (1995) |SUMMARY. This paper outlines a multiple imputation method for handling missing data in designed lon-gitudinal studies. A random coefficients model is developed to accommodate incomplete multivariate con-tinuous longitudinal data. Multivariate repeated measures are jointly modeled; specifically, an i.i.d. normal model is assumed for time-independent variables and a hierarchical random coefficients model is assumed for time-dependent variables in a regression model conditional on the time-independent variables and time, with heterogeneous error variances across variables and time points. Gibbs sampling is used to draw model parameters and for imputations of missing observations. An application to data from a study of startle reactions illustrates the model. A simulation study compares the multiple imputation procedure to the weighting approach of Robins, Rotnitzky, and Zhao (1995, Journal of the American Statistical Association 90, 106-121) that can be used to address similar data structures. KEY WORDS: Gibbs sampling; Missing data; Multiple imputation; Multivariate longitudinal data 1. Background In designed longitudinal studies, missing data often occur be-cause subjects miss visits during the study, because some vari-ables may not be measured at particular visits, or because
629|Online clustering of parallel data streams|In recent years, the management and processing of so-called data streams has become a topic of active research in several fields of computer science such as, e.g., distributed systems, database systems, and data mining. A data stream can roughly be thought of as a transient, continuously increasing sequence of time-stamped data. In this paper, we consider the problem of clustering parallel streams of real-valued data, that is to say, continuously evolving time series. In other words, we are interested in grouping data streams the evolution over time of which is similar in a specific sense. In order to maintain an up-to-date clustering structure, it is necessary to analyze the incoming data in an online manner, tolerating not more than a constant time delay. For this purpose, we develop an efficient online version of the classical K-means clustering algorithm. Our method’s efficiency is mainly due to a scalable online transformation of the original data which allows for a fast computation of approximate distances between streams. Key words: data mining, clustering, data streams, fuzzy sets 1
630|The Elements of|Several years ago a native found in the bed of the Alpheus River in Greece a roughly rectangular sheet of metal which was evidently the flattened side of a cylindrical vessel, possibly a bucket or similar container. A repousee design in Greek style of considerable artistic merit had been formed in the metal. This sheet of metal was brought to the attention of an archaeologist who purchased it because of its artistic value. * Since the object was uniformly covered with a green patina, it was first believed to be composed of bronze or copper, but, in the course of cleaning it for the purposes of study and exhibition, the surface of the bare metal was seen to have the appearance of silver, which was puzzling in view of the color of the patina. Because of this discrepancy the writer was asked to make a chemical examination. Visual inspection of cleaned places on the edge of the sheet showed that it was composite in structure. The sheet consisted of a layer of a reddish metal sand-wiched between two layers of a white metal, and the three were firmly bonded
631|Approximate aggregation techniques for sensor databases|In the emerging area of sensor-based systems, a significant challenge is to develop scalable, fault-tolerant methods to extract useful information from the data the sensors collect. An approach to this data management problem is the use of sensor database systems, exemplified by TinyDB and Cougar, which allow users to perform aggregation queries such as MIN, COUNT and AVG on a sensor network. Due to power and range constraints, centralized approaches are generally impractical, so most systems use in-network aggregation to reduce network traffic. Also, aggregation strategies must provide fault-tolerance to address the issues of packet loss and node failures inherent in such a system. An unfortunate consequence of standard methods is that they typically introduce duplicate values, which must be accounted for to compute aggregates correctly. Another consequence of loss in the network is that exact aggregation is not possible in general. With this in mind, we investigate the use of approximate in-network aggregation using small sketches. Our contributions are as follows: 1) we generalize well known duplicateinsensitive sketches for approximating COUNT to handle SUM (and by extension, AVG and other aggregates), 2) we present and analyze methods for using sketches to produce accurate results with low communication and computation overhead (even on low-powered CPUs with little storage and no floating point operations), and 3) we present an extensive experimental validation of our methods. 1
632|Clustering Large Graphs via the Singular Value Decomposition|We consider the problem of partitioning a set of m points in the n-dimensional Euclidean space into k clusters (usually m and n are variable, while k is fixed), so as to minimize the sum of squared distances between each point and its cluster center. This formulation is usually the objective of the k-means clustering algorithm (Kanungo et al. (2000)). We prove that this problem in NP-hard even for k    2, and we consider a continuous relaxation of this discrete problem: find the k-dimensional subspace V that minimizes the sum of squared distances to V of the m points. This relaxation can be solved by computing the Singular Value Decomposition (SVD) of the   n matrix A that represents the m points; this solution can be used to get a 2-approximation algorithm for the original problem. We then argue that in fact the relaxation provides a generalized clustering which is useful in its own right. Finally, we
633|A General Framework for Mining Massive Data Stream|In many domains, data now arrives faster than we are able to mine it. To avoid wasting this data, we must switch from the traditional &#034;one-shot&#034; data mining approach to systems that are able to mine continuous, high-volume, open-ended data streams as they arrive. In this extended abstract we identify some desiderata for such systems, and outline our framework for realizing them. A key property of our approach is that it minimizes the time required to build a model on a stream, while guaranteeing (as long as the data is i.i.d.) that the model learned is e#ectively indistinguishable from the one that would be obtained using infinite data. Using this framework, we have successfully adapted several learning algorithms to massive data streams, including decision tree induction, Bayesian network learning, k-means clustering, and the EM algorithm for mixtures of Gaussians. These algorithms are able to process on the order of billions of examples per day using o#-the-shelf hardware. Building on this, we are currently developing software primitives for scaling arbitrary learning algorithms to massive data streams with minimal e#ort.
634|Cost-Efficient Mining Techniques for Data Streams|A data stream is a continuous and high-speed flow of data items. High speed refers to the phenomenon that the data rate is high relative to the computational power. The increasing focus of applications that generate and receive data streams stimulates the need for online data stream analysis tools. Mining data streams is a real time process of extracting interesting patterns from high-speed data streams. Mining data streams raises new problems for the data mining community in terms of how to mine continuous high-speed data items that you can only have one look at. In this paper, we propose algorithm output granularity as a solution for mining data streams. Algorithm output granularity is the amount of mining results that fits in main memory before any incremental integration. We show the application of the proposed strategy to build efficient clustering, frequent items and classification techniques. The empirical results for our clustering algorithm are presented and discussed which demonstrate acceptable accuracy coupled with efficiency in running time.
635|Data Streaming Algorithms for Geometric Problems |A data stream is an ordered sequence of points that can be read only once or a small number of times. Formally, a data stream is a sequence of points
636|Approximating the Minimum Spanning Tree Weight in Sublinear Time|We present a probabilistic algorithm that, given a connected graph G (represented by adjacency lists) of average degree d, with edge weights in the set {1,...,w}, and given a parameter 0 &lt; e &lt; 1/2, estimates in time O(dwe-2 log dw e) the weight of the minimum span-ning tree of G with a relative error of at most e. Note that the running time does not depend on the number of vertices in G. We also prove a nearly matching lower bound of ?(dwe-2) on the probe and time complexity of any approximation algorithm for MST weight. The essential component of our algorithm is a procedure for estimating in time O(de-2 log d e) the number of connected components of an unweighted graph to within an additive error of en. (This becomes O(e-2 log 1 e) for d = O(1).) The time bound is shown to be tight up to within the log d e factor. Our connected-components algorithm picks O(1/e2) vertices in the graph and then grows “local spanning trees” whose sizes are specified by a stochastic process. From the local information collected in this way, the algorithm is able to infer, with high confidence, an estimate of the number of connected components. We then show how estimates on the number of components in various subgraphs of G can be used to estimate the weight of its MST. 1
637|Estimating the weight of metric minimum spanning trees in sublinear-time |In this paper we present a sublinear time (1+ ?)-approximation randomized algorithm to estimate the weight of the minimum spanning tree of an n-point metric space. The running time of the algorithm is Õ(n/?O(1)). Since the full description of an n-point metric space is of size T(n 2),the complexity of our algorithm is sublinear with respect to the input size. Our algorithm is almost optimal as it is not possible to approximate in o(n) time the weight of the minimum spanning tree to within any factor. Furthermore,it has been previously shown that no o(n 2) algorithm exists that returns a spanning tree whose weight is within a constant times the optimum.
638|Linked Data -- The story so far  |The term Linked Data refers to a set of best practices for publishing and connecting structured data on the Web. These best practices have been adopted by an increasing number of data providers over the last three years, leading to the creation of a global data space containing billions of assertions- the Web of Data. In this article we present the concept and technical principles of Linked Data, and situate these within the broader context of related technological developments. We describe progress to date in publishing Linked Data on the Web, review applications that have been developed to exploit the Web of Data, and map out a research agenda for the Linked Data community as it moves forward.
639|DBpedia: A Nucleus for a Web of Open Data|Abstract DBpedia is a community effort to extract structured informa-tion from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human- and machine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data. 1
640|Duplicate record detection: A survey|Often, in the real world, entities have two or more representations in databases. Duplicate records do not share a common key and/or they contain errors that make duplicate matching a dif cult task. Errors are introduced as the result of transcription errors, incomplete information, lack of standard formats or any combination of these factors. In this article, we present a thorough analysis of the literature on duplicate record detection. We cover similarity metrics that are commonly used to detect similar eld entries, and we present an extensive set of duplicate detection algorithms that can detect approximately duplicate records in a database. We also cover multiple techniques for improving the ef ciency and scalability of approximate duplicate detection algorithms. We conclude with a coverage of existing tools and with a brief discussion of the big open problems in the area.  
641|Sindice.com: A document-oriented lookup index for open linked data |Developers of Semantic Web applications face a challenge with respect to the decentralised publication model: how and where to find statements about encountered resources. The “linked data” approach mandates that resource URIs should be de-referenced to return resource metadata. But for data discovery linkage itself is not enough, and crawling and indexing of data is necessary. Existing Semantic Web search engines are focused on database-like functionality, compromising on index size, query performance and live updates. We present Sindice, a lookup index over resources crawled on the Semantic Web. Our index allows applications to automatically locate documents containing information about a given resource. In addition, we allow resource retrieval through uniquely identifying inverse-functional properties, offer a full-text search and index SPARQL endpoints. Finally we introduce an extension to the sitemap protocol which allows us to efficiently index large Semantic Web datasets with minimal impact on the data providers.
642|Querying Distributed RDF Data Sources with SPARQL|Abstract. Integrated access to multiple distributed and autonomous RDF data sources is a key challenge for many semantic web applications. As a reaction to this challenge, SPARQL, the W3C Recommendation for an RDF query language, supports querying of multiple RDF graphs. However, the current standard does not provide transparent query federation, which makes query formulation hard and lengthy. Furthermore, current implementations of SPARQL load all RDF graphs mentioned in a query to the local machine. This usually incurs a large overhead in network traffic, and sometimes is simply impossible for technical or legal reasons. To overcome these problems we present DARQ, an engine for federated SPARQL queries. DARQ provides transparent query access to multiple SPARQL services, i.e., it gives the user the impression to query one single RDF graph despite the real data being distributed on the web. A service description language enables the query engine to decompose a query into sub-queries, each of which can be answered by an individual service. DARQ also uses query rewriting and cost-based query optimization to speed-up query execution. Experiments show that these optimizations significantly improve query performance even when only a very limited amount of statistical information is available. DARQ is available under GPL License at
643|Principles of dataspace systems|The most acute information management challenges today stem from organizations relying on a large number of diverse, interrelated data sources, but having no means of managing them in a convenient, integrated, or principled fashion. These challenges arise in enterprise and government data management, digital libraries, “smart ” homes and personal information management. We have proposed dataspaces as a data management abstraction for these diverse applications and DataSpace Support Platforms (DSSPs) as systems that should be built to provide the required services over dataspaces. Unlike data integration systems, DSSPs do not require full semantic integration of the sources in order to provide useful services. This paper lays out specific technical challenges to realizing DSSPs and ties them to existing work in our field. We focus on query answering in DSSPs, the DSSP’s ability to introspect on its content, and the use of human attention to enhance the semantic relationships in a dataspace.  
645|Triplify -- Light-Weight Linked Data Publication from Relational Databases|In this paper we present Triplify – a simplistic but effective approach to publish Linked Data from relational databases. Triplify is based on mapping HTTP-URI requests onto relational database queries. Triplify transforms the resulting relations into RDF statements and publishes the data on the Web in various RDF serializations, in particular as Linked Data. The rationale for developing Triplify is that the largest part of information on the Web is already stored in structured form, often as data contained in relational databases, but usually published by Web applications only as HTML mixing structure, layout and content. In order to reveal the pure structured information behind the current Web, we have implemented Triplify as a light-weight software component, which can be easily integrated into and deployed by the numerous, widely installed Web applications. Our approach includes a method for publishing update logs to enable incremental crawling of linked data sources. Triplify is complemented by a library of configurations for common relational schemata and a REST-enabled data source registry. Triplify configurations containing mappings are provided for many popular Web applications, including osCommerce, WordPress, Drupal, Gallery, and phpBB. We will show that despite its light-weight architecture Triplify is usable to publish very large datasets, such as 160GB of geo data from the OpenStreetMap project.
646|Named Graphs|The Semantic Web consists of many RDF graphs nameable by URIs. This paper extends the syntax and semantics of RDF to cover such named graphs. This enables RDF statements that describe graphs, which is beneficial in many Semantic Web application areas. Named graphs are given an abstract syntax, a formal semantics, an XML syntax, and a syntax based on N3. SPARQL is a query language applicable to named graphs. A specific application area discussed in detail is that of describing provenance information. This paper provides a formally defined framework suited to being a foundation for the Semantic Web trust layer.
647|Bootstrapping pay-as-you-go data integration systems|Data integration systems offer a uniform interface to a set of data sources. Despite recent progress, setting up and maintaining a data integration application still requires significant upfront effort of creating a mediated schema and semantic mappings from the data sources to the mediated schema. Many application contexts involving multiple data sources (e.g., the web, personal information management, enterprise intranets) do not require full integration in order to provide useful services, motivating a pay-as-you-go approach to integration. With that approach, a system starts with very few (or inaccurate) semantic mappings and these mappings are improved over time as deemed necessary. This paper describes the first completely self-configuring data integration system. The goal of our work is to investigate how advanced of a starting point we can provide a pay-as-you-go system. Our system is based on the new concept of a probabilistic mediated schema that is automatically created from the data sources. We automatically create probabilistic schema mappings between the sources and the mediated schema. We describe experiments in multiple domains, including 50-800 data sources, and show that our system is able to produce high-quality answers with no human intervention.
648|Provenance Information in the Web of Data|The openness of the Web and the ease to combine linked data from different sources creates new challenges. Systems that consume linked data must evaluate quality and trustworthiness of the data. A common approach for data quality assessment is the analysis of provenance information. For this reason, this paper discusses provenance of data on the Web and proposes a suitable provenance model. While traditional provenance research usually addresses the creation of data, our provenance model also represents data access, a dimension of provenance that is particularly relevant in the context of Web data. Based on our model we identify options to obtain provenance information and we raise open questions concerning the publication of provenance-related metadata for linked data on the Web.
649|Automatic Interlinking of Music Datasets on the Semantic Web |In this paper, we describe current efforts towards interlinking music-related datasets on the Web. We first explain some initial interlinking experiences, and the poor results obtained by taking a naïve approach. We then detail a particular interlinking algorithm, taking into account both the similarities of web resources and of their neighbours. We detail the application of this algorithm in two contexts: to link a Creative Commons music dataset to an editorial one, and to link a personal music collection to corresponding web identifiers. The latter provides a user with personally meaningful entry points for exploring the web of data, and we conclude by describing some concrete tools built to generate and use such links.
650|The Open Provenance Model|The Open Provenance Model (OPM) is a community-driven data model for Provenance that is designed to support inter-operability of provenance technology. Underpinning OPM, is a notion of directed acyclic graph, used to represent data products and processes involved in past computations, and causal dependencies between these. The Open Provenance Model was derived following two “Provenance Challenges”, international, multidisciplinary activities trying to investigate how to exchange information between multiple systems supporting provenance and how to query it. The OPM design was mostly driven by practical and pragmatic considerations, and is being tested in a third Provenance Challenge, which has just started. The purpose of this paper is to investigate the theoretical foundations of this data model. The formalisation consists of a set-theoretic definition of the data model, a definition of the inferences by transitive closure that are permitted, a formal description of how the model can be used to express dependencies in past computations, and finally, a description of the kind of time-based inferences that are supported. A novel element that OPM introduces is the concept of an account, by which multiple descriptions of a same execution are allowed to co-exist in a same graph. Our formalisation gives a precise meaning to such accounts and associated notions of alternate and refinement. Warning It was decided that this paper should be released as early as possible since it brings useful clarifications on the Open Provenance Model, and therefore can benefit the Provenance Challenge 3 community. The reader should recognise that this paper is however an early draft, and several sections are incomplete. Additionally, figures rely on colours but these may be difficult to read when printed in a black and white. It is advisable to print the paper in colour. 1 1
651|Which Semantic Web?|Through scenarios in the popular press and technical papers in the research literature, the promise of the Semantic Web has raised a number of different expectations. These expectations can be traced to three different perspectives on the Semantic Web. The Semantic Web is portrayed as: (1) a universal library, to be readily accessed and used by humans in a variety of information use contexts; (2) the backdrop for the work of computational agents completing sophisticated activities on behalf of their human counterparts; and (3) a method for federating particular knowledge bases and databases to perform anticipated tasks for humans and their agents. Each of these perspectives has both theoretical and pragmatic entailments, and a wealth of past experiences to guide and temper our expectations. In this paper, we examine all three perspectives from rhetorical, theoretical, and pragmatic viewpoints with an eye toward possible outcomes as Semantic Web efforts move forward.
652|M.: Linked movie data base|The Linked Movie Database (LinkedMDB) project provides a demonstration of the first open linked dataset connecting several major existing (and highly popular) movie web resources. The database exposed by LinkedMDB contains millions of RDF triples with hundreds of thousands of RDF links to existing web data sources that are part of the growing Linking Open Data cloud, as well as to popular movierelated web pages such as IMDb. LinkedMDB uses a novel way of creating and maintaining large quantities of high quality links by employing state-of-the-art approximate join techniques for finding links, and providing additional RDF metadata about the quality of the links and the techniques used for deriving them.
653|A Framework for Semantic Link Discovery over Relational Data |In this paper, we present a framework for online discovery of semantic links from relational data. Our framework is based on declarative specification of the linkage requirements by the user, that allows matching data items in many real-world scenarios. These requirements are translated to queries that can run over the relational data source, potentially using the semantic knowledge to enhance the accuracy of link discovery. Our framework lets data publishers to easily find and publish high-quality links to other data sources, and therefore could significantly enhance the value of the data in the next generation of web.
654|How will we interact with the web of data|The Semantic Web is a global information space of linked data, designed not for human use but for consumption by machines. Right? Well, yes and no. It&#039;s true to say that machine-readable data,  given explicit semantics and published online,  coupled with the ability to link data in distributed data sets are the key selling points of the Semantic Web. Together, these features allow aggregation and integration of heterogeneous data on an unprecedented scale,  and machines will do the grunt work for us. However, without a human being somewhere in this process, to reap the rewards of these new capabilities, the endeavour is meaningless. Far from removing human beings from the equation, a Web of machine-readable data creates significant challenges and significant opportunities for human-computer interaction. To date,  the Semantic Web community has mostly been busy developing the technical infrastructure to make the Web of Data feasible in principle and on publishing linked data sets in order to make it a reality. If we are to fully exploit the challenges and opportunities of a Web of Data from a human perspective,  we need to move beyond the initial phase and work to understand how this changes the user interaction paradigm of the Web.
655|What is the Size of the Semantic Web|Abstract: When attempting to build a scaleable Semantic Web application, one has to know about the size of the Semantic Web. In order to be able to understand the characteristics of the Semantic Web, we examined an interlinked dataset acting as a representative proxy for the Semantic Web at large. Our main finding was that regarding the size of the Semantic Web, there is more than the sheer number of triples; the number and type of links is an equally crucial measure.
656|Tabulator Redux: Browsing and Writing Linked Data |second frame shows information within that source expanded, the third frame shows another source within that source expanded, and finally, the last frame shows that the label of that source has been edited from “Music and artist data interlinked ” to “Music and artist data linked on the Semantic Web” A first category of Semantic Web browsers was designed to present a given dataset (an RDF graph) for perusal in various forms. These include mSpace, Exhibit, and to a certain extent
657|Integration of semantically annotated data by the knofuss architecture|Abstract. Most of the existing work on information integration in the Semantic Web concentrates on resolving schema-level problems. Specific issues of data-level integration (instance coreferencing, conflict resolu-tion, handling uncertainty) are usually tackled by applying the same techniques as for ontology schema matching or by reusing the solutions produced in the database domain. However, data structured according to OWL ontologies has its specific features: e.g., the classes are organized into a hierarchy, the properties are inherited, data constraints differ from those defined by database schema. This paper describes how these fea-tures are exploited in our architecture KnoFuss, designed to support data-level integration of semantic annotations. 1
658|DBpedia Mobile - A Location-Aware Semantic Web Client|Abstract. DBpedia Mobile is a location-aware client for the Semantic Web that can be used on an iPhone and other mobile devices. Based on the current GPS position of a mobile device, DBpedia Mobile renders a map indicating nearby locations from the DBpedia dataset. Starting from this map, the user can explore background information about his surroundings by navigating along data links into other Web data sources. DBpedia Mobile has been designed for the use case of a tourist exploring a city. As the application is not restricted to a fixed set of data sources but can retrieve and display data from arbitrary Web data sources, DBpedia Mobile can also be employed within other use cases, including ones un-foreseen by its developers. Besides accessing Web data, DBpedia Mobile also enables users to publish their current location, pictures and reviews to the Semantic Web so that they can be used by other Semantic Web applications. Instead of simply being tagged with geographical coordi-nates, published content is interlinked with a nearby DBpedia resource and thus contributes to the overall richness of the Geospatial Semantic Web.
659|Information-seeking on the Web with Trusted Social Networks – from Theory to Systems|This research investigates how synergies between the Web and social networks can enhance the process of obtaining relevant and trustworthy information. A review of literature on personalised search, social search, recommender systems, social networks and trust propagation reveals limitations of existing technology in areas such as relevance, collaboration, task-adaptivity and trust. In response to these limitations I present a Web-based approach to information-seeking using social networks. This approach takes a source-centric perspective on the information-seeking process, aiming to identify trustworthy sources of relevant information from within the user&#039;s social network. An empirical study of source-selection decisions in information- and recommendationseeking identified five factors that influence the choice of source, and its perceived trustworthiness. The priority given to each of these factors was found to vary according to the criticality and subjectivity of the task. A series of algorithms have been developed that operationalise three of these factors (expertise, experience, affinity) and generate from various data sources a number of trust metrics for use in social network-based information seeking. The most significant of these data sources is Revyu.com, a reviewing and rating Web site implemented as part of this research, that takes input from regular users and makes it available on the Semantic Web for easy re-use by the implemented algorithms. Output of the algorithms is used in Hoonoh.com, a Semantic Web-based system that has been developed to support users in identifying relevant and trustworthy information   sources within their social networks. Evaluation of this system&#039;s ability to predict source selections showed more promising results for the experience factor than for expertise or affinity. This may be attributed to the greater demands these two factors place in terms of input data. Limitations of the work and opportunities for future research are discussed.  
660|Detection in Sensor Data Streams|This paper describes two novel learning algorithms for abrupt change detection in multivariate sensor data streams that can be applied when no explicit models of data distributions before and after the change are available. One of the algorithms, MB-GT, uses average Euclidean distances between pairs of data sets as the decision variable, and the other, MB-CUSUM, is a direct extension of the CUSUM algorithm to the case when the unknown probability density functions are estimated by means of kernel density estimates. The algorithms operate on a sliding memory buffer of the most recent N data readings, and consider all possible splits of that buffer into two contiguous windows before and after the change. Despite the apparent computational complexity of O(N^4) of this computation, our proposed algorithmic solutions exploit the structure present in their respective decision functions and exhibit computational complexity of only O(N^2) and memory
662|Locally weighted learning|This paper surveys locally weighted learning, a form of lazy learning and memorybased learning, and focuses on locally weighted linear regression. The survey discusses distance functions, smoothing parameters, weighting functions, local model structures, regularization of the estimates and bias, assessing predictions, handling noisy data and outliers, improving the quality of predictions by tuning t parameters, interference between old and new data, implementing locally weighted learning e ciently, and applications of locally weighted learning. A companion paper surveys how locally weighted learning can be used in robot learning and control.
663|Analysis and Visualization of Classifier Performance: Comparison under Imprecise Class and Cost Distributions|Applications of inductive learning algorithms to realworld data mining problems have shown repeatedly that using accuracy to compare classifiers is not adequate because the underlying assumptions rarely hold. We present a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. The ROC convex hull method combines techniques from ROC analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. The method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses. Introduction  When mining data with inductive methods, we often experiment with a wide variety of learning algorithms, using different algorithm parameters, varying output threshold values, and using different training regimens. Such experimentation yields a large number of classifiers to be evaluated a...
664|The click modular router| Click is a new software architecture for building flexible and configurable routers. A Click router is assembled from packet processing modules called elements. Individual elements implement simple router functions like packet classification, queueing, scheduling, and interfacing with network devices. A router configuration is a directed graph with elements at the vertices; packets flow along the edges of the graph. Configurations are written in a declarative language that supports user-defined abstractions. This language is both readable by humans and easily manipulated by tools. We present language tools that optimize router configurations and ensure they satisfy simple invariants. Due to Click’s architecture and language, Click router configurations are modular and easy to extend. A standards-compliant Click IP router has sixteen elements on its forwarding path. We present extensions to this router that support dropping policies, fairness among flows, quality-of-service, and
665|Parallel database systems: the future of high performance database systems|Abstract: Parallel database machine architectures have evolved from the use of exotic hardware to a software parallel dataflow architecture based on conventional shared-nothing hardware. These new designs provide impressive speedup and scaleup when processing relational database queries. This paper reviews the techniques used by such systems, and surveys current commercial and research systems. 1.
666|Complex queries in dht-based peer-to-peer networks|Recently a new generation of P2P systems, offering distributed hash table (DHT) functionality, have been proposed. These systems greatly improve the scalability and exact-match accuracy of P2P systems, but offer only the exact-match query facility. This paper outlines a research agenda for building complex query facilities on top of these DHT-based P2P systems. We describe the issues involved and outline our research plan and
667|Yfilter: Efficient and scalable filtering of XML documents|Soon, much of the data exchanged over the Internet will be encoded in XML, allowing for sophisticated filtering and content-based routing. We have built a filtering engine called YFilter, which filters streaming XML documents according to XQuery or XPath queries that involve both path expressions and predicates. Unlike previous work, YFilter uses a novel NFA-based execution model. In this demonstration, we present the structures and algorithms underlying YFilter, and show its efficiency and scalability under various workloads. 1
668|The SIFT Information Dissemination System|Information dissemination is a powerful mechanism for finding information in wide-area environments.  An information dissemination server accepts long-term user queries, collects new documents from information  sources, matches the documents against the queries, and continuously updates the users with  relevant information.  This paper is a retrospective of the Stanford Information Filtering Service (SIFT), a system that  as of April 1996 was processing over 40,000 worldwide subscriptions and over 80,000 daily documents.  The paper describes some of the indexing mechanisms that were developed for SIFT, as well as the  evaluations that were conducted to select a scheme to implement. It also describes the implementation  of SIFT, and experimental results for the actual system. Finally, it also discusses and experimentally  evaluates techniques for distributing a service such as SIFT for added performance and availability.  Note to Referees: This paper contains material from three earlier...
669|An Evaluation of Non-Equijoin Algorithms|A non-equijoin of relations R and S is a band join if the join predicate requires values in the join attribute of R to fall within a speci ed band about the values in the join attribute of S. We propose a new algorithm, termed a partitioned band join, for evaluating band joins. We present a comparison between the partitioned band join algorithm and the classical sort-merge join algorithm (optimized for band joins) using both an analytical model and an implementation on top of the WiSS storage system. The results show that the partitioned band join algorithm outperforms sortmerge unless memory is scarce and the operands of the join are of equal size. We also describe a parallel implementation of the partitioned band join on the Gamma database machine, and present data from speedup and scaleup experiments demonstrating that the partitioned band join is efficiently parallelizable. 
670|Incremental Computation and Maintenance of Temporal Aggregates|We consider the problems of computing aggregation queries in temporal databases, and of maintaining materialized temporal aggregate views efficiently. The latter problem is particularly challenging since a single data update can cause aggregate results to change over the entire time line. We introduce a new index structure called the SBtree, which incorporates features from both segment-trees and B-trees. SB-trees support fast lookup of aggregate results based on time, and can be maintained efficiently when the data changes. We also extend the basic SB-tree index to handle cumulative (also called moving-window) aggregates. For materialized aggregate views in a temporal database or warehouse, we propose building and maintaining SB-tree indices instead of the views themselves.  1. 
671|WSQ/DSQ: A Practical Approach for Combined Querying of Databases and the Web|We present WSQ/DSQ (pronounced &#034;wisk-disk&#034;), a new approach for combining the query facilities  of traditional databases with existing search engines on the Web. WSQ, for Web-Supported (Database)  Queries, leverages results from Web searches to enhance SQL queries over a relational database. DSQ,  for Database-Supported (Web) Queries, uses information stored in the database to enhance and explain  Web searches. This paper focuses primarily on WSQ, describing a simple, low-overhead way to support  WSQ in a relational DBMS, and demonstrating the utility of WSQ with a number of interesting  queries and results. The queries supported by WSQ are enabled by two virtual tables, whose tuples  represent Web search results generated dynamically during query execution. WSQ query execution may  involve many high-latency calls to one or more search engines, during which the query processor is  idle. We present a lightweight technique called asynchronous iteration that can be integrated easily into  a standard sequential query processor to enable concurrency between query processing and multiple  Web search requests. Asynchronous iteration has broader applications than WSQ alone, and it opens up  many interesting query optimization issues. We have developed a prototype implementation of WSQ by  extending a DBMS with virtual tables and asynchronous iteration; performance results are reported.  1 
672|Query Execution Techniques for Caching Expensive Methods|. Object-Relational and Object-Oriented DBMSs allow users to invoke time-consuming (&#034;expensive&#034;) methods in their queries. When queries containing these expensive methods are run on data with duplicate values, time is wasted redundantly computing methods on the same value. This problem has been studied in the context of programming languages, where &#034;memoization&#034; is the standard solution. In the database literature, sorting has been proposed to deal with this problem. We compare these approachesalong with a third solution, a variant of unary hybrid hashing which we call Hybrid Cache. We demonstrate that Hybrid Cache always dominates memoization, and significantly outperforms sorting in many instances. This provides new insights into the tradeoff between hashing and sorting for unary operations. Additionally, our Hybrid Cache algorithm includes some new optimizations for unary hybrid hashing, which can be used for other applications such as grouping and duplicate elimination. We conclude...
673|Optimization of Sequence Queries in Database Systems| The need to search for complex and recurring patterns in database sequences is shared by many applications. In this work, we discuss how to express and support efficiently sophisticated sequential pattern queries in relational database systems. Thus, we first
674|Temporal View Self-Maintenance|. View self-maintenance refers to maintaining materialized views without accessing base data. Self-maintenance is particularly useful in data warehousing settings, where base data comes from sources that may be inaccessible. Selfmaintenance has been studied for nontemporal views, but is even more important when a warehouse stores temporal views over the history of source data, since the source history needed to perform view maintenance may no longer exist. This paper tackles the self-maintenance problem for temporal views. We show how to derive auxiliary data to be stored at the warehouse so that the warehouse views and auxiliary data can be maintained without accessing the sources. The temporal view self-maintenance problem is considerably harder than the nontemporal case because a temporal view may need to be maintained not only when source data is modified but also as time advances, and these two dimensions of change interact in subtle ways. We also seek to minimize the amount of au...
675|Java Support for Data-Intensive Systems: Experiences Building the Telegraph Dataflow System|Database system designers have traditionally had trouble with the default services and interfaces provided by operating systems. In recent years, developers and enthusiasts have increasingly promoted Java as a serious platform for building data-intensive servers. Java provides a number of very helpful language features, as well as a full run-time environment reminiscent of a traditional operating system. This combination of features and community support raises the question of whether Java is better or worse at supporting dataintensive server software than a traditional operating system coupled with a weakly-typed language such as C or C++.  In this paper, we summarize and discuss our experience building the Telegraph dataow system in Java. We highlight some of the pleasures of coding with Java, and some of the pains of coding around Java in order to obtain good performance in a data-intensive server. For those issues that were painful, we present concrete suggestions for evolving Java&#039;s interfaces to better suit serious software systems development. We believe these experiences can provide insight for other designers to avoid pitfalls we encountered and to decide if Java is a suitable platform for their system.  1. 
676|Statistics on Data Streams|This is taken from [SZ04, Chap. 5]. It is the first of three applications they develop based on their review of timeseries techniques in the first four chapters. 1. Data streams are unending sequences of data arriving rapidly and needing to be processed. For example, quotations and transactions arriving every second for fifty thousand stocks would constitute a data stream of fifty thousand sequences. Or the Space Shuttle telemeters readings each second for twenty thousand sensors to Houston. The kind of analyses discussed in chapter 5 of [SZ04] include single-stream statistics such as average, standard deviation and best-fit slope, pairwise statistics such as correlation and “beta”, and lagged statistics such as autocorrelation for single streams or cross correlation for pairs of streams. We should start with a review. We write an arbitrary timeseries with capital letters, X or X1,X2,..,Xn. Often we normalize the timeseries so that its average is 0 and its standard deviation is the the square root of its length,  v n. We write a normalized series with small letters, x or x1,x2,..,xn. xi = Xi - avg(X) std(X) where and n? avg(X)  = Xi/n i=1 (std(X)) 2 n? = (Xi - avg(X)) i=1 2 /n The Pearson Correlation Coefficient between series X and Y is corr(X,Y) = avg(X. * Y)  - avg(X)avg(Y) std(X)std(Y)
677|Experiential Sampling on Multiple Data Streams |Abstract — Multimedia systems must deal with multiple data streams. Each data stream usually contains significant volume of redundant noisy data. In many real-time applications, it is essential to focus the computing resources on a relevant subset of data streams at any given time instant and use it to build the model of the environment. We formulate this problem as an experiential sampling problem and propose an approach to utilize computing resources efficiently on the most informative subset of data streams. In this paper, we generalize our experiential sampling framework to multiple data streams and provide an evaluation measure for this technique. We have successfully applied this framework to the problems of traffic monitoring, face detection and monologue detection.
678|On Sequential Monte Carlo Sampling Methods for Bayesian Filtering|In this article, we present an overview of methods for sequential simulation from posterior distributions. These methods are of particular interest in Bayesian filtering for discrete time dynamic models that are typically nonlinear and non-Gaussian. A general importance sampling framework is developed that unifies many of the methods which have been proposed over the last few decades in several different scientific disciplines. Novel extensions to the existing methods are also proposed. We show in particular how to incorporate local linearisation methods similar to those which have previously been employed in the determin-istic filtering literature; these lead to very effective importance distributions. Furthermore we describe a method which uses Rao-Blackwellisation in order to take advantage of the analytic structure present in some important classes of state-space models. In a final section we develop algorithms for prediction, smoothing and evaluation of the likelihood in dynamic models.
679|Towards a better understanding of context and context-awareness|Abstract. The use of context is important in interactive applications. It is particularly important for applications where the user’s context is changing rapidly, such as in both handheld and ubiquitous computing. In order to better understand how we can use context and facilitate the building of context-aware applications, we need to more fully understand what constitutes a contextaware application and what context is. Towards this goal, we have surveyed existing work in context-aware computing. In this paper, we provide an overview of the results of this survey and, in particular, definitions and categories of context and context-aware. We conclude with recommendations for how this better understanding of context inform a framework for the development of context-aware applications. 1
680|Information Foraging|Information foraging theory is an approach to understanding how strategies and technologies for information seeking, gathering, and consumption are adapted to the flux of information in the environment. The theory assumes that people, when possible, will modify their strategies or the structure of the environment to maximize their rate of gaining valuable information. The theory is developed by (a) adaptation (rational) analysis of information foraging problems and (b) a detailed process model (adaptive control of thought in information foraging [ACT-IF]). The adaptation analysis develops (a) information patch models, which deal with time allocation and information filtering and enrichment activities in environments in which information is encountered in clusters; (b) information scent models, which address the identification of information value from proximal cues; and (c) information diet models, which address decisions about the selection and pursuit of information items. ACT-IF is instantiated as a production system model of people interacting with complex information technology. Humans actively seek, gather, share, and consume information to a degree unapproached by other organisms. Ours might properly be characterized as a species of informavores (Dennett, 1991). Our adaptive success depends to a large extent on a vast and complex
681|A User Attention Model for Video Summarization|Automatic generation of video summarization is one of the key techniques in video management and browsing. In this paper, we present a generic framework of video summarization based on the modeling of viewer&#039;s attention. Without fully semantic understanding of video content, this framework takes advantage of computational attention models and eliminates the needs of complex heuristic rules in video summarization. A set of methods of audio-visual attention model features are proposed and presented. The experimental evaluations indicate that the computational attention based approach is an effective alternative to video semantic analysis for video summarization.
682|How not to be seen: The contribution of similarity and selective ignoring to sustained inattentional blindness|When people attend to objects or events in a visual display, they often fail to notice an additional, unexpected, but fully visible object or event in the same display. This phenomenon is now known as inat-tentional blindness. We present a new approach to the study of sus-tained inattentional blindness for dynamic events in order to explore the roles of similarity, distinctiveness, and attentional set in the de-tection of unexpected objects. In Experiment 1, we found that the similarity of an unexpected object to other objects in the display influences attentional capture: The more similar an unexpected object is to the attended items, and the greater its difference from the ignored items, the more likely it is that people will notice it. Experiment 2 explored whether this effect of similarity is driven by selective ignor-ing of irrelevant items or by selective focusing on attended items. The results of Experiment 3 suggest that the distinctiveness of the unex-pected object alone cannot entirely account for the similarity effects found in the first two experiments; when attending to black items or white items in a dynamic display, nearly 30 % of observers failed to notice a bright red cross move across the display, even though it had a unique color, luminance, shape, and motion trajectory and was visible for 5 s. Together, the results suggest that inattentional blind-ness for ongoing dynamic events depends both on the similarity of the unexpected object to the other objects in the display and on the ob-server’s attentional set. The belief that in order to see something one simply needs to direct one’s eyes toward it has received several empirical challenges over the past three decades (e.g., Mack &amp; Rock,
683|Attentional Selection for Object Recognition - a Gentle Way|Attentional selection of an object for recognition is often  modeled using all-or-nothing switching of neuronal connection pathways  from the attended region of the retinal input to the recognition units.
684|A goal oriented attention guidance model|Abstract. Previous experiments have shown that human attention is influenced by high level task demands. In this paper, we propose an architecture to estimate the task-relevance of attended locations in a scene. We maintain a task graph and compute relevance of fixations using an ontology that contains a description of real world entities and their relationships. Our model guides attention according to a topographic attention guidance map that encodes the bottom-up salience and task-relevance of all locations in the scene. We have demonstrated that our model detects entities that are salient and relevant to the task even on natural cluttered scenes and arbitrary tasks. 1
685|Wavelet Foveation|A foveated image is a non-uniform resolution image whose resolution is highest at a point (fovea) but falls o away from the fovea. It can be obtained from a uniform image through a space-variant smoothing process, where the width of the smoothing function is small near the fovea and gradually expanding as the distance from the fovea increases. We treat this process as an integral operator and analyze its kernel. This kernel is dominated by its diagonal in the wavelet bases and thus permits a fast algorithm for foveating images. In addition, the transformed kernel takes a simple form which can be easily computed using a look-up table. This is useful since in applications, the fovea changes rapidly. We describe an application of our approximation algorithm in image visualization over the Internet.
686|The Joy of Sampling|. A standard method for handling Bayesian models is to use Markov chain Monte Carlo methods to draw samples from the posterior. We demonstrate this method on two core problems in computer vision---structure from motion and colour constancy. These examples illustrate a samplers producing useful representations for very large problems. We demonstrate that the sampled representations are trustworthy, using consistency checks in the experimental design. The sampling solution to structure from motion is strictly better than the factorisation approach, because: it reports uncertainty on structure and position measurements in a direct way; it can identify tracking errors; and its estimates of covariance in marginal point position are reliable. Our colour constancy solution is strictly better than competing approaches, because: it reports uncertainty on surface colour and illuminant measurements in a direct way; it incorporates all available constraints on surface reflectance and on illumination in a direct way; and it integrates a spatial model of reflectance and illumination distribution with a rendering model in a natural way. One advantage of a sampled representation is that it can be resampled to take into account other information. We demonstrate the effect of knowing that, in our colour constancy example, a surface viewed in two different images is in fact the same object. We conclude with a general discussion of the strengths and weaknesses of the sampling paradigm as a tool for computer vision.  Keywords: Markov chain Monte Carlo, colour constancy, structure from motion  1. 
687|On an Optimization Problem in Sensor Selection|We address the following sensor selection problem. We assume that a dynamic system possesses a certain property, call it Property D, when a set G of sensors is used. There is a cost c A associated with each set A of sensors that is a subset of G. Given any set of sensors that is a subset of G, it is possible to determine, via a test, whether the resulting system-sensor combination possesses Property D. Each test required to check whether or not Property D holds incurs a ®xed cost. For each set of sensors A that is a subset of G there is an a priori probability p A that the test will be positive, i.e., the system-sensor combination possesses Property D. The objective is to determine a test strategy, i.e., a sequence of tests, to minimize the expected cost, associated with the tests, that is incurred until a least expensive combination of sensors that results in a system-sensor combination possessing Property D is identified. We determine conditions on the sensor costs c A and the a priori probabilities p A under which the strategy that tests combinations of sensors in increasing order of cost is optimal with respect to the aforementioned objective.
688|A Scalable Content-Addressable Network|Hash tables – which map “keys ” onto “values” – are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation. 
689|Pastry: Scalable, distributed object location and routing for large-scale peer-to-peer systems|This paper presents the design and evaluation of Pastry, a scalable, distributed object location and routing scheme for wide-area peer-to-peer applications. Pastry provides application-level routing and object location in a potentially very large overlay network of nodes connected via the Internet. It can be used to support a wide range of peer-to-peer applications like global data storage, global data sharing, and naming. An insert operation in Pastry stores an object at a user-defined number of diverse nodes within the Pastry network. A lookup operation reliably retrieves a copy of the requested object if one exists. Moreover, a lookup is usually routed to the node nearest the client issuing the lookup (by some measure of proximity), among the nodes storing the requested object. Pastry is completely decentralized, scalable, and self-configuring; it automatically adapts to the arrival, departure and failure of nodes. Experimental results obtained with a prototype implementation on a simulated network of 100,000 nodes confirm Pastry&#039;s scalability, its ability to self-configure and adapt to node failures, and its good network locality properties.
690|Tapestry: An infrastructure for fault-tolerant wide-area location and routing|In today’s chaotic network, data and services are mobile and replicated widely for availability, durability, and locality. Components within this infrastructure interact in rich and complex ways, greatly stressing traditional approaches to name service and routing. This paper explores an alternative to traditional approaches called Tapestry. Tapestry is an overlay location and routing infrastructure that provides location-independent routing of messages directly to the closest copy of an object or service using only point-to-point links and without centralized resources. The routing and directory information within this infrastructure is purely soft state and easily repaired. Tapestry is self-administering, faulttolerant, and resilient under load. This paper presents the architecture and algorithms of Tapestry and explores their advantages through a number of experiments. 1
691|Resilient Overlay Networks|A Resilient Overlay Network (RON) is an architecture that allows distributed Internet applications to detect and recover from path outages and periods of degraded performance within several seconds, improving over today’s wide-area routing protocols that take at least several minutes to recover. A RON is an application-layer overlay on top of the existing Internet routing substrate. The RON nodes monitor the functioning and quality of the Internet paths among themselves, and use this information to decide whether to route packets directly over the Internet or by way of other RON nodes, optimizing application-specific routing metrics. Results from two sets of measurements of a working RON deployed at sites scattered across the Internet demonstrate the benefits of our architecture. For instance, over a 64-hour sampling period in March 2001 across a twelve-node RON, there were 32 significant outages, each lasting over thirty minutes, over the 132 measured paths. RON’s routing mechanism was able to detect, recover, and route around all of them, in less than twenty seconds on average, showing that its methods for fault detection and recovery work well at discovering alternate paths in the Internet. Furthermore, RON was able to improve the loss rate, latency, or throughput perceived by data transfers; for example, about 5 % of the transfers doubled their TCP throughput and 5 % of our transfers saw their loss probability reduced by 0.05. We found that forwarding packets via at most one intermediate RON node is sufficient to overcome faults and improve performance in most cases. These improvements, particularly in the area of fault detection and recovery, demonstrate the benefits of moving some of the control over routing into the hands of end-systems. 
692|How to Model an Internetwork|Graphs are commonly used to model the structure of internetworks, for the study of problems ranging from routing to resource reservation. A variety of graph models are found in the literature, including regular topologies such as rings or stars, &#034;well-known&#034; topologies such as the original ARPAnet, and randomly generated topologies. Less common is any discussion of how closely these models correlate with real network topologies. We consider the problem of efficiently generating graph models that accurately reflect the topological properties of real internetworks. We compare properties of graphs generated using various methods with those of real internets. We also propose efficient methods for generating topologies with particular properties, including a Transit-Stub model that correlates well with Internet structure. Improved models for internetwork structure have the potential to impact the significance of simulation studies of internetworking solutions, providing basis for the validi...
693|SCRIBE: The design of a large-scale event notification infrastructure|This paper presents Scribe, a large-scale event notification infrastructure  for topic-based publish-subscribe applications. Scribe supports large numbers  of topics, with a potentially large number of subscribers per topic. Scribe is  built on top of Pastry, a generic peer-to-peer object location and routing substrate  overlayed on the Internet, and leverages Pastry&#039;s reliability, self-organization and  locality properties. Pastry is used to create a topic (group) and to build an efficient  multicast tree for the dissemination of events to the topic&#039;s subscribers  (members). Scribe provides weak reliability guarantees, but we outline how an  application can extend Scribe to provide stronger ones.
695|ALMI: An Application Level Multicast Infrastructure|The IP multicast model allows scalable and efficient multi-party communication, particularly for groups of large size. However, deployment of IP multicast requires substantial infrastructure modifications and is hampered by a host of unresolved open problems. To circumvent this situation, we have designed and implemented ALMI, an application level group communication middleware, which allows accelerated application deployment and simplified network configuration, without the need of network infrastructure support. ALMI is tailored toward support of multicast groups of relatively small size (several I Os of members) with many to many semantics. Session participants are connected via a vir- tual multicast tree, which consists of unicast connections between end hosts and is formed as a minimum spanning tree (MST) using application-specific performance metric. Using simulation, we show that the performance penalties, introduced by this shift of multicast to end systems, is a relatively small increase in traffic load and that ALMI multicast trees approach the efficiency of IP multicast trees. We have also implemented ALMi as a Java based middleware package and performed experiments over the Internet. Experimental results show that ALMI is able to cope with network dynamics and keep the mul- ticast tree efficient.
696|Host Multicast: A Framework for Delivering Multicast To End Users|While the advantages of multicast delivery over multiple unicast deliveries is undeniable, the deployment of the IP multicast protocol has been limited to &#034;islands&#034; of network domains under single administrative control. Deployment of inter-domain multicast delivery has been slow due to both technical and administrative reasons. In this paper we propose a Host Multicast Tree Protocol (HMTP) that (1) automates the interconnection of IP-multicast enabled islands and (2) provides multicast delivery to end hosts where IP multicast is not available. With HMTP, end-hosts and proxy gateways of IP multicast-enabled islands can dynamically create shared multicast trees across different islands. Members of an HMTP multicast group self-organize into an efficient, scalable and robust multicast tree. The tree structure is adjusted periodically to accommodate changes in group membership and network topology. Simulation results show that the multicast tree has low cost, and data delivered over it experiences moderately low latency. I. 
697|Detour: a Case for Informed Internet Routing and Transport|Despite its obvious success, robustness, and scalability, the Internet suffers from a number of end-to-end performance and availability problems. In this paper, we attempt to quantify the Internet&#039;s inefficiencies and then we argue that Internet behavior can be improved by spreading intelligent routers at key access and interchange points to actively manage traffic. Our Detour prototype aims to demonstrate practical benefits to end users, without penalizing non-Detour users, by aggregating traffic information across connections and using more efficient routes to improve Internet performance. 1 Introduction  By any metric, the Internet has scaled remarkably; from 4 nodes in 1969 to an estimated 25 million hosts and 100 million users today. This reflects a sustained growth rate over three decades of roughly 80% per year, all while providing nearly continuous service. As a system, the Internet&#039;s growth has been matched only by the major infrastructure projects of the early 1900&#039;s: the ele...
698|Scalable Secure Group Communication over IP Multicast|We introduce and analyze a scalable re-keying scheme for implementing secure group communications IP multicast. We show that our scheme incurs constant processing, message, and storage overhead for a re-key operation when a single member joins or leaves the group, and logarithmic overhead for bulk simultaneous changes to the group membership. These bounds hold even when group dynamics are not known a-priori.
699|Correlation Clustering in Data Streams |In this paper, we address the problem of cor-relation clustering in the dynamic data stream model. The stream consists of updates to the edge weights of a graph on n nodes and the goal is to find a node-partition such that the end-points of negative-weight edges are typically in different clusters whereas the end-points of positive-weight edges are typically in the same cluster. We present polynomial-time, O(n ·polylog n)-space approxi-mation algorithms for natural problems that arise. We first develop data structures based on linear sketches that allow the “quality ” of a given node-partition to be measured. We then combine these data structures with convex programming and sampling techniques to solve the relevant approx-imation problem. However the standard LP and SDP formulations are not obviously solvable in O(n ·polylog n)-space. Our work presents space-efficient algorithms for the convex programming required, as well as approaches to reduce the adap-tivity of the sampling. Note that the improved space and running-time bounds achieved from streaming algorithms are also useful for offline settings such as MapReduce models.
700|Correlation Clustering|We consider the following clustering problem: we have a complete graph on # vertices (items), where each edge ### ## is labeled either # or    depending on whether # and # have been deemed to be similar or different. The goal is to produce a partition of the vertices (a clustering) that agrees as much as possible with the edge labels. That is, we want a clustering that maximizes the number of # edges within clusters, plus the number of    edges between clusters (equivalently, minimizes the number of disagreements: the number of    edges inside clusters plus the number of # edges between clusters). This formulation is motivated from a document clustering problem in which one has a pairwise similarity function # learned from past data, and the goal is to partition the current set of documents in a way that correlates with # as much as possible; it can also be viewed as a kind of &#034;agnostic learning&#034; problem. An interesting
701|Approximate Max-Flow Min-(multi)cut Theorems and Their Applications  (1993) |Consider the multicommodity flow problem in which the object is to maximize the sum of commodities routed. We prove the following approximate max-flow min-multicut theorem: min multicut  O(logk)   max flow  min multicut; where k is the number of commodities. Our proof is constructive; it enables us to find a multicut within O(log k) of the max flow (and hence also the optimal multicut). In addition, the proof technique provides a unified framework in which one can also analyse the case of flows with specified demands, of Leighton-Rao and Klein et.al., and thereby obtain an improved bound for the latter problem. 1 Introduction  Much of flow theory, and the theory of cuts in graphs, is built around a single theorem - the celebrated max-flow min-cut theorem of Ford and Fulkerson [FF], and Elias, Feinstein and Shannon [EFS]. The power of this theorem lies in that it relates two fundamental graph-theoretic entities via the potent mechanism of a min-max relation. The importance of this theor...
702|The multiplicative weights update method: a meta algorithm and applications|Algorithms in varied fields use the idea of maintaining a distribution over a certain set and use the multiplicative update rule to iteratively change these weights. Their analysis are usually very similar and rely on an exponential potential function. We present a simple meta algorithm that unifies these disparate algorithms and drives them as simple instantiations of the meta algorithm. 1
703|Clustering with qualitative information|We consider the problem of clustering a collection of el-ements based on pairwise judgments of similarity and dis-similarity. Bansal, Blum and Chawla [1] cast the problem thus: given a graph G whose edges are labeled “+ ” (sim-ilar) or “- ” (dissimilar), partition the vertices into clus-ters so that the number of pairs correctly (resp. incorrectly) classified with respect to the input labeling is maximized (resp. minimized). Complete graphs, where the classifier la-bels every edge, and general graphs, where some edges are not labeled, are both worth studying. We answer several questions left open in [1] and provide a sound overview of clustering with qualitative information. We give a factor 4 approximation for minimization on complete graphs, and a factor O(log n) approximation for general graphs. For the maximization version, a PTAS for complete graphs is shown in [1]; we give a factor 0.7664 approximation for general graphs, noting that a PTAS is unlikely by proving APX-hardness. We also prove the APX-hardness of minimization on complete graphs. 1.
704|Correlation clustering: Maximizing agreements via semidefinite programming|Abstract We consider the Correlation Clustering problem introducedin [2]. Given a graph G = (V, E) where each edge is labeled
705|Graph sketches: sparsification, spanners, and subgraphs|When processing massive data sets, a core task is to construct synopses of the data. To be useful, a synopsis data structure should be easy to construct while also yielding good approximations of the relevant properties of the data set. A particularly useful class of synopses are sketches, i.e., those based on linear projections of the data. These are applicable in many models including various parallel, stream, and compressed sensing settings. A rich body of analytic and empirical work exists for sketching numerical data such as the frequencies of a set of entities. Our work investigates graph sketching where the graphs of interest encode the relationships between these entities. The main challenge is to capture this richer structure and build the necessary synopses with only linear measurements. In this paper we consider properties of graphs including the size of the cuts, the distances between nodes, and the prevalence of
706|Correlation clustering with a fixed number of clusters |Abstract: We continue the investigation of problems concerning correlation clustering or clustering with qualitative information, which is a clustering formulation that has been studied recently (Bansal, Blum, Chawla (2004), Charikar, Guruswami, Wirth (FOCS’03), Charikar, Wirth (FOCS’04), Alon et al. (STOC’05)). In this problem, we are given a complete graph on n nodes (which correspond to nodes to be clustered) whose edges are labeled + (for similar pairs of items) and - (for dissimilar pairs of items). Thus our input consists of only qualitative information on similarity and no quantitative distance measure between items. The quality of a clustering is measured in terms of its number of agreements, which is simply the number of edges it correctly classifies, that is the sum of number of - edges whose endpoints it places in different clusters plus the number of + edges both of whose endpoints it places within the same cluster. In this paper, we study the problem of finding clusterings that maximize the number of agreements, and the complementary minimization version where we seek clusterings that minimize the number of disagreements. We focus on the situation when the number of clusters is stipulated to be a small constant k. Our main result is that for every k, there is a polynomial time approximation scheme for both maximizing agreements and minimizing disagreements.
707|On the exact space complexity of sketching and streaming small norms|We settle the 1-pass space complexity of (1 ± e)approximating the Lp norm, for real p with 1 = p = 2, of a length-n vector updated in a length-m stream with updates to its coordinates. We assume the updates are integers in the range [-M, M]. In particular, we show the space required is T(e -2 log(mM) + log log(n)) bits. Our result also holds for 0 &lt; p &lt; 1; although Lp is not a norm in this case, it remains a well-defined function. Our upper bound improves upon previous algorithms of [Indyk, JACM ’06] and [Li, SODA ’08]. This improvement comes from showing an improved derandomization of the Lp sketch of Indyk by using k-wise independence for small k, as opposed to using the heavy hammer of a generic pseudorandom generator against space-bounded computation such as Nisan’s PRG. Our lower bound improves upon previous work of [Alon-Matias-Szegedy, JCSS ’99] and [Woodruff, SODA ’04], and is based on showing a direct sum property for the 1-way communication of the gap-Hamming problem. 1
708|Streaming k-means approximation |We provide a clustering algorithm that approximately optimizes the k-means objective, in the one-pass streaming setting. We make no assumptions about the data, and our algorithm is very light-weight in terms of memory, and computation. This setting is applicable to unsupervised learning on massive data sets, or resource-constrained devices. The two main ingredients of our theoretical work are: a derivation of an extremely simple pseudo-approximation batch algorithm for k-means (based on the recent k-means++), in which the algorithm is allowed to output more than k centers, and a streaming clustering algorithm in which batch clustering algorithms are performed on small inputs (fitting in memory) and combined in a hierarchical manner. Empirical evaluations on real and simulated data reveal the practical utility of our method. 1
709|Declaring Independence via the Sketching of Sketches |We consider the problem of identifying correlations in data streams. Surprisingly, our work seems to be the first to consider this natural problem. In the centralized model, we consider a stream of pairs (i, j)â??[n] 2 whose frequencies define a joint distribution (X, Y). In the distributed model, each coordinate of the pair may appear separately in the stream. We present a range of algorithms for approximating to what extent X and Y are independent, i.e., how close the joint distribution is to the product of the marginals. We consider various measures of closeness including â??1, â??2, and the mutual information between X and Y. Our algorithms are based on â??sketching sketchesâ?, i.e., composing smallspace linear synopses of the distributions. Perhaps ironically, the biggest technical challenges that arise relate to ensuring that different components of our estimates are sufficiently independent.  
710|Linear Programming in the Semi-streaming Model with Application to the Maximum Matching Problem|In this paper we study linear-programming based approaches to the maximum matching problem in the semi-streaming model. In this model edges are presented sequentially, possibly in an adversarial order, and we are only allowed to use a small space. The allowed space is near linear in the number of vertices (and sublinear in the number of edges) of the input graph. The semi-streaming model is relevant in the context of processing of very large graphs. In recent years, there have been several new and exciting results in the semi-streaming model. However broad techniques such as linear programming have not been adapted to this model. In this paper we present several techniques to adapt and optimize linear-programming based approaches in the semi-streaming model. We use the maximum matching problem as a foil to demonstrate the e ectiveness of adapting such tools in this model. As a consequence we improve almost all previous results on the semi-streaming maximum matching problem. We also prove new results on interesting variants. 
711|AMS without 4-wise independence on product domains|In their fundamental work, Alon, Matias and Szegedy [3] presented celebrated sketching techniques and showed that 4-wise independence is sufficient to obtain good approximations. The question of what random functions are necessary is fundamental for streaming algorithms (see, e.g., Cormode and Muthukrishnan [9].) We present a somewhat surprising fact: on product domain [n] k, the 4-wise independence can be omitted at least for the L2 norm. That is, we prove that the sketch of Alon, Matias and Szegedy [3] works even if the 4-wise independent functions on [n] k are replaced by the product of 4-wise independent functions on [n]. The main technical contribution of our paper is a novel combinatorial approach to analyzing the second moment (i.e., variance) of dependent sketches. By using our technique, we obtain a new result for the problem of measuring independence of datasets under the L2 norm. Measuring independence and k-wise independence is a fundamental problem that has multiple applications, and it has been the subject of intensive research during the last decade (see, among others, the recent work of Batu, Fortnow, Fischer, Kumar, Rubinfeld and White [4] and of Alon, Andoni, Kaufman, Matulef, Rubinfeld and Xie [1]). In the streaming environment, this problem was first addressed by Indyk and McGregor [15]. In this model the joint distribution is given empirically
712|Fast SDP Algorithms for Constraint Satisfaction Problems  |The class of constraint satisfactions problems (CSPs) captures many fundamental combinatorial optimization problems such as Max Cut, Max q-Cut, Unique Games, and Max k-Sat. Recently, Raghavendra (STOC‘08) identified a simple semidefinite programming relaxation that gives the best possible approximation for any CSP, assuming the Unique Games Conjecture. Raghavendra and Steurer (FOCS‘09) showed that, independent of the truth of the Unique Games Conjecture, the integrality gap of this relaxation cannot be improved even by adding a large class of valid inequalities. We present an algorithm that finds an approximately optimal solution to this relaxation in near-linear time. Combining this algorithm with a rounding scheme of Raghavendra and Steurer (FOCS‘09) leads to an approximation algorithm for any CSP that runs in near-linear time and has an approximation guarantee that matches the integrality gap, which is optimal assuming the Unique Games Conjecture. 
713|Streaming Algorithms for k-Center Clustering with Outliers and with Anonymity |Abstract. Clustering is a common problem in the analysis of large data sets. Streaming algorithms, which make a single pass over the data set using small working memory and produce a clustering comparable in cost to the optimal offline solution, are especially useful. We develop the first streaming algorithms achieving a constant-factor approximation to the cluster radius for two variations of the k-center clustering problem. We give a streaming (4+?)-approximation algorithm using O(? -1 kz) memory for the problem with outliers, in which the clustering is allowed to drop up to z of the input points; previous work used a random sampling approach which yields only a bicriteria approximation. We also give a streaming (6 + ?)-approximation algorithm using O(? -1 ln(? -1)k + k 2) memory for a variation motivated by anonymity considerations in which each cluster must contain at least a certain number of input points.
714|Bounding and comparing methods for correlation clustering beyond ILP|We evaluate several heuristic solvers for correlation clustering, the NP-hard problem of partitioning a dataset given pairwise affinities between all points. We experiment on two practical tasks, document clustering and chat disentanglement, to which ILP does not scale. On these datasets, we show that the clustering objective often, but not always, correlates with external metrics, and that local search always improves over greedy solutions. We use semi-definite programming (SDP) to provide a tighter bound, showing that simple algorithms are already close to optimality. 1
715|Tight results for clustering and summarizing data streams|This paper is posted at ScholarlyCommons.
716|DSS: Data Stream Scan |Abstract — dss (data stream scan) is a framework for describing, transforming, reading, querying, and writing streams of record oriented data. dss is implemented as a command and library API and used extensively to aid network measurements in our organization. The API is extended by DLLs (shared libraries) that define data domain specific I/O, type and query functions. We provide a best-in-class repository for data scanning, along with up-to-date documentation as a side effect of coding to the API. Many large scale network applications have used dss significantly reducing the time spent in coding and in querying data. The reasons for the success of dss are its lightweight and extensible architecture, generic usage template, scope of supported data domains, scalability, and speed. dss compares extremely favorably against perl, the typical recourse in the networking community, and against customized C/C++ code written to deal with specific data sets. dss has been successfully applied over three years over a wide range of applications, including large volumes of NETFLOW data, BGP ta-bles,HTTP proxy and server logs, ¢¡¤£¦¥
717|Sketch-based Change Detection: Methods, Evaluation, and Applications|Traffic anomalies such as failures and attacks are commonplace in today&#039;s network, and identifying them rapidly and accurately is critical for large network operators. The detection typically treats the traffic as a collection of flows that need to be examined for significant changes in traffic pattern (e.g., volume, number of connections) . However, as link speeds and the number of flows increase, keeping per-flow state is either too expensive or too slow. We propose building compact summaries of the traffic data using the notion of sketches. We have designed a variant of the sketch data structure, k-ary sketch, which uses a constant, small amount of memory, and has constant per-record update and reconstruction cost. Its linearity property enables us to summarize traffic at various levels. We then implement a variety of time series forecast models (ARIMA, Holt-Winters, etc.) on top of such summaries and detect significant changes by looking for flows with large forecast errors. We also present heuristics for automatically configuring the model parameters. Using a 
718|Flowscan: A network traffic flow reporting and visualization tool|Permission is granted for noncommercial reproduction of the work for educational or research purposes.
719|A Model of BGP Routing for Network Engineering|The performance of IP networks depends on a wide variety of dynamic conditions. Traffic shifts, equipment failures, planned maintenance, and topology changes in other parts of the Internet can all degrade performance. To maintain good performance, network operators must continually reconfigure the routing protocols. Operators configure BGP to control how traffic flows to neighboring Autonomous Systems (ASes), as well as how traffic traverses their networks. However, because BGP route selection is distributed, indirectly controlled by configurable policies, and influenced by complex interactions with intradomain routing protocols, operators cannot predict how a particular BGP configuration would behave in practice. To avoid inadvertently degrading network performance, operators need to evaluate the effects of configuration changes before deploying them on a live network. We propose an algorithm that computes the outcome of the BGP route selection process for each router in a single AS, given only a static snapshot of the network state, without simulating the complex details of BGP message passing. We describe a BGP emulator based on this algorithm; the emulator exploits the unique characteristics of routing data to reduce computational overhead. Using data from a large ISP, we show that the emulator correctly computes BGP routing decisions and has a running time that is acceptable for many tasks, such as traffic engineering and capacity planning.
720|Experience in black-box OSPF measurement|All in-text	references	underlined	in	blue	are	linked	to	publications	on	ResearchGate, letting you	access	and	read	them	immediately.
721|Engineering the Compression of Massive Tables: An Experimental Approach|We study the problem of compressing massive tables. We devise a novel compression paradigm---training for lossless compression--- which assumes that the data exhibit dependencies that can be learned by examining a small amount of training material. We develop an experimental methodology to test the approach. Our result is a system, pzip, which outperforms gzip by factors of two in compression size and both compression and uncompression time for various tabular data. Pzip is now in production use in an AT&amp;T network traffic data warehouse.
722|Engineering a differencing and compression data format|Conference
723|SFIO: Safe/Fast String/File IO|This paper describes Sfio, a new input/output library, that can be used as a replacement for  Stdio, the C language standard I/O library. Sfio is more complete, consistent, and efficient than Stdio. New facilities are provided for convenient, safe and efficient manipulation of data streams. An Sfio stream may be entirely memory resident or it may correspond to some actual file. Alternative I/O disciplines can be applied to a stream to customize its behavior with respect to data transformation and exception handling. Stream pools can be maintained to guarantee stream synchronization when switching streams for I/O operations. Separate streams can be stacked on one another to make new virtual streams. Both source and binary compatibility packages are provided allowing Stdio-based programs to benefit from the new library without recoding. Sfio has been used successfully in a number of applications including many rewritten standard system utilities. Benchmark timings show that Sfio  perform...
724|The Discipline and Method Architecture for Reusable Libraries|resource functions  Discipline Methods  Resource definition Algorithms  Resource acquisition Management styles  Event handling Special modes  Figure 1: The discipline and method architecture  Figure 1 summarizes the discipline and method library architecture. Four main interface constructs are used to manage resources:  ffl Handle: A handle holds resources and states that need to be maintained across operations.  ffl Operations: Library operations create/delete handles and access handle resources.  ffl Discipline: A discipline type publically and uniformly defines certain resource requirements.  ffl Methods: Methods encapsulate different operational or performance characteristics.  The top two parts of Figure 1 constitute the familiar handle and operations architecture of many traditional libraries such as the ANSI-C Stdio library  [1]  and the STL template libraries.  [4]  This architecture is simple and easy for both library writers and application developers to learn and use. Howeve...
725|Bigtable: A distributed storage system for structured data|Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable.  
726|MapReduce: Simplified Data Processing on Large Clusters|MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper. Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system. Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google’s clusters every day.  
727|Space/Time Trade-offs in Hash Coding with Allowable Errors|this paper trade-offs among certain computational factors in hash coding are analyzed. The paradigm problem considered is that of testing a series of messages one-by-one for membership in a given set of messages. Two new hash- coding methods are examined and compared with a particular conventional hash-coding method. The computational factors considered are the size of the hash area (space), the time required to identify a message as a nonmember of the given set (reject time), and an allowable error frequency
728|The Google File System |We have designed and implemented the Google File Sys-tem, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous dis-tributed file systems, our design has been driven by obser-vations of our application workloads and technological envi-ronment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore rad-ically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our ser-vice as well as research and development efforts that require large data sets. The largest cluster to date provides hun-dreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use. Categories and Subject Descriptors D [4]: 3—Distributed file systems
729|The ubiquitous B-tree|B-trees have become, de facto, a standard for file organization. File indexes of users, dedicated database systems, and general-purpose access methods have all been proposed and nnplemented using B-trees This paper reviews B-trees and shows why they have been so successful It discusses the major variations of the B-tree, especially the B+-tree,
730|Resource Containers: A New Facility for Resource Management in Server Systems|General-purpose operating systems provide inadequate support for resource management in large-scale servers. Applications lack sufficient control over scheduling and management of machine resources, which makes it difficult to enforce priority policies, and to provide robust and controlled service. There is a fundamental mismatch between the original design assumptions underlying the resource management mechanisms of current general-purpose operating systems, and the behavior of modern server applications. In particular, the operating system’s notions of protection domain and resource principal coincide in the process abstraction. This coincidence prevents a process that manages large numbers of network connections, for example, from properly allocating system resources among those connections. We propose and evaluate a new operating system abstraction called a resource container, which separates the notion of a protection domain from that of a resource principal. Resource containers enable fine-grained resource management in server systems and allow the development of robust servers, with simple and firm control over priority policies. 1
731|Operating System Support for Planetary-Scale Network Services|PlanetLab is a geographically distributed overlay network designed to support the deployment and evaluation of planetary-scale network services. Two high-level goals shape its design. First, to enable a large research community to share the infrastructure, PlanetLab provides distributed virtualization, whereby each service runs in an isolated slice of PlanetLab’s global resources. Second, to support competition among multiple network services, PlanetLab decouples the operating system running on each node from the networkwide services that define PlanetLab, a principle referred to as unbundled management. This paper describes how Planet-Lab realizes the goals of distributed virtualization and unbundled management, with a focus on the OS running on each node. 1
732|Paxos made live: an engineering perspective|We describe our experience building a fault-tolerant data-base using the Paxos consensus algorithm. Despite the existing literature in the field, building such a database proved to be non-trivial. We describe selected algorithmic and engineering problems encountered, and the solutions we found for them. Our measurements indicate that we have built a competitive system. 1
733|Integrating compression and execution in column-oriented database systems|Column-oriented database system architectures invite a reevaluation of how and when data in databases is compressed. Storing data in a column-oriented fashion greatly increases the similarity of adjacent records on disk and thus opportunities for compression. The ability to compress many adjacent tuples at once lowers the per-tuple cost of compression, both in terms of CPU and space overheads. In this paper, we discuss how we extended C-Store (a column-oriented DBMS) with a compression sub-system. We show how compression schemes not traditionally used in roworiented DBMSs can be applied to column-oriented systems. We then evaluate a set of compression schemes and show that the best scheme depends not only on the properties of the data but also on the nature of the query workload.
734|Weaving Relations for Cache Performance|Relational database systems have traditionally optimzed for I/O performance and organized records sequentially on disk pages using the N-ary Storage Model (NSM) (a.k.a., slotted pages). Recent research, however, indicates that cache utilization and performance is becoming increasingly important on modern platforms. In this paper, we first demonstrate that in-page data placement is the key to high cache performance and that NSM exhibits low cache utilization on modern platforms. Next, we propose a new data organization model called PAX (Partition Attributes Across), that significantly improves cache performance by grouping together all values of each attribute within each page. Because PAX only affects layout inside the pages, it incurs no storage penalty and does not affect I/O behavior. According to our experimental results, when compared to NSM (a) PAX exhibits superior cache and memory bandwidth utilization, saving at least 75% of NSM&#039;s stall time due to data cache accesses, (b) range selection queries and updates on memoryresident relations execute 17-25% faster, and (c) TPC-H queries involving I/O execute 11-48% faster.
735|Data Placement in Bubba|Thus paper examines the problem of data placement in Bubba, a highly-parallel system for data-intensive applications bemg developed at MCC “Highly-parallel” lmplres that load balancmng IS a cntlcal performance issue “Data-mtenave” means data IS so large that operatrons should be executed where the data resides As a result, data placement becomes a cntlcal performance issue In general, determmmg the optimal placement of data across processmg nodes for performance IS a difficult problem We describe our heuristic approach to solvmg the data placement problem w Bubba We then present expenmental results using a specific workload to provide msrght into the problem Several researchers have argued the benefits of deelustering (1 e, spreading each base relation over many nodes) We show that as declustermg IS increased. load balancing contmues to improve However, for transactions mvolvmg complex Joins, further declusterrng reduces throughput because of communications, startup and termmatron overhead We argue that data placement, especially declustermg, m a highly-parallel system must be considered early in the design, so that mechanrsms can be included for supportmg variable declustermg, for mmtmlzmg the most significant overheads associated with large-scale declustenng, and for gathering the required statistics.
736|DB2 Parallel Edition|The rate of increase in database size and response time requirements has outpaced  advancements in processor and mass storage technology. One way to satisfy the increasing  demand for processing power and I/O bandwidth in database applications is to have a  number of processors, loosely or tightly coupled, serving database requests concurrently.  Technologies developed during the last decade have made commercial parallel database  systems a reality and these systems have made an inroad into the stronghold of traditionally  mainframe based large database applications. This paper describes the parallel database  project initiated at IBM Research at Hawthorne and the DB2/AIX-PE product based on  it.  1 Introduction  Large scale parallel processing technology has made giant strides in the past decade and there is no doubt that it has established a place for itself. However, almost all of the applications harnessing this technology are scientific or engineering applications. The lack of com...
737|From data mining to knowledge discovery in databases|¦ Data mining and knowledge discovery in databases have been attracting a significant amount of research, industry, and media attention of late. What is all the excitement about? This article provides an overview of this emerging field, clarifying how data mining and knowledge discovery in databases are related both to each other and to related fields, such as machine learning, statistics, and databases. The article mentions particular real-world applications, specific data-mining techniques, challenges involved in real-world applications of knowledge discovery, and current and future research directions in the field. Across a wide variety of fields, data are
738|The Merge/Purge Problem for Large Databases|Many commercial organizations routinely gather large numbers of databases for various marketing and business analysis functions. The task is to correlate information from different databases by identifying distinct individuals that appear in a number of different databases typically in an inconsistent and often incorrect fashion. The problem we study here is the task of merging data from multiple sources in as efficient manner as possible, while maximizing the accuracy of the result. We call this the merge/purge problem. In this paper we detail the sorted neighborhood method that is used by some to solve merge/purge and present experimental results that demonstrates this approach may work well in practice but at great expense. An alternative method based upon clustering is also presented with a comparative evaluation to the sorted neighborhood method. We show a means of improving the accuracy of the results based upon a multi-pass approach that succeeds by computing the Transitive Clos...
739|Unexpectedness as a Measure of Interestingness in Knowledge Discovery|Organizations are taking advantage of &#034;data-mining&#034; techniques to leverage the vast amounts of data captured as they process routine transactions. Data-mining is the process of discovering hidden structure or patterns in data. However several of the pattern discovery methods in datamining systems have the drawbacks that they discover too many obvious or irrelevant patterns and that they do not leverage to a full extent valuable prior domain knowledge that managers have. This research addresses these drawbacks by developing ways to generate interesting patterns by incorporating managers&#039; prior knowledge in the process of searching for patterns in data. Specifically we focus on providing methods that generate unexpected patterns with respect to managerial intuition by eliciting managers&#039; beliefs about the domain and using these beliefs to seed the search for unexpected patterns in data. Our approach should lead to the development of decision support systems that provide managers with mor...
740|The interestingness of deviations|gps~gte.com, matheus~gte.com One of the moet promising areas in Knowledge Discovery in Databases is the automatic analysis of changes and deviations. Several systems have recently been developed for this task. Suc ~ of these systems hinges on their ability to identify s few important and relevant deviations among the multitude of potentially interesting events:  ~ In this paper we argue that related deviations should be grouped togetherin a finding and that the interestingness of a finding is the estimated benefit from a poesible ~tion connected to it. We discuss methods for determining the estimated benefit from the impact of the deviations and the success probability of an action. Our analysis is done in the context of the Key Findings Reporter (KEFIIt), a system for discovering and explaining ~key findings &#034; in large relational databases, currently being applied to the analysis of healthcare information.
741|The World Wide Web: quagmire or gold mine?|This article considers the question: is effective Web mining possible?
742|Discovering Informative Patterns and Data Cleaning|We present a method for discovering informative patterns from data. With this method, large databases can be reduced to only a few representative data entries. Our framework also encompasses methods for cleaning databases containing corrupted data. Both on-line and off-line algorithms are proposed and experimentally checked on databases of handwritten images. The generality of the framework makes it an attractive candidate for new applications in knowledge discovery.  Keywords: knowledge discovery, machine learning, informative patterns, data cleaning, information gain.  4.1 
743|Selecting Among Rules Induced from a Hurricane Database|can achieve orders of magnitude reduction in the volume of data For example, we applied a commercial tool (IXLtin) to a 1,819 record tropical storm database, yielding 161 rules. However, the human comprehension goals of Knowledge Discovery in Databases may require still more orders of magnitude. We present a rule refinement strategy, partly implemented in a Prolog program, that operationalizes &#034;interestingness &#034; into performance, simplicity, novelty, and significance. Applying the strategy to the induced rulebase yielded 10 &#034;genuinely interesting &#034; rules. I. PURPOSE OF THE STUDY At The Travelers Insurance Company, we are involved in applying statistics and artificial intelligence techniques to the solution of business problems. This work is part of an investigation into applications for Natural Hazards Research Services. The purpose of this study is not to deyelop a hurricane model or predictor. It is, rather, to assess the utility of rule induction technology and our particular rule refinement strategy. The object task of the study is to develop rules that
744|KDD for Science Data Analysis: Issues and Examples|Tile analysis of tile massive data sets collected by scientific instruments demands automation as a pre-requisite to analysis. There is an urgent need to cre-ate an intermediate level at which scientists can oper-ate effectively; isolating them from the massive sizes and harnessing human analysis capabilities to focus on tasks in which machines do not even renmtely ap-proach humans--namely, creative data analysis, the-ory and hypothesis formation, and drawing insights into underlying phe,mmena. We give an overview of the main issues in the exploitation of scientific data.sets, present five c,~se studies where KDD tools play important and enabling roles, and conclude with fi,ture challenges for data mining and KDD techniques in science data analysis. 1
745|Fast Spatio-Temporal Data Mining of Large Geophysical Datasets|The important scientific challenge of understanding global climate change is one that clearly requires the application of knowledge discovery and datamining techniques on a massive scale. Advances in parallel supercomputing technology, enabling high-resolution modeling, as well as in sensor technology, allowing data capture on an unprecedented scale, conspire to overwhelm present-day analysis approaches. We present here early experiences with a prototype exploratory data analysis environment, CONQUEST, designed to provide content-based access to such massive scientific datasets. CONQUEST (CONtent-based Querying in Space and Time) employs a combination of workstations and massively parallel processors (MPP&#039;s) to mine geophysical datasets possessing a prominent temporal component. It is designed to enable complex multi-modal interactive querying and knowledge discovery, while simultaneously coping with the extraordinary computational demands posed by the scope of the datasets involved. A...
746|Predicting Equity Returns from Securities Data|Our experiments with capital markets data suggest that the domain can be effectively modeled by classification rules induced from available historical data for the purpose of making gainful predictions for equityinvestments. New classification techniques developed at IBM Research, including minimal rule generation (R-MINI) and contextual feature analysis, seem robust enough for consistently extracting useful information from noisy domains such as financial markets. We will briefly introduce the rationale for our minimal rule generation technique, and the motivation for the use of contextual information in analyzing features. We will then describe our experience from several experiments with the S&amp;P 500 data, illustrating the general methodology, and the results of correlations and simulated managed investment based on classification rules generated by R-MINI. Wewillsketchhow the rules for classifications can be effectively used for numerical prediction, and eventually to an investment ...
747|Graphical Models for Discovering Knowledge|There are many different ways of representing knowledge, and for each of these ways there are many different discovery algorithms. How can we compare different representations? How can we mix, match and merge representations and algorithms on new problems with their own unique requirements? This chapter introduces probabilistic modeling as a philosophy for addressing these questions and presents graphical models for representing probabilistic models. Probabilistic graphical models are a unified qualitative and quantitative framework for representing and reasoning with probabilities and independencies. 4.1 Introduction Perhaps one common element of the discovery systems described in this and previous books on knowledge discovery is that they are all different. Since the class of discovery problems is a challenging one, we cannot write a single program to address all of knowledge discovery. The KEFIR discovery system applied to health care by Matheus, Piatetsky-Shapiro, and McNeill (199...
748|An Overview of Issues in Developing Industrial Data Mining and Knowledge Discovery Applications|This paper surveys the growing number of indu5 trial applications of data mining and knowledge discovery. We look at the existing tools, describe some representative applications, and discuss the major issues and problems for building and deploying successful applications and their adoption by business users. Finally, we examine how to assess the potential of a knowledge discovery application. 1
749|Analyzing the Benefits of Domain Knowledge in Substructure Discovery|Discovering repetitive, interesting, and functional substructures in a structural  database improves the ability to interpret and compress the data. However, scientists  working with a database in their area of expertise often search for a predetermined  type of structure, or for structures exhibiting characteristics specic to the domain.  This paper presents methods for guiding the discovery process with domain-specic  knowledge. In this paper, the Subdue discovery system is used to evaluate the bene-  ts of using domain knowledge. The domain knowledge is incorporated into Subdue  following a single general methodology to guide the discovery process. Results show  using domain-specic knowledge improves the search for substructures which are useful  to the domain, and leads to greater compression of the data. To illustrate these bene-  ts, examples and experiments from the domain of computer programming, computer  aided design circuit, and a series of articially-generated domains...
750|Sensor Data Stream Protocol |Embedded sensor systems have been successfully implemented in a wide variety of settings, and there have been numerous research efforts that show how these sensor networks can be applied to areas ranging from education to science. These sensing systems are becoming more robust, easier to use, and widely deployed. Due to the various hardware/software platforms that are available, there is little standardization that exists in the realm of application level communication protocols, especially in the transferring or publishing of the data that is generated from sensor systems. For these sensor networks to become truly ubiquitous, there needs to be a standard protocol for the data they generate. We define a radically simple protocol, Sensor Data Stream Protocol (SDSP), to collect, move, and store sensor data. SDSP, which is built on XML as the markup language, contains references to the context of the information that is generated along with the actual values from the sensor systems. Furthermore, the protocol enables such operations as data sharing, republishing via aggregation, and concatenation. Finally, SDSP has a reference section that contains links to other sensor stores which search engines can use for discovery and ranking purposes. Overall, SDSP is a common, interoperable protocol that is designed to be handled by a range of different platforms ranging from 8-bit embedded processors to high-end cluster heads that are connected to sensor networks.
751|The PageRank Citation Ranking: Bringing Order to the Web|The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a method for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.
752|Telos: enabling ultra-low power wireless research|Abstract — We present Telos, an ultra low power wireless sensor module (“mote”) for research and experimentation. Telos is the latest in a line of motes developed by UC Berkeley to enable wireless sensor network (WSN) research. It is a new mote design built from scratch based on expe-riences with previous mote generations. Telos ’ new design consists of three major goals to enable experimentation: minimal power consumption, easy to use, and increased software and hardware robustness. We discuss how hardware components are selected and integrated in order to achieve these goals. Using a Texas Instruments MSP430 microcontroller, Chipcon IEEE 802.15.4-compliant radio, and USB, Telos ’ power profile is almost one-tenth the consumption of previous mote platforms while providing greater performance and throughput. It eliminates programming and support boards, while enabling experimentation with WSNs in both lab, testbed, and deployment settings. I.
753|SenSay: A Context-Aware Mobile Phone|SenSay is a context-aware mobile phone that adapts to dynamically changing environmental and physiological states. In addition to manipulating ringer volume, vibration, and phone alerts, SenSay can provide remote callers with the ability to communicate the urgency of their calls, make call suggestions to users when they are idle, and provide the caller with feedback on the current status of the Sensay user. A number of sensors including accelerometers, light, and microphones are mounted at various points on the body to provide data about the user’s context. A decision module uses a set of rules to analyze the sensor data and manage a state machine composed of uninterruptible, idle, active and normal states. Results from our threshold analyses show a clear delineation can be made among several user states by examining sensor data trends. SenSay augments its contextual knowledge by tapping into applications such as electronic calendars, address books, and task lists. The phone alleviates cognitive load on users by various methods including detecting when the user is uninterruptible and automatically turning the ringer off. 1.
755|TASK: Sensor Network in a Box|Abstract — Sensornet systems research is being conducted with various applications and deployment scenarios in mind. In many of these scenarios, the presumption is that the sensornet will be deployed and managed by users who do not have a background in computer science. In this paper we describe the “Tiny Application Sensor Kit” (TASK), a system we have designed for use by end-users with minimal sensornet sophistication. We describe the requirements that guided our design, the architecture of the system, and results from initial deployments. Based on our experience to date we present preliminary design principles and research challenges that arise in delivering sensornet research to end users. I.
756|Aggregate Computation over Data Streams |Abstract. Nowadays, we have witnessed the widely recognized phenomenon of high speed data streams. Various statistics computation over data streams is often required by many applications, including processing of relational type queries, data mining and high speed network management. In this paper, we provide survey for three important kinds of aggregate computations over data streams: frequency moment, frequency count and order statistic. 1
757|Optimal Aggregation Algorithms for Middleware|Assume that each object in a database has m grades, or scores, one for each of m attributes. For example, an object can have a color grade, that tells how red it is, and a shape grade, that tells how round it is. For each attribute, there is a sorted list, which lists each object and its grade under that attribute, sorted by grade (highest grade first). There is some monotone aggregation function, or combining rule, such as min or average, that combines the individual grades to obtain an overall grade. To determine the top k objects (that have the best overall grades), the naive algorithm must access every object in the database, to find its grade under each attribute. Fagin has given an algorithm (“Fagin’s Algorithm”, or FA) that is much more efficient. For some monotone aggregation functions, FA is optimal with high probability in the worst case. We analyze an elegant and remarkably simple algorithm (“the threshold algorithm”, or TA) that is optimal in a much stronger sense than FA. We show that TA is essentially optimal, not just for some monotone aggregation functions, but for all of them, and not just in a high-probability worst-case sense, but over every database. Unlike FA, which requires large buffers (whose size may grow unboundedly as the database size grows), TA requires only a small, constant-size buffer. TA allows early stopping, which yields, in a precise sense, an approximate version of the top k answers. We distinguish
758|Rank Aggregation Methods for the Web|We consider the problem of combining ranking results from various sources. In the context of the Web, the main applications include building meta-search engines, combining ranking functions, selecting documents based on multiple criteria, and improving search precision through word associations. Wedevelop a set of techniques for the rank aggregation problem and compare their performance to that of well-known methods. A primary goal of our work is to design rank aggregation techniques that can effectively combat &#034;spam,&#034; a serious problem in Web searches. Experiments show that our methods are simple, efficient, and effective.  
759|Combining fuzzy information from multiple systems (Extended Abstract)  (1996) |In a traditional database system, the result of a query is a set of values (those values that satisfy the query). In other data servers, such as a system with queries baaed on image content, or many text retrieval systems, the result of a query is a sorted list. For example, in the case of a system with queries based on image content, the query might aak for objects that are a particular shade of red, and the result of the query would be a sorted list of objects in the database, sorted by how well the color of the object matches that given in the query. A multimedia system must somehow synthesize both types of queries (those whose result is a set, and those whose result is a sorted list) in a consistent manner. In this paper we discuss the solution adopted by Garlic, a multimedia information system being developed at
761|Progressive Skyline Computation in Database Systems|The skyline of a d-dimensional dataset contains the points that are not dominated by any other point on all dimensions. Skyline computation has recently received considerable attention in the database community, especially for progressive methods that can quickly return the initial results without reading the entire database. All the existing algorithms, however, have some serious shortcomings which limit their applicability in practice. In this article we develop branch-- skyline (BBS), an algorithm based on nearest-neighbor search, which is I/O optimal, that is, it performs a single access only to those nodes that may contain skyline points. BBS is simple to implement and supports all types of progressive processing (e.g., user preferences, arbitrary dimensionality, etc). Furthermore, we propose several interesting variations of skyline computation, and show how BBS can be applied for their efficient processing.
762|Medians and Beyond: New Aggregation Techniques for Sensor Networks|Wireless sensor networks offer the potential to span and monitor large geographical areas inexpensively. Sensors, however, have significant power constraint (battery life), making communication very expensive. Another important issue in the context of sensorbased information systems is that individual sensor readings are inherently unreliable. In order to address these two aspects, sensor database systems like TinyDB and Cougar enable in-network data aggregation to reduce the communication cost and improve reliability. The existing data aggregation techniques, however, are limited to relatively simple types of queries such as SUM, COUNT, AVG, andMIN/MAX. In this paper we propose a data aggregation scheme that significantly extends the class of queries that can be answered using sensor networks. These queries include (approximate) quantiles, such as the median, the most frequent data values, such as the consensus value, a histogram of the data distribution, as well as range queries. In our scheme, each sensor aggregates the data it has received from other sensors into a fixed (user specified) size message. We provide strict theoretical guarantees on the approximation quality of the queries in terms of the message size. We evaluate the performance of our aggregation scheme by simulation and demonstrate its accuracy, scalability and low resource utilization for highly variable input data sets.
763|New directions in traffic measurement and accounting: Focusing on the elephants, ignoring the mice|Accurate network traffic measurement is required for accounting, bandwidth provisioning and detecting DoS attacks. These applications see the traffic as a collection of flows they need to measure. As link speeds and the number of flows increase, keeping a counter for each flow is too expensive (using SRAM) or slow (using DRAM). The current state-of-the-art methods (Cisco’s sampled NetFlow) which count periodically sampled packets are slow, inaccurate and resourceintensive. Previous work showed that at different granularities a small number of “heavy hitters” accounts for a large share of traffic. Our paper introduces a paradigm shift by concentrating the measurement process on large flows only — those above some threshold such as 0.1 % of the link capacity. We propose two novel and scalable algorithms for identifying the large flows: sample and hold and multistage filters, which take a constant number of memory references per packet and use a small amount of memory. If M is the available memory, we show analytically that the errors of our new algorithms are proportional to 1/M; by contrast, the error of an algorithm based on classical sampling is proportional to 1 /  v M, thus providing much less accuracy for the same amount of memory. We also describe further optimizations such as early removal and conservative update that further improve the accuracy of our algorithms, as measured on real traffic traces, by an order of magnitude. Our schemes allow a new form of accounting called threshold accounting in which only flows above a threshold are charged by usage while the rest are charged a fixed fee. Threshold accounting generalizes usage-based and duration based pricing.
764|Prefer: A system for the efficient execution of multi-parametric ranked queries|Users often need to optimize the selection of objects by appropriately weighting the importance of multiple object attributes. Such optimization problems appear often in operations’ research and applied mathematics as well as everyday life; e.g., a buyer may select a home as a weighted function of a number of attributes like its distance from office, its price, its area, etc. We capture such queries in our definition of preference queries that use a weight function over a relation’s attributes to derive a score for each tuple. Database systems cannot efficiently produce the top results of a preference query because they need to evaluate the weight function over all tuples of the relation. PREFER answers preference queries efficiently by using materialized views that have been preprocessed
765|Fuzzy Queries in Multimedia Database Systems|There are essential differences between multimedia databases (which may contain complicated objects, such as images), and traditional databases. These differences lead to interesting new issues, and in particular cause us to consider new types of queries. For example, in a multimedia database it is reasonable and natural to ask for images that are somehow &#034;similar to&#034; some fixed image. Furthermore, there are different ways of obtaining and accessing information in a multimedia database than information in a traditional database. For example, in a multimedia database, it might be reasonable to have a query that asks for, say, the top 10 images that are similar to a fixed image. This is in contrast to a relational database, where the answer to a query is simply a set. (Of course, in a relational database, the result to a query may be sorted in some way for convenience in presentation, such as sorting department members by salary, but logically speaking, the result is still simply a set, ...
767|Tributaries and deltas: Efficient and robust aggregation in sensor network streams|Existing energy-efficient approaches to in-network aggregation in sensor networks can be classified into two categories, tree-based and multi-path-based, with each having unique strengths and weaknesses. In this paper, we introduce Tributary-Delta, a novel approach that combines the advantages of the tree and multi-path approaches by running them simultaneously in different regions of the network. We present schemes for adjusting the regions in response to changes in network conditions, and show how many useful aggregates can be readily computed within this new framework. We then show how a difficult aggregate for this context— finding frequent items—can be efficiently computed within the framework. To this end, we devise the first algorithm for frequent items (and for quantiles) that provably minimizes the worst case total communication for non-regular trees. In addition, we give a multi-path algorithm for frequent items that is considerably more accurate than previous approaches. These algorithms form the basis for our efficient Tributary-Delta frequent items algorithm. Through extensive simulation with real-world and synthetic data, we show the significant advantages of our techniques. For example, in computing Count under realistic loss rates, our techniques reduce answer error by up to a factor of 3 compared to any previous technique. 1.
768|Approximate Counts and Quantiles over Sliding Windows|We consider the problem of maintaining approximate counts and quantiles over fixed- and variable-size sliding windows in limited space. For quantiles, we present deterministic algorithms whose space requirements are O ( 1! log 1! logN) and O(
769|Estimating aggregates on a peer-to-peer network|As Peer-to-Peer (P2P) networks become popular, there is an emerging need to collect a variety of statistical summary information about the participating nodes. The P2P networks of today lack mechanisms to compute even such basic aggregates as MIN, MAX, SUM, COUNT or AVG. In this paper, we define and study the NODEAGGREGATION problem that is concerned with aggregating data stored at nodes in the network. We present generic schemes that can be used to compute any of the basic aggregation functions accurately and robustly. Our schemes can be used as building blocks for tools to collect statistics on network topology, user behavior and other node characteristics. This is a STUDENT paper intended as a REGULAR presentation. I.
770|Continuous monitoring of top-k queries over sliding windows|Given a dataset P and a preference function f, atop-k query retrieves the k tuples in P with the highest scores according to f. Even though the problem is well-studied in conventional databases, the existing methods are inapplicable to highly dynamic environments involving numerous longrunning queries. This paper studies continuous monitoring of top-k queries over a fixed-size window W of the most recent data. The window size can be expressed either in terms of the number of active tuples or time units. We propose a general methodology for top-k monitoring that restricts processing to the sub-domains of the workspace that influence the result of some query. To cope with high stream rates and provide fast answers in an on-line fashion, the data in W reside in main memory. The valid records are indexed by a grid structure, which also maintains book-keeping information. We present two processing techniques: the first one computes the new answer of a query whenever some of the current top-k points expire; the second one partially precomputes the future changes in the result, achieving better running time at the expense of slightly higher space requirements. We analyze the performance of both algorithms and evaluate their efficiency through extensive experiments. Finally, we extend the proposed framework to other query types and a different data stream model. 1.
771|Communication-efficient distributed monitoring of thresholded counts|Monitoring is an issue of primary concern in current and next gen-eration networked systems. For example, the objective of sensor networks is to monitor their surroundings for a variety of differ-ent applications like atmospheric conditions, wildlife behavior, and troop movements among others. Similarly, monitoring in data net-works is critical not only for accounting and management, but also for detecting anomalies and attacks. Such monitoring applications are inherently continuous and distributed, and must be designed to minimize the communication overhead that they introduce. In this context we introduce and study a fundamental class of problems called “thresholded counts ” where we must return the aggregate frequency count of an event that is continuously monitored by dis-tributed nodes with a user-specified accuracy whenever the actual count exceeds a given threshold value. In this paper we propose to address the problem of thresholded counts by setting local thresholds at each monitoring node and initi-ating communication only when the locally observed data exceeds these local thresholds. We explore algorithms in two categories: static thresholds and adaptive thresholds. In the static case, we consider thresholds based on a linear combination of two alternate strategies, and show that there exists an optimal blend of the two strategies that results in minimum communication overhead. We further show that this optimal blend can be found using a steep-est descent search. In the adaptive case, we propose algorithms that adjust the local thresholds based on the observed distributions of updated information in the distributed monitoring system. We use extensive simulations not only to verify the accuracy of our algorithms and validate our theoretical results, but also to evalu-ate the performance of the two approaches. We find that both ap-proaches yield significant savings over the naive approach of per-forming processing at a centralized location. 1.
772|New Streaming Algorithms for Fast Detection of Superspreaders|High-speed monitoring of Internet traffic is an important and challenging problem, with applications to realtime attack detection and mitigation, traffic engineering, etc. However, packet-level monitoring requires fast streaming algorithms that use very little memory and little communication among collaborating network monitoring points. In this paper, we consider the problem of detecting superspreaders, which are sources that connect to a large number of distinct destinations. We propose new streaming algorithms for detecting superspreaders and prove guarantees on their accuracy and memory requirements. We also show experimental results on real network traces. Our algorithms are substantially more efficient (both theoretically and experimentally) than previous approaches. We also extend our algorithms to identify superspreaders in a distributed setting, with sliding windows, and when deletions are allowed in the stream (which lets us identify sources that make a large number of failed connections to distinct destinations). More generally, our algorithms are applicable to any problem that can be formulated as follows: given a stream of (x, y) pairs, find all the x’s that are paired with a large number of distinct y’s. We call this the heavy distinct-hitters problem. There are many network security applications of this general problem. This paper discusses these applications and, for concreteness, focuses on the superspreader problem. 1
773|Fast and approximate stream mining of quantiles and frequencies using graphics processors|We present algorithms for fast quantile and frequency estimation in large data streams using graphics processors (GPUs). We exploit the high computation power and memory bandwidth of graphics processors and present a new sorting algorithm that performs ras-terization operations on the GPUs. We use sorting as the main computational component for histogram approximation and con-struction of -approximate quantile and frequency summaries. Our algorithms for numerical statistics computation on data streams are deterministic, applicable to xed or variable-sized sliding windows and use a limited memory footprint. We use GPU as a co-processor and minimize the data transmission between the CPU and GPU by taking into account the low bus bandwidth. We implemented our algorithms on a PC with a NVIDIA GeForce FX 6800 Ultra GPU and a 3:4 GHz Pentium IV CPU and applied them to large data streams consisting of more than 100 million values. We also compared the performance of our GPU-based algorithms with op-timized implementations of prior CPU-based algorithms. Overall, our results demonstrate that the graphics processors available on a commodity computer system are efcient stream-processor and useful co-processors for mining data streams.
774|Dynamically Maintaining Frequent Items over A Data Stream|It is challenge to maintain frequent items over a data stream, with a small bounded memory, in a dynamic environment where both insertion/deletion of items are allowed. In this paper, we propose a new novel algorithm, called hCount, which can handle both insertion and deletion of items with a much less memory space than the best reported algorithm. Our algorithm is also superior in terms of precision, recall and processing time. In addition, our approach does not request the preknowledge on the size of range for a data stream, and can handle range extension dynamically. Given a little modification, algorithm hCount can be improved to hCount*, which even owns significantly better performance than before. 1.
775|Diamond in the Rough: Finding Hierarchical Heavy Hitters in Multi-Dimensional Data|Data items archived in data warehouses or those that arrive online as streams typically have attributes which take values from multiple hierarchies (e.g., time and geographic location; source and destination IP addresses). Providing an aggregate view of such data is important to summarize, visualize, and analyze. We develop the aggregate view based on certain hierarchically organized sets of large-valued regions (“heavy hitters”). Such Hierarchical Heavy Hitters (HHHs) were previously introduced as a crucial aggregation technique in one dimension. In order to analyze the wider range of data warehousing applications and realistic IP data streams, we generalize this problem to multiple dimensions. We identify and study two variants of HHHs for multi-dimensional data, namely the “overlap ” and “split ” cases, depending on how an aggregate computed for a child node in the multi-dimensional hierarchy is propagated to its parent element(s). For data warehousing applications, we present offline algorithms that take multiple passes over the data and produce the exact HHHs. For data stream applications, we present online algorithms that find approximate HHHs in one pass, with proven accuracy guarantees. We show experimentally, using real and synthetic data, that our proposed online algorithms yield outputs which are very similar (virtually identical, in many cases) to their offline counterparts. The lattice property of the product of hierarchical dimensions (“diamond”) is crucially exploited in our online algorithms to track approximate HHHs using only a small, fixed number of statistics per candidate node, regardless of the number of dimensions. 1.
777|Ranked Join Indices|... be ordered according to a variety of attributes associated with the entities. Such orderings result effectively in a ranking  of the entities according to the values in the attribute domain. Commonly, users correlate such sources for query processing purposes through join operations. In query processing, it is desirable to incorporate user preferences towards specific attributes or their values. A way to incorporate such preferences, is by utilizing scoring functions that combine user preferences and attribute values and return a numerical score for each tuple in the join result. Then, a target query, which we refer to as top-k join query, seeks to identify the  tuples in the join result with the highest scores. In this paper
778|Efficient maintenance of materialized top-k views|We tackle the problem of maintaining materialized top-k views in this paper. Top-k queries, includingMIN andMAX as important special cases, occur frequently in common database workloads. A top-k view can be materialized to improve query performance, but in general it is not self-maintainable unless it contains all tuples in the base table. Deletions and updates on the base table may cause tuples to leave the top-k view, resulting in expensive queries over the base table to “refill ” the view. In this paper, we propose an algorithm that reduces the frequency of refills by maintaining a top-k ' view instead of a top-k view, where k ' changes at runtime between k and some kmax = k. We show that in most practical cases, our algorithm can reduce the expected amortized cost of refill queries to O(1) while still keeping the view small. The optimal value of kmax depends on the update pattern and the costs of querying the base table and updating the view. Compared with the simple approach of maintaining either the top-k view itself or a copy of the base table, our algorithm can provide orders-of-magnitude improvements in performance with appropriate kmax values. We show how to choose kmax dynamically to adapt to the actual system workload and performance at runtime, without requiring accurate prior knowledge.
779|Ad-hoc Top-k Query Answering for Data Streams|A top-k query retrieves the k highest scoring tuples from a data set with respect to a scoring function defined on the attributes of a tuple. The efficient evaluation of top-k queries has been an active research topic and many different instantiations of the problem, in a variety of settings, have been studied. However, techniques developed for conventional, centralized or distributed databases are not directly applicable to highly dynamic environments and on-line applications, like data streams. Recently, techniques supporting top-k queries on data streams have been introduced. Such techniques are restrictive however, as they can only efficiently report top-k answers with respect to a pre-specified (as opposed to ad-hoc) set of queries. In this paper we introduce a novel geometric representation for the top-k query problem that allows us to raise this restriction. Utilizing notions of geometric arrangements, we design and analyze algorithms for incrementally maintaining a data set organized in an arrangement representation under streaming updates. We introduce query evaluation strategies that operate on top of an arrangement data structure that are able to guarantee efficient evaluation for ad-hoc queries. The performance of our core technique is augmented by incorporating tuple pruning strategies, minimizing the number of tuples that need to be stored and manipulated. This results in a main memory indexing technique supporting both efficient incremental updates and the evaluation of ad-hoc top-k queries. A thorough experimental study evaluates the efficiency of the proposed technique. 
780|Continuously maintaining quantile summaries of the most recent n elements over a data stream|Statistics over the most recently observed data elements are often required in applications involving data streams, such as intrusion detection in network monitoring, stock price prediction in financial markets, web log mining for access prediction, and user click stream mining for personalization. Among various statistics, computing quantile summary is probably most challenging because of its complexity. In this paper, we study the problem of continuously maintaining quantile summary of the most recently observed N elements over a stream so that quantile queries can be answered with a guaranteed precision of ?N. We developed a space efficient algorithm for pre-defined N that requires only one scan of the input data stream and O ( log(?2N) ? + 1 ?2) space in the worst cases. We also developed an algorithm that maintains quantile summaries for most recent N elements so that quantile queries on any most recent n elements (n = N) can be answered with a guaranteed precision of ?n. The worst case space requirement for this algorithm is only O ( log2 (?N) ?2). Our performance study indicated that not only the actual quantile estimation error is far below the guaranteed precision but the space requirement is also much less than the given theoretical bound. 1
781|Approximate quantiles and the order of the stream |Recently, there has been an increased focus on modeling uncertainty by distributions. Suppose we wish to compute a function of a stream whose elements are samples drawn independently from some distribution. The distribution is unknown, but the order in which the samples are presented to us will not be completely adversarial. In this paper, we investigate the importance of the ordering of a data stream, without making any assumptions about the actual distri-bution of the data. Using quantiles as an example appli-cation, we show that we can design provably better algo-rithms, and settle several open questions on the impact of order on streams. With the recent impetus in the investiga-tion of models for sensor networks, we believe that our ap-proach will allow the construction of novel and significantly improved algorithms.
782|Branch-and-bound processing of ranked queries |Despite the importance of ranked queries in numerous applications involving multi-criteria decision making, they are not efficiently supported by traditional database systems. In this paper, we propose a simple yet powerful technique for processing such queries based on multidimensional access methods and branch-and-bound search. The advantages of the proposed methodology are: (i) it is space efficient, requiring only a single index on the given relation (storing each tuple at most once), (ii) it achieves significant (i.e., orders of magnitude) performance gains with respect to the current state-of-the-art, (iii) it can efficiently handle data updates, and (iv) it is applicable to other important variations of ranked search (including the support for non-monotone preference functions), at no extra space overhead. We confirm the superiority of the proposed methods with a detailed experimental study.
783|On estimating frequency moments of data streams|Abstract. Space-economical estimation of the pth frequency moments, defined as Fp = P n i=1 |fi|p, for p&gt; 0, are of interest in estimating all-pairs distances in a large data matrix [14], machine learning, and in data stream computation. Random sketches formed by the inner product of the frequency vector f1,..., fn with a suitably chosen random vector were pioneered by Alon, Ma-tias and Szegedy [1], and have since played a central role in estimating Fp and for data stream computations in general. The concept of p-stable sketches formed by the inner product of the frequency vector with a random vector whose components are drawn from a p-stable distribution, was proposed by Indyk [11] for estimating Fp, for 0 &lt; p &lt; 2, and has been further studied in Li [13]. In this paper, we consider the problem of estimating Fp, for 0 &lt; p &lt; 2. A disadvantage of the sta-ble sketches technique and its variants is that they require O ( 1 ? 2) inner-products of the frequency vector with dense vectors of stable (or nearly stable [14, 13]) random variables to be maintained. This means that each stream update can be quite time-consuming. We present algorithms for esti-mating Fp, for 0 &lt; p &lt; 2, that does not require the use of stable sketches or its approximations. Our technique is elementary in nature, in that, it uses simple randomization in conjunction with well-known summary structures for data streams, such as the COUNT-MIN sketch [7] and the COUNTSKETCH structure [5]. Our algorithms require space 1 ± ? factors and requires expected time O(log F1 log 1 d Õ ( 1 ? 2+p) 3 to estimate Fp to within) to process each update. Thus, our tech-nique trades an O ( 1 ? p) factor in space for much more efficient processing of stream updates. We also present a stand-alone iterative estimator for F1. 1
784|Efficient Skyline and Top-k Retrieval in Subspaces |Skyline and top-k queries are two popular operations for preference retrieval. In practice, applications that require these operations usually provide numerous candidate attributes, whereas, depending on their interests, users may issue queries regarding different subsets of the dimensions. The existing algorithms are inadequate for subspace skyline/top-k search because they have at least one of the following defects: they (i) require scanning the entire database at least once; (ii) are optimized for one subspace but incur significant overhead for other subspaces; (iii) demand expensive maintenance cost or space consumption. In this paper, we propose a technique, SUBSKY, which settles both types of queries using purely relational technologies. The core of SUBSKY is a transformation that converts multidimensional data to 1D values. These values are indexed by a simple B-tree, which allows us to answer subspace queries by accessing a fraction of the database. SUBSKY entails low maintenance overhead, which equals the cost of updating a traditional B-tree. Extensive experiments with real data confirm that our technique outperforms alternative solutions significantly in both efficiency and scalability. 
785|Effective computation of biased quantiles over data streams|Skew is prevalent in many data sources such as IP traffic streams. To continually summarize the distribution of such data, a high-biased set of quantiles (e.g., 50th, 90th and 99th percentiles) with finer error guarantees at higher ranks (e.g., errors of 5, 1 and 0.1 percent, respectively) is more useful than uniformly distributed quantiles (e.g., 25th, 50th and 75th percentiles) with uniform error guarantees. In this paper, we address the following two problems. First, can we compute quantiles with finer error guarantees for the higher ranks of the data distribution effectively, using less space and computation time than computing all quantiles uniformly at the finest error? Second, if specific quantiles and their error bounds are requested a priori, can the necessary space usage and computation time be reduced? We answer both questions in the affirmative by formalizing them as the “high-biased ” and the “targeted ” quantiles problems, respectively, and presenting algorithms with provable guarantees, that perform significantly better than previously known solutions for these problems. We implemented our algorithms in the Gigascope data stream management system, and evaluated alternate approaches for maintaining the relevant summary structures. Our experimental results on real and synthetic IP data streams complement our theoretical analyses, and highlight the importance of lightweight, non-blocking implementations when maintaining summary structures over high-speed data streams. 1
786|Distributed operation in the Borealis stream processing engine|Borealis is a distributed stream processing engine that is being developed at Brandeis University, Brown University, and MIT. Borealis inherits core stream processing functional-ity from Aurora and inter-node communication functionality from Medusa. We propose to demonstrate some of the key aspects of distributed operation in Borealis, using a multi-player net-work game as the underlying application. The demonstra-tion will illustrate the dynamic resource management, query optimization and high availability mechanisms employed by Borealis, using visual performance-monitoring tools as well as the gaming experience. 1.
787|Fast Data Stream Algorithms using Associative Memories|The primary goal of data stream research is to develop space and time efficient solutions for answering continuous online summarization queries. Research efforts over the last decade have resulted in a number of efficient algorithms with varying degrees of space and time complexities. While these techniques are developed in a standard CPU setting, many of their applications such as click-fraud detection and network-traffic summarization typically execute on special networking architectures called Network Processing Units (NPUs). These NPUs interface with a special type of associative memories, known as Ternary Content Addressable Memories (TCAMs), to provide gigabit rate forwarding at network routers. In this paper, we describe how the integrated architecture of NPU and TCAMs can be exploited towards achieving the goal of developing high-speed stream summarization solutions. We propose two TCAM-conscious solutions for the frequent elements problem in data streams and present a comprehensive evaluation of these techniques on a state-of-the-art networking platform.
788|Robust sketching and aggregation of distributed data streams|The data streaming model provides an attractive framework for one-pass summarization of massive data sets at a single observation point. However, in an environment where multiple data streams arrive at a set of distributed observation points, sketches must be computed remotely and then must be aggregated through a hierarchy before queries may be conducted. As a result, many sketchbased methods for the single stream case do not apply directly, as either the error introduced becomes large, or because the methods assume that the streams are non-overlapping. These limitations hinder the application of these techniques to practical problems in network traffic monitoring and aggregation in sensor networks. To address this, we develop a framework for evaluating and enabling robust computation of duplicate-sensitive aggregate functions (e.g., SUM and QUANTILE), over data produced by distributed sources. We instantiate our approach by augmenting the Count-Min and Quantile Digest sketches to apply in this distributed setting, and analyze their performance. We conclude with an experimental evaluation to validate our analysis. 1
790|Space Complexity of Hierarchical Heavy Hitters|Heavy hitters, which are items occurring with frequency above a given threshold, are an important aggregation and summary tool when processing data streams or data warehouses. Hierarchical heavy hitters (HHHs) have been introduced as a natural generalization for hierarchical data domains, including multi-dimensional data. An item x in a hierarchy is called a f-HHH if its frequency after discounting the frequencies of all its descendant hierarchical heavy hitters exceeds fn, where f is a user-specified parameter and n is the size of the data set. Recently, single-pass schemes have been proposed for computing f-HHHs using space roughly O ( 1 log(fn)). The frequency estimates of these algorithms, f however, hold only for the total frequencies of items, and not the discounted frequencies; this leads to false positives because the discounted frequency can be significantly smaller than the total frequency. This paper attempts to explain the difficulty of finding hierarchical heavy hitters with better accuracy. We show that a single-pass deterministic scheme that computes f-HHHs in a d-dimensional hierarchy with any approximation guarantee must use ?(1/f d+1) space. This bound is tight: in fact, we present a data stream algorithm that can report the f-HHHs without false positives in O(1/f d+1) space. 1
791|Efficient Processing of Ranked Queries with Sweeping Selection ? |Abstract. Existing methods for top-k ranked query employ techniques including sorting, updating thresholds and materializing views. In this paper, we propose two novel index-based techniques for top-k ranked query: (1) indexing the layered skyline, and (2) indexing microclusters of objects into a grid structure. We also develop efficient algorithms for ranked query by locating the answer points during the sweeping of the line/hyperplane of the score function over the indexed objects. Both methods can be easily plugged into typical multi-dimensional database indexes. The comprehensive experiments not only demonstrate that our methods outperform the existing ones, but also illustrate that the application of data mining technique (microclustering) is a useful and effective solution for database query processing. 1
792|Approximate processing of massive continuous quantile queries over high-speed data streams|Abstract—Quantile computation has many applications including data mining and financial data analysis. It has been shown that an-approximate summary can be maintained so that, given a quantile query ð; Þ, the data item at rank d Ne may be approximately obtained within the rank error precision N over all N data items in a data stream or in a sliding window. However, scalable online processing of massive continuous quantile queries with different and poses a new challenge because the summary is continuously updated with new arrivals of data items. In this paper, first we aim to dramatically reduce the number of distinct query results by grouping a set of different queries into a cluster so that they can be processed virtually as a single query while the precision requirements from users can be retained. Second, we aim to minimize the total query processing costs. Efficient algorithms are developed to minimize the total number of times for reprocessing clusters and to produce the minimum number of clusters, respectively. The techniques are extended to maintain near-optimal clustering when queries are registered and removed in an arbitrary fashion against whole data streams or sliding windows. In addition to theoretical analysis, our performance study indicates that the proposed techniques are indeed scalable with respect to the number of input queries as well as the number of items and the item arrival rate in a data stream. Index Terms—Query processing, online computation, data mining. æ 1
793|Space-efficient relative error order sketch over data streams|We consider the problem of continuously maintaining order sketches over data streams with a relative rank error guarantee ?. Novel space-efficient and one-scan randomised techniques are developed. Our first randomised algorithm can guarantee such a relative error precision ? with confidence 1 - d using O ( 1 ?2 log 1 d log ?2N) space, where N is the number of data elements seen so far in a data stream. Then, a new one-scan space compression technique is developed. Combined with the first randomised algorithm, the one-scan space compression technique yields another one-scan randomised algorithm that guarantees the space requirement is O ( 1
794|Fast algorithms for heavy distinct hitters using associative memories|Real-time detection of worm attacks, port scans and Distributed Denial of Service (DDoS) attacks, as network packets belonging to these security attacks flow through a network router, is of paramount importance. In a typical worm attack, a worm infected host tries to spread the worm by scanning a number of other hosts thus resulting in significant number of network connections at an intermediate router. Detecting such attacks amounts to finding all hosts that are associated with unusually high number of other hosts, which is equivalent to solving the classic heavy distinct hitter problem over data streams. While several heavy distinct hitter solutions have been proposed and evaluated in a standard CPU setting, most of the above applications typically execute on special networking architectures called Network Processing Units (NPUs). These NPUs interface with special associative memories known as the Ternary Content Addressable Memories (TCAMs) to provide gigabit rate forwarding at network routers. In this paper, we describe how the integrated architecture of NPU and TCAMs can be exploited to develop high-speed solutions for heavy distinct hitters. 1
795|Summarizing order statistics over data streams with duplicates|A rank query is essentially to find a data element with a given rank against a monotonic order specified on data elements. Rank queries have several equivalent variations
796|Processing Ranked Queries with the Minimum Space |Abstract. Practical applications often need to rank multi-variate records by assigning various priorities to different attributes. Consider a relation that stores students ’ grades on two courses: database and algorithm. Student performance is evaluated by an “overall score ” calculated as w1·gdb+w2·galg,wherew1, w2 are two input “weights”, and gdb (galg) is the student grade on database (algorithm). A “top-k ranked query ” retrieves the k students with the best scores according to specific w1 and w2. We focus on top-k queries whose k is bounded by a constant c, and present solutions that guarantee low worst-case query cost by using provably the minimum space. The core of our methods is a novel concept, “minimum covering subset”, which contains only the necessary data for ensuring correct answers for all queries. Any 2D ranked search, for example, can be processed in O(log B(m/B)+c/B) I/Os using O(m/B) space, where m is the size of the minimum covering subset, and B the disk page capacity. Similar results are also derived for higher dimensionalities and approximate ranked retrieval. 1
799|Regularization and variable selection via the Elastic Net|Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together.The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.
800|On Model Selection Consistency of Lasso|Sparsity or parsimony of statistical models is crucial for their proper interpretations, as  in sciences and social sciences. Model selection is a commonly used method to find such  models, but usually involves a computationally heavy combinatorial search. Lasso (Tibshirani,  1996) is now being used as a computationally feasible alternative to model selection.
801|Leave-One-Out Support Vector Machines|We present a new learning algorithm for pattern recognition inspired by a recent upper bound on leave--one--out error [ Jaakkola and Haussler, 1999 ] proved for Support Vector Machines (SVMs) [ Vapnik, 1995; 1998 ] . The new approach directly minimizes the expression given by the bound in an attempt to minimize leave--one--out error. This gives a convex optimization problem which constructs a sparse linear classifier in feature space using the kernel technique. As such the algorithm possesses many of the same properties as SVMs. The main novelty of the algorithm is that apart from the choice of kernel, it is parameterless -- the selection of the number of training errors is inherent in the algorithm and not chosen by an extra free parameter as in SVMs. First experiments using the method on benchmark datasets from the UCI repository show results similar to SVMs which have been tuned to have the best choice of parameter.  1 Introduction  Support Vector Machines (SVMs), motivated by minim...
802|Sparse Principal Component Analysis|Principal component analysis (PCA) is widely used in data processing and dimensionality  reduction. However, PCA su#ers from the fact that each principal component is a linear combination  of all the original variables, thus it is often di#cult to interpret the results. We introduce  a new method called sparse principal component analysis (SPCA) using the lasso (elastic net)  to produce modified principal components with sparse loadings. We show that PCA can be  formulated as a regression-type optimization problem, then sparse loadings are obtained by imposing  the lasso (elastic net) constraint on the regression coe#cients. E#cient algorithms are  proposed to realize SPCA for both regular multivariate data and gene expression arrays. We  also give a new formula to compute the total variance of modified principal components. As  illustrations, SPCA is applied to real and simulated data, and the results are encouraging.
803|Boosting with early stopping: convergence and consistency|Abstract Boosting is one of the most significant advances in machine learning for classification and regression. In its original and computationally flexible version, boosting seeks to minimize empirically a loss function in a greedy fashion. The resulted estimator takes an additive function form and is built iteratively by applying a base estimator (or learner) to updated samples depending on the previous iterations. An unusual regularization technique, early stopping, is employed based on CV or a test set. This paper studies numerical convergence, consistency, and statistical rates of convergence of boosting with early stopping, when it is carried out over the linear span of a family of basis functions. For general loss functions, we prove the convergence of boosting&#039;s greedy optimization to the infinimum of the loss function over the linear span. Using the numerical convergence result, we find early stopping strategies under which boosting is shown to be consistent based on iid samples, and we obtain bounds on the rates of convergence for boosting estimators. Simulation studies are also presented to illustrate the relevance of our theoretical results for providing insights to practical aspects of boosting. As a side product, these results also reveal the importance of restricting the greedy search step sizes, as known in practice through the works of Friedman and others. Moreover, our results lead to a rigorous proof that for a linearly separable problem, AdaBoost with ffl! 0 stepsize becomes an L1-margin maximizer when left to run to convergence. 1 Introduction In this paper we consider boosting algorithms for classification and regression. These algorithms present one of the major progresses in machine learning. In their original version, the computational aspect is explicitly specified as part of the estimator/algorithm. That is, the empirical minimization of an appropriate loss function is carried out in a greedy fashion, which means that at each step, a basis function that leads to the largest reduction of empirical risk is added into the estimator. This specification distinguishes boosting from other statistical procedures which are defined by an empirical minimization of a loss function without the numerical optimization details.
804|Empty alternation|Abstract. We introduce the notion of empty alternation by investigating alternating automata which are restricted to empty their storage except for a logarithmically space-bounded tape before making an alternating transition. In particular, we consider the cases when the depth of alternation is bounded by a constant or a polylogarithmic function. In this way we get new characterizations of the classes AC k, SAC k and P using a push-down store and new characterizations of the class T P 2 using Turing tapes. 1
805|Multiple aggregations over data streams|Monitoring aggregates on IP traffic data streams is a compelling application for data stream management systems. The need for exploratory IP traffic data analysis naturally leads to posing related aggregation queries on data streams, that differ only in the choice of grouping attributes. In this paper, we address this problem of efficiently computing multiple aggregations over high speed data streams, based on a two-level LFTA/HFTA DSMS architecture, inspired by Gigascope. Our first contribution is the insight that in such a scenario, additionally computing and maintaining fine-granularity aggregation queries (phantoms) at the LFTA has the benefit of supporting shared computation. Our second contribution is an investigation into the problem of identifying beneficial LFTA configurations of phantoms and user-queries. We formulate this problem as a cost optimization problem, which consists of two sub-optimization problems: how to choose phantoms and how to allocate space for them in the LFTA. We formally show the hardness of determining the optimal configuration, and propose cost greedy heuristics for these independent sub-problems based on detailed analyses. Our final contribution is a thorough experimental study, based on real IP traffic data, as well as synthetic data, to demonstrate the effectiveness of our techniques for identifying beneficial configurations. 1.
806|Implementing data cubes efficiently|Decision support applications involve complex queries on very large databases. Since response times should be small, query optimization is critical. Users typically view the data as multidimensional data cubes. Each cell of the data cube is a view consisting of an aggregation of interest, like total sales. The values of many of these cells are dependent on the values of other cells in the data cube..A common and powerful query optimization technique is to materialize some or all of these cells rather than compute them from raw data each time. Commercial systems differ mainly in their approach to materializing the data cube. In this paper, we investigate the issue of which cells (views) to materialize when it is too expensive to materialize all views. A lattice framework is used to express dependencies among views. We present greedy algorithms that work off this lattice and determine a good set of views to materialize. The greedy algorithm performs within a small constant factor of optimal under a variety of models. We then consider the most common case of the hypercube lattice and examine the choice of materialized views for hypercubes in detail, giving some good tradeoffs between the space used and the average time to answer a query. 1
807|Materialized view maintenance and integrity constraint checking: Trading space for time|Abstract We investigate the problem of incremental maintenance of an SQL view in the face of database updates, and show that it is possible to reduce the total time cost of view maintenance by materializing (and maintaining) additional views. We formulate the problem of determining the optimal set of additional views to materialize as an optimization problem over the space of possible view sets (which includes the empty set). The optimization problem is harder than query optimization since it has to deal with multiple view sets, updates of multiple relations, and multiple ways of maintaining each view set for each updated relation. We develop a memoing solution for the problem; the solution can be implemented using the expression DAG representation used in rule-based optimizers such as Volcano. We demonstrate that global optimization cannot, in general, be achieved by locally optimizing each materialized subview, because common subexpressions between different materialized subviews can allow nonoptimal local plans to be combined into an optimal global plan. We identify conditions on materialized subviews in the expression DAG when local optimization is possible. Finally, we provide a systematic space of heuristics that can be used to efficiently determine a useful set of additional views to materialize. Our results are particularly important for the efficient checking of assertions (complex integrity constraints) in the SQL-92 standard, since the incremental checking of such integrity constraints is known to be essentially equivalent to the view maintenance problem.
808|Sketch-based multi-query processing over data streams|Abstract. Recent years have witnessed an increasing interest in designing algorithms for querying and analyzing streaming data (i.e., data that is seen only once in a fixed order) with only limited memory. Providing (perhaps approximate) answers to queries over such continuous data streams is a crucial requirement for many application environments; examples include large telecom and IP network installations where performance data from different parts of the network needs to be continuously collected and analyzed. Randomized techniques, based on computing small “sketch ” synopses for each stream, have recently been shown to be a very effective tool for approximating the result of a single SQL query over streaming data tuples. In this paper, we investigate the problems arising when data-stream sketches are used to process multiple such queries concurrently. We demonstrate that, in the presence of multiple query expressions, intelligently sharing sketches among concurrent query evaluations can result in substantial improvements in the utilization of the available sketching space and the quality of the resulting approximation error guarantees. We provide necessary and sufficient conditions for multi-query sketch sharing that guarantee the correctness of the result-estimation process. We also prove that optimal sketch sharing typically gives rise to N P-hard questions, and we propose novel heuristic algorithms for finding good sketch-sharing configurations in practice. Results from our experimental study with realistic workloads verify the effectiveness of our approach, clearly demonstrating the benefits of our sketch-sharing methodology. 1
809|Active Learning from Data Streams * |In this paper, we address a new research problem on active learning from data streams where data volumes grow continuously and labeling all data is considered expensive and impractical. The objective is to label a small portion of stream data from which a model is derived to predict newly arrived instances as accurate as possible. In order to tackle the challenges raised by data streams ’ dynamic nature, we propose a classifier ensembling based active learning framework which selectively labels instances from data streams to build an accurate classifier. A Minimal Variance principle is introduced to guide instance labeling from data streams. In addition, a weight updating rule is derived to ensure that our instance labeling process can adaptively adjust to dynamic drifting concepts in the data. Experimental results on synthetic and real-world data demonstrate the performances of the proposed efforts in comparison with other simple approaches. * 1.
810|Query by Committee|We propose an algorithm called query by committee, in which a committee of students is trained on the same data set. The next query is chosen according to the principle of maximal disagreement. The algorithm is studied for two toy models: the high-low game and perceptron learning of another perceptron. As the number of queries goes to infinity, the committee algorithm yields asymptotically finite information gain. This leads to generalization error that decreases exponentially with the number of examples. This in marked contrast to learning from randomly chosen inputs, for which the information gain approaches zero and the generalization error decreases with a relatively slow inverse power law. We suggest that asymptotically finite information gain may be an important characteristic of good query algorithms.
811|Selective sampling using the Query by Committee algorithm|We analyze the &#034;query by committee&#034; algorithm, a method for filtering informative queries from a random stream of inputs. We show that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error decreases exponentially with the number of queries. We show that, in particular, this exponential decrease holds for query learning of perceptrons.
812|Moment: Maintaining Closed Frequent Itemsets over a Stream Sliding Window|This paper considers the problem of mining closed frequent itemsets over a sliding window using limited memory space. We design a synopsis data structure to monitor transactions in the sliding window so that we can output the current closed frequent itemsets at any time. Due to time and memory constraints, the synopsis data structure cannot monitor all possible itemsets. However, monitoring only frequent itemsets will make it impossible to detect new itemsets when they become frequent. In this paper, we introduce a compact data structure, the closed enumeration tree (CET), to maintain a dynamically selected set of itemsets over a sliding-window. The selected itemsets consist of a boundary between closed frequent itemsets and the rest of the itemsets. Concept drifts in a data stream are reflected by boundary movements in the CET. In other words, a status change of any itemset (e.g., from non-frequent to frequent) must occur through the boundary. Because the boundary is relatively stable, the cost of mining closed frequent itemsets over a sliding window is dramatically reduced to that of mining transactions that can possibly cause boundary movements in the CET. Our experiments show that our algorithm performs much better than previous approaches.
813|Batch mode active learning and its application to medical image classification |The goal of active learning is to select the most informative examples for manual labeling. Most of the previous studies in active learning have focused on selecting a single unlabeled example in each iteration. This could be inefficient since the classification model has to be retrained for every labeled example. In this paper, we present a framework for “batch mode active learning ” that applies the Fisher information matrix to select a number of informative examples simultaneously. The key computational challenge is how to efficiently identify the subset of unlabeled examples that can result in the largest reduction in the Fisher information. To resolve this challenge, we propose an efficient greedy algorithm that is based on the property of submodular functions. Our empirical studies with five UCI datasets and one realworld medical image classification show that the proposed batch mode active learning algorithm is more effective than the state-ofthe-art algorithms for active learning. 1.
814|Class Noise vs. Attribute Noise: A Quantitative Study of Their Impacts |Abstract. Real-world data is never perfect and can often suffer from corruptions (noise) that may impact interpretations of the data, models created from the data and decisions made based on the data. Noise can reduce system performance in terms of classification accuracy, time in building a classifier and the size of the classifier. Accordingly, most existing learning algorithms have integrated various approaches to enhance their learning abilities from noisy environments, but the existence of noise can still introduce serious negative impacts. A more reasonable solution might be to employ some preprocessing mechanisms to handle noisy instances before a learner is formed. Unfortunately, rare research has been conducted to systematically explore the impact of noise, especially from the noise handling point of view. This has made various noise processing techniques less significant, specifically when dealing with noise that is introduced in attributes. In this paper, we present a systematic evaluation on the effect of noise in machine learning. Instead of taking any unified theory of noise to evaluate the noise impacts, we differentiate noise into two categories: class noise and attribute noise, and analyze their impacts on the system performance separately. Because class noise has been widely addressed in existing research efforts, we concentrate on attribute noise. We investigate the relationship between attribute noise and classification accuracy, the impact of noise at different attributes, and possible solutions in handling attribute noise. Our conclusions can be used to guide interested readers to enhance data quality by designing various noise handling mechanisms.
815|Combining Proactive and Reactive Predictions for Data Streams|Mining data streams is important in both science and commerce. Two major challenges are (1) the data may grow without limit so that it is difficult to retain a long history; and (2) the underlying concept of the data may change over time. Different from common practice that keeps recent raw data, this paper uses a measure of conceptual equivalence to organize the data history into a history of concepts. Along the journey of concept change, it identifies new concepts as well as re-appearing ones, and learns transition patterns among concepts to help prediction. Different from conventional methodology that passively waits until the concept changes, this paper incorporates proactive and reactive predictions. In a proactive mode, it anticipates what the new concept will be if a future concept change takes place, and prepares prediction strategies in advance. If the anticipation turns out to be correct, a proper prediction model can be launched instantly upon the concept change. If not, it promptly resorts to a reactive mode: adapting a prediction model to the new data. A system RePro is proposed to implement these new ideas. Experiments compare the system with representative existing prediction methods on various benchmark data sets that represent diversified scenarios of concept change. Empirical evidence demonstrates that the proposed methodology is an effective and efficient solution to prediction for data streams.
816|Decision Tree Evolution Using Limited Number of Labeled Data Items from Drifting Data Streams |Most previously proposed mining methods on data streams make an unrealistic assumption that “labelled” data stream is readily available and can be mined at anytime. However, in most real-world problems, labelled data streams are rarely immediately available. Due to this reason, models are reconstructed only when labelled data become available periodically. This passive stream mining model has several drawbacks. We propose a new concept of demand-driven active data mining. In active mining, the loss of the model is either continuously guessed without using any true class labels or estimated, whenever necessary, from a small number of instances whose actual class labels are verified by paying an affordable cost. When the estimated loss is more than a tolerable threshold, the model evolves by using a small number of instances with verified true class labels. Previous work on active mining concentrates on error guess and estimation. In this paper, we discuss several approaches on decision tree evolution. 1
817|Space-time codes for high data rate wireless communication: Performance criterion and code construction| We consider the design of channel codes for improving the data rate and/or the reliability of communications over fading channels using multiple transmit antennas. Data is encoded by a channel code and the encoded data is split into n streams that are simultaneously transmitted using n transmit antennas. The received signal at each receive antenna is a linear superposition of the n transmitted signals perturbed by noise. We derive performance criteria for designing such codes under the assumption that the fading is slow and frequency nonselective. Performance is shown to be determined by matrices constructed from pairs of distinct code sequences. The minimum rank among these matrices quantifies the diversity gain, while the minimum determinant of these matrices quantifies the coding gain. The results are then extended to fast fading channels. The design criteria are used to design trellis codes for high data rate wireless communication. The encoding/decoding complexity of these codes is comparable to trellis codes employed in practice over Gaussian channels. The codes constructed here provide the best tradeoff between data rate, diversity advantage, and trellis complexity. Simulation results are provided for 4 and 8 PSK signal sets with data rates of 2 and 3 bits/symbol, demonstrating excellent performance that is within 2–3 dB of the outage capacity for these channels using only 64 state encoders.
818|On limits of wireless communications in a fading environment when using multiple antennas|Abstract. This paper is motivated by the need for fundamental understanding of ultimate limits of bandwidth efficient delivery of higher bit-rates in digital wireless communications and to also begin to look into how these limits might be approached. We examine exploitation of multi-element array (MEA) technology, that is processing the spatial dimension (not just the time dimension) to improve wireless capacities in certain applications. Specifically, we present some basic information theory results that promise great advantages of using MEAs in wireless LANs and building to building wireless communication links. We explore the important case when the channel characteristic is not available at the transmitter but the receiver knows (tracks) the characteristic which is subject to Rayleigh fading. Fixing the overall transmitted power, we express the capacity offered by MEA technology and we see how the capacity scales with increasing SNR for a large but practical number, n, of antenna elements at both transmitter and receiver. We investigate the case of independent Rayleigh faded paths between antenna elements and find that with high probability extraordinary capacity is available. Compared to the baseline n = 1 case, which by Shannon’s classical formula scales as one more bit/cycle for every 3 dB of signal-to-noise ratio (SNR) increase, remarkably with MEAs, the scaling is almost like n more bits/cycle for each 3 dB increase in SNR. To illustrate how great this capacity is, even for small n, take the cases n = 2, 4 and 16 at an average received SNR of 21 dB. For over 99%
819|Spatio-Temporal Coding for Wireless Communication|Multipath signal propagation has long been viewed as an impairment to reliable communication in wireless channels. This paper shows that the presence of multipath greatly improves achievable data rate if the appropriate communication structure is employed. A compact model is developed for the multiple-input multiple-output (MIMO) dispersive spatially selective wireless communication channel. The multivariate information capacity is analyzed. For high signal-to-noise ratio (SNR) conditions, the MIMO channel can exhibit a capacity slope in bits per decibel of power increase that is proportional to the minimum of the number multipath components, the number of input antennas, or the number of output antennas. This desirable result is contrasted with the lower capacity slope of the well-studied case with multiple antennas at only one side of the radio link. A spatio-temporal vector-coding (STVC) communication structure is suggested as a means for achieving MIMO channel capacity. The complexity of STVC motivates a more practical reduced-complexity discrete matrix multitone (DMMT) space--frequency coding approach. Both of these structures are shown to be asymptotically optimum. An adaptive-lattice trellis-coding technique is suggested as a method for coding across the space and frequency dimensions that exist in the DMMT channel. Experimental examples that support the theoretical results are presented.  Index Terms---Adaptive arrays, adaptive coding, adaptive modulation, antenna arrays, broad-band communication, channel coding, digital modulation, information rates, MIMO systems, multipath channels.  I. 
820|New Trellis Codes Based on Lattices and Cosets| A new technique is proposed for constructing trellis codes, which provides an alternative to Ungerboeck’s method of “set partitioning.” The new codes use a signal constellation consisting of points,from an n-dimensional lattice A, with an equal number of hints from each coset of a sublattice A’. One part of the input stream drives a generalized convolutional code whose outputs are co&amp;s of A’, while the other part selects points from these cosets. Several of the new codes are better than those previously known. 
821|Combined Effect of Phase Sweeping Transmitter Diversity and Channel Coding|Abstract-A two-branch phase sweeping transmitter diversity scheme that can produce forced fast fading at the receiver is proposed for improving the effect of channel coding on bit error rate (BER) performance in very slow multipath fading environments. While the proposed transmitter diversity requires two transmit antennas, a single receive antenna can be used. Hence, it is most applicable for digital paging systems that require very simple receivers. The digital modulated signal is transmitted simultaneously from the two spatially separated an-tennas, with the carrier for one antenna being phase modulated by the phase sweeping function 9(t). Two sweeping functions are considered:  ~  ( t)  = A 0 s i n ( 2 r f ~ t)  (sinusoidal) and 2 7 r f ~ t (linear). An analysis shows that when bit interleaving of m-bit depth is used, it is required that A 0&gt; r and mnfHT&gt; 112 (sinusoidal) or&gt;1 (linear) where n is the codeword length of the error correction code and T is the bit length of the digital transmission. When 32-kbps transmission with m = 10-bits interleaving and BCH (23,12) error correction code (n = 23) are used, fa = 70 Hz is sufficient for the sinusoidal phase sweeping function. Therefore, bandwidth expansion due to phase sweeping is negligible. Experimental results on transmitter diver-sity with the sinusoidal phase sweeping function are presented for 32 kbps quarternary differential phase shift keying (QDPSK) with differential detection. I.
822|Static Scheduling of Synchronous Data Flow Programs for Digital Signal Processing|Large grain data flow (LGDF) programming is natural and convenient for describing digital signal processing (DSP) systems, but its runtime overhead is costly in real time or cost-sensitive applications. In some situations, designers are not willing to squander computing resources for the sake of program-mer convenience. This is particularly true when the target machine is a programmable DSP chip. However, the runtime overhead inherent in most LGDF implementations is not required for most signal processing systems because such systems are mostly synchronous (in the DSP sense). Synchronous data flow (SDF) differs from traditional data flow in that the amount of data produced and consumed by a data flow node is specified a priori for each input and output. This is equivalent to specifying the relative sample rates in signal processing system. This means that the scheduling of SDF nodes need not be done at runtime, but can be done at compile time (statically), so the runtime overhead evaporates. The sample rates can all be different, which is not true of most current data-driven digital signal processing programming methodologies. Synchronous data flow is closely related to computation graphs, a special case of Petri nets. This self-contained paper develops the theory necessary to statically schedule SDF programs on single or multiple proces-sors. A class of static (compile time) scheduling algorithms is proven valid, and specific algorithms are given for scheduling SDF systems onto single or multiple processors. 
823|Petri Nets|Over the last decade, the Petri net has gamed increased usage and acceptance as a basic model of systems of asynchronous concurrent computation. This paper surveys the basic concepts and uses of Petm nets. The structure of Petri nets, their markings and execution, several examples of Petm net models of computer hardware and software, and
824|Operator scheduling in data stream systems| In many applications involving continuous data streams, data arrival is bursty and data rate fluctuates over time. Systems that seek to give rapid or real-time query responses in such an environment must be prepared to deal gracefully with bursts in data arrival without compromising system performance. We discuss one strategy for processing bursty streams – adaptive, load-aware scheduling of query operators to minimize resource consumption during times of peak load. We show that the choice of an operator scheduling strategy can have significant impact on the runtime system memory usage as well as output latency. Our aim is to design a scheduling strategy that minimizes the maximum runtime system memory while maintaining the output latency within prespecified bounds. We first present Chain scheduling, an operator scheduling strategy for data stream systems that is
825|On the Self-similar Nature of Ethernet Traffic (Extended Version)  (1994) | We demonstrate that Ethernet LAN traffic is statistically self-similar, that none of the commonly used traffic models is able to capture this fractal-like behavior, that such behavior has serious implications for the design, control, and analysis of high-speed, cell-based networks, and that aggregating streams of such traffic typically intensifies the self-similarity (“burstiness”) instead of smoothing it. Our conclusions are supported by a rigorous statistical analysis of hundreds of millions of high quality Ethernet traffic measurements collected between 1989 and 1992, coupled with a discussion of the underlying mathematical and statistical properties of self-similarity and their relationship with actual network behavior. We also present traffic models based on self-similar stochastic processes that provide simple, accurate, and realistic descriptions of traffic scenarios expected during B-ISDN deployment. 
827|Predicate Migration: Optimizing Queries with Expensive Predicates|. The traditional focus of relational query optimization schemes has been on the choice of join methods and join orders. Restrictions have typically been handled in query optimizers by &#034;predicate pushdown&#034; rules, which apply restrictions in some random order before as many joins as possible. These rules work under the assumption that restriction is essentially a zero-time operation. However, today&#039;s extensible and object-oriented database systems allow users to define time-consuming functions, which may be used in a query&#039;s restriction and join predicates. Furthermore, SQL has long supported subquery predicates, which may be arbitrarily time-consuming to check. Thus restrictions should not be considered zero-time operations, and the model of query optimization must be enhanced. In this paper we develop a theory for moving expensive predicates in a query plan so that the total cost of the plan --- including the costs of both joins and restrictions --- is minimal. We present an algorithm to implement the theory, as well as results of our implementation in POSTGRES. Our experience with the newly enhanced POSTGRES query optimizer demonstrates that correctly optimizing queries with expensive predicates often produces plans that are orders of magnitude faster than plans generated by a traditional query optimizer. The additional complexity of considering expensive predicates during optimization is found to be manageably small. 1
828|Optimization of queries with user-defined predicates|Relational databases provide the ability to store user-defined functions and predicates which can be invoked in SQL queries. When evaluation of a user-defined predicate is relatively expensive, the traditional method of evaluating predicates as early as possible is no longer a sound heuristic. There are two previous approaches for optimizing such queries. However, neither is able to guarantee the optimal plan over the desired execution space. We present efficient techniques that are able to guarantee the choice of an optimal plan over the desired execution space. The naive optimization algorithm is very general, and therefore is most widely applicable. The optimization algorithm with complete rank-ordering improves upon the naive optimization algorithm by exploiting the nature of the cost formulas for join methods and is polynomial in the number of user-defined predicates (for a given number of relations). We also propose pruning rules that significantly reduce the cost of searching the execution space for both the naive algorithm as well as for the optimization algorithm with complete rank-ordering, without compromising optimality. We also propose a conservative local heuristic that is simpler and has low optimization overhead. Although it is not always guaranteed to find the optimal plans, it produces close to optimal plans in most cases. We discuss how, depending on application requirements, to determine the algorithm of choice. It should be emphasized that our optimization algorithms handle user-defined selections as well as user-defined join predicates uniformly. We present complexity analysis and experimental comparison of the algorithms.
829|Operator Scheduling in a Data Stream Manager|Many stream-based applications have sophisticated data processing requirements and real-time performance expectations that need to be met under asynchronous, time-varying data streams. In order to address these challenges, we propose novel operator scheduling approaches that specify (1) which operators to schedule (2) in which order to schedule the operators, and (3) how many tuples to process at each execution; and study them in the context of the Aurora data stream manager. We argue and provide experimental evidence that a fine-grained scheduling approach in combination with various scheduling techniques (such as batching of operators and tuples) can significantly improve the efficiency by reducing various system overheads. We also discuss application-aware extensions that address Quality of Service (QoS) issues by making scheduling decisions according to tuple processing delays and per-application QoS specifications. Finally, we present prototype-based experimental results that characterize the efficiency and effectiveness of our approaches under various stream workloads and processing scenarios. 1
830|Scheduling Algorithms|Introduction  Scheduling theory is concerned with the optimal allocation of scarce resources to activities over time. The practice of this field dates to the first time two humans contended for a shared resource and developed a plan to share it without bloodshed. The theory of the design of algorithms for scheduling is younger, but still has a significant history---the earliest papers in the field were published more than forty years ago. Scheduling problems arise in a variety of settings, as is illustrated by the following examples:  Example 1: Consider the central processing unit of a computer that must process a sequence of jobs that arrive over time. In what order should the jobs be processed in order to minimize, on average, the time that a job is in the system from arrival to completion?  Example 2: Consider a team of five astronauts preparing for the reentry of their space shuttle into the at
831|Cost-based Query Scrambling for Initial Delays|Remote data access from disparate sources across a wide-area network such as the Internet is problematic due to the unpredictable nature of the communications medium and the lack of knowledge about the load and potential delays at remote sites. Traditional, static, query processing approaches break down in this environment because they are unable to adapt in response to unexpected delays. Query scrambling has been proposed to address this problem. Scrambling modifies query execution plans on-the-fly when delays are encountered during runtime. In its original formulation, scrambling was based on simple heuristics, which although providing good performance in many cases, were also shown to be susceptible to problems resulting from bad scrambling decisions. In this paper we address these shortcomings by investigating ways to exploit query optimization technology to aid in making intelligent scrambling choices. We propose three different approaches to using query optimization for scramblin...
832|Dynamic Query Operator Scheduling for Wide-Area Remote Access|Distributed databases operating over wide-area networks such as the Internet, must deal with the unpredictable nature of the performance of communication. The response times of accessing remote sources can vary widely due to network congestion, link failure, and other problems. In such an unpredictable environment, the traditional iterator-based query execution model performs poorly. We have developed a class of methods, called query scrambling, for dealing explicitly with the problem of unpredictable response times. Query scrambling dynamically modifies query execution plans on-the-fly in reaction to unexpected delays in data access. In this paper we focus on the dynamic scheduling of query operators in the context of query scrambling. We explore various choices for dynamic scheduling and examine, through a detailed simulation, the effects of these choices. Our experimental environment considers pipelined and non-pipelined join processing in a client with multiple remote data sources ...
833|Long-Range Dependence and Data Network Traffic|This is an overview of a relatively recent application of long-range dependence (LRD) to the area of communication networks, in particular to problems concerned with the dynamic nature of packet flows in high-speed data networks such as the Internet. We demonstrate that this new application area offers unique opportunities for significantly advancing our understanding of LRD and related phenomena. These advances are made possible by moving beyond the conventional approaches associated with the wide-spread &#034;black-box&#034; perspective of traditional time series analysis and exploiting instead the physical mechanisms that exist in the networking context and that are intimately tied to the observed characteristics of measured network traffic. In order to describe this complexity we provide a basic understanding of the design, architecture and operations of data networks, including a description of the TCP/IP protocols used in today&#039;s Internet. LRD is observed in the large scale behavior of the data traffic and we provide a physical explanation for its presence. LRD tends to be caused by user and application characteristics and has little to do with the network itself. The network affects mostly small time scales, and this is why a rudimentary understanding of the main protocols is important. We illustrate why multifractals may be relevant for describing some aspects of the highly irregular traffic behavior over small time scales. We distinguish between a time-domain and wavelet-domain approach to analyzing the small time scale dynamics and discuss why the wavelet-domain approach appears to be better suited than the time-domain approach for identifying features in measured traffic (e.g., relatively regular traffic patterns over certain time scales) that have a direct networking interpretation (e....
834|Memory Allocation Strategies for Complex Decision Support Queries|Complex decision support queries, as exemplified by the TPC-D benchmark, make heavy use of join, aggregation and sorting operations. These operations can be very memory intensive and it is unlikely (particularly in a multi-user environment) that a database system will always have enough memory to completely satisfy the demands of all concurrently running operators. In this paper we propose, analyze and evaluate four different algorithms that distribute available memory among operators in ways that satisfy all operator requirements and concurrent schedulability constraints. One of these algorithms, based on linear programming, is also optimal in that it is guaranteed to produce the best query response time. We also show how these algorithms can be extended to work on shared-nothing parallel database systems. All the proposed strategies are completely general and can be used with any extended relational operations that show a linear improvement in performance with increased memory availa...
835|Caching Queues in Memory Buffers|Motivated by the need for maintaining multiple, large queues of data in modern high-performance systems, we study the problem of caching queues in memory under the following simple, but widely applicable, model. At each clock-tick, any number of data items may enter the various queues, while data-items are consumed from the heads of the queues. Since the number of unconsumed items may exceed memory buffer size, some items in the queues need to be spilled to secondary storage and later moved back into memory for consumption. We provide online queue-caching algorithms under a number of interesting cost models. 1
836|Conceptual Modelling of Computations on Data Streams|This paper proposes a new symbolic language for the conceptual modelling of computations on data streams. We consider a class of algorithms related to the evaluation of mathematical operators on data streams. A vector model is defined to represent the sliding windows. A graph abstraction is used to model the algorithms. The notation is general enough to be used for visualisation and  optimisation of a wide class of data stream processing applications.
837|Context Aggregation and Dissemination in Ubiquitous Computing Systems|Many &#034;ubiquitous computing&#034; applications need a constant flow of information about their environment to be able to adapt to their changing context. To support these &#034;context-aware&#034; applications we propose a graph-based abstraction for collecting, aggregating, and disseminating context information. The abstraction models context information as events, produced by sources and flowing through a directed acyclic graph of event-processing operators  and delivered to subscribing applications. Applications describe their desired event stream as a tree of operators that aggregate low-level context information published by existing sources into the high-level context information needed by the application. The operator graph is thus the dynamic combination of all applications&#039; subscription trees.
838|STREAM: The Stanford Stream Data Manager|The STREAM project at Stanford is developing a general-purpose system for processing continuous queries over multiple continuous data streams and stored relations. It is designed to handle high-volume and bursty data streams with large numbers of complex continuous queries. We describe the status of the system as of early 2003 and outline our ongoing research directions.
839|The eyes have it: A task by data type taxonomy for information visualizations| A useful starting point for designing advanced graphical user interjaces is the Visual lnformation-Seeking Mantra: overview first, zoom and filter, then details on demand. But this is only a starting point in trying to understand the rich and varied set of information visualizations that have been proposed in recent years. This paper offers a task by data type taxonomy with seven data types (one-, two-, three-dimensional datu, temporal and multi-dimensional data, and tree and network data) and seven tasks (overview, Zoom, filter, details-on-demand, relate, history, and extracts). 
840|Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays|This paper offers new principles for visual information seeking (VIS). A key concept is to support browsing, which is distinguished from familiar query composition and information retrieval because of its emphasis on rapid filtering to reduce result sets, progressive refinement of search parameters, continuous reformulation of goals, and visual scanning to identify results. VIS principles developed include: dynamic query filters (query parameters are rapidly adjusted with sliders, buttons, maps, etc.), starfield displays (two-dimensional scatterplots to structure result sets and zooming to reduce clutter), and tight coupling (interrelating query components to preserve display invariants and support progressive refinement combined with an emphasis on using search output to foster search input). A FilmFinder prototype using a movie database demonstrates these principles in a VIS environment.
841|Tree visualization with Tree-maps: A 2-d space-filling approach|this paper deals with a two-dimensional (2-d) space-filling approach in which each node is a rectangle whose area is proportional to some attribute such as node size. Research on relationships between 2-d images and their representation in tree structures has focussed on node and link representations of 2-d images. This work includes quad-trees (Samet, 1989) and their variants which are important in image processing. The goal of quad trees is to provide a tree representation for storage compression and efficient operations on bit-mapped images. XY-trees (Nagy &amp; Seth, 1984) are a traditional tree representation of two-dimensional layouts found in newspaper, magazine, or book pages. Related concepts include k-d trees (Bentley and Freidman, 1979), which are often explained with the help of a
842|Treemaps: a space-filling approach to the visualization of hierarchical information structures|This paper describes a novel methodfor the visualization of hierarchically structured information. The Tree-Map visualization technique makes 100 % use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information. 1
843|The Table Lens: Merging Graphical and Symbolic Representations in an Interactive Focus+Context Visualization for Tabular Information|We present a new visualization, called the Table Lens, for visualizing and making sense of large tables. The visualization uses a focus context (fisheye) technique that works effectively on tabular information because it allows display of crucial label information and multiple distal focal areas. In addition, a graphical mapping scheme for depicting table contents has been developed for the most widespread kind of tables, the cases-by-variables table. The Table Lens fuses symbolic and graphical representations into a single coherent view that can be fluidly adjusted by the user. This fusion and interactivity enables an extremely rich and natural style of direct manipulation exploratory data analysis.
844|Dynamic Queries for Information Exploration: An Implementation and Evaluation|We designed, implemented and evaluated a new concept for direct manipulation of databases, called dynamic queries, that allows users to formulate queries with graphical widgets, such as sliders. By providing a graphical visualization of the database and search results, users can find trends and exceptions easily. Eighteen undergraduate chemistry students performed statistically significantly faster usingadynamicqueries interface compared to two interfaces both providing form fillin as input method, one with graphical visualization output and one with all-textual output. The interfaces were used to expore the periodic table of elements and search on their properties. 1. INTRODUCTION Mostdatabasesystems require the user to create andformulate a complex query, whichpresumes that the user is familiar with the logical structure of the database [4]. The queries on a database are usually expressed in high level query languages (such as SQL,QUEL). This works well for many applications, but it ...
845|Visualizing the non-visual: spatial analysis and interaction with information from test documents|This paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations andprocedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts’ mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language. 1
846|Dynamic Queries for Visual Information Seeking|Dynamic queries are a novel approach to information seeking that may enable users to cope with information overload. They allow users to see an overview of the database, rapidly (100 msec updates) explore and conveniently filter out unwanted information. Users fly through information spaces by incrementally adjusting a query (with sliders, buttons, and other filters) while continuously viewing the changing results. Dynamic queries on the chemical table of elements, computer directories, and a real estate database were built and tested in three separate exploratory experiments. These results show statistically significant performance improvements and user enthusiasm more commonly seen with video games. Widespread application seems possible but research issues remain in database and display algorithms, and user interface design. Challenges include methods for rapidly displaying and changing many points, colors, and areas; multidimensional pointing; incorporation of sound and visual displ...
847|LifeLines: Visualizing Personal Histories|LifeLines provide a general visualization environment for personal histories that can be applied to medical and court records, professional histories and other types of biographical data. A one screen overview shows multiple facets of the records. Aspects, for example medical conditions or legal cases, are displayed as individual time lines, while icons indicate discrete events, such as physician consultations or legal reviews. Line color and thickness illustrate relationships or significance, rescaling tools and filters allow users to focus on part of the information. LifeLines reduce the chances of missing information, facilitate spotting anomalies and trends, streamline access to details, while remaining tailorable and easily transferable between applications. The paper describes the use of LifeLines for youth records of the Maryland Department of Juvenile Justice and also for medical records. User&#039;s feedback was collected using a Visual Basic prototype for the youth record. Techniq...
848|Graphical Fisheye Views|A fisheye camera lens is a very wide angle lens that magnifies nearby objects while shrinking distant objects. It is a valuable tool for seeing both &#034;local detail&#034; and &#034;global context&#034; simultaneously. This paper describes a system for viewing and browsing graphs using a software analog of a fisheye lens. We first show how to implement such a view using solely geometric transformations. We then describe a more general transformation that allows global information about the graph to affect the view. Our general transformation is a fundamental extension to previous research in fisheye views.  
849|The dynamic HomeFinder: evaluating dynamic queries in a real-estate information exploration system|We designed, implemented, and evaluated a new concept for visualizing and searching databases utilizing direct manipulation called dynarruc queries. Dynamic queries allow users to formulate queries by adjusting graphical widgets, such as sliders, and see the results immediately. By providing a graphical visualization of the database and search results, users can find trends and exceptions easily. User testing was done with eighteen undergraduate students who performed significantly faster using a dynamic queries interface compared to both a natural language system and paper printouts. The interfaces were used to explore a real-estate database and find homes meeting specific search criteria. 1
850|InfoCrystal: a visual tool for information retrieval|This paper introduces a novel representation, called the I n f o C r y s t a l T M,  that can be used as a v isual i za t ion tool as well as a visual query lan-g u a g e to help users search for information. The lnfoCrysta1 visualizes all the possible relation-ships among N concepts. Users can assign relevance weights to the concepts and use thresholding to select relationships of interest. The lnfocrystal allows users to specify Boolean as well as v e c t o r-s p a c e queries graphically. Arbitrarily complex queries can be created by using the 1nfoCrystals as building blocks and organizing them in a hierarchical structure. The 1nfoCrystal enables users to explore and filter information in a flexible, dynamic and interactive way.
851|IVEE: An Information Visualization &amp; Exploration Environment|The Information Visualization and Exploration Environment (IVEE) is a system for automatic creation of dynamic queries applications. IVEE imports database relations and automatically creates environments holding visualizations and query devices. IVEE offers multiple visualizations such as maps and starfields, and multiple query devices, such as sliders, alphasliders, and toggles. Arbitrary graphical objects can be attached to database objects in visualizations. Multiple visualizations may be active simultaneously. Users can interactively lay out and change between types of query devices. Users may retrieve details-on-demand by clicking on visualization objects. An HTML file may be provided along with the database, specifying how details-ondemand information should be presented, allowing for presentation of multimedia information in database objects. Finally, multiple IVEE clients running on separate workstations on a network can communicate by letting one users actions affect the visua...
852|The Information Mural: A Technique for Displaying and Navigating Large Information Spaces|Abstract—Information visualizations must allow users to browse information spaces and focus quickly on items of interest. Being able to see some representation of the entire information space provides an initial gestalt overview and gives context to support browsing and search tasks. However, the limited number of pixels on the screen constrain the information bandwidth and make it difficult to completely display large information spaces. The Information Mural is a two-dimensional, reduced representation of an entire information space that fits entirely within a display window or screen. The Mural creates a miniature version of the information space using visual attributes, such as gray-scale shading, intensity, color, and pixel size, along with antialiased compression techniques. Information Murals can be used as stand-alone visualizations or in global navigational views. We have built several prototypes to demonstrate the use of Information Murals in visualization applications; subject matter for these views includes computer software, scientific data, text documents, and geographic information. Index Terms—Information visualization, software visualization, data visualization, focus+context, navigation, browsers. 1 INFORMATION MURALS
853|Visdb: Database exploration using multidimensional visualization|In this paper we describe the VisDB system, which allows an exploration of large databases using visualization techniques. The goal of the system is to support the query specification process by using each pixel of the display to represent one data item of the database. By arranging and coloring the pixels according to the relevance of the data items with respect to the query, the user gets a visual impression of the resulting data set. Using sliders for each condition of the query, the user may change the query dynamically and receives immediate feedback from the visual representation of the resulting data set. Different visualization techniques are available for different stages of exploration. The first technique uses multiple windows for the different query parts, providing visual feedback for each part of the query and helping the user to understand the overall result. The second technique is an extension of the first one, providing additional information by assigning two dimensions to the axes. The third technique uses a grouping of dimensions and is designed to support a focused search on smaller data sets.
854|The Alphaslider: A Compact and Rapid Selector|Research has suggested that rapid, serial, visual presentation of text (RSVP) may be an effective way to scan and search through lists of text strings in search of words, names, etc. The Alphaslider widget employs RSVP as a method for rapidly scanning and searching lists or menus in a graphical user interface environment. The Alphaslider only uses an area less than 7 cm x 2.5 cm. The tiny size of the Alphaslider allows it to be placed on a credit card, on a control panel for a VCR, or as a widget in a direct manipulation based database interface. An experiment was conducted with four Alphaslider designs which showed that novice Alphaslider users could locate one item in a list of 10,000 film titles in 24 seconds on average, an expert user in about 13 seconds.  KEYWORDS: Alphaslider, widget, selection technology, menus, dynamic queries  INTRODUCTION  Selecting items from lists is a common task in today&#039;s society. New and exciting applications for selection technology are credit card siz...
855|The Continuous Zoom: A Constrained Fisheye Technique for Viewing and Navigating Large Information Spaces|Navigating and viewing large information spaces, such as hierarchically-organized networks from complex realtime systems, suffer the problems of viewing a large space on a small screen. Distorted-view approaches, such as fisheye techniques, have great potential to reduce these problems by representing detail within its larger context but introduce new issues of focus, transition between views and user disorientation from excessive distortion. We present a fisheyebased method which supports multiple focus points, enhances continuity through smooth transitions between views, and maintains location constraints to reduce the user’s sense of spatial disorientation. These are important requirements for the representation and navigation of networked systems in supervisory control applications. The method consists of two steps: a global allocation of space to rectangular sections of the display, based on scale factors, followed by degree-of-interest adjustments. Previous versions of the algorithm relied solely on relative scale factors to assign size; we present a new version which allocates space more efficiently using a dynamically calculated degree of interest. In addition to the automatic system sizing, manual user control over the amount of space assigned each area is supported. The amount of detail shown in various parts of the network is controlled by pruning the hierarchy and presenting those sections in summary form. KEYWORDS: graphical user interface, supervisory control systems, information space, hierarchical network, information visualization, fisheye view, navigation.
856|Enhanced Dynamic Queries via Movable Filters|Traditional database query systems allow users to construct complicated database queries from specialized database language primitives. While powerful and expressive, such systems are not easy to use, especially for browsing or exploring the data. Information visualization systems address this problem by providing graphical presentations of the data and direct manipulation tools for exploring the data. Recent work in this area has reported the value of dynamic queries coupled with two-dimensional data representations for progressive refinement of user queries. However, the queries generated by these systems are limited to conjunctions of global ranges of parameter values. In this paper, we extend dynamic queries by encoding each operand of the query as a Magic Lens filter. Compound queries can be constructed by overlapping the lenses. Each lens includes a slider and a set of buttons to control the value of the filter function and to define the compostion operation generated by overlapp...
857|Navigating Large Networks with Hierarchies|This paper is aimed at the exploratory visualization of networks where there is a strength or weight associated with each link, and makes use of any hierarchy present on the nodes to aid the investigation of large networks. It describes a method of placing nodes on the plane that gives meaning to their relative positions. The paper discusses how linking and interaction principles aid the user in the exploration. Two examples are given; one of electronic mail communication over eight months within a department, another concerned with changes to a large section of a computer program. I. THE PROBLEM It has almost become a clichŽ to start a paper with the observation that the amount of data in the world is growing rapidly, and that current efforts to extract useful information from data lag far behind the ability to create data. However the clichŽ is true, and no less so in the field of network analysis and visualization than in any other. In many areas, scientists are realizing that the tools they have been using are limited in utility when applied to large, information-rich networks. Not only are networks of interest large in terms of size (as measured by number of nodes or links between nodes), but also in terms of the data collected for each node or link. The ability to examine statistics on the nodes and relate them to the network is of crucial importance. Examples of areas in which the analysis of large networks is important include: i. Trade flows. The concern in this area is monitoring imports and exports of various products at several levels; international, interstate and local. Besides examining many types of trade goods, there is also strong interest in spotting temporal patterns. ii. Communication networks. This is an important and wide category, covering not only telecommunication networks, but also electronic mail (email), financial transaction, ATM/bank data transferal and other data distribution networks.
858|Using Aggregation and Dynamic Queries for Exploring Large Data Sets|When working with large data sets, users perform three primary types of activities: data manipulation, data analysis, and data visualization. The data manipulation process involves the selection and transformation of data prior to viewing. This paper addresses user goals for this process and the interactive interface mechanisms that support them. We consider three classes of data manipulation goals: controlling the scope (selecting the desired portion of the data), selecting the focus of attention (concentrating on the attributes of data that are relevant to current analysis), and choosing the level of detail (creating and decomposing aggregates of data). We use this classification to evaluate the functionality of existing data exploration interface techniques. Based on these results, we have expanded an interface mechanism called the Aggregate Manipulator (AM) and combined it with Dynamic Query (DQ) to provide complete coverage of the data manipulation goals. We use real estate sales data to demonstrate how the AM and DQ synergistically function in our interface.
859|Interacting with Huge Hierarchies: Beyond Cone Trees|This paper describes an implementation of a tool for visualizing and interacting with huge information hierarchies. Existing systems for visualizing huge hierarchies using cone trees &#034;break down&#034; once the hierarchy to be displayed exceeds roughly 1000 nodes, due to increasing visual clutter. This paper describes a system called fsviz which visualizes arbitrarily large hierarchies while retaining user control. This is accomplished by augmenting cone trees with several graphical and interaction techniques: usage-based filtering, animated zooming, handcoupled rotation, fish-eye zooming, coalescing of nodes, texturing, effective use of colour for depth cueing, and the applications of dynamic queries. The fsviz system also improves upon earlier cone tree visualization systems through a more elaborate node layout algorithm. This algorithm enhances the usefulness of cone tree visualization for large hierarchies by all but eliminating clutter.  Keywords: Information Visualization, Information ...
860|Using treemaps to visualize the Analytic Hierarchy Process|this article. References
861|Exploratory Access to Geographic Data Based on the Map-Overlay Metaphor|Many geographic information systems (GISs) attempt to imitate the manual process of laying transparent map layers over one another on a light table and analyzing the resulting configurations. While this map-overlay metaphor, familiar to many geo-scientists, has been used as a design principle for the underlying architecture of GISs, it has not yet been visually manifested at the user interface. To overcome this shortage, a new direct manipulation user interface for overlay-based GISs has been designed and prototyped. It is characterized by the separation of map layers into data cubes and map templates such that different thematic data can be combined and the same kind of data can be displayed in different formats. This paper introduces the conceptual objects that the user manipulates at the screen surface and discusses ways to visualize effectively the objects and operations upon them.
862|Visualizing Network Data|Networks are critical to modern society, and a thorough understanding of how they behave is crucial to their efficient operation. Fortunately, data on networks is plentiful; by visualizing this data, it is possible to greatly improve our understanding. Our focus is on visualizing the data associated with a network and not on simply visualizing the structure of the network itself. We begin with three static network displays; two of these use geographical relationships, while the third is a matrix arrangement that gives equal emphasis to all network links. Static displays can be swamped with large amounts of data; hence we introduce directmanipulation techniques that permit the graphs to continue to reveal relationships in the context of much more data. In effect, the static displays are parameterized so that interesting views may easily be discovered interactively. The software to carry out this network visualization is called SeeNet.  1. INTRODUCTION  We are currently in the midst of a...
863|Dryad: Distributed Data-Parallel Programs from Sequential Building Blocks|Dryad is a general-purpose distributed execution engine for coarse-grain data-parallel applications. A Dryad applica-tion combines computational “vertices ” with communica-tion “channels ” to form a dataflow graph. Dryad runs the application by executing the vertices of this graph on a set of available computers, communicating as appropriate through files, TCP pipes, and shared-memory FIFOs. The vertices provided by the application developer are quite simple and are usually written as sequential programs with no thread creation or locking. Concurrency arises from Dryad scheduling vertices to run simultaneously on multi-ple computers, or on multiple CPU cores within a computer. The application can discover the size and placement of data at run time, and modify the graph as the computation pro-gresses to make efficient use of the available resources. Dryad is designed to scale from powerful multi-core sin-gle computers, through small clusters of computers, to data centers with thousands of computers. The Dryad execution engine handles all the difficult problems of creating a large distributed, concurrent application: scheduling the use of computers and their CPUs, recovering from communication or computer failures, and transporting data between ver-tices.
864|PVM: A Framework for Parallel Distributed Computing|The PVM system is a programming environment for the development and execution of large concurrent or parallel applications that consist of many interacting, but relatively independent, components. It is intended to operate on a collection of heterogeneous computing elements interconnected by one or more networks. The participating processors may be scalar machines, multiprocessors, or special-purpose computers, enabling application components to execute on the architecture most appropriate to the algorithm. PVM provides a straightforward and general interface that permits the description of various types of algorithms (and their interactions), while the underlying infrastructure permits the execution of applications on a virtual computing environment that supports multiple parallel computation models. PVM contains facilities for concurrent, sequential, or conditional execution of application components, is portable to a variety of architectures, and supports certain forms of error dete...
865|Cilk: An Efficient Multithreaded Runtime System|Cilk (pronounced &#034;silk&#034;) is a C-based runtime system for multithreaded parallel programming. In this paper, we document the efficiency of the Cilk work-stealing scheduler, both empirically and analytically. We show that on real and synthetic applications, the &#034;work&#034; and &#034;critical-path length&#034; of a Cilk computation can be used to model performance accurately. Consequently, a Cilk programmer can focus on reducing the computation&#039;s work and critical-path length, insulated from load balancing and other runtime scheduling issues. We also prove that for the class of &#034;fully strict&#034; (well-structured) programs, the Cilk scheduler achieves space, time, and communication bounds all within a constant factor of optimal. The Cilk
866|Distributed Computing in Practice: The Condor Experience|Since 1984, the Condor project has enabled ordinary users to do extraordinary computing. Today, the project continues to explore the social and technical problems of cooperative computing on scales ranging from the desktop to the world-wide computational grid. In this chapter, we provide the history and philosophy of the Condor project and describe how it has interacted with other projects and evolved along with the field of distributed computing. We outline the core components of the Condor system and describe how the technology of computing must correspond to social structures. Throughout, we reflect on the lessons of experience and chart the course traveled by research ideas as they grow into production systems.
867|Cluster-Based Scalable Network Services|This paper has benefited from the detailed and perceptive comments of our reviewers, especially our shepherd Hank Levy. We thank Randy Katz and Eric Anderson for their detailed readings of early drafts of this paper, and David Culler for his ideas on TACC&#039;s potential as a model for cluster programming. Ken Lutz and Eric Fraser configured and administered the test network on which the TranSend scaling experiments were performed. Cliff Frost of the UC Berkeley Data Communications and Networks Services group allowed us to collect traces on the Berkeley dialup IP network and has worked with us to deploy and promote TranSend within Berkeley. Undergraduate researchers Anthony Polito, Benjamin Ling, and Andrew Huang implemented various parts of TranSend&#039;s user profile database and user interface. Ian Goldberg and David Wagner helped us debug TranSend, especially through their implementation of the rewebber
869|Interpreting the Data: Parallel Analysis with Sawzall |Very large data sets often have a flat but regular structure and span multiple disks and machines. Examples include telephone call records, network logs, and web document repositories. These large data sets are not amenable to study using traditional database techniques, if only because they can be too large to fit in a single relational database. On the other hand, many of the analyses done on them can be expressed using simple, easily distributed computations: filtering, aggregation, extraction of statistics, and so on. We present a system for automating such analyses. A filtering phase, in which a query is expressed using a new procedural programming language, emits data to an aggregation phase. Both phases are distributed over hundreds or even thousands of computers. The results are then collated and saved to a file. The design—including the separation into two phases, the form of the programming language, and the properties of the aggregators—exploits the parallelism inherent in having data and computation distributed across many machines. 1
870|The Gamma database machine project|This paper describes the design of the Gamma database machine and the techniques employed in its implementation. Gamma is a relational database machine currently operating on an Intel iPSC/2 hypercube with 32 processors and 32 disk drives. Gamma employs three key technical ideas which enable the architecture to be scaled to 100s of processors. First, all relations are horizontally partitioned across multiple disk drives enabling relations to be scanned in parallel. Second, novel parallel algorithms based on hashing are used to implement the complex relational operators such as join and aggregate functions. Third, dataflow scheduling techniques are used to coordinate multioperator queries. By using these techniques it is possible to control the execution of very complex queries with minimal coordination- a necessity for configurations involving a very large number of processors. In addition to describing the design of the Gamma software, a thorough performance evaluation of the iPSC/2 hypercube version of Gamma is also presented. In addition to measuring the effect of relation size and indices on the response time for selection, join, aggregation, and update queries, we also analyze the performance of Gamma relative to the number of processors employed when the sizes of the input relations are kept constant (speedup) and when the sizes of the input relations are increased proportionally to the number of processors (scaleup). The speedup results obtained for both selection and join queries are linear; thus, doubling the number of processors
871|Programming Parallel Algorithms|In the past 20 years there has been treftlendous progress in developing and analyzing parallel algorithftls. Researchers have developed efficient parallel algorithms to solve most problems for which efficient sequential solutions are known. Although some ofthese algorithms are efficient only in a theoretical framework, many are quite efficient in practice or have key ideas that have been used in efficient implementations. This research on parallel algorithms has not only improved our general understanding ofparallelism but in several cases has led to improvements in sequential algorithms. Unf:ortunately there has been less success in developing good languages f:or prograftlftling parallel algorithftls, particularly languages that are well suited for teaching and prototyping algorithms. There has been a large gap between languages
872|Programmable stream processors|The Imagine Stream Processor is a single-chip programmable media processor with 48 parallel ALUs. At 400 MHz, this translates to a peak arithmetic rate of 16 GFLOPS on single-precision data and 32 GOPS on 16bit fixed-point data. The scalability of Imagine’s programming model and architecture enable it to achieve such high arithmetic rates. Imagine executes applications that have been mapped to the stream programming model. The stream model decomposes applications into a set of computation kernels that operate on data streams. This mapping exposes the inherent locality and parallelism in the application, and Imagine exploits the locality and parallelism to provide a scalable architecture that supports 48 ALUs on a single chip. This paper presents the Imagine architecture and programming model in the first half, and explores the scalability of the Imagine architecture in the second half. 1.
873|Accelerator: using data parallelism to program GPUs for general-purpose uses|GPUs are difficult to program for general-purpose uses. Programmers can either learn graphics APIs and convert their applications to use graphics pipeline operations or they can use stream programming abstractions of GPUs. We describe Accelerator, a system that uses data parallelism to program GPUs for general-purpose uses instead. Programmers use a conventional imperative programming language and a library that provides only high-level data-parallel operations. No aspects of GPUs are exposed to programmers. The library implementation compiles the data-parallel operations on the fly to optimized GPU pixel shader code and API calls. We describe the compilation techniques used to do this. We evaluate the effectiveness of using data parallelism to program GPUs by providing results for a set of compute-intensive benchmarks. We compare the performance of Accelerator versions of the benchmarks against hand-written pixel shaders. The speeds of the Accelerator versions are typically within 50 % of the speeds of hand-written pixel shader code. Some benchmarks significantly outperform C versions on a CPU: they are up to 18 times faster than C code running on a CPU.
874|Using Cohort Scheduling to Enhance Server Performance|A server application is commonly organized as a collection of concurrent threads, each of which executes the code necessary to process a request. This software architecture, which causes frequent control transfers between unrelated pieces of code, decreases instruction and data locality, and consequently reduces the effec- tiveness of hardware mechanisms such as caches, TLBs, and branch predictors. Numerous measurements demonstrate this effect in server applications, which often utilize only a fraction of a modern processor&#039;s computational throughput.
875|The CODE 2.0 Graphical Parallel Programming Language |CODE 2.0 is a graphical parallel programming system that targets the three goals of ease of use, portability, and production of efficient parallel code. Ease of use is provided by an integrated graphical/textual interface, a powerful dynamic model of parallel computation, and an integrated concept of program component reuse. Portability is approached by the declarative expression of synchronization and communication operators at a high level of abstraction in a manner which cleanly separates overall computation structure from the primitive sequential computations that make up a program. Execution efficiency is approached through a systematic class hierarchy that supports hierarchical translation refinement including special case recognition. This paper reports results obtained through experimental use of a prototype implementation of the CODE 2.0 system. CODE 2.0 represents a major conceptual advance over its predecessor systems (CODE 1.0 and CODE 1.2) in terms of the expressive power ...
876|Stream Computations Organized for Reconfigurable Execution (SCORE): Introduction and Tutorial  (2000) |A primary impediment to wide-spread exploitation of reconfigurable computing is the lack of a unifying computational model which allows application portability and longevity without sacrificing a substantial fraction of the raw capabilities. We introduce SCORE (Stream Computation Organized for Reconfigurable Execution), a streambased compute model which virtualizes reconfigurable computing resources (compute, storage, and communication) by dividing a computation up into fixed-size &#034;pages&#034; and time-multiplexing the virtual pages on available physical hardware. Consequently, SCORE applications can scale up or down automatically to exploit a wide range of hardware sizes. We hypothesize that the SCORE model will ease development and deployment of reconfigurable applications and expand the range of applications which can benefit from reconfigurable execution. Further, we believe that a well engineered SCORE implementation can be efficient, wasting little of the capabilities of the raw hardw...
877|Paralex: An Environment for Parallel Programming in Distributed Systems|Modern distributed systems consisting of powerful workstations and high-speed interconnection networks are an economical alternative to special-purpose super computers. The technical issues that need to be addressed in exploiting the parallelism inherent in a distributed system include heterogeneity, high-latency communication, fault tolerance and dynamic load balancing. Current software systems for parallel programming provide little or no automatic support towards these issues and require users to be experts in fault-tolerant distributed computing. The Paralex system is aimed at exploring the extent to which the parallel application programmer can be liberated from the complexities of distributed systems. Paralex is a complete programming environment and makes extensive use of graphics to define, edit, execute and debug parallel scientific applications. All of the necessary code for distributing the computation across a network and replicating it to achieve fault tolerance and dynamic load balancing is automatically generated by the system. In this paper we give an overview of Paralex and present our experiences with a prototype implementation.
878|Parallel and Distributed Haskells|Parallel and distributed languages specify computations on multiple processors and have a computation language to describe the algorithm, i.e. what to compute, and a coordination language to describe how to organise the computations across the processors. Haskell has been used as the computation language for a wide variety of parallel and distributed languages, and this paper is a comprehensive survey of implemented languages. We outline parallel and distributed language concepts and classify Haskell extensions using them. Similar example programs are used to illustrate and contrast the coordination languages, and the comparison is facilitated by the common computation language. A lazy language is not an obvious choice for parallel or distributed computation, and we address the question of why Haskell is a common functional computation language.
879|Highly Available, Fault-Tolerant, Parallel Dataflows|We present a technique that masks failures in a cluster to provide high availability and fault-tolerance for long-running, parallelized dataflows. We can use these dataflows to implement a variety of continuous query (CQ) applications that require high-throughput, 24x7 operation. Examples include network monitoring, phone call processing, click-stream processing, and online financial analysis. Our main contribution is a scheme that carefully integrates traditional query processing techniques for partitioned parallelism with the process-pairs approach for high availability. This delicate integration allows us to tolerate failures of portions of a parallel dataflow  without sacrificing result quality. Upon failure, our technique provides quick fail-over, and automatically recovers the lost pieces on the fly. This piecemeal recovery provides minimal disruption to the ongoing dataflow computation and improved reliability as compared to the straight-forward application of the process-pairs technique on a per dataflow basis. Thus, our technique provides the high availability necessary for critical CQ applications. Our techniques are encapsulated in a reusable dataflow operator called Flux, an extension of the Exchange that is used to compose parallel dataflows. Encapsulating the fault-tolerance logic into Flux minimizes modifications to existing operator code and relieves the burden on the operator writer of repeatedly implementing and verifying this critical logic. We present experiments illustrating these features with an implementation of Flux in the TelegraphCQ code base [8].
880|A comparison of stream-oriented high availability algorithms|Recently, significant efforts have focused on developing novel data-processing systems to support a new class of applications that commonly require sophisticated and timely processing of high-volume data streams. Early work in stream processing has primarily focused on streamoriented languages and resource-constrained, one-pass query-processing. High availability, an increasingly important goal for virtually all data processing systems, is yet to be addressed. In this paper, we first describe how the standard highavailability approaches used in data management systems can be applied to distributed stream processing. We then propose a novel stream-oriented approach that exploits the unique data-flow nature of streaming systems. Using analysis and a detailed simulation study, we characterize the performance of each approach and demonstrate that the stream-oriented algorithm significantly reduces runtime overhead at the expense of a small increase in recovery time. 1
881|Eraser: a dynamic data race detector for multithreaded programs|Multi-threaded programming is difficult and error prone. It is easy to make a mistake in synchronization that produces a data race, yet it can be extremely hard to locate this mistake during debugging. This paper describes a new tool, called Eraser, for dynamically detecting data races in lock-based multi-threaded programs. Eraser uses binary rewriting techniques to monitor every shared memory reference and verify that consistent locking behavior is observed. We present several case studies, including undergraduate coursework and a multi-threaded Web search engine, that demonstrate the effectiveness of this approach. 1
882|Atom: A system for building customized program analysis tools|research relevant to the design and application of high performance scientific computers. We test our ideas by designing, building, and using real systems. The systems we build are research prototypes; they are not intended to become products. There is a second research laboratory located in Palo Alto, the Systems Research Center (SRC). Other Digital research groups are located in Paris (PRL) and in Cambridge,
883|Monitors: An Operating System Structuring Concept|This is a digitized copy derived from an ACM copyrighted work. It is not guaranteed to be an accurate copy of the author&#039;s original work. This paper develops Brinch-Hansen&#039;s concept of a monitor as a method of structuring an operating system. It introduces a form of synchronization, describes a possible rnctltotl of implementation in terms of semaphorcs and gives a suitable proof rule. Illustrative examples include a single rcsourcc scheduler, a bounded buffer, an alarm clock, a buffer pool, a disk head optimizer, and a version of the problem of readers and writers. Key Words and Phrases: monitors, operating systems,schcduling, mutual exclusion, synchronization, system implementation langua yes, structured multiprogramming CR Categories:
884|Extensibility, safety and performance in the SPIN operating system|This paper describes the motivation, architecture and performance of SPIN, an extensible operating system. SPIN provides an extension infrastructure, together with a core set of extensible services, that allow applications to safely change the operating system&#039;s interface and implementation. Extensions allow an application to specialize the underlying operating system in order to achieve a particular level of performance and functionality. SPIN uses language and link-time mechanisms to inexpensively export ne-grained interfaces to operating system services. Extensions are written in a type safe language, and are dynamically linked into the operating system kernel. This approach o ers extensions rapid access to system services, while protecting the operating system code executing within the kernel address space. SPIN and its extensions are written in Modula-3 and run on DEC Alpha workstations. 1
885|Petal: Distributed Virtual Disks|The ideal storage system is globally accessible, always available, provides unlimited performance and capacity for a large number of clients, and requires no management. This paper describes the design, implementation, and performance of Petal, a system that attempts to approximate this ideal in practice through a novel combination of features. Petal consists of a collection of networkconnected servers that cooperatively manage a pool of physical disks. To a Petal client, this collection appears as a highly available block-level storage system that provides large abstract containers called virtual disks. A virtual disk is globally accessible to all Petal clients on the network. A client can create a virtual disk on demand to tap the entire capacity and performance of the underlying physical resources. Furthermore, additional resources, such as servers and disks, can be automatically incorporated into Petal. We have an initial Petal prototype consisting of four 225 MHz DEC 3000/700 work...
887|Shasta: A LowOverhead Software-Only Approach to Fine-Grain Shared Memory|Digital Equipment Corporation This paper describes Shasta, a system that supports a shared address space in software on clusters of computers with physically distributed memory. A unique aspect of Shasta compared to most other software distributed shared memory systems is that shared data can be kept coherent at a fine granularity. In addition, the system allows the coherence granularity to vary across different shared data structures in a single application. Shasta implements the shared address space by transparently rewriting the application executable to intercept loads and stores. For each shared load or store, the inserted code checks to see if the data is available locally and communicates with other processors if necessary. The system uses numerous techniques to reduce the run-time overhead of these checks. Since Shasta is implemented entirely in software,
888|Experience with Processes and Monitors in Mesa|The use of monitors for describing concurrency has been much discussed in the literature. When monitors are used in real systems of any size, however, a number of problems arise which have not been adequately dealt with: the semantics of nested monitor calls; the various ways of defining the meaning of WAIT; priority scheduling; handling of timeouts, aborts and other exceptional conditions; interactions with process creation and destruction; monitoring large numbers of small objects. These problems are addressed by the facilities described here for concurrent programming in Mesa. Experience with several substantial applications gives us some confidence in the validity of our solutions.
889|On-the-fly Detection of Data Races for Programs with Nested Fork-Join Parallelism|Detecting data races in shared-memory parallel programs is an important debugging problem. This paper presents a new protocol for run-time detection of data races in executions of shared-memory programs with nested fork-join parallelism and no other interthread synchronization. This protocol has significantly smaller worst-case run-time overhead than previous techniques. The worst-case space required by our protocol when monitoring an execution of a program P is O(V N), where V is the number of shared variables in P , and N is the maximum dynamic nesting of parallel constructs in P &#039;s execution. The worst-case time required to perform any monitoring operation is O(N). We formally prove that our new protocol always reports a non-empty subset of the data races in a monitored program execution and describe how this property leads to an e#ective debugging strategy.
890|Online Data-Race Detection via Coherency Guarantees|We present the design and evaluation of an on-thefly data-race-detection technique that handles applications written for the lazy release consistent (LRC) shared memory model. We require no explicit association between synchronization and shared memory. Hence, shared accesses have to be tracked and compared at the minimum granularity of data accesses, which is typically a single word.  The novel aspect of this system is that we are able to leverage information used to support the underlying memory abstraction to perform on-the-fly data-race detection, without compiler support. Our system consists of a minimally modified version of the CVM distributed shared memory system, and instrumentation code inserted by the ATOM code re-writer.  We present an experimental evaluation of our technique by using our system to look for data races in four unaltered programs. Our system correctly found read-write data races in a program that allows unsynchronized read access to a global tour bound, and a write-write race in a program from a standard benchmark suite. Overall, our mechanism reduced program performance by approximately a factor of two.   
891|Compile-time Support for Efficient Data Race Detection in Shared-Memory Parallel Programs|Data race detection strategies based on software runtime monitoring are notorious for dramatically inflating execution times of shared-memory parallel programs. Without significant reductions in the execution overhead incurred when using these techniques, there is little hope that they will be widely used. A promising approach to this problem is to apply compile-time analysis to identify variable references that need not be monitored at run time because they will never be involved in a data race. In this paper we describe eraser, a data race instrumentation tool that uses aggressive program analysis to prune the number of references to be monitored. To quantify the effectiveness of our analysis techniques, we compare the overhead of race detection with three levels of compile-time analysis ranging from little analysis to aggressive interprocedural analysis for a suite of test programs. For the programs tested, using interprocedural analysis and dependence analysis dramatically reduced ...
892|Pig Latin: A Not-So-Foreign Language for Data Processing |There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where innovation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, offer a solution, but are usually prohibitively expensive at this scale. Besides, many of the people who analyze this data are entrenched procedural programmers, who find the declarative, SQL style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hardware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse. We describe a new language called Pig Latin that we have designed to fit in a sweet spot between the declarative style of SQL, and the low-level, procedural style of map-reduce. The accompanying system, Pig, is fully implemented, and compiles Pig Latin into physical plans that are executed over Hadoop, an open-source, map-reduce implementation. We give a few examples of how engineers at Yahoo! are using Pig to dramatically reduce the time required for the development and execution of their data analysis tasks, compared to using Hadoop directly. We also report on a novel debugging environment that comes integrated with Pig, that can lead to even higher productivity gains. Pig is an open-source, Apache-incubator project, and available for general use. 1.
893|Map-Reduce-Merge: simplified relational data processing on large clusters|than the artifacts. 2. MapReduce 3. Map-Reduce-Merge: extending MapReduce 4. Using Map-Reduce-Merge to implement
894|Algorithmic Techniques for Processing Data Streams|We give a survey at some algorithmic techniques for processing data streams. After covering the basic methods of sampling and sketching, we present more evolved procedures that resort on those basic ones. In particular, we examine algorithmic schemes for similarity mining, the concept of group testing, and techniques for clustering and summarizing data streams.
895|On the Resemblance and Containment of Documents|Given two documents A and B we define two mathematical notions: their  resemblance r(A, B)andtheircontainment c(A, B) that seem to capture well  the informal notions of &#034;roughly the same&#034; and &#034;roughly contained.&#034;  The basic idea is to reduce these issues to set intersection problems that can  be easily evaluated by a process of random sampling that can be done independently  for each document. Furthermore, the resemblance can be evaluated  using a fixed size sample for each document.
896|Randomized Search Trees|We present a randomized strategy for maintaining balance in dynamically changing search  trees that has optimal expected behavior. In particular, in the expected case a search or an  update takes logarithmic time, with the update requiring fewer than two rotations. Moreover,  the update time remains logarithmic, even if the cost of a rotation is taken to be proportional  to the size of the rotated subtree. Finger searches and splits and joins can be performed in  optimal expected time also. We show that these results continue to hold even if very little true  randomness is available, i.e. if only a logarithmic number of truely random bits are available.  Our approach generalizes naturally to weighted trees, where the expected time bounds for  accesses and updates again match the worst case time bounds of the best deterministic methods.  We also discuss ways of implementing our randomized strategy so that no explicit balance  information is maintained. Our balancing strategy and our alg...
897|Maintaining time-decaying stream aggregates|ABSTRACT We formalize the problem of maintaining time-decaying aggregates and statistics of a data stream: the relative contribution of each data item to the aggregate is scaled down by a factor that depends on, and is non-decreasing with, elapsed time. Time-decaying aggregates are used in applications where the significance of data items decreases over time. We develop storage-efficient algorithms, and establish upper and lower bounds. Surprisingly, even though maintaining decayed aggregates have become a widely-used tool, our work seems to be the first both to explore it formally and to provide storage-efficient algorithms for important families of decay functions, including polynomial decay. 1.
898|An Optimal Algorithm for the Distinct Elements Problem |We give the first optimal algorithm for estimating the number of distinct elements in a data stream, closing a long line of theoretical research on this problem begun by Flajolet and Martin in their seminal paper in FOCS 1983. This problem has applications to query optimization, Internet routing, network topology, and data mining. For a stream of indices in {1,..., n}, our algorithm computes a (1 ± e)approximation using an optimal O(e -2 +log(n)) bits of space with 2/3 success probability, where 0 &lt; e &lt; 1 is given. This probability can be amplified by independent repetition. Furthermore, our algorithm processes each stream update in O(1) worst-case time, and can report an estimate at any point midstream in O(1) worst-case time, thus settling both the space and time complexities simultaneously.
899|Min-wise independent permutations (extended abstract  (1998) |We define and study the notion of min-wise independent families of permutations. We say that F?Sn is min-wise independent if for any set X ? [n] and any x ? X, when p is chosen at random in F we have Pr ( min{p(X)}  = p(x) )  = 1 |X |. In other words we require that all the elements of any fixed set X have an equal chance to become the minimum element of the image of X under p. Our research was motivated by the fact that such a family (under some relaxations) is essential to the algorithm used in practice by the AltaVista web index software to detect and filter near-duplicate documents. However, in the course of
900|Approximation and streaming algorithms for histogram construction problems |Histograms are typically used to approximate data distributions. Histograms and related synopsis structures have been successful in a wide variety of popular database applications including approximate querying, similarity searching and data mining. Histograms were a few of the earliest synopsis structures proposed and continue to be popular tools. Typically, the histograms are used as quick and easy estimates, and thus the slight loss of accuracy can be offset by fast histogram construction algorithms. A natural question arises in this context: can we find a fast near optimal approximation algorithm for the histogram construction problem? In this paper, we give the first linear time (1 + ?)-factor approximation algorithms (for any ?&gt; 0) for several histogram construction problems. Several of our algorithms extend to data streams. We also show that our method generalizes to a large number of histogram construction problems including the use of piecewise small degree polynomials to approximate data. Using synthetic and real-life data sets, we demonstrate that the approximate histograms have almost identical quality in many scenarios and offer significant performance benefits. 1
901|REHIST: Relative error histogram construction algorithms|Histograms and Wavelet synopses provide useful tools in query optimization and approximate query answering. Traditional histogram construction algorithms, such as V-Optimal, optimize absolute error measures for which the error in estimating a true value of 10 by 20 has the same effect of estimating a true value of 1000 by 1010. However, several researchers have recently pointed out the drawbacks of such schemes and proposed wavelet based schemes to minimize relative error measures. None of these schemes provide satisfactory guarantees – and we provide evidence that the difficulty may lie in the choice of wavelets as the representation scheme. In this paper, we consider histogram construction for the known relative error measures. We develop optimal as well as fast approximation algorithms. We provide a comprehensive theoretical analysis and demonstrate the effectiveness of these algorithms in providing significantly more accurate answers through synthetic and real life data sets.
902|Optimal Sampling from Sliding Windows|A sliding windows model is an important case of the streaming model, where only the most “recent” elements remain active and the rest are discarded in a stream. The sliding windows model is important for many applications (see, e.g., Babcock, Babu, Datar, Motwani and Widom (PODS 02); and Datar, Gionis, Indyk and Motwani (SODA 02)). There are two equally important types of the sliding windows model – windows with fixed size, (e.g., where items arrive one at a time, and only the most recent n items remain active for some fixed parameter n), and bursty windows (e.g., where many items can arrive in “bursts ” at a single step and where only items from the last t steps remain active, again for some fixed parameter t). Random sampling is a fundamental tool for data streams, as numerous algorithms operate on the sampled data instead of on the entire stream. Effective sampling from sliding windows is a nontrivial problem, as elements eventually expire. In fact, the deletions are implicit; i.e., it is not possible to identify deleted elements without storing the entire window. The implicit nature of deletions on sliding windows does not allow the existing methods (even those that support explicit deletions, e.g., Cormode, Muthukrishnan and Rozenbaum (VLDB 05); Frahling, Indyk and Sohler (SOCG 05)) to be directly “translated ” to the sliding windows model. One trivial approach to overcoming the problem of implicit deletions is that of over-sampling. When k samples are required, the over-sampling method maintains k '&gt; k samples in the hope that at least k samples are not expired. The obvious disadvantages of this method are twofold: (a) It introduces additional costs and thus decreases the performance; and (b) The memory bounds are not deterministic, which is atypical for
903|Exploiting duality in summarization with deterministic guarantees|Summarization is an important task in data mining. A major chal-lenge over the past years has been the efficient construction of fixed-space synopses that provide a deterministic quality guaran-tee, often expressed in terms of a maximum-error metric. His-tograms and several hierarchical techniques have been proposed for this problem. However, their time and/or space complexities remain impractically high and depend not only on the data set size n, but also on the space budget B. These handicaps stem from a requirement to tabulate all allocations of synopsis space to different regions of the data. In this paper we develop an alternative method-ology that dispels these deficiencies, thanks to a fruitful application of the solution to the dual problem: given a maximum allowed er-ror, determine the minimum-space synopsis that achieves it. Com-pared to the state-of-the-art, our histogram construction algorithm reduces time complexity by (at least) a B log 2 n log  * factor and our hier-archical synopsis algorithm reduces the complexity by (at least) a factor of log 2 B log *+logn in time andB(1 - logBlogn) in space, where  * is the optimal error. These complexity advantages offer both a space-efficiency and a scalability that previous approaches lacked. We verify the benefits of our approach in practice by experimentation.
904|A note on linear time algorithms for maximum error histograms|permission of the IEEE. Such permission of the IEEE does not in any way imply IEEE endorsement of any of the University of Pennsylvania’s products or services. Internal or personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by writing to
905|A Digital Fountain Approach to Reliable Distribution of Bulk Data|The proliferation of applications that must reliably distribute bulk data to a large number of autonomous clients motivates the design of new multicast and broadcast prot.ocols. We describe an ideal, fully scalable protocol for these applications that we call a digital fountain. A digital fountain allows any number of heterogeneous clients to acquire bulk data with optimal efficiency at times of their choosing. Moreover, no feedback channels are needed to ensure reliable delivery, even in the face of high loss rates. We develop a protocol that closely approximates a digital fountain using a new class of erasure codes that for large block sizes are orders of magnitude faster than standard erasure codes. We provide performance measurements that demonstrate the feasibility of our approach and discuss the design, implementation and performance of an experimental system. 
906|Dissemination-based Data Delivery Using Broadcast Disks|Mobile computers and wireless networks are emerging technologies which promise to make ubiquitous computing a reality. One challenge that must be met in order to truly realize this potential is that of providing mobile clients with ubiquitous access to data. Mobile clients may often be disconnected from stationary server machines or may have only a low-bandwidth channel for sending messages to servers. Such an environment raises difficulties for supporting data-intensive applications for three reasons: 1) the inability to predict, with 100% accuracy, the future data needs of many applications, 2) limits on storage capacities of mobile machines, and 3) the need to provide clients with new or updated data values. One (and perhaps the only) way to address these challenges is to provide stationary server machines with a relatively high-bandwidth channel over which to broadcast data to a client population in anticipation of the need for that data at the clients. Such a system can be said to...
907| Mining Data Bases and Data Streams |  Data mining represents an emerging technology area of great importance to homeland security. Data mining enables knowledge discovery on databases by identifying patterns that are novel, useful, and actionable. It has proven successful in many domains, such as banking, e-commerce, genomic, investment, telecom, web analysis, link analysis, and security applications. In this chapter, we will survey the main methods and applications of data mining and the information systems recently developed for supporting the mining process. We then overview the key areas of data mining research, in particular, on-line mining of massive data streams, such as those that flow continuously on the Internet and other communication channels. We show that the traditional store-now &amp; mine-later techniques are no longer effective either because of the size of the data stream or because of the real-time response requirement. Thus new fast &amp; light algorithms and suitable systems must be developed for mining data streams.  
908|Achieving K-Anonymity Privacy Protection Using Generalization and Suppression|This paper provides a formal presentation of combining generalization and  suppression to achieve k-anonymity. Generalization involves replacing (or recoding) a  value with a less specific but semantically consistent value. Suppression involves not  releasing a value at all. The Preferred Minimal Generalization Algorithm (MinGen),  which is a theoretical algorithm presented herein, combines these techniques to provide  k-anonymity protection with minimal distortion. The real-world algorithms Datafly and  -Argus are compared to MinGen. Both Datafly and -Argus use heuristics to make  approximations, and so, they do not always yield optimal results. It is shown that Datafly  can over distort data and -Argus can additionally fail to provide adequate protection
909|A Framework for Constructing Features and Models for Intrusion Detection Systems|Intrusion detection (ID) is an important component of infrastructure protection mechanisms. Intrusion detection systems (IDSs) need to be accurate, adaptive, and extensible. Given these requirements and the complexities of today’s network environments, we need a more systematic and automated IDS development process rather than the pure knowledge encoding and engineering approaches. This article describes a novel framework, MADAM ID, for Mining Audit Data for Automated Models for Intrusion Detection. This framework uses data mining algorithms to compute activity patterns from system audit data and extracts predictive features from the patterns. It then applies machine learning algorithms to the audit records that are processed according to the feature definitions to generate intrusion detection rules. Results from the 1998 DARPA Intrusion Detection Evaluation showed that our ID model was one of the best performing of all the participating systems. We also briefly discuss our experience in converting the detection models produced by off-line data mining programs to real-time modules of existing IDSs. Categories and Subject Descriptors: C.2.0 [Computer-Communication Networks]: General—Security and protection (e.g., firewalls); C.2.3 [Computer-Communication Networks]:
910|A New SQL-like Operator for Mining Association Rules|  Data mining evolved as a collection of applicative problems and efficient solution algorithms relative to rather peculiar problems, all focused on the discovery of relevant information hidden in databases of huge dimensions. In particular, one of the most investigated topics is the discovery of association rules. This work proposes a unifying model that enables a uniform description of the problem of discovering association rules. The model provides SQL-like operator, named MINE RULE, which is capable of expressing all the problems presented so far in the literature concerning the mining of association rules. We demonstrate the expressive power of the new operator by means of several examples, some of which are classical, while some others are fully original and correspond to novel and unusual applications. We also present the operational semantics of the operator by means of an extended relational algebra. 
911|DMQL: A Data Mining Query Language for Relational Databases|The emerging data mining tools and systems lead naturally to the demand of a powerful data mining query language, on top of which many interactive and flexible graphical user interfaces can be developed. This motivates us to design a data mining query language, DMQL, for mining different kinds of knowledge in relational databases. Portions of the proposed DMQL language have been implemented in our DBMiner system for interactive mining of multiple-level knowledge in relational databases.
912|Integrating association rule mining with relational database systems: Alternatives and implications |Abstract. Data mining on large data warehouses is becoming increasingly important. In support of this trend, we consider a spectrum of architectural alternatives for coupling mining with database systems. These alternatives include: loose-coupling through a SQL cursor interface; encapsulation of a mining algorithm in a stored procedure; caching the data to a file system on-the-fly and mining; tight-coupling using primarily user-defined functions; and SQL implementations for processing in the DBMS. We comprehensively study the option of expressing the mining algorithm in the form of SQL queries using Association rule mining as a case in point. We consider four options in SQL-92 and six options in SQL enhanced with object-relational extensions (SQL-OR). Our evaluation of the different architectural alternatives shows that from a performance perspective, the Cache option is superior, although the performance of the SQL-OR option is within a factor of two. Both the Cache and the SQL-OR approaches incur a higher storage penalty than the loose-coupling approach which performance-wise is a factor of 3 to 4 worse than Cache. The SQL-92 implementations were too slow to qualify as a competitive option. We also compare these alternatives on the basis of qualitative factors like automatic parallelization, development ease, portability and inter-operability. As a byproduct of this study, we identify some primitives for native support in database systems for decision-support applications. Keywords: mining system architecture, association rule mining, database mining, mining algorithms in SQL
913|MSQL: a query language for database mining|Abstract. The tremendous number of rules generated in the mining process makes it necessary for any good data mining system to provide for powerful query primitives to post-process the generated rulebase, as well as for performing selective, query based generation. In this paper, we present the design and compilation of MSQL, the rule query language developed as part of the Discovery Board system. Keywords:
914|Incremental Mining of Frequent Patterns Without Candidate Generation Or Support |In this paper, we propose a novel data structure called CATS Tree. CATS Tree extends the idea of FPTree to improve storage compression and allow frequent pattern mining without generation of candidate itemsets. The proposed algorithms enable frequent pattern mining with different supports without rebuilding the tree structure. Furthermore, the algorithms allow mining with a single pass over the database as well as efficient insertion or deletion of transactions at any time.
915|Fast and Light Boosting for Adaptive Mining of Data Streams|Supporting continuous mining queries on data streams requires  algorithms that (i) are fast, (ii) make light demands on memory resources,  and (iii) are easily to adapt to concept drift. We propose a novel boosting  ensemble method that achieves these objectives. The technique is based on  a dynamic sample-weight assignment scheme that achieves the accuracy of  traditional boosting without requiring multiple passes through the data. The  technique assures faster learning and competitive accuracy using simpler  base models. The scheme is then extended to handle concept drift via change  detection. The change detection approach aims at significant data changes  that could cause serious deterioration of the ensemble performance, and  replaces the obsolete ensemble with one built from scratch. Experimental results  confirm the advantages of our adaptive boosting scheme over previous approaches.
916|Verifying and mining frequent patterns from large windows over data streams|Abstract — Mining frequent itemsets from data streams has proved to be very difficult because of computational complexity and the need for real-time response. In this paper, we introduce a novel verification algorithm which we then use to improve the performance of monitoring and mining tasks for association rules. Thus, we propose a frequent itemset mining method for sliding windows, which is faster than the state-of-the-art methods—in fact, its running time that is nearly constant with respect to the window size entails the mining of much larger windows than it was possible before. The performance of other frequent itemset mining methods (including those on static data) can be improved likewise, by replacing their counting methods (e.g., those using hash trees) by our verification algorithm. I.
917|Using semantic web technologies for policy management on the web |With policy management becoming popular as a means of providing flexible Web security, the number of policy lan-guages being proposed for the Web is constantly increasing. We recognize the importance of policies for securing the Web and believe that the future will only bring more policy lan-guages. We do not, however, believe that users should be forced to conform the description of their policy relationships to a single standard policy language. Instead there should be a way of encompassing different policy languages and sup-porting heterogeneous policy systems. As a step in this di-rection, we propose Rein, a policy framework grounded in Semantic Web technologies, which leverages the distributed nature and linkability of the Web to provide Web-based policy management. Rein provides ontologies for describing policy domains in a decentralized manner and provides an engine for reasoning over these descriptions, both of which can be used to develop domain and policy language specific security systems. We describe the Rein policy framework and discuss how a Rein policy management systems can be developed for access control in an online photo sharing application.
918|Converting output scores from outlier detection algorithms into probability estimates|Current outlier detection schemes typically output a numeric score representing the degree to which a given observation is an outlier. We argue that converting the scores into well-calibrated probability estimates is more favorable for several reasons. First, the probability estimates allow us to select the appropriate threshold for declaring outliers using a Bayesian risk model. Second, the probability estimates obtained from individual models can be aggregated to build an ensemble outlier detection framework. In this paper, we present two methods for transforming outlier scores into probabilities. The first approach assumes that the posterior probabilities follow a logistic sigmoid function and learns the parameters of the function from the distribution of outlier scores. The second approach models the score distributions as a mixture of exponential and Gaussian probability functions and calculates the posterior probabilites via the Bayes ’ rule. We evaluated the efficacy of both methods in the context of threshold selection and ensemble outlier detection. We also show that the calibration accuracy improves with the aid of some labeled examples. 1
919|An outlier-based data association method for linking criminal incidents|Data association is an important data-mining task and it has various applications. In crime analysis, data association means to link criminal incidents committed by the same person. It helps to discover crime patterns and catch the criminal. In this paper, we present an outlier-based data association method. An outlier score function is defined to measure the extremeness of an observation, and the data association method is developed based upon the outlier score function. We apply this method to the robbery data from Richmond, Virginia, and compare the result with a similarity-based association method. Result shows that the outlier-based data association method is promising.
920|Mining databases and data streams with query languages and rules|Abstract. Among data-intensive applications that are beyond the reach of traditional Data Base Management Systems (DBMS), data mining stands out because of practical importance and the complexity of the research problems that must be solved before the vision of Inductive DBMS can become a reality. In this paper, we first discuss technical developments that have occurred since the very notion of Inductive DBMS emerged as a result of the seminal papers authored by Imielinski and Mannila a decade ago. The research progress achieved since then can be subdivided into three main problem subareas as follows: (i) language (ii) optimization, and (iii) representation. We discuss the problems in these three areas and the different approaches to Inductive DBMS that are made possible by recent technical advances. Then, we pursue a languagecentric solution, and introduce simple SQL extensions that have proven very effective at supporting data mining. Finally, we turn our attention to the related problem of supporting data stream mining using Data Stream Management Systems (DSMS) and introduce the notion of Inductive DSMS. In addition to continuous query languages, DSMS provide support for synopses, sampling, load shedding, and other built-in functions that are needed for data stream mining. Moreover, we show that Inductive DSMS can be achieved by generalizing DSMS to assure that their continuous query languages support efficiently data stream mining applications. Thus, DSMS extended with inductive capabilities will provide a uniquely supportive environment for data stream mining applications. 1
921|Data streaming with affinity propagation |Abstract. This paper proposed StrAP (Streaming AP), extending Affinity Propagation (AP) to data steaming. AP, a new clustering algorithm, extracts the data items, or exemplars, that best represent the dataset using a message passing method. Several steps are made to build StrAP. The first one (Weighted AP) extends AP to weighted items with no loss of generality. The second one (Hierarchical WAP) is concerned with reducing the quadratic AP complexity, by applying AP on data subsets and further applying Weighted AP on the exemplars extracted from all subsets. Finally StrAP extends Hierarchical WAP to deal with changes in the data distribution. Experiments on artificial datasets, on the Intrusion Detection benchmark (KDD99) and on a real-world problem, clustering the stream of jobs submitted to the EGEE grid system, provide a comparative validation of the approach. 1
922|Clustering by passing messages between data points|Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such “exemplars ” can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called “affinity propagation,” which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time. Clustering data based on a measure of similarity is a critical step in scientific data analysis and in engineering systems. A common approach is to use data to learn a set of centers such that the sum of
923|A data mining framework for building intrusion detection models|There is often the need to update an installed Intrusion Detection System (IDS) due to new attack methods or upgraded computing environments. Since many current IDSs are constructed by manual encoding of expert knowledge, changes to IDSs are expensive and slow. In this paper, we describe a data mining framework for adaptively building Intrusion Detection (ID) models. The central idea is to utilize auditing programs to extract an extensive set of features that describe each network connection or host session, and apply data mining programs to learn rules that accurately capture the behavior of intrusions and normal activities. These rules can then be used for misuse detection and anomaly detection. New detection models are incorporated into an existing IDS through a meta-learning (or co-operative learning) process, which produces a meta detection model that combines evidence from multiple models. We discuss the strengths of our data mining programs, namely, classification, meta-learning, association rules, and frequent episodes. We report our results of applying these programs to the extensively gathered network audit data for the 1998 DARPA Intrusion Detection Evaluation
924|Density-based clustering over an evolving data stream with noise|Clustering is an important task in mining evolving data streams. Beside the limited memory and one-pass constraints, the nature of evolving data streams implies the following requirements for stream clustering: no assumption on the number of clusters, discovery of clusters with arbitrary shape and ability to handle outliers. While a lot of clustering algorithms for data streams have been proposed, they offer no solution to the combination of these requirements. In this paper, we present DenStream, a new approach for discovering clusters in an evolving data stream. The “dense ” micro-cluster (named core-micro-cluster) is introduced to summarize the clusters with arbitrary shape, while the potential core-micro-cluster and outlier micro-cluster structures are proposed to maintain and distinguish the potential clusters and outliers. A novel pruning strategy is designed based on these concepts, which guarantees the precision of the weights of the micro-clusters with limited memory. Our performance study over a number of real and synthetic data sets demonstrates the effectiveness and efficiency of our method.
925|Clustering by soft-constraint affinity propagation: applications to gene-expression data|Motivation: Similarity-measure-based clustering is a crucial problem appearing throughout scientific data analysis. Recently, a powerful new algorithm called Affinity Propagation (AP) based on message-passing techniques was proposed by Frey and Dueck (2007a). In AP, each cluster is identified by a common exemplar all other data points of the same cluster refer to, and exemplars have to refer to themselves. Albeit its proved power, AP in its present form suffers from a number of drawbacks. The hard constraint of having exactly one exemplar per cluster restricts AP to classes of regularly shaped clusters, and leads to suboptimal performance, e.g. in analyzing gene expression data. Results: This limitation can be overcome by relaxing the AP hard constraints. A new parameter controls the importance of the constraints compared to the aim of maximizing the overall similarity, and allows to interpolate between the simple case where each data point selects its closest neighbor as an exemplar and the original AP. The resulting soft-constraint affinity propagation (SCAP) becomes more informative, accurate and leads to more stable clustering. Even though a new a priori free parameter is introduced, the overall dependence of the algorithm on external tuning is reduced, as robustness is increased and an optimal strategy for parameter selection emerges more naturally. SCAP is tested on biological benchmark data, including in particular microarray data related to various cancer types. We show that the algorithm efficiently unveils the hierarchical cluster structure present in the data sets. Further on, it allows to extract sparse gene expression signatures for each cluster.
926|A near-optimal algorithm for computing the entropy of a stream|We describe a simple algorithm for approximating the empirical entropy of a stream of m values in a single pass, using O(e -2 log(d -1) log m) words of space. Our algorithm is based upon a novel extension of a method introduced by Alon, Matias, and Szegedy [1]. We show a space lower bound of ?(e -2 / log(e -1)), meaning that our algorithm is near optimal in terms of its dependency on e. This improves over previous work on this problem [8, 13, 17, 5]. We show that generalizing to kth order entropy requires close to linear space for all k = 1, and give additive approximations using our algorithm. Lastly, we show how to compute a multiplicative approximation to the entropy of a random walk on an undirected graph. 1
927|MJRTY - A Fast Majority Vote Algorithm|A new algorithm is presented for determining which, if any, of an arbitrary number of candidates has received a majority of the votes cast in an election. The number of comparisons required is at most twice the number of votes. Furthermore, the algorithm uses storage in a way that permits an efficient use of magnetic tape. A Fortran version of the algorithm is exhibited. The Fortran code has been proved correct by a mechanical verification system for Fortran. The system and the proof are discussed.  1  The work described here was conducted in the Computer Science Laboratory of SRI International and suported in part by NASA Contract NAS1-15528, NSF Grant MCS7904081, and ONR Contract N00014-75-C-0816 1981. A brief history of this work is given in the concluding section.  106 Robert S. Boyer and J Strother Moore  5.1 Introduction  Reliability may be obtained by redundant computation and voting in critical hardware systems. What is the best way to determine the majority, if any, of a mult...
928|Simpler algorithm for estimating frequency moments of data streams|The problem of estimating the kth frequency moment Fk over a data stream by looking at the items exactly once as they arrive was posed in [1, 2]. A succession of algorithms have been proposed for this problem [1, 2, 6, 8, 7]. Recently, Indyk and Woodruff [11] have presented the first algorithm for estimating Fk, for k &gt; 2, using space Õ(n1-2/k), matching the space lower bound (up to poly-logarithmic factors) for this problem [1, 2, 3, 4, 13] (n is the number of distinct items occurring in the stream.) In this paper, we present a simpler 1-pass algorithm for estimating Fk.
929|A Fast Majority Vote Algorithm|A new algorithm is presented for determining which, if any, of an arbitrary number of candidates has received a majority of the votes cast in an election. The number of comparisons required is at most twice the number of votes. Furthermore, the algorithm uses storage in a way that permits an efficient use of magnetic tape.
930|Bounds for Frequency Estimation of Packet Streams|We consider the problem of approximating the frequency of frequently occurring elements in a stream of length n using only a memory of size m « n. This models the process of gathering statistics on Internet packet streaming using a memory that is small relative to the number of classes (e.g. IP addresses) of packets. We show that when some data item a occurs an times in a stream of length n, the FREQUENT algorithm of Demaine et al. [4], can approximate a’s frequency with an error of no more than (1-a)n/m. We also give a lower-bound of (1-a)n/(m+1) on the accuracy of any deterministic packet counting algorithm, which implies the FREQUENT algorithm is nearly optimal. Finally, we show that randomized algorithms can not be significantly more accurate since there is a lower bound of (1 - a)O(n/m) on the expected accuracy of any randomized packet counting algorithm. 1
931|Adaptive spatial partitioning for multidimensional data streams|We propose a space-efficient scheme for summarizing multidimensional data streams. Our sketch can be used to solve spatial versions of several classical data stream queries efficiently. For instance, we can track e-hotspots, which are congruent boxes containing at least an e fraction of the stream, and maintain hierarchical heavy hitters in d dimensions. Our sketch can also be viewed as a multidimensional generalization of the e-approximate quantile summary. The space complexity of our scheme is O ( 1 e log R) if the points lie in the domain [0, R]d, where d is assumed to be a constant. The scheme extends to the sliding window model with a log(en) factor increase in space, where n is the size of the sliding window. Our sketch can also be used to answer e-approximate rectangular range queries over a stream of d-dimensional points. 1
932|Robust Aggregation in Sensor Networks|In the emerging area of sensor-based systems, a significant challenge is to develop scalable, fault-tolerant methods to extract useful information from the data the sensors collect. An approach to this data management problem is the use of sensor “database” systems, which allow users to perform aggregation queries on the readings of a sensor network. Due to power and range constraints, centralized approaches are generally impractical, so most systems use in-network aggregation to reduce network traffic. However, these aggregation strategies become bandwidthintensive when combined with the fault-tolerant, multi-path routing methods often used in these environments. In order to avoid this expense, we investigate the use of approximate in-network aggregation using small sketches and we survey robust and scalable methods for computing duplicate-sensitive aggregates.
933|Reversible Sketches: Enabling Monitoring and Analysis over High-speed Data Streams |Abstract — A key function for network traffic monitoring and analysis is the ability to perform aggregate queries over multiple data streams. Change detection is an important primitive which can be extended to construct many aggregate queries. The recently proposed sketches [1] are among the very few that can detect heavy changes online for high speed links, and thus support various aggregate queries in both temporal and spatial domains. However, it does not preserve the keys (e.g., source IP address) of flows, making it difficult to reconstruct the desired set of anomalous keys. To address this challenge, we propose the reversible sketch data structure along with reverse hashing algorithms to infer the keys of culprit flows. There are two phases. The first operates online, recording the packet stream in a compact representation with negligible extra memory and few extra memory accesses. Our prototype single FPGA board implementation can achieve a throughput of over 16 Gbps for 40-byte-packet streams (the worst case). The second phase identifies heavy changes and their keys from the representation in nearly real time. We evaluate our scheme using traces from large edge routers with OC-12 or higher links. Both the analytical and experimental results show that we are able to achieve online traffic monitoring and accurate change/intrusion detection over massive data streams on high speed links, all in a manner that scales to large key space size. To the best of our knowledge, our system is the first to achieve these properties simultaneously. I.
934|Why go logarithmic if we can go linear? Towards effective distinct counting of search traffic|Estimating the number of distinct elements in a large multiset has several applications, and hence has attracted active research in the past two decades. Several sampling and sketching algorithms have been proposed to accurately solve this problem. The goal of the literature has always been to estimate the number of distinct elements while using minimal resources. However, in some modern applications, the accuracy of the estimate is of primal importance, and businesses are willing to trade more resources for better accuracy. Throughout our experience with building a distinct count system at a major search engine, Ask.com, we reviewed the literature of approximating distinct counts, and compared most algorithms in the literature. We deduced that Linear Counting, one of the least used algorithms, has unique and impressive advantages when the accuracy of the distinct count is critical to the business. For other estimators to attain comparable accuracy, they need more space than Linear Counting. We have supported our analytical results through comprehensive experiments. The experimental results highly favor Linear Counting when the number of distinct elements is large and the error tolerance is low. 1.
935|Sequential data assimilation with a nonlinear quasi-geostrophic model using Monte Carlo methods to forecast error statistics|. A new sequential data assimilation method is discussed. It is based on forecasting the error statistics using Monte Carlo methods, a better alternative than solving the traditional and computationally extremely demanding approximate error covariance equation used in the extended Kalman filter. The unbounded error growth found in the extended Kalman filter, which is caused by an overly simplified closure in the error covariance equation, is completely eliminated. Open boundaries can be handled as long as the ocean model is well posed. Well-known numerical instabilities associated with the error covariance equation are avoided because storage and evolution of the error covariance matrix itself are not needed. The results are also better than what is provided by the extended Kalman filter since there is no closure problem and the quality of the forecast error statistics therefore improves. The method should be feasible also for more sophisticated primitive equation models. The computati...
936|Using the Extended Kalman Filter with a Multilayer Quasi-Geostrophic Ocean Model|this paper the extended Kalman filter is used with a nonlinear multilayer quasi-geostrophic (QG) model. This provides us with both a realistic ocean model and a very sophisticated error statistics scheme. The extended Kalman filter is an extension of the common Kalman filter and may be used when the model dynamics or the measurement equation is nonlinear. It consists of an approximative equation for the propagation of error covariances, and also approximative filter equations if the measurement equation is nonlinear. When changing from a linear system to nonlinear dynamics the possible existence of a wide variety of phenomena which are nonexistent in the linear theory is introduced. Nonlinear systems may have solutions with multiple equilibria, where the solutions sometimes abruptly undergo transitions from one equilibrium to another as parameters change (bifurcations). Also chaotic behavior occurs in many deterministic systems, where solutions exhibit an apparently random behavior. The Lorenz [1963] model is probably the best known example of chaotic systems. It has solutions which undergo &#034;unpredictable&#034; transitions between two different equilibria (chaos). As discussed by Miller and Ghil
937|Simplification of the Kalman Filter for Meteorological Data Assimilation|We propose a new statistical data assimilation method that is based on a simplification of the Kalman filter equations. The forecast error covariance evolution is approximated by simply advecting the mass error covariance field, by deriving the remaining covariances geostrophically, and by accounting for external model error forcing only at the end of each forecast cycle. This greatly reduces the cost of the forecast error covariance computation, which is the central and most expensive aspect of the Kalman filter algorithm. In simulations with a linear, one-dimensional shallow-water model and artificially generated data, the performance of the simplified filter is compared with that of the Kalman filter and the optimal interpolation (OI) method. These experiments are designed to isolate the effect of simplifying the forecast error covariance evolution. The simplified filter produces analyses that are nearly optimal, and represents a significant improvement over OI. ae  1 Introduction ...
938|Open Boundary Conditions for the Extended Kalman Filter With a Quasi-Geostrophic Ocean Model|this paper the work in Part I is extended to include open boundaries with inflow and outflow. The use of inflow boundaries with the QG model severely complicates the numerical treatment, but it is also of vital importance if mesoscale circulation is to be studied, using an extended Kalman filter to assimilate data in the QG model. Open and closed boundaries have quite different properties and are normally treated differently in a way that leads to a well-posed problem. It should be remembered that an open boundary with inflow or outflow is an artificial boundary. No knowledge is therefore available about how an open boundary shall be updated unless external data or information can be used. The general boundary conditions for the QG model have been discussed in several publications where Charney et al.
939|Privacy-Preserving Classification for Data Streams |In a wide range of applications, multiple data streams need to be examined together in order to discover trends or patterns existing across several data streams. One common practice is to redirect all data streams into a central place for joint analysis. This “centralized ” practice is challenged by the fact that data streams often are private in that they come from different owners. In this paper, we focus on the problem of building a classifier in this context and assume that classification evolves as the current window of streams slides forward. This problem faces two major challenges. First, the many-to-many join relationship of streams will blow up the already fast arrival rate of data streams. Second, the privacy requirement implies that data exchange among owners should be minimal. These considerations rule out all classification methods that require producing the join in the current window. We show that Naïve Bayesian Classification (NBC) presents a unique opportunity to address this problem. Our main contribution is to adopt NBC to solve the classification problem for private data streams. 1.
940|Privacy-Preserving Data Mining|A fruitful direction for future data mining research will be the development of techniques that incorporate privacy concerns. Specifically, we address the following question. Since the primary task in data mining is the development of models about aggregated data, can we develop accurate models without access to precise information in individual data records? We consider the concrete case of building a decision-tree classifier from tredning data in which the values of individual records have been perturbed. The resulting data records look very different from the original records and the distribution of data values is also very different from the original distribution. While it is not possible to accurately estimate original values in individual data records, we propose a-novel reconstruction procedure to accurately estimate the distribution of original data values. By using these reconstructed distributions, we are able to build classifiers whose accuracy is comparable to the accuracy of classifiers built with the original data. 
941|On the optimality of the simple Bayesian classifier under zero-one loss|The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier’s probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article’s results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically.
942|Privacy Preserving Data Mining|In this paper we address the issue of privacy preserving data mining. Specifically, we consider a  scenario in which two parties owning confidential databases wish to run a data mining algorithm on  the union of their databases, without revealing any unnecessary information. Our work is motivated  by the need to both protect privileged information and enable its use for research or other purposes. The
943|Privacy Preserving Association Rule Mining in Vertically Partitioned Data|Privacy considerations often constrain data mining projects. This paper addresses the problem of association rule mining where transactions are distributed across sources. Each site holds some attributes of each transaction, and the sites wish to collaborate to identify globally valid association rules. However, the sites must not reveal individual transaction data. We present a two-party algorithm for efficiently discovering frequent itemsets with minimum support levels, without either site revealing individual transaction values.
944|Information Sharing across Private Databases|Literature on information integration across databases tacitly assumes that the data in each database can be revealed to the other databases. However, there is an increasing need for sharing information across autonomous entities in such a way that no information apart from the answer to the query is revealed. We formalize the notion of minimal information sharing across private databases,  and develop protocols for intersection, equijoin, intersection size, and equijoin size. We also show how new applications can be built using the proposed protocols.
945|An empirical study of the naive bayes classifier|The naive Bayes classifier greatly simplify learning by assuming that features are independent given class. Although independence is generally a poor assumption, in practice naive Bayes often competes well with more sophisticated classifiers. Our broad goal is to understand the data characteristics which affect the performance of naive Bayes. Our approach uses Monte Carlo simulations that allow a systematic study of classification accuracy for several classes of randomly generated problems. We analyze the impact of the distribution entropy on the classification error, showing that low-entropy feature distributions yield good performance of naive Bayes. We also demonstrate that naive Bayes works well for certain nearlyfunctional feature dependencies, thus reaching its best performance in two opposite cases: completely independent features (as expected) and functionally dependent features (which is surprising). Another surprising result is that the accuracy of naive Bayes is not directly correlated with the degree of feature dependencies measured as the classconditional mutual information between the features. Instead, a better predictor of naive Bayes accuracy is the amount of information about the class that is lost because of the independence assumption. 1
946|Building Decision Tree Classifier on Private Data|This paper studies how to build a decision tree classifier under the following scenario: a database is vertically partitioned into two pieces, with one piece owned by Alice and the other piece owned by Bob. Alice and Bob want to build a decision tree classifier based on such a database, but due to the privacy constraints, neither of them wants to disclose their private pieces to the other party or to any third party. We present a protocol that allows Alice and Bob to conduct such a classifier building without having to compromise their privacy. Our protocol uses an untrusted third-party server, and is built upon a useful building block, the scalar product protocol. Our solution to the scalar product protocol is more efficient than any existing solutions.
947|Memory-Limited Execution of Windowed Stream Joins|We address the problem of computing approximate  answers to continuous sliding-window joins  over data streams when the available memory may  be insufficient to keep the entire join state. One  approximation scenario is to provide a maximum  subset of the result, with the objective of losing as  few result tuples as possible. An alternative scenario  is to provide a random sample of the join  result, e.g., if the output of the join is being aggregated.
949|Private Searching On Streaming Data|In this paper, we consider the problem of private searching on streaming data, where we can efficiently implement searching for documents that satisfy a secret criteria (such as presence or absence of a hidden combination of hidden keywords) under various cryptographic assumptions. Our results can be viewed in a variety of ways: as a generalization of the notion of Private Information Retrieval (to more general queries and to a streaming environment); as positive results on privacy-preserving datamining; and as a delegation of hidden program computation to other machines.
950|Why is the Snowflake Schema a Good Data Warehouse Design?|Database design for data warehouses is based on the notion of the snowflake schema and its important special case, the star schema. The snowflake schema represents a dimensional model which is composed of a central fact table and a set of constituent dimension tables which can be further broken up into subdimension tables. We formalise the concept of a snowflake schema in terms of an acyclic database schema whose join tree satisfies certain structural properties. We then define a normal form for snowflake schemas which captures its intuitive meaning with respect to a set of functional and inclusion dependencies. We show that snowflake schemas in this normal form are independent as well as separable when the relation schemas are pairwise incomparable. This implies that relations in the data warehouse can be updated independently of each other as long as referential integrity is maintained. In addition, we show that a data warehouse in snowflake normal form can be queried by joining the relation over the fact table with the relations over its dimension and subdimension tables. We also examine an informationtheoretic interpretation of the snowflake schema and show that the redundancy of the primary key of the fact table is zero. Key words. Data warehouse design, star and snowflake schema, independent and separable database schema, acyclic database schema. 1 
951|MAIDS: Mining Alarming Incidents from Data Streams |Real-time surveillance systems, network and telecommunication systems, and other dynamic processes often generate tremendous (potentially infinite) volume of stream data. Effective analysis of such stream data poses great challenges to database and data mining researchers, due to its unique features, such as single-scan algorithm, multi-dimensional online analysis, fast response time, etc.
952|Sequential pattern mining in multiple streams|In this paper, we deal with mining sequential patterns in multiple data streams. Building on a state-of-the-art sequential pattern mining algorithm PrefixSpan for mining transaction databases, we propose MILE 1, an efficient algorithm to facilitate the mining process. MILE recursively utilizes the knowledge of existing patterns to avoid redundant data scanning, and can therefore effectively speed up the new patterns ’ discovery process. Another unique feature of MILE is that it can incorporate some prior knowledge of the data distribution in data streams into the mining process to further improve the performance. Extensive empirical results show that MILE is significantly faster than PrefixSpan. As MILE consumes more memory than PrefixSpan, we also present a solution to balance the memory usage and time efficiency in memory constrained environments. 1.
953|Join-Distinct aggregate estimation over update streams|There is growing interest in algorithms for processing and querying continuous data streams (i.e., data that is seen only once in a fixed order) with limited memory resources. Providing (perhaps approximate) answers to queries over such streams is a crucial requirement for many application environments; examples include large IP network installations where performance data from different parts of the network needs to be continuously collected and analyzed. The ability to estimate the number of distinct (sub)tuples in the result of a join operation correlating two data streams (i.e., the cardinality of a projection with duplicate elimination over a join) is an important requirement for several data-analysis scenarios. For instance, to enable real-time traffic analysis and load balancing, a network-monitoring application may need to estimate the number of distinct (source, destination) IP-address pairs occurring in the stream of IP packets observed by router R1, where the source address is also seen in packets routed through a different router R2. Earlier work has presented solutions to the individual problems of distinct counting and join-size estimation (without duplicate elimination) over streams. These solutions, however, are fundamentally different and extending or combining them to handle our more complex “Join-Distinct ” estimation problem is far from obvious. In this paper, we propose the first space-efficient algorithmic solution to the general Join-Distinct estimation problem over continuous data streams (our techniques can actually handle general update streams comprising tuple deletions as well as insertions). Our estimators are probabilistic in nature and rely on novel algorithms for building and combining a new class of hash-based synopses (termed “JD sketches”) for individual update streams. We demonstrate that our algorithms can provide low error, high-confidence Join-Distinct estimates using only small space and small processing time per update. In fact, we present lower bounds showing that the space usage of our estimators is within small factors of the best possible for the Join-Distinct problem. Preliminary experimental results verify the effectiveness of our approach. 1.
954|Classification spanning private databases|In this paper, we study the classification problem involving information spanning multiple private databases. The privacy challenges lie in the facts that data cannot be collected in one place and the classifier itself may disclose private information. We present a novel solution that builds the same decision tree classifier as if data are collected in a central place, but preserves the privacy of participating sites.
955|Semantic approximation of data stream joins|Abstract—We consider the problem of approximating sliding window joins over data streams in a data stream processing system with limited resources. In our model, we deal with resource constraints by shedding load in the form of dropping tuples from the data streams. We make two main contributions. First, we define the problem space by discussing architectural models for data stream join processing and surveying suitable measures for the quality of an approximation of a set-valued query result. Second, we examine in detail a large part of this problem space. More precisely, we consider the number of generated result tuples as the quality measure and we propose optimal offline and fast online algorithms for it. In a thorough experimental study with synthetic and real data, we show the efficacy of our solutions. Index Terms—Data streams, approximation algorithms, semantic load shedding, set approximation error metrics, join processing. 1
956|Property Testing and its connection to Learning and Approximation |We study the question of determining whether an unknown function has a particular property or is ffl-far from any function with that property. A property testing algorithm is given a sample of the value of the function on instances drawn according to some distribution, and possibly may query the function on instances of its choice. First, we establish some connections between property testing and problems in learning theory. Next, we focus on testing graph properties, and devise algorithms to test whether a graph has properties such as being k-colorable or having a ae-clique (clique of density ae w.r.t the vertex set). Our graph property testing algorithms are probabilistic and make assertions which are correct with high probability, utilizing only poly(1=ffl) edge-queries into the graph, where ffl is the distance parameter. Moreover, the property testing algorithms can be used to efficiently (i.e., in time linear in the number of vertices) construct partitions of the graph which corre...
957|Processing Set Expressions over Continuous Update Streams|There is growing interest in algorithms for processing and querying continuous data streams (i.e., data that is seen only once in a fixed order) with limited memory resources. In its most general form, a data stream is actually an update stream, i.e., comprising data-item deletions as well as insertions. Such massive update streams arise naturally in several application domains (e.g., monitoring of large IP network installations, or processing of retail-chain transactions). Estimating the cardinality of set expressions dened over several (perhaps, distributed) update streams is perhaps one of the most fundamental query classes of interest; as an example, such a query may ask \what is the number of distinct IP source addresses seen in passing packets from both router R1 and R2 but not router R3?&#034;. Earlier work has only addressed very restricted forms of this problem, focusing solely on the special case of insert-only streams and specic operators (e.g., union). In this paper, we propose the first space-efficient algorithmic solution for estimating the cardinality of full-
edged set expressions over general update streams. Our estimation algorithms are probabilistic in nature and rely on a novel, hash-based synopsis data structure, termed &#034;2-level hash sketch&#034;. We demonstrate how our 2-level hash sketch synopses can be used to provide low-error, high-confidence estimates for the cardinality of set expressions (including operators such as set union, intersection, and difference) over continuous update streams, using only small space and small processing time per update. Furthermore, our estimators never require rescanning or resampling of past stream items, regardless of the number of deletions in the stream. We also present lower bounds for the problem, demonstrating that the space usage of our estimation algorithms is within small factors of the optimal. Preliminary experimental results verify the effectiveness of our approach.
958|Smaller coresets for k-median and k-means clustering|In this paper, we show that there exists a (k, e)-coreset for k-median and k-means clustering of n points in R d, which is of size independent of n. In particular, we construct a (k, e)-coreset of size O(k 2 /e d) for k-median clustering, and of size O(k 3 /e d+1) for k-means clustering. 1
959|Deterministic Sampling and Range Counting in Geometric Data Streams|We present memory-efficient deterministic algorithms for constructing   #-nets and #-approximations of streams of geometric data. Unlike probabilistic approaches, these deterministic samples provide guaranteed bounds on their approximation factors. We show how our deterministic samples can be used to answer approximate online iceberg geometric queries on data streams. We use these techniques to approximate several robust statistics of geometric data streams, including Tukey depth, simplicial depth, regression depth, the Thiel-Sen estimator, and the least median of squares. Our algorithms use only a polylogarithmic amount of memory, provided the desired approximation factors are inverse-polylogarithmic. We also include a lower bound for non-iceberg geometric queries.
960|A Randomized Approximation Scheme for Metric MAX-CUT |Metric MAX-CUT is the problem of dividing a set of points in metric space into two parts so as to maximize the sum of the distances between points belonging to distinct parts. We show that metric MAX-CUT has a polynomial time randomized approximation scheme.  
961|Range counting over multidimensional data streams|\Lambda \Lambda Abstract We consider the problem of approximate range counting over streams of d-dimensional points. In the data stream model, the algorithm makes a single scan of the data, which is presented in an arbitrary order, and computes a compact summary (called a sketch). The sketch, whose size depends on the approximation parameter &amp;quot;, can be used to count the number of points inside a query range within additive error &amp;quot;n, where n is the size of the stream. We present several results, deterministic and randomized, for both rectangle and halfplane ranges. 1 Introduction Data streams have emerged as an important paradigm for processing data that arrives and needs to be processed continuously. For instance, telecom service providers routinely monitor packet flows through their networks to infer usage patterns and signs of attack, or to optimize their routing tables. Financial markets, banks, web servers, and news organizations also generate rapid and continuous data streams.
962|Summarizing and mining inverse distributions on data streams via dynamic inverse sampling|Database management systems face the challenge of dealing with massive data distributions which arrive at high speeds while there is only small storage available for managing and mining them. Emerging data stream management systems approach this problem by summarizing and mining the distributions using samples or sketches. However, data distributions can be “viewed” in different ways. For example, a data stream of integer values can be viewed either as the forward distribution f(x), ie., the number of occurrences of x in the stream, or as its inverse, f -1 (i), which is the number of items that appear i times. While both such “views ” are equivalent in stored data systems, over data streams that entail approximations, they may be significantly different. In other words, samples and sketches developed for the forward distribution may be ineffective for summarizing or mining the inverse distribution. Yet, many applications such as IP traffic monitoring naturally rely on mining inverse distributions. We formalize the problems of managing and mining inverse distributions and show provable differences between summarizing the forward distribution vs the inverse distribution. We present methods for summarizing and mining inverse distributions of data streams: they rely on a novel technique to maintain a dynamic sample over the stream with provable guarantees which can be used for variety of summarization tasks (building quantiles or equidepth histograms) and mining (anomaly detection: finding heavy hitters, and measuring the number of rare items), all with provable guarantees on quality of approximations and time/space used by our streaming methods. We also complement our analytical and algorithmic results by presenting an experimental study of the methods over network data streams.
963|Geometric optimization problems over sliding windows|Abstract. We study the problem of maintaining a (1+ffl)-factor approximation of the diameter of a stream of points under the sliding window model. In one dimension, we give a simple algorithm that only needs to store O( 1 ffl log R) points at any time, where the parameter R denotes the &amp;quot;spread &amp;quot; of the point set. This bound is optimal and improves Feigenbaum, Kannan, and Zhang&#039;s recent solution by two logarithmic factors. We then extend our one-dimensional algorithm to higher constant dimensions and, at the same time, correct an error in the previous solution. In high nonconstant dimensions, we also observe a constant-factor approximation algorithm that requires sublinear space. Related optimization problems, such as the width, are also considered in the two-dimensional case.
964|Survey on Outlier Detection in Data Stream |Data mining provides a way for finding hidden and useful knowledge from the large amount of data.usually we find any information by finding normal trends or distribution of data.But sometimes rare event or data object may provide information which is very interesting to us.Outlier detection is one of the task of data mining.It finds abnormal data point or sequence hidden in the dataset.Data stream is unbounded sequence of data with explicit or implicit temporal context.Data stream is uncertain and dynamic in nature. Traditional outlier detection techniques for static data which require whole dataset for modelling is not suitable for data stream because whole data stream cannot be stored. Network intrusion detection,web click stream analysis,fraud detection,fault detection in machines,sensor data analysis are some of the applications of data stream outlier detection.In this paper, we have described several issues in data stream outlier detection and usual approaches or techniques for finding outlier in data stream.
965|Outlier Detection for Temporal Data: A Survey |Abstract—In the statistics community, outlier detection for time series data has been studied for decades. Recently, with advances in hardware and software technology, there has been a large body of work on temporal outlier detection from a computational perspective within the computer science community. In particular, advances in hardware technology have enabled the availability of various forms of temporal data collection mechanisms, and advances in software technology have enabled a variety of data management mechanisms. This has fueled the growth of different kinds of data sets such as data streams, spatiotemporal data, distributed streams, temporal networks, and time series data, generated by a multitude of applications. There arises a need for an organized and detailed study of the work done in the area of outlier detection with respect to such temporal datasets. In this survey, we provide a comprehensive and structured overview of a large set of interesting outlier definitions for various forms of temporal data, novel techniques, and application scenarios in which specific definitions and techniques have been widely used. Index Terms—temporal outlier detection, time series data, data streams, distributed data streams, temporal networks, spatiotemporal outliers 1
966|Securing the Borealis data stream engine, in |As data stream management systems (DSMSs) become more and more popular, there is an increasing need to protect such systems from adversaries. In this paper we present an approach to secure DSMSs. We propose a general se-curity framework and an access control model to secure DSMSs. We implement our framework into an existing data stream management system and show that our approach not only works, by protecting the system from major secu-rity threats, but also has little impact on the overall system performance. 1.
967|The design of the borealis stream processing engine|Borealis is a second-generation distributed stream processing engine that is being developed at Brandeis University, Brown University, and MIT. Borealis inherits core stream processing functionality from Aurora [14] and distribution functionality from Medusa [51]. Borealis modifies and extends both systems in non-trivial and critical ways to provide advanced capabilities that are commonly required by newly-emerging stream processing applications. In this paper, we outline the basic design and functionality of Borealis. Through sample real-world applications, we motivate the need for dynamically revising query results and modifying query specifications. We then describe how Borealis addresses these challenges through an innovative set of features, including revision records, time travel, and control lines. Finally, we present a highly flexible and scalable QoS-based optimization model that operates across server and sensor networks and a new fault-tolerance model with flexible consistency-availability trade-offs.
968|High-availability algorithms for distributed stream processing|Stream-processing systems are designed to support an emerging class of applications that require sophisticated and timely processing of high-volume data streams, often originating in distributed environments. Unlike traditional dataprocessing applications that require precise recovery for correctness, many stream-processing applications can tolerate and benefit from weaker recovery guarantees. In this paper, we study various recovery guarantees and pertinent recovery techniques that can meet the correctness and performance requirements of stream-processing applications. We discuss the design and algorithmic challenges associated with the proposed recovery techniques and describe how each can provide different guarantees with proper combinations of redundant processing, checkpointing, and remote logging. Using analysis and simulations, we quantify the cost of our recovery guarantees and examine the performance and applicability of the recovery techniques. We also analyze how the knowledge of query network properties can help decrease the cost of high availability.
969|First Experiences Using XACML for Access Control in Distributed Systems|Authorization systems today are increasingly complex. They span domains of administration, rely on many different authentication sources, and manage permissions that can be as complex as the system itself. Worse still, while there are many standards that define authentication mechanisms, the standards that address authorization are less well defined and tend to work only within homogeneous systems. This paper presents XACML, a standard access control language, as one component of a distributed and inter-operable authorization framework. Several emerging systems which incorporate XACML are discussed. These discussions illustrate how authorization can be deployed in distributed, decentralized systems. Finally, some new and future topics are presented to show where this work is heading and how it will help connect the general components of an authorization system.
970|Content-based routing: Different plans for different data|Query optimizers in current database systems are designed to pick a single efficient plan for a given query based on current statistical properties of the data. However, different subsets of the data can sometimes have very different statistical properties. In such scenarios it can be more efficient to process different subsets of the data for a query using different plans. We propose a new query processing technique called content-based routing (CBR) that eliminates the single-plan restriction in current systems. We present low-overhead adaptive algorithms that partition input data based on statistical properties relevant to query execution strategies, and efficiently route individual tuples through customized plans based on their partition. We have implemented CBR as an extension to the Eddies query processor in the TelegraphCQ system, and we present an extensive experimental evaluation showing the significant performance benefits of CBR. 1.
971|An integration framework for sensor networks and data stream management systems|This demonstration shows an integrated query processing environment where users can seamlessly query both a data stream management system and a sensor network with one query expression. By integrating the two query processing systems, the optimization goals of the sensor network (primarily power) and server network (primarily latency and quality) can be unified into one quality of service metric. The demo shows various steps of the unified optimization process for a sample query where the effects of each step that the optimizer takes can be directly viewed using a quality of service monitor. Our demo includes sensors deployed in the demo area in a tiny mockup of a factory application. 1
972|A Public Infrastructure for Processing and Exploring Streams|PIPES is a flexible and extensible infrastructure offering fundamental building blocks that allow the construction of a fully functional prototype of a data stream management system (DSMS). It is seamlessly integrated into the Java li-brary XXL [5, 7] for advanced query processing and extends its scope towards continuous data-driven query processing over autonomous data sources. Our demonstration considers two realistic scenarios as ex-ample applications, namely traffic management and online auctions, whose relevance results from the fact that these represent a foundation for the development of benchmarks in stream processing. Subsequently, we will demonstrate how PIPES can be employed to these application domains. We will illustrate the construction and execution of query
973|Towards a secure data stream management system |Abstract. Todays data stream management systems (DSMSs) lack security functionality. Based on adversary scenarios we show how a DSMS architecture can be protected. We sketch a general DSMS architecture and introduce security issues that need to be considered. To face the threats we develop an extended system architecture that provides the necessary security mechanisms. We descuss the chosen concepts and illustrate how they can be realized by various system components. Our design focus is, considering the unique properties of data stream engines, to keep the impact on existing system components as little as possible and to limit the effect on the overall performance to a minimum. 1
974|Maintaining security and timeliness in real-time database system|Real-time database systems can have security constraints in addition to timing constraints. Such real-time systems are typically contained in environments that exhibit hierarchical propagation of information, where mandatory access control for security is required. Conventional multi-level secure database models that implement mandatory access control are inadequate for time-critical applications and conventional real-time database models do not address security constraints. The objective of this work is to incorporate security constraints in real-time database systems in such a way that not only is security achieved, but achieving security does not degrade real-time performance significantly in terms of deadlines missed. We present two concurrency control algorithms for secure real-time databases: the Secure 2PLHP algorithm is based on a two-phase locking protocol and the Secure OPT algorithm uses the properties of an optimistic concurrency protocol. We implement the two algorithms and study their performance using a real-time database system simulation model. Our study covers both soft and firm real-time databases. Results show that both the algorithms perform fairly well in terms of security and timeliness compared to non-secure algorithms. We show that achieving increased security does not necessarily mean an increased sacrifice in real-time performance. Submitted to the Journal of Systems and Software
977|A comparison of document clustering techniques|This paper presents the results of an experimental study of some common document clustering techniques: agglomerative hierarchical clustering and K-means. (We used both a “standard” K-means algorithm and a “bisecting ” K-means algorithm.) Our results indicate that the bisecting K-means technique is better than the standard K-means approach and (somewhat surprisingly) as good or better than the hierarchical approaches that we tested.
978|Two-Stage language models for information retrieval|The optimal settings of retrieval parameters often depend on both the document collection and the query, and are usually found through empirical tuning. In this paper, we propose a family of two-stage language models for information retrieval that explicitly captures the different influences of the query and document collection on the optimal settings of retrieval parameters. As a special case, we present a two-stage smoothing method that allows us to estimate the smoothing parameters completely automatically. In the first stage, the document language model is smoothed using a Dirichlet prior with the collection language model as the reference model. In the second stage, the smoothed document language model is further in-terpolated with a query background language model. We propose a leave-one-out method for estimating the Dirichlet parameter of the first stage, and the use of document mixture models for estimating the interpolation parameter of the second stage. Evaluation on five different databases and four types of queries indicates that the two-stage smoothing method with the proposed parameter estimation methods consistently gives retrieval performance that is close to— or better than—the best results achieved using a single smoothing method and exhaustive parameter search on the test data.
979|A Study on Retrospective and On-Line Event Detection|This paper investigates the use and extension of text retrieval and clustering techniques for event detection. The task is to automatically detect novel events from a temporally-ordered stream of news stories, either retrospectively or as the stories arrive. We applied hierarchical and non-hierarchical document clustering algorithms to a corpus of 15,836 stories, focusing on the exploitation of both content and temporal information. We found the resulting cluster hierarchies highly informative for retrospective detection of previously unidentified events, effectively supporting both query-free and query-driven retrieval. We also found that temporal distribution patterns of document clusters provide useful information for improvement in both retrospective detection and on-line detection of novel events. In an evaluation using manually labelled events to judge the system-detected events, we obtained a result of 82% in the F1 measure for retrospective detection, and a F1  value of 42% for...
980|Discovering evolutionary theme patterns from text: an exploration of temporal text mining|Temporal Text Mining (TTM) is concerned with discovering temporal patterns in text information collected over time. Since most text information bears some time stamps, TTM has many applications in multiple domains, such as summarizing events in news articles and revealing research trends in scientific literature. In this paper, we study a particular TTM task – discovering and summarizing the evolutionary patterns of themes in a text stream. We define this new text mining problem and present general probabilistic methods for solving this problem through (1) discovering latent themes from text; (2) constructing an evolution graph of themes; and (3) analyzing life cycles of themes. Evaluation of the proposed methods on two different domains (i.e., news articles and literature) shows that the proposed methods can discover interesting evolutionary theme patterns effectively.
981|A Framework for Projected Clustering of High Dimensional Data Streams|The data stream problem has been studied extensively  in recent years, because of the great  ease in collection of stream data. The nature  of stream data makes it essential to use  algorithms which require only one pass over  the data. Recently, single-scan, stream analysis  methods have been proposed in this context. However,
982|Generative model-based document clustering: a comparative study|Semi-supervised learning has become an attractive methodology for improving classification models and is often viewed as using unlabeled data to aid supervised learning. However, it can also be viewed as using labeled data to help clustering, namely, semi-supervised clustering. Viewing semi-supervised learning from a clustering angle is useful in practical situations when the set of labels available in labeled data are not complete, i.e., unlabeled data contain new classes that are not present in labeled data. This paper analyzes several multinomial modelbased semi-supervised document clustering methods under a principled model-based clustering framework. The framework naturally leads to a deterministic annealing extension of existing semi-supervised clustering approaches. We compare three (slightly) different semi-supervised approaches for clustering documents: Seeded damnl, Constrained damnl, and Feedback-based damnl, where damnl stands for multinomial model-based deterministic annealing algorithm. The first two are extensions of the seeded k-means and constrained k-means algorithms studied by Basu et al. (2002); the last one is motivated by Cohn et al. (2003). Through empirical experiments on text datasets, we show that: (a) deterministic annealing can often significantly improve the performance of semi-supervised clustering; (b) the constrained approach is the best when available labels are complete whereas the feedback-based approach excels when available labels are incomplete.
983|Topic models over text streams: a study of batch and online unsupervised learning |Topic modeling techniques have widespread use in text data mining applications. Some applications use batch models, which perform clustering on the document collection in aggregate. In this paper, we analyze and compare the performance of three recently-proposed batch topic models—Latent Dirichlet Allocation (LDA), Dirichlet Compound Multinomial (DCM) mixtures and von-Mises Fisher (vMF) mixture models. In cases where offline clustering on complete document collections is infeasible due to resource and response-rate constraints, online unsupervised clustering methods that process incoming data incrementally are necessary. To this end, we propose online variants of vMF, EDCM and LDA. Experiments on large real-world document collections, in both the offline and online settings, demonstrate that though LDA is a good model for finding word-level topics, vMF finds better document-level topic clusters more efficiently, which is often important in text mining applications. Finally, we propose a practical heuristic for hybrid topic modeling, which learns online topic models on streaming text and intermittently runs batch topic models on aggregated documents offline. Such a hybrid model is useful for several applications (e.g., dynamic topic-based aggregation of user-generated content in social networks) that need a good tradeoff between the performance of batch offline algorithms and efficiency of incremental online algorithms. 1
984|A Framework for Clustering Massive Text and Categorical Data Streams|Many applications such as news group filtering, text crawling, and document organization require real time clustering and segmentation of text data records. The categorical data stream clustering problem also has a number of applications to the problems of customer segmentation and real time trend analysis. We will present an online approach for clustering massive text and categorical data streams with the use of a statistical summarization methodology. We present results illustrating the effectiveness of the technique.
985|Bursty Feature Representation for Clustering Text Streams |Text representation plays a crucial role in classical text mining, where the primary focus was on static text. Nevertheless, well-studied static text representations including TFIDF are not optimized for non-stationary streams of information such as news, discussion board messages, and blogs. We therefore introduce a new temporal representation for text streams based on bursty features. Our bursty text representation differs significantly from traditional schemes in that it 1) dynamically represents documents over time, 2) amplifies a feature in proportional to its burstiness at any point in time, and 3) is topic independent. Our bursty text representation model was evaluated against a classical bagof-words text representation on the task of clustering TDT3 topical text streams. It was shown to consistently yield more cohesive clusters in terms of cluster purity and cluster/class entropies. This new temporal bursty text representation can be extended to most text mining tasks involving a temporal dimension, such as modeling of online blog pages. 1
986|Context-Sensitive Semantic Smoothing for the Language Modeling Approach to Genomic IR|Semantic smoothing, which incorporates synonym and sense information into the language models, is effective and potentially significant to improve retrieval performance. The implemented semantic smoothing models, such as the translation model which statistically maps document terms to query terms, and a number of works that have followed have shown good experimental results. However, these models are unable to incorporate contextual information. Thus, the resulting translation might be mixed and fairly general. To overcome this limitation, we propose a novel context-sensitive semantic smoothing method that decomposes a document or a query into a set of weighted context-sensitive topic signatures and then translate those topic signatures into query terms. In detail, we solve this problem through (1) choosing concept pairs as topic signatures and adopting an ontology-based approach to extract concept pairs; (2) estimating the translation model for each topic signature using the EM algorithm; and (3) expanding document and query models based on topic signature translations. The new smoothing method is evaluated on TREC 2004/05 Genomics Track collections and significant improvements are obtained. The MAP (mean average precision) achieves a 33.6 % maximal gain over the simple language model, as well as a 7.8 % gain over the language model with context-insensitive semantic smoothing.
987|Semantic Smoothing for Model-based Document Clustering |A document is often full of class-independent “general ” words and short of class-specific “core” words, which leads to the difficulty of document clustering. We argue that both problems will be relieved after suitable smoothing of document models in agglomerative approaches and of cluster models in partitional approaches, and hence improve clustering quality. To the best of our knowledge, most modelbased clustering approaches use Laplacian smoothing to prevent zero probability while most similarity-based approaches employ the heuristic TF*IDF scheme to discount the effect of “general ” words. Inspired by a series of statistical translation language model for text retrieval, we propose in this paper a novel smoothing method referred to as context-sensitive semantic smoothing for document clustering purpose. The comparative experiment on three datasets shows that model-based clustering approaches with semantic smoothing is effective in improving cluster quality. 1.
988|  Summarizing and Mining Skewed Data Streams |Many applications generate massive data streams. Summarizing such massive data requires fast, small space algorithms to support post-hoc queries and mining. An important observation is that such streams are rarely uniform, and real data sources typically exhibit significant skewness. These are well modeled by Zipf distributions, which are characterized by a parameter, z, that captures the amount of skew. We present a data stream summary that can answer point queries with e accuracy and show that the space needed is only O(e - min{1,1/z}). This is the first o(1/e) space algorithm for this problem, and we show it is essentially tight for skewed distributions. We show that the same data structure can also estimate the L2 norm of the stream in o(1/e2) space for z&gt; 1 2, another improvement over the existing ?(1/e2) methods. We support our theoretical results with an experimental study over a large variety of real and synthetic data. We show that significant skew is present in both textual and telecommunication data. Our methods give strong accuracy, significantly better than other methods, and behave exactly in line with their analytic bounds.
989|Aurora: A Data Stream Management System|Streams are continuous data feeds generated by such sources as sensors, satellites, and stock feeds. Monitoring applications track data from numerous streams, filtering them for signs of abnormal activity, and processing them for purposes of filtering,
990|Discovering Hidden Groups in Communication Networks|We describe models and efficient algorithms for detecting groups (communities) functioning in  communication networks which attempt to hide their functionality -- hidden groups. Our results  reveal the properties of the background network activity that make detection of the hidden  group easy, as well as those that make it difficult.
992|Mining Association Rules between Sets of Items in Large Databases|We are given a large database of customer transactions. Each transaction consists of items purchased by a customer in a visit. We present an efficient algorithm that generates all significant association rules between items in the database. The algorithm incorporates buffer management and novel estimation and pruning techniques. We also present results of applying this algorithm to sales data obtained from a large retailing company, which shows the effectiveness of the algorithm. 
993|An information-theoretic approach to detecting changes in multi-dimensional data streams|Abstract An important problem in processing large data streams is detecting changes in the underly-ing distribution that generates the data. The challenge in designing change detection schemes is making them general, scalable, and statistically sound. In this paper, we take a general,information-theoretic approach to the change detection problem, which works for multidimensional as well as categorical data. We use relative entropy, also called the Kullback-Leiblerdistance, to measure the difference between two given distributions. The KL-distance is known to be related to the optimal error in determining whether the two distributions are the sameand draws on fundamental results in hypothesis testing. The KL-distance also generalizes traditional distance measures in statistics, and has invariance properties that make it ideally suitedfor comparing distributions. Our scheme is general; it is nonparametric and requires no assumptions on the underlyingdistributions. It employs a statistical inference procedure based on the theory of bootstrapping, which allows us to determine whether our measurements are statistically significant. The schemeis also quite flexible from a practical perspective; it can be implemented using any spatial partitioning scheme that scales well with dimensionality. In addition to providing change detections,our method generalizes Kulldorff&#039;s spatial scan statistic, allowing us to quantitatively identify specific regions in space where large changes have occurred.We provide a detailed experimental study that demonstrates the generality and efficiency of our approach with different kinds of multidimensional datasets, both synthetic and real. 1 Introduction We are collecting and storing data in unprecedented quantities and varieties--streams, images, audio, text, metadata descriptions, and even simple numbers. Over time, these data streams change as the underlying processes that generate them change. Some changes are spurious and pertain to glitches in the data. Some are genuine, caused by changes in the underlying distributions. Some changes are gradual and some are more precipitous. We would like to detect changes in a variety of settings:
994|Mining multi-dimensional constrained gradients in data cubes|1 Introduction In recent years, there have been growing interests in multi-dimensional analysis of relational databases, transactional
995|An Intuitive Framework for understanding Changes in Evolving Data Streams|Many organizations today store large streams of transactional data in real time. This data can often show important changes in trends over time. In many commercial applications, it may be valuable to provide the user with an understanding of the nature of changes occuring over time in the data stream. In this poster, we discuss the process of analysis of the significant changes and trends in data streams in a way which is understandable, intuitive and friendly to a user. 1
997|Abstract Active Mining of Data Streams |Most previously proposed mining methods on data streams make an unrealistic assumption that “labelled ” data stream is readily available and can be mined at anytime. However, in most real-world problems, labelled data streams are rarely immediately available. Due to this reason, models are refreshed periodically, that is usually synchronized with data availability schedule. There are several undesirable consequences of this “passive periodic refresh”. In this paper, we propose a new concept of demand-driven active data mining. It estimates the error of the model on the new data stream without knowing the true class labels. When significantly higher error is suspected, it investigates the true class labels of a selected number of examples in the most recent data stream to verify the suspected higher error. 1 State-of-the-art Stream Mining State-of-the-art work on mining data streams concentrates on capturing time-evolving trends and patterns with “labeled” data. However, one important aspect that is often ignored or unrealistically assumed is the availability of “class labels ” of data streams. Most algorithms make an implicit and impractical assumption that labeled data is readily available. Most works focus on how to detect the change in patterns and how to update the model to reflect such changes when there are “labelled ” instances to be learned. However, for many applications, the class labels are not “immediately ” available unless dedicated efforts and substantial costs are spent to investigate these labels right away. If the true class labels were readily available, data mining models would not be very useful- we might just wait. In credit card fraud detection, we usually do not know if a particular transaction is a fraud until at least one month later after the account holder receives and reviews the monthly statement. Due to these facts, most current applications obtain class labels and update existing models in preset frequency, usually synchronized with data refresh. The effectiveness of the passive mode is dictated by some “statuary and static constraints”, yet not by the “demand” for a better model with a lower loss. Such a pas-
998|The quadtree and related hierarchical data structures|A tutorial survey is presented of the quadtree and related hierarchical data structures. They are based on the principle of recursive decomposition. The emphasis is on the representation of data used in applications in image processing, computer graphics, geographic information systems, and robotics. There is a greater emphasis on region data (i.e., two-dimensional shapes) and to a lesser extent on point, curvilinear, and threedimensional data. A number of operations in which such data structures find use are examined in greater detail.
999|Finding Surprising Patterns in a Time Series Database in Linear Time and Space|The problem of finding a specified pattern in a time series database (i.e. query by content) has received much attention and is now a relatively mature field. In contrast, the important problem of enumerating all surprising or interesting patterns has received far less attention. This problem requires a meaningful definition of &#034;surprise&#034;, and an efficient search technique. All previous attempts at finding surprising patterns in time series use a very limited notion of surprise, and/or do not scale to massive datasets. To overcome these lim- itations we introduce a novel technique that defines a pattern surprising if the frequency of its occurrence differs substantially from that expected by chance, given some previously seen data. This notion has the advantage of not requiring an explicit definition of surprise, which may be impossible to elicit from a domain expert. Instead the user simply gives the algorithm a collection of previously observed normal data. Our algorithm uses a suffix tree to efficiently encode the frequency of all observed patterns and allows a Markov model to predict the expected frequency of previously unobserved patterns. Once the suffix tree has been constructed, a measure of surprise for all the patterns in a new database can be determined in time and space linear in the size of the database. We demonstrate the utility of our approach with an extensive experimental evaluation.
1000|Data mining meets performance evaluation: Fast algorithms for modeling bursty traffic|Network, web, and disk I/O traffic are usually bursty, self-similar [9, 3, 5, 6] and therefore can not be modeled adequately with Poisson arrivals[9]. However, we do want to model these types of traffic and to generate realistic traces, because of obvious applications for disk scheduling, network management, web server design. Previous models (like fractional Brownian motion, ARFIMA etc) tried to capture the ‘burstiness’. However the proposed models either require too many parameters to fit and/or require prohibitively large (quadratic) time to generate large traces. We propose a simple, parsimonious method, the b-model, which solves both problems: It requires just one parameter (b), and it can easily generate large traces. In addition, it has many more attractive properties: (a) With our proposed estimation algorithm, it requires just a single pass over the actual trace to estimate b. For example, a one-day-long disk trace in milliseconds contains about 86Mb data points and requires about 3 minutes for model fitting and 5 minutes for generation. (b) The resulting synthetic traces are very realistic: our experiments on real disk and web traces show that our synthetic traces match the real ones very well in terms of queuing behavior.
1001|TSA-tree: A wavelet-based approach to improve the efficiency of multi-level surprise and trend queries on time-series data|We introduce a novel wavelet-based tree structure, termed TSA-tree, which improves the efficiency of multilevel trend and surprise queries on time sequence data. With the explosion of scientific observation data (some conceptualized as time-sequences), we are facing the challenge of efficiently storing, retrieving and analyzing this data. Frequent queries on this data set is to find trends (e.g., global warming) or surprises (e.g., undersea volcano eruption) within the original time-series. The challenge, however, is that these trend and surprise queries are needed at different levels of abstractions (e.g., within the last week, last month, last year or last decade). To support these multi-level trend and surprise queries, sometimes huge subset of raw data needs to be retrieved and processed. To
1002|Data Stream Clustering: Challenges and Issues|Abstract — Very large databases are required to store massive amounts of data that are continuously inserted and queried. Analyzing huge data sets and extracting valuable pattern in many applications are interesting for researchers. We can identify two main groups of techniques for huge data bases mining. One group refers to streaming data and applies mining techniques whereas second group attempts to solve this problem directly with efficient algorithms. Recently many researchers have focused on data stream as an efficient strategy against huge data base mining instead of mining on entire data base. The main problem in data stream mining means evolving data is more difficult to detect in this techniques therefore unsupervised methods should be applied. However, clustering techniques can lead us to discover hidden information. In this survey, we try to clarify: first, the different problem definitions related to data stream clustering in general; second, the specific difficulties encountered in this field of research; third, the varying assumptions, heuristics, and intuitions forming the basis of different approaches; and how several prominent solutions tackle different problems. Index Terms — Data Stream, Clustering, K-Means, Concept drift I.
1003|Model-Based Clustering, Discriminant Analysis, and Density Estimation|Cluster analysis is the automated search for groups of related observations in a data set. Most clustering done in practice is based largely on heuristic but intuitively reasonable procedures and most clustering methods available in commercial software are also of this type. However, there is little systematic guidance associated with these methods for solving important practical questions that arise in cluster analysis, such as \How many clusters are there?&#034;, &#034;Which clustering method should be used?&#034; and \How should outliers be handled?&#034;. We outline a general methodology for model-based clustering that provides a principled statistical approach to these issues. We also show that this can be useful for other problems in multivariate analysis, such as discriminant analysis and multivariate density estimation. We give examples from medical diagnosis, mineeld detection, cluster recovery from noisy data, and spatial density estimation. Finally, we mention limitations of the methodology, a...
1004|Concept Decompositions for Large Sparse Text Data using Clustering|. Unlabeled document collections are becoming increasingly common and available; mining such data sets represents a major contemporary challenge. Using words as features, text documents are often represented as high-dimensional and sparse vectors--a few thousand dimensions and a sparsity of 95 to 99% is typical. In this paper, we study a certain spherical k-means algorithm for clustering such document vectors. The algorithm outputs k disjoint clusters each with a concept vector that is the centroid of the cluster normalized to have unit Euclidean norm. As our first contribution, we empirically demonstrate that, owing to the high-dimensionality and sparsity of the text data, the clusters produced by the algorithm have a certain &#034;fractal-like&#034; and &#034;self-similar&#034; behavior. As our second contribution, we introduce concept decompositions to approximate the matrix of document vectors; these decompositions are obtained by taking the least-squares approximation onto the linear subspace spanned...
1005|The Problem of Concept Drift: Definitions and Related Work|In the real world concepts are often not stable but change with time. Typical examples of this are weather prediction rules and customers&#039; preferences. The underlying data distribution may change as well. Often these changes make the model built on old data inconsistent with the new data, and regular updating of the model is necessary. This problem, known as concept drift, complicates the task of learning a model from data and requires special approaches, different from commonly used techniques, which treat arriving instances as equally important contributors to the final concept. This paper considers different types of concept drift, peculiarities of the problem, and gives a critical review of existing approaches to the problem.
1006|Density-connected subspace clustering for high-dimensional data|Several application domains such as molecular biology and geography produce a tremendous amount of data which can no longer be managed without the help of efficient and effective data mining methods. One of the primary data mining tasks is clustering. However, traditional clustering algorithms often fail to detect meaningful clusters because most real-world data sets are characterized by a high dimensional, inherently sparse data space. Nevertheless, the data sets often contain interesting clusters which are hidden in various subspaces of the original feature space. Therefore, the concept of subspace clustering has recently been addressed, which aims at automatically identifying subspaces of the feature space in which clusters exist. In this paper, we introduce SUBCLU (density-connected Subspace Clustering), an effective and efficient approach to the subspace clustering problem. Using the concept of density-connectivity underlying the algorithm DBSCAN [EKSX96], SUBCLU is based on a formal clustering notion. In contrast to existing grid-based approaches, SUBCLU is able to detect arbitrarily shaped and positioned clusters in subspaces. The monotonicity of density-connectivity is used to efficiently prune subspaces in the process of generating all clusters in a bottom up way. While not examining any unnecessary subspaces, SUBCLU delivers for each subspace the same clusters DBSCAN would have found, when applied to this subspace separately.
1007|A Framework for Clustering Uncertain Data Streams|Abstract — In recent years, uncertain data management applications have grown in importance because of the large number of hardware applications which measure data approximately. For example, sensors are typically expected to have considerable noise in their readings because of inaccuracies in data retrieval, transmission, and power failures. In many cases, the estimated error of the underlying data stream is available. This information is very useful for the mining process, since it can be used in order to improve the quality of the underlying results. In this paper we will propose a method for clustering uncertain data streams. We use a very general model of the uncertainty in which we assume that only a few statistical measures of the uncertainty are available. We will show that the use of even modest uncertainty information during the mining process is sufficient to greatly improve the quality of the underlying results. We show that our approach is more effective than a purely deterministic method such as the CluStream approach. We will test the approach on a variety of real and synthetic data sets and illustrate the advantages of the method in terms of effectiveness and efficiency. I.
1008|Density-Based Clustering for Real-Time Stream Data|Existing data-stream clustering algorithms such as CluStream are based on k-means. These clustering algorithms are incompetent to find clusters of arbitrary shapes and cannot handle outliers. Further, they require the knowledge of k and user-specified time window. To address these issues, this paper proposes D-Stream, a framework for clustering stream data using a density-based approach. The algorithm uses an online component which maps each input data record into a grid and an offline component which computes the grid density and clusters the grids based on the density. The algorithm adopts a density decaying technique to capture the dynamic changes of a data stream. Exploiting the intricate relationships between the decay factor, data density and cluster structure, our algorithm can efficiently and effectively generate and adjust the clusters in real time. Further, a theoretically sound technique is developed to detect and remove sporadic grids mapped to by outliers in order to dramatically improve the space and time efficiency of the system. The technique makes high-speed data stream clustering feasible without degrading the clustering quality. The experimental results show that our algorithm has superior quality and efficiency, can find clusters of arbitrary shapes, and can accurately recognize the evolving behaviors of real-time data streams. 1.
1009|Using the Fractal Dimension to Cluster Datasets Paper 145|Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. Clustering of large datasets has received a lot of attention in recent years. However, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the dataset and the number of dimensions that describe the points, or in nding arbitrary shapes of clusters, or dealing e ectively with the presence of noise. In this paper, we present a new clustering algorithm, based in the fractal properties of the datasets. The new algorithm, which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same cluster have a great degree of self-similarity among them (and much less self-similarity with respect to points in other clusters). FC requires one scan of the data, is suspendable at will, providing the best answer possible at that point, and is incremental. We show via experiments that FC e ectively deals with large datasets, high-dimensionality and noise and is capable of recognizing clusters of arbitrary shape. This work has been supported by NSF grant IIS-9732113 1
1010|Distributed data streams|A majority of today’s data is constantly evolving and fundamentally distributed in nature. Data for almost any large-scale data-management task is continuously collected over a wide area, and at a much greater rate than ever before. Compared to traditional, centralized stream processing, querying such large-scale, evolving data collections poses new challenges, due mainly to the physical distribution of the streaming data and the communication constraints of the underlying network. Distributed stream processing algorithms should guarantee efficiency not only in terms of space and processing time (as conventional streaming techniques), but also in terms of the communication load imposed on the network infrastructure.  
1011|Gossip-Based Computation of Aggregate Information|between computers, and a resulting paradigm shift from centralized to highly distributed systems. With massive scale also comes massive instability, as node and link failures become the norm rather than the exception. For such highly volatile systems, decentralized gossip-based protocols are emerging as an approach to maintaining simplicity and scalability while achieving fault-tolerant information dissemination.
1012|OpenDHT: A Public DHT Service and Its Uses|Large-scale distributed systems are hard to deploy, and distributed hash tables (DHTs) are no exception. To lower the barriers facing DHT-based applications, we have created a public DHT service called OpenDHT. Designing a DHT that can be widely shared, both among mutually untrusting clients and among a variety of applications, poses two distinct challenges. First, there must be adequate control over storage allocation so that greedy or malicious clients do not use more than their fair share. Second, the interface to the DHT should make it easy to write simple clients, yet be sufficiently general to meet a broad spectrum of application requirements. In this paper we describe our solutions to these design challenges. We also report our early deployment experience with OpenDHT and describe the variety of applications already using the system.
1013|Distributed regression: an efficient framework for modeling sensor network data|We present distributed regression, an efficient and general framework for in-network modeling of sensor data. In this framework, the nodes of the sensor network collaborate to optimally fit a global function to each of their local measurements. The algorithm is based upon kernel linear regression, where the model takes the form of a weighted sum of local basis functions; this provides an expressive yet tractable class of models for sensor network data. Rather than transmitting data to one another or outside the network, nodes communicate constraints on the model parameters, drastically reducing the communication required. After the algorithm is run, each node can answer queries for its local region, or the nodes can efficiently transmit the parameters of the model to a user outside the network. We present an evaluation of the algorithm based upon data from a 48-node sensor network deployment at the Intel Research- Berkeley Lab, demonstrating that our distributed algorithm converges to the optimal solution at a fast rate and is very robust to packet losses.
1014|Network-aware operator placement for stream-processing systems|To use their pool of resources efficiently, distributed stream-processing systems push query operators to nodes within the network. Currently, these operators, ranging from simple filters to custom business logic, are placed manually at intermediate nodes along the transmission path to meet application-specific performance goals. Determining placement locations is challenging because network and node conditions change over time and because streams may interact with each other, opening venues for reuse and repositioning of operators. This paper describes a stream-based overlay network (SBON), a layer between a stream-processing system and the physical network that manages operator placement for stream-processing systems. Our design is based on a cost space, an abstract representation of the network and on-going streams, which permits decentralized, large-scale multi-query optimization decisions. We present an evaluation of the SBON approach through simulation, experiments on PlanetLab, and an integration with Borealis, an existing stream-processing engine. Our results show that an SBON consistently improves network utilization, provides low stream latency, and enables dynamic optimization at low engineering cost.
1015|Declarative Networking: Language, Execution and Optimization|The networking and distributed systems communities have recently explored a variety of new network architectures, both for applicationlevel overlay networks, and as prototypes for a next-generation Internet architecture. In this context, we have investigated declarative  networking: the use of a distributed recursive query engine as a powerful vehicle for accelerating innovation in network architectures [23, 24, 33]. Declarative networking represents a significant new application area for database research on recursive query processing. In this paper, we address fundamental database issues in this domain. First, we motivate and formally define the Network Datalog (NDlog) language for declarative network specifications. Second, we introduce and prove correct relaxed versions of the traditional semi-na ve query evaluation technique, to overcome fundamental problems of the traditional technique in an asynchronous distributed setting. Third, we consider the dynamics of network state, and formalize the &#034;eventual consistency&#034; of our programs even when bursts of updates can arrive in the midst of query execution. Fourth, we present a number of query optimization opportunities that arise in the declarative networking context, including applications of traditional techniques as well as new optimizations. Last, we present evaluation results of the above ideas implemented in our P2 declarative networking system, running on 100 machines over the Emulab network testbed.
1016|Fault-tolerance in the Borealis distributed stream processing system|Over the past few years, Stream Processing Engines (SPEs) have emerged as a new class of software systems, enabling low latency processing of streams of data arriving at high rates. As SPEs mature and get used in monitoring applications that must continuously run (e.g., in network security monitoring), a significant challenge arises: SPEs must be able to handle various software and hardware faults that occur, masking them to provide high availability (HA). In this paper, we develop, implement, and evaluate DPC (Delay, Process, and Correct), a protocol to handle crash failures of processing nodes and network failures in a distributed SPE. Like previous approaches to HA, DPC uses replication and masks many types of node and network failures. In the presence of network partitions, the designer of any replication system faces a choice between providing availability or data consistency across the replicas. In DPC, this choice is made explicit: the user specifies an availability bound (no result should be delayed by more than a specified delay threshold even under failure if the corresponding input is available), and DPC attempts to minimize the resulting inconsistency between replicas (not all of which might have seen the input data) while meeting the given delay threshold. Although conceptually simple, the DPC protocol tolerates the occurrence of multiple simultaneous failures as well as any
1017|A Geometric Approach to Monitoring Threshold Functions Over Distributed Data Streams |Monitoring data streams in a distributed system is the fo-cus of much research in recent years. Most of the proposed schemes, however, deal with monitoring simple aggregated values, such as the frequency of appearance of items in the streams. More involved challenges, such as the important task of feature selection (e.g., by monitoring the information gain of various features), still require very high communica-tion overhead using naive, centralized algorithms. We present a novel geometric approach by which an arbi-trary global monitoring task can be split into a set of con-straints applied locally on each of the streams. The con-straints are used to locally filter out data increments that do not affect the monitoring outcome, thus avoiding unnec-essary communication. As a result, our approach enables monitoring of arbitrary threshold functions over distributed data streams in an efficient manner. We present experimental results on real-world data which demonstrate that our algorithms are highly scalable, and considerably reduce communication load in comparison to centralized algorithms. 1.
1018|from data streams |frequent itemsets
1019|Discovering Frequent Closed Itemsets for Association Rules|In this paper, we address the problem of finding frequent itemsets in a database. Using the closed itemset lattice framework, we show that this problem can be reduced to the problem of finding frequent closed itemsets. Based on this statement, we can construct efficient data mining algorithms by limiting the search space to the closed itemset lattice rather than the subset lattice. Moreover, we show that the set of all frequent closed itemsets suffices to determine a reduced set of association rules, thus addressing another important data mining problem: limiting the number of rules produced without information loss. We propose a new algorithm, called A-Close, using a closure mechanism to find frequent closed itemsets. We realized experiments to compare our approach to the commonly used frequent itemset search approach. Those experiments showed that our approach is very valuable for dense and/or correlated data that represent an important part of existing databases.
1020|CHARM: An efficient algorithm for closed itemset mining|The set of frequent closed itemsets uniquely determines the exact frequency of all itemsets, yet it can be orders of magnitude smaller than the set of all frequent itemsets. In this paper we present CHARM, an efficient algorithm for mining all frequent closed itemsets. It enumerates closed sets using a dual itemset-tidset search tree, using an efficient hybrid search that skips many levels. It also uses a technique called diffsets to reduce the memory footprint of intermediate computations. Finally it uses a fast hash-based approach to remove any “non-closed” sets found during computation. An extensive experimental evaluation on a number of real and synthetic databases shows that CHARM significantly outperforms previous methods. It is also linearly scalable in the number of transactions.
1021|CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets|Association mining may often derive an undesirably large set of frequent itemsets and association rules. Recent studies have proposed an interesting alternative: mining frequent closed itemsets and their corresponding rules, which has the same power as association mining but substantially reduces the number of rules to be presented. In this paper, we propose an efficient algorithm, CLOSET, for mining closed itemsets, with the development of three techniques: (1) applying a compressed, frequent pattern tree FP-tree structure for mining closed itemsets without candidate generation, (2) developing a single prefix path compression technique to identify frequent closed itemsets quickly, and (3) exploring a partition-based projection mechanism for scalable mining in large databases. Our performance study shows that CLOSET is efficient and scalable over large databases, and is faster than the previously proposed methods. 1 Introduction It has been well recognized that frequent pattern minin...
1022|A regression-based temporal pattern mining scheme for data streams|We devise in this paper a regression-based algorithm, called algorithm FTP-DS (Frequent Temporal Patterns of Data Streams), to mine frequent temporal patterns for data streams. While providing a general framework of pattern frequency counting, algorithm FTP-DS has two major features, namely one data scan for online statistics collection and regressionbased compact pattern representation. To attain the feature of one data scan, the data segmentation and the pattern growth scenarios are explored for the frequency counting purpose. Algorithm FTP-DS scans online transaction flows and generates candidate frequent patterns in real time. The second important feature of algorithm FTP-DS is on the regression-based compact pattern representation. Specifically, to meet the space constraint, we devise for pattern representation a compact ATF (standing for Accumulated Time and Frequency) form to aggregately comprise all the information required for regression analysis. In addition, we develop the techniques of the segmentation tuning and segment relaxation to enhance the functions of FTP-DS. With these features, algorithm FTP-DS is able to not only conduct mining with variable time intervals but also perform trend detection effectively. Synthetic data and a real dataset which contains net-
1023|large sets of data streams |software architecture for the analysis of
1024|Models and framework for supporting run-time decisions in web-based systems |Efficient management of distributed Web-based systems requires several mechanisms that decide on request dispatching, load balance, admission control, request redirection. The algorithms be-hind these mechanisms typically make fast decisions on the basis of the load conditions of the system resources. The architecture complexity and workloads characterizing most Web-based ser-vices make it extremely difficult to deduce a representative view of a resource load from collected measures that show extreme variability even at different time scales. Hence, any decision based on instantaneous or average views of the system load may lead to useless or even wrong actions. As an alternative, we propose a two-phase strategy that first aims to obtain a representative view of the load trend from measured system values and then applies this representation to support runtime decision systems. We consider two classical problems behind decisions: how to detect significant and nontransient load changes of a system resource and how to predict its future load behavior. The two-phase strategy is based on stochastic functions that are characterized by a computational complexity that is compatible with runtime decisions. We describe, test, and tune the two-phase strategy by considering as a first example a multitier Web-based system that is subject to different classes of realistic and synthetic workloads. Also, we integrate the proposed strategy into a frame-
1025|Heavy-Tailed Probability Distributions in the World Wide Web|The explosion of the World Wide Web as a medium for information  dissemination has made it important to understand its characteristics, in  particular the distribution of its file sizes. This paper presents evidence  that a number of file size distributions in the Web exhibit heavy tails,  including files requested by users, files transmitted through the network,  transmission durations of files, and files stored on servers. In addition,  we argue that because of the presence of caching in the Web, the size  distribution of transmitted files is primarily determined by the distribution  of files available in the Web, and is relatively insensitive to the distribution  of files requested by users. Finally, we discuss some of the implications  of heavy-tailed transmission durations and relate these results to selfsimilarity  in network traffic.  
1026|Design and Evaluation of Alternative Selection Placement Strategies in Optimizing Continuous Queries|selection placement strategies for optimizing a very large number of continuous queries in an Internet environment. Two grouping strategies, PushDown and PullUp, in which selections are either pushed below, or pulled above, joins are proposed and investigated. While our earlier research has demonstrated that the incremental group optimization can significantly outperform an ungrouped approach, the results from this paper show that different incremental group optimization strategies can have significantly different performance characteristics. Surprisingly, in our studies, PullUp, in which selections are pulled above joins, is often better and achieves an average 10-fold performance improvement over PushDown (occasionally 100 times faster). Furthermore, a revised algorithm of PullUp, termed filtered PullUp is proposed that is able to further reduce the cost of PullUp by 75% when the union of the selection predicates is selective. Detailed cost models, which consider several special parameters, including (1) characteristics of queries to be grouped, and (2) characteristics of data changes, are presented in this paper. Preliminary experiments using an implementation of both strategies show that our models are fairly accurate in predicting the results obtained from the implementation of these techniques in the Niagara system. This work can serve as the basis for building a cost-based incremental group query optimizer to choose a better grouping strategy.
1027|Dimensionless Parameters For Evaluation Of Thermal Design And Performance Of Large-Scale Data Centers|Large-scale data centers (~20,000m    ) will be the major energy consumers of the next generation. The trend towards deployment of computer systems in large numbers, in very dense configurations in racks in a data center, has resulted in very high power densities at room level. Due to high heat loads (~3MWs) in an  interconnected environment, data center design based  on simple energy balance with zones, is inadequate. Energy consumption of data centers can be severely increased by inadequate air handling systems and rack  layouts that allow the hot and cold air streams to mix.
1028|ANALYSIS OF WIRELESS SENSOR NETWORKS FOR HABITAT MONITORING|  We provide an in-depth study of applying wireless sensor networks (WSNs) to real-world habitat monitoring. A set of system design requirements were developed that cover the hardware design of the nodes, the sensor network software, protective enclosures, and system architecture to meet the requirements of biologists. In the summer of 2002, 43 nodes were deployed on a small island off the coast of Maine streaming useful live data onto the web. Although researchers anticipate some challenges arising in real-world deployments of WSNs, many problems can only be discovered through experience. We present a set of experiences from a four month long deployment on a remote island. We analyze the environmental and node health data to evaluate system performance. The close integration of WSNs with their environment provides environmental data at densities previously impossible. We show that the sensor data is also useful for predicting system operation and network failures. Based on over one million 2 Polastre et. al. data readings, we analyze the node and network design and develop network reliability profiles and failure models.
1029|Directed Diffusion: A scalable and robust communication paradigm for sensor networks|Advances in processor, memory and radio technology will enable small and cheap nodes capable of sensing, communication and computation. Networks of such nodes can coordinate to perform distributed sensing of environmental phenomena. In this paper, we explore the directed diffusion paradigm for such coordination. Directed diffusion is data-centric in that all communication is for named data. All nodes in a directed diffusion-based network are application-aware. This enables diffusion to achieve energy savings by selecting empirically good paths and by caching and processing data in-network. We explore and evaluate the use of directed diffusion for a simple remote-surveillance sensor network.
1030|System architecture directions for networked sensors|Technological progress in integrated, low-power, CMOS communication devices and sensors makes a rich design space of networked sensors viable. They can be deeply embedded in the physical world or spread throughout our environment. The missing elements are an overall system architecture and a methodology for systematic advance. To this end, we identify key requirements, develop a small device that is representative of the class, design a tiny event-driven operating system, and show that it provides support for efficient modularity and concurrency-intensive operation. Our operating system fits in 178 bytes of memory, propagates events in the time it takes to copy 1.25 bytes of memory, context switches in the time it takes to copy 6 bytes of memory and supports two level scheduling. The analysis lays a groundwork for future architectural advances. 
1031|An Energy-Efficient MAC Protocol for Wireless Sensor Networks|This paper proposes S-MAC, a medium-access control (MAC) protocol designed for wireless sensor networks. Wireless sensor networks use battery-operated computing and sensing devices. A network of these devices will collaborate for a common application such as environmental monitoring. We expect sensor networks to be deployed in an ad hoc fashion, with individual nodes remaining largely inactive for long periods of time, but then becoming suddenly active when something is detected. These characteristics of sensor networks and applications motivate a MAC that is different from traditional wireless MACs such as IEEE 802.11 in almost every way: energy conservation and self-configuration are primary goals, while per-node fairness and latency are less important. S-MAC uses three novel techniques to reduce energy consumption and support self-configuration. To reduce energy consumption in listening to an idle channel, nodes periodically sleep. Neighboring nodes form virtual clusters to auto-synchronize on sleep schedules. Inspired by PAMAS, S-MAC also sets the radio to sleep during transmissions of other nodes. Unlike PAMAS, it only uses in-channel signaling. Finally, S-MAC applies message passing to reduce contention latency for sensor-network applications that require store-andforward processing as data move through the network. We evaluate our implementation of S-MAC over a sample sensor node, the Mote, developed at University of California, Berkeley. The experiment results show that, on a source node, an 802.11-like MAC consumes 2--6 times more energy than S-MAC for traffic load with messages sent every 1-10s.
1032|Next century challenges: Scalable coordination in sensor networks|Networked sensors-those that coordinate amongst them-selves to achieve a larger sensing task-will revolutionize information gathering and processing both in urban envi-ronments and in inhospitable terrain. The sheer numbers of these sensors and the expected dynamics in these environ-ments present unique challenges in the design of unattended autonomous sensor networks. These challenges lead us to hypothesize that sensor network coordination applications may need to be structured differently from traditional net-work applications. In particular, we believe that localized algorithms (in which simple local node behavior achieves a desired global objective) may be necessary for sensor net-work coordination. In this paper, we describe localized al-gorithms, and then discuss directed diffusion, a simple com-munication model for describing localized algorithms. 1
1033|Geography-informed Energy Conservation for Ad Hoc Routing|We introduce a geographical adaptive fidelity (GAF) algorithm that reduces energy consumption in ad hoc wireless networks. GAF conserves energy by identifying nodes that are equivalent from a routing perspective and then turning off unnecessary nodes, keeping a constant level of routing fidelity. GAF moderates this policy using application- and system-level information; nodes that source or sink data remain on and intermediate nodes monitor and balance energy use. GAF is independent of the underlying ad hoc routing protocol; we simulate GAF over unmodified AODV and DSR. Analysis and simulation studies of GAF show that it can consume 40% to 60% less energy than an unmodified ad hoc routing protocol. Moreover, simulations of GAF suggest that network lifetime increases proportionally to node density; in one example, a four-fold increase in node density leads to network lifetime increase for 3 to 6 times (depending on the mobility pattern). More generally, GAF is an example of adaptive fidelity, a technique proposed for extending the lifetime of self-configuring systems by exploiting redundancy to conserve energy while maintaining application fidelity.   
1035|Maté: A Tiny Virtual Machine for Sensor Networks|Composed of tens of thousands of tiny devices with very limited resources (&#034;motes&#034;), sensor networks are subject to novel systems problems and constraints. The large number of motes in a sensor network means that there will often be some failing nodes; networks must be easy to repopu-late. Often there is no feasible method to recharge motes, so energy is a precious resource. Once deployed, a network must be reprogrammable although physically unreachable, and this reprogramming can be a significant energy cost. We present Maté, a tiny communication-centric virtual machine designed for sensor networks. Mat~&#039;s high-level in-terface allows complex programs to be very short (under 100 bytes), reducing the energy cost of transmitting new programs. Code is broken up into small capsules of 24 instructions, which can self-replicate through the network. Packet sending and reception capsules enable the deploy-ment of ad-hoc routing and data aggregation algorithms. Maté&#039;s concise, high-level program representation simplifies programming and allows large networks to be frequently re-programmed in an energy-efficient manner; in addition, its safe execution environment suggests a use of virtual ma-chines to provide the user/kernel boundary on motes that have no hardware protection mechanisms. 
1036|The Impact of Data Aggregation in Wireless Sensor Networks|Sensor networks are distributed event-based systems that differ from traditional communication networks in several ways: sensor networks have severe energy constraints, redundant low-rate data, and many-to-one flows. Datacentric mechanisms that perform in-network aggregation of data are needed in this setting for energy-efficient information flow. In this paper we model data-centric routing and compare its performance with traditional end-toend routing schemes. We examine the impact of sourcedestination placement and communication network density on the energy costs and delay associated with data aggregation. We show that data-centric routing offers significant performance gains across a wide range of operational scenarios. We also examine the complexity of optimal data aggregation, showing that although it is an NP-hard problem in general, there exist useful polynomial-time special cases. 1 
1037|Computing Aggregates for Monitoring Wireless Sensor Networks|Wireless sensor networks involve very large numbers of small, low-power, wireless devices. Given their unattended nature, and their potential applications in harsh environments, we need a monitoring infrastructure that indicates system failures and resource depletion. In this paper, we briefly describe an architecture for sensor network monitoring, then focus on one aspect of this architecture: continuously computing aggregates (sum, average, count) of network properties (loss rates, energylevels  etc., packet counts). Our contributions are two-fold. First, we propose a novel tree construction algorithm that enables energy-efficient computation of some classes of aggregates. Second, we show through actual implementation and experiments that wireless communication artifacts in even relatively benign environments can significantly impact the computation of these aggregate properties. In some cases, without careful attention to detail, the relative error in the computed aggregates can be as much as 50%. However, by carefully discarding links with heavy packet loss and asymmetry, we can improve accuracy by an order of magnitude.
1038|Calibration as Parameter Estimation in Sensor Networks|We describe an ad-hoc localization system for sensor networks and explain why traditional calibration methods are inadequate for this system. Building upon previous work, we frame calibration as a parameter estimation problem; we parameterize each device and choose the values of those parameters that optimize the overall system performance. This method reduces our average error from 74.6% without calibration to 10.1%. We propose ways to expand this technique to a method of autocalibration for localization as well as to other sensor network applications.
1039|Survey of Quality of Service in Mobile Computing Environments|The specification and management of Quality of Service (QoS) is important in networks and distributed computing systems, particularly to support multimedia applications. The advent of portable lap-top computers, palmtops and Personal Digital Assistants with integrated communication capabilities facilitates mobile computing. This paper is a survey of QoS concepts and techniques for mobile distributed computing environments. The QoS attributes typically specified and negotiated for general communication systems are described as well as some QoS models. A brief overview is given of some practical systems described in the literature. The design issues relating to both mobile and nomadic computing are explained and then the specific QoS issues related to mobile and nomadic systems are discussed. The conclusion summarises the important issues relating to supporting QoS for mobile systems. Keywords Mobile systems, nomadic systems, quality of service, multimedia Quality of Service in Mobile...
1040|A Wireless Embedded Sensor Architecture for System-Level Optimization|Emerging low power, embedded, wireless sensor devices are targeting a wide range of applications, yet have very limited processing, storage, and energy resources. An architecture must be developed that can efficiently meet system demands while simultaneously remaining flexible to application specific optimizations. Analysis of past designs identifies core architectural issues and their impact on system performance. This paper outlines these issues and presents a generalized architecture designed to provide efficient communication mechanisms while allowing for system-level optimizations. The importance of providing a tight coupling between application and communication processing is shown and the tradeoffs associated with virtual versus physical parallelism are investigated. We conclude that a shared controller closely integrated with special-purpose hardware accelerators is the preferred building block for a flexible yet efficient node. A subset of the architecture is implemented using commercial building blocks and shows substantial improvements in communication performance and the ability to perform system-level optimizations that obtain tight synchronization and low power channel monitoring.
1041|A Collaborative Approach to In-Place Sensor Calibration|Numerous factors contribute to errors in sensor measurements.
1042|Design and Implementation of WIreless Sensor Networks for Habitat Monitoring|We provide an in-depth study of applying wireless sensor networks to real-world habitat monitoring. A set of system design requirements were developed that cover the hardware design of the nodes, the design of the sensor network, and the capabilities for remote data access and management. We propose a system architecture that addresses these requirements for habitat monitoring in general. We present an in-depth discussion of the implementation of the architecture for habitat monitoring. In the summer of 2002, 32 nodes were deployed on a small island off the coast of Maine streaming useful live data onto the web using our implementation. Results from the deployment show the profound impact software and hardware power management has on node longevity. The effectiveness of the system architecture is shown through the packet throughput and through the delivery of over 1.2 million readings logged at our database in Berkeley. The system operated for over four months; it provided data for two months after researchers had left the island for the winter due to poor weather conditions. The application-driven design exercise serves to identify important areas of further work in power management, data sampling, communications, network retasking, and health monitoring. We discuss the lessons learned from our deployment and provide a series of solutions that include new hardware, software, and protective enclosures.
1043|Preprocessing in a Tiered Sensor Network for Habitat Monitoring|We investigate task-decomposition and collaboration in a two-tiered sensor network for habitat monitoring. The system recognizes and localizes a specified type of birdcalls. The system has a few powerful macro nodes in the first tier, and many less-powerful micro nodes in the second tier. Each macro node combines data collected by multiple micro nodes for target classification and localization. We describe two types of lightweight preprocessing, which significantly reduce data transmission from micro nodes to macro nodes. Micro nodes classify events according to their cross-zero rates and discard irrelevant events. Data about events of interest are reduced and compressed before being transmitted to macro nodes for target localization. Preliminary experiments illustrate the effectiveness of event filtering and data reduction at micro nodes.
1044|A Dual-Space Approach to Tracking and Sensor Management in Wireless Sensor Networks|Wireless ad hoc sensor networks have the advantage of spanning a large geographical region and being able to collaboratively detect and track non-local spatio-temporal events. This paper presents a dual-space approach to event tracking and sensor resource management in sensor networks. The dual-space transformation maps a non-local phenomenon, e.g., the edge of a half-plane shadow, to a single point in the dual space, and maps locations of distributed sensor nodes to a set of lines that partitions the dual space. The detection problem becomes finding and tracking the cell that contains the point in the arrangement defined by these lines. This mechanism can be effectively used for power management of the sensor network -- nodes that will not be immediately visited by an event can be turned off to save energy required for sensing, processing, and communication. The approach has been successfully demonstrated on a laboratory testbed built using the UC Berkeley motes sensors. An implemented application of detecting and tracking light shadow edges moving over a sensor field is described.
1045|Target Classification and Localization in Habitat Monitoring|We are developing an acoustic habitat-monitoring sensor network that recognizes and locates specific animal calls in real time. In this paper, we investigate the system requirements of such a real-time acoustic monitoring network. We propose a system architecture and a set of lightweight collaborative signal processing algorithms that achieve real-time behavior while minimizing inter-node communication to extend the system lifetime. In particular, the target classification is based on spectrogram pattern matching while the target localization is based on beamforming using Time Difference Of Arrival (TDOA). We describe our preliminary implementation on a Commercial Off The Shelf (COTS) testbed and present its performance based on testbed measurements.
1046|Calibration of NASA Turbulent Air Motion Measurement System|. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 2. Background of Air Motion Measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 3. Instrumentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 3.1. Nose Boom and Meteorological Instrumentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 3.2. Inertial Navigation System. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 3.3. Aircraft Data Acquisition System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...
1047|Fuzzy Clustering of Parallel Data Streams |The management and processing of so-called data streams has recently become a topic of active research in several fields of computer science, notably database systems and data mining. A data stream can roughly be thought of as a transient, continuously increasing sequence of time-stamped data. In this paper, we consider the problem of clustering parallel streams of real-valued data, that is to say, continuously evolving time series. More specifically, we are interested in grouping data streams the evolution over time of which is similar in a specific sense. In order to maintain an up-to-date clustering structure, it is necessary to analyze the incoming data in an online manner, tolerating not more than a constant time delay. For this purpose, we develop an efficient online version of the fuzzy C-means clustering algorithm. A fuzzy approach appears to be particularly useful for this type of application, in which the clustering structure is subject to continuous changes.
1049|Answering queries using views|We consider the problem of computing answers to queries by using materialized views. Aside from its potential in optimizing query evaluation, the problem also arises in applications such as Global Information Systems, Mobile Computing and maintaining physical data independence. We consider the problem of nding a rewriting of a query that uses the materialized views, the problem of nding minimal rewritings, and nding complete rewritings (i.e., rewritings that use only the views). We show that all the possible rewritings can be obtained by considering containment mappings from the views to the query, and that the problems we consider are NP-complete when both the query and the views are conjunctive and don&#039;t involve built-in comparison predicates. We show that the problem has two independent sources of complexity (the number of possible containment mappings, and the complexity of deciding which literals from the original query can be deleted). We describe a polynomial time algorithm for nding rewritings, and show that under certain conditions, it will nd the minimal rewriting. Finally, we analyze the complexity of the problems when the queries and views may be disjunctive and involve built-in comparison predicates. 1
1050|Querying XML Views of Relational Data|XML has emerged as the standard data exchange format for Internet-based business applications. This has created the need to publish existing business data, stored in relational databases, as XML. A general way to publish relational data as XML is to provide XML views over relational data, and allow business partners to query these views using an XML query language. In this paper, we address the problem of evaluating XML queries over XML views of relational data. This paper makes two main contributions. The first is a general framework for processing arbitrarily complex queries specified using the XQuery query language. The second is a technique for efficiently evaluating XML queries by pushing most of the query computation down to the relational engine.  1. 
1051|Operator Placement for In-Network Stream Query Processing|In sensor networks, data acquisition frequently takes place at low-capability devices. The acquired data is then transmitted through a hierarchy of nodes having progressively increasing network bandwidth and computational power. We consider the problem of executing queries over these data streams, posed at the root of the hierarchy. To minimize data transmission, it is desirable to perform “in-network ” query processing: do some part of the work at intermediate nodes as the data travels to the root. Most previous work on in-network query processing has focused on aggregation and inexpensive filters. In this paper, we address in-network processing for queries involving possibly expensive conjunctive filters, and joins. We consider the problem of placing operators along the nodes of the hierarchy so that the overall cost of computation and data transmission is minimized. We show that the problem is tractable, give an optimal algorithm, and demonstrate that a simpler greedy operator placement algorithm can fail to find the optimal solution. Finally we define a number of interesting variations of the basic operator placement problem and demonstrate their hardness. 1
1052|Dynamic plan migration for continuous queries over data streams|Dynamic plan migration is concerned with the on-the-fly transition from one continuous query plan to a semantically equivalent yet more efficient plan. Migration is important for stream monitoring systems where long-running queries may have to withstand fluctuations in stream workloads and data characteristics. Existing migration methods generally adopt a pause-drain-resume strategy that pauses the processing of new data, purges all old data in the existing plan, until finally the new plan can be plugged into the system. However, these existing strategies do not address the problem of migrating query plans that contain stateful operators, such as joins. We now develop solutions for online plan migration for continuous stateful plans. In particular, in this paper, we propose two alternative strategies, called the moving state strategy and the parallel track strategy, one exploiting reusability and the second employs parallelism to seamlessly migrate between continuous join plans without affecting the results of the query. We develop cost models for both migration strategies to analytically compare them. We embed these migration strategies into the CAPE [7], a prototype system of a stream query engine, and conduct a comparative experimental study to evaluate these two strategies for window-based join plans. Our experimental results illustrate that the two strategies can vary significantly in terms of output rates and intermediate storage spaces given distinct system configurations and stream workloads. 1.
1053|Network-Aware Query Processing for Stream-based Applications|This paper investigates the benefits of network  awareness when processing queries in widelydistributed  environments such as the Internet.
1054|On-the-fly sharing for streamed aggregation|Data streaming systems are becoming essential for monitoring applications such as financial analysis and network intrusion detection. These systems often have to process many similar but different queries over common data. Since executing each query separately can lead to significant scalability and performance problems, it is vital to share resources by exploiting similarities in the queries. In this paper we present ways to efficiently share streaming aggregate queries with differing periodic windows and arbitrary selection predicates. A major contribution is our sharing technique that does not require any up-front multiple query optimization. This is a significant departure from existing techniques that rely on complex static analyses of fixed query workloads. Our approach is particularly vital in streaming systems where queries can join and leave the system at any point. We present a detailed performance study that evaluates our strategies with an implementation and real data. In these experiments, our approach gives us as much as an order of magnitude performance improvement over the state of the art. 1.
1055|A Temporal Foundation for Continuous Queries over Data Streams|Despite the surge of research in continuous stream processing, there is still a semantical gap. In many cases, continuous queries are formulated in an enriched SQL-like query language without specifying the semantics of such a query precisely enough. To overcome this problem, we present a sound and precisely defined temporal operator algebra over data streams ensuring deterministic query results of continuous queries. In analogy to traditional database systems, we distinguish between a logical and physical operator algebra. While our logical operator algebra specifies the semantics of each operation in a descriptive way over temporal multisets, the physical operator algebra provides adequate implementations in form of stream-to-stream operators. We show that query plans built with either the logical or the physical algebra produce snapshot-equivalent results. Moreover, we introduce a rich set of transformation rules that forms a solid foundation for query optimization, one of the major research topics in the stream community. Examples throughout the paper motivate the applicability of our approach and illustrate the steps from query formulation to query execution.  
1056|State-slice: New paradigm of multi-query optimization of window-based stream queries|Modern stream applications such as sensor monitoring systems and publish/subscription services necessitate the handling of large numbers of continuous queries specified over high volume data streams. Efficient sharing of computations among multiple continuous queries, especially for the memory- and CPU-intensive window-based operations, is critical. A novel challenge in this scenario is to allow resource sharing among similar queries, even if they employ windows of different lengths. This paper first reviews the existing sharing methods in the literature, and then illustrates the significant performance shortcomings of these methods. This paper then presents a novel paradigm for the sharing of window join queries. Namely we slice window states of a join operator into fine-grained window slices and form a chain of sliced window joins. By using an elaborate pipelining methodology, the number of joins after state slicing is reduced from quadratic to linear. This novel sharing paradigm enables us to push selections down into the chain and flexibly select subsequences of such sliced window joins for computation sharing among queries with different window sizes. Based on the state-slice sharing paradigm, two algorithms are proposed for the chain buildup. One minimizes the memory consumption while the other minimizes the CPU usage. The algorithms are proven to find the optimal chain with respect to memory or CPU usage for a given query workload. We have implemented the slice-share paradigm within the data stream management system CAPE. The experimental results show that our strategy provides the best performance over a diverse range of workload settings among all alternate solutions in the literature.
1057|HybMig: A Hybrid Approach to Dynamic Plan Migration for Continuous Queries|Abstract—In data stream environments, the initial plan of a long-running query may gradually become inefficient due to changes of the data characteristics. In this case, the query optimizer will generate a more efficient plan based on the current statistics. The online transition from the old to the new plan is called dynamic plan migration. In addition to correctness, an effective technique for dynamic plan migration should achieve the following objectives: 1) minimize the memory and CPU overhead of the migration, 2) reduce the duration of the transition, and 3) maintain a steady output rate. The only known solutions for this problem are the moving states (MS) and parallel track (PT) strategies, which have some serious shortcomings related to the above objectives. Motivated by these shortcomings, we first propose HybMig, which combines the merits of MS and PT and outperforms both in every aspect. As a second step, we extend PT, MS, and HybMig to the general problem of migration, where both the new and the old plans are treated as black boxes. Index Terms—Query processing. 1
1058|Multi-query optimization of sliding window aggregates by schedule synchronization |optimization
1059|Dynamic plan migration for snapshot-equivalent continuous queries in data stream systems|A data stream management system executes a large number of continuous queries in parallel. As stream characteristics and query workload change over time, the plan initially installed for a continuous query may become inefficient. As a consequence, the query optimizer will re-optimize this plan based on the current statistics. The replacement of the running plan with a more efficient but semantically equivalent plan at runtime is called dynamic plan migration. In order to have a sound semantic foundation for query optimization, we investigate dynamic plan migration for snapshot-equivalent plans. We develop a general method for dynamic plan migration that treats the old and new plan as snapshotequivalent black boxes. This enables the query optimizer to apply the conventional transformation rules during re-optimization. As a consequence, our approach supports the dynamic optimization of arbitrary continuous queries expressible in CQL, whereas existing solutions are limited in their scope.  
1060|Matching and Evaluation of Disjunctive Predicates for Data Stream Sharing|New optimization techniques, e. g., in data stream management systems (DSMSs), make the treatment of disjunctive predicates a necessity. In this paper, we introduce and compare methods for matching and evaluating disjunctive predicates.
1061|Systolic Opportunities for Multidimensional Data Streams|AbstractÐPortable image processing applications require an efficient, scalable platform with localized computing regions. This paper presents a newclass of area I/O systolic architecture to exploit the physical data locality of planar data streams by processing data where it falls. A synthesis technique using dependence graphs, data partitioning, and computation mapping is developed to handle planar data streams and to systematically design arrays with area I/O. Simulation results show that the use of area I/O provides a 16 times speedup over systems with perimeter I/O. Performance comparisons for a set of signal processing algorithms show that systolic arrays that consider planar data streams in the design process are up to three times faster than traditional arrays. Index TermsÐParallel computer architecture, systolic arrays, area I/O, design and performance evaluation. 1
1062|Will Physical Scalability Sabotage Performance Gains?|Many designers expect processor performance to keep improving at the current rate indefinitely as feature sizes shrink. However, as wire delays become a larger percentage of overall signal delay and as clock speeds grow faster than transistor speed, I believe performance increases will ultimately fall off. These delays are inevitable simply because wires are not keeping pace with the scaling of other features. In fact, for CMOS processes below 0.25 micron, the physical limits of wire scaling 1 may begin to change high-speed processor design. That is, an unacceptably small percentage of the die will be reachable during a single clock cycle. To support my prediction, I have mapped trends in a metric that relates time and distance and projections in clock speed across eight processor generations, from 0.6 to 0.06 micron. During this span (probably 0.1 micton) we&#039;ll see a billion transistor processor. To illustrate how physical scalability could affect the design of processors on this scale, I also compared signal drive distance and clock speed for the span endpoints, 0.6 and 0.06 micon.
1063|A scheme for supporting automatic data migration on multicomputers|We propose a data migration mechanism that allows an explicit and controlled mapping of data to memory. While read or write copies of each data element can be assigned to any processor&#039;s memory, longer term storage of each data element is assigned to a specific location in the memory of a particular processor. We present data that suggests that the scheme may be a practical method for efficiently supporting data migration.
1064|FAST VOLUME RENDERING USING A SHEAR-WARP FACTORIZATION OF THE VIEWING TRANSFORMATION|Volume rendering is a technique for visualizing 3D arrays of sampled data. It has applications in areas such as medical imaging and scientific visualization, but its use has been limited by its high computational expense. Early implementations of volume rendering used brute-force techniques that require on the order of 100 seconds to render typical data sets on a workstation. Algorithms with optimizations that exploit coherence in the data have reduced rendering times to the range of ten seconds but are still not fast enough for interactive visualization applications. In this thesis we present a family of volume rendering algorithms that reduces rendering times to one second. First we present a scanline-order volume rendering algorithm that exploits coherence in both the volume data and the image. We show that scanline-order algorithms are fundamentally more efficient than commonly-used ray casting algorithms because the latter must perform analytic geometry calculations (e.g. intersecting rays with axis-aligned boxes). The new scanline-order algorithm simply streams through the volume and the image in storage order. We describe variants of the algorithm for both parallel and perspective projections and
1065|Marching cubes: A high resolution 3D surface construction algorithm|We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.
1066|The rendering equation|ABSTRACT. We present an integral equation which generallzes a variety of known rendering algorithms. In the course of discussing a monte carlo solution we also present a new form of variance reduction, called Hierarchical sampling and give a number of elaborations shows that it may be an efficient new technique for a wide variety of monte carlo procedures. The resulting renderlng algorithm extends the range of optical phenomena which can be effectively simulated.
1067|Display of Surfaces from Volume Data|The application of volume rendering techniques to the display of surfaces from sampled scalar functions of three spatial dimensions is explored. Fitting of geometric primitives to the sampled data is not required. Images are formed by directly shading each sample and projecting it onto the picture plane. Surface shading calculations are performed at every voxel with local gradient vectors serving as surface normals. In a separate step, surface classification operators are applied to obtain a partial opacity for every voxel. Operators that detect isovalue contour surfaces and region boundary surfaces are presented. Independence of shading and classification calculations insures an undistorted visualization of 3-D shape. Non-binary classification operators insure that small or poorly defined features are not lost. The resulting colors and opacities are composited from back to front along viewing rays to form an image. The technique is simple and fast, yet displays surfaces exhibiting smooth silhouettes and few other aliasing artifacts. The use of selective blurring and super-sampling to further improve image quality is also described. Examples from two applications are given: molecular graphics and medical imaging.
1068|Footprint evaluation for volume rendering|This paper presents a forward mapping rendering algo-rithm to display regular volumetric grids that may not have the same spacings in the three grid directions. It takes advantage of the fact that convolution can be thought of as distributing energy from input samples into space. The renderer calculates an image plane footprint for each data sample and uses the footprint to spread the sample&#039;s energy onto the image plane. A result of the technique is that the forward mapping algorithm can support perspective without excessive cost, and support adaptive resampling of the three-dimensional data set during image generation.
1069|Volume Rendering|A technique for rendering images Of volumes containing mixtures of materials is presented. The shading model allows both the interior of a material and the boundary between materials to be colored. Image projection is performed by simulating the absorption of light along the ray path to the eye. The algorithms used are designed to avoid artifacts caused by aliasing and quantization and can be efficiently implemented on an image computer. Images from a variety of applications are shown.
1070|Efficient ray tracing of volume data|Volume rendering is a technique for visualizing sampled scalar or vector fields of three spatial dimensions without fitting geometric primitives to the data. A subset of these techniques generates images by computing 2-D projections of a colored semitransparent volume, where the color and opacity at each point are derived from the data using local operators. Since all voxels participate in the generation of each image, rendering time grows linearly with the size of the dataset. This paper presents a front-to-back image-order volume-rendering algorithm and discusses two techniques for improving its performance. The first technique employs a pyramid of binary volumes to encode spatial coherence present in the data, and the second technique uses an opacity threshold to adaptively terminate ray tracing. Although the actual time saved depends on the data, speedups of an order of magnitude have been observed for datasets of useful size and complexity. Examples from two applications are given: medical imaging and molecular graphics.
1071|Radiosity and Realistic Image Synthesis|this paper, such as the global distribution of radiative energy in the tree crowns, which affects the amount of light reaching the leaves and the local temperature of plant organs. The presented framework itself is also open to further research. To begin, the precise functional specification of the environment, implied by the design of the modeling framework, is suitable for a formal analysis of algorithms that capture various environmental processes. This analysis may highlight tradeoffs between time, memory, and communication complexity, and lead to programs matching the needs of the model to available system resources in an optimal manner. A deeper understanding of the spectrum of processes taking place in the environment may lead to the design of a mini-language for environment specification. Analogous to the language of L-systems for plant specification, this mini-language would simplify the modeling of various environments, relieving the modeler from the burden of low-level programming in a general-purpose language. Fleischer and Barr&#039;s work on the specification of environments supporting collisions and reaction-diffusion processes [20] is an inspiring step in this direction. Complexity issues are not limited to the environment, but also arise in plant models. They become particularly relevant as the scope of modeling increases from individual plants to groups of plants and, eventually, entire plant communities. This raises the problem of selecting the proper level of abstraction for designing plant models, including careful selection of physiological processes incorporated into the model and the spatial resolution of the resulting structures. The complexity of the modeling task can be also addressed at the level of system design, by assigning various components o...
1072|Octrees for faster isosurface generation| The large size of many volume data sets often prevents visualization algorithms from providing interactive rendering. The use of hierarchical data structures can ameliorate this problem by storing summary information to prevent useless exploration of regions of little or no current interest within the volume. This paper discusses research into the use of the octree hierarchical data structure when the regions of current interest can vary during the application, and are not known a priori. Octrees are well suited to the six-sided cell structure of many volumes. A new space-efficient design is introduced for octree representations of volumes whose resolutions are not conveniently a power of two; octrees following this design are called branch-on-need octrees (BONOs). Also, a caching method is described that essentially passes information between octree neighbors whose visitation times may be quite different, then discards it when its useful life is over. Using the application of octrees to isosurface generation as a focus, space and time comparisons for octree-based versus more traditional &#034;marching&#034; methods are presented.
1074|Ray Tracing Volume Densities|This paper presents new algorithms to trace objects represented by densities within a volume grid, e.g. clouds, fog, flames, dust, particle systems. We develop the light scattering equations, discuss previous methods of solu-tion, and present a new approximate solution to the full three-dimensional radiative scattering problem suitable for use in computer graphics. Additionally we review dynamical models for clouds used to make an animated movie.
1075|A Polygonal Approximation to Direct Scalar Volume Rendering|One method of directly rendering a three-dimensional volume of scalar data is to project each cell in a volume onto the screen. Rasterizing a volume cell is more complex than rasterizing a polygon. A method is presented that approximates tetrahedral volume cells with hardware renderable transparent triangles. This method produces results which are visually similar to more exact methods for scalar volume rendering, but is faster and has smaller memory requirements. The method is best suited for display of smoothlychanging data.  CR Categories and Subject Descriptors: I.3.0 [Computer Graphics]: General; I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling.  Additional Key Words and Phrases: Volume rendering, scientific visualization. 1 Introduction  Display of three-dimensional scalar volumes has recently become an active area of research. A scalar volume is described by some function f(x; y; z) defined over some region R of three-dimensional space. In many scientific ap...
1076|Survey Of Texture Mapping|This paper appeared in IEEE Computer Graphics and Applications, Nov. 1986, pp. 56-67. An earlier version of thi aper appeared in Graphics Interface &#039;86, May 1986, pp. 207-212. This postscript version is missing all of the paste-up -
1077|A language for shading and lighting calculations|A shading language provides a means to extend the shading and lighting formulae used by a rendering system. This paper discusses the design of a new shading language based on previous work of Cook and Perlin. This language has various types of shaders for light sources and surface reflectances, point and color data types, control flow constructs that support the casting of outgoing and the integration of incident light, a clearly specified interface to the rendering system using global state variables, and a host of useful built-in functions. The design issues and their impact on the implementation are also discussed. CR Categories: 1.3.3 [Computer Graphics] Picture/Image Generation- Display algorithms; 1.3.5 [Computer Graphics]
1078|Fourier volume rendering|In computer graphics we have traditionally rendered images of data sets specified spatially, Here, we present a volume rendering technique that operates on a frequency domain representation of the data set and that efficiently generates line integral projections of the spatial data it represents, The motivation for this approach is that the Fourier Projection-Slice Theorem allows us to compute 2-D projections of 3-D data seta using only a 2-D slice of the data in the frequency domain. In general, these “X-ray-like ” images can be rendered at a significantly lower computational cost than images generated by current volume rendering techniques, Additionally, assurances of image accuracy can he made.
1079|Fast Algorithms for Volume Ray Tracing|We examine various simple algorithms that exploit homogeneity and accumulated opacity for tracing rays through shaded volumes. Most of these methods have error criteria which allow them to trade quality for speed. The time vs. quality tradeoff for these adaptive methods is compared to fixed step multiresolution methods. These methods are also useful for general light transport in volumes. 1 Introduction  We are interested in speeding volume ray tracing computations. We concentrate on the one dimensional problem of tracing a single ray, or computing the intensity at a point from a single direction. In addition to being the kernel of a simple volume ray tracer, this computation can be used to generate shadow volumes and as an element in more general light transport problems. Our data structures will be view independent to speed the production of animations of preshaded volumes and interactive viewing. In [11] Levoy introduced two key concepts which we will be expanding on: presence accel...
1080|MemSpy: Analyzing Memory System Bottlenecks in Programs|To cope with the increasing difference between processor and main memory speeds, modern computer systems use deep memory hierarchies. In the presence of such hierarchies, the performance attained by an application is largely determined by its memory reference behavior--- if most references hit in the cache, the performance is significantly higher than if most references have to go to main memory. Frequently, it is possible for the programmer to restructure the data or code to achieve better memory reference behavior. Unfortunately, most existing performance debugging tools do not assist the programmer in this component of the overall performance tuning task. This paper describes MemSpy, a prototype tool that helps programmers identify and fix memory bottlenecks in both sequential and parallel programs. A key aspect of MemSpy is that it introduces the notion of data oriented, in addition to code oriented, performance tuning. Thus, for both source level code objects and data objects, Mem...
1081|The DASH Prototype: Logic Overhead and Performance|Abstract-The fundamental premise behind the DASH project is that it is feasible to build large-scale shared-memory multi-processors with hardware cache coherence. While paper studies and software simulators are useful for understanding many high-level design tradeoffs, prototypes are essential to ensure that no critical details are overlooked. A prototype provides convincing evidence of the feasibility of the design, allows one to accurately estimate both the hardware and the complexity cost of various features, and provides a platform for studying real workloads. A 48-processor prototype of the DASH multiprocessor is now operational. In this paper, we first examine the hardware overhead of directory-based cache coherence in the prototype. The data show that the overhead is only about M-15%, which appears to be a small cost for the ease of programming offered by coherent caches and the potential for higher performance. We then discuss the performance of the system and show the speedups obtained by a variety of parallel applications running on the prototype. Using a sophisticated hardware performance monitor, we also characterize the effectiveness of coherent caches and the relationship between an application’s reference behavior and its speedup. Finally, we present an evaluation of the optimizations incorporated in the DASH protocol in terms of their effectiveness on parallel applications and on atomic tests that stress the memory system.’ Index Terms- Directory-based cache coherence, implementa-tion cost, multiprocessor, parallel architecture, performance anal-
1082|Feature-Based Volume Metamorphosis|Image metamorphosis, or image morphing, is a popular technique for creating a smooth transition between two images. For synthetic images, transforming and rendering the underlying three-dimensional (3D) models has a number of advantages over morphing between two pre-rendered images. In this paper we consider 3D metamorphosis applied to volume-based representations of objects. We discuss the issues which arise in volume morphing and present a method for creating morphs. Our morphing method has two components: first a warping of the two input volumes, then a blending of the resulting warped volumes. The warping component, an extension of Beier and Neely&#039;s image warping technique to 3D, is feature-based and allows fine user control, thus ensuring realistic looking intermediate objects. In addition, our warping method is amenable to an efficient approximation which gives a 50 times speedup and is computable to arbitrary accuracy. Also, our technique corrects the ghosting problem present in...
1083|Volume Rendering on Scalable Shared-Memory MIMD Architectures|Volume rendering is a useful visualization technique for understanding the large amounts of data generated in a variety of scientific disciplines. Routine use of this technique is currently limited by its computational expense. We have designed a parallel volume rendering algorithm for MIMD architectures based on ray tracing and a novel task queue image partitioning technique. The combination of ray tracing and MIMD architectures allows us to employ algorithmic optimizations such as hierarchical opacity enumeration, early ray termination, and adaptive image sampling. The use of task queue image partitioning makes these optimizations efficient in a parallel framework. We have implemented our algorithm on the Stanford DASH Multiprocessor, a scalable shared-memory MIMD machine. Its single address-space and coherent caches provide programming ease and good performance for our algorithm. With only a few days of programming effort, we have obtained nearly linear speedups and near real-time frame update rates on a 48 processor machine. Since DASH is constructed from Silicon Graphics multiprocessors, our code runs on any Silicon Graphics workstation without modification.
1084|Template-Based Volume Viewing|We present an efficient three-phase algorithm for volume viewing that is based on exploit- - t ing coherency between rays in parallel projection. The algorithm starts by building a ray emplate and determining a special plane for projection -- the base-plane. Parallel rays are cast t into the volume from within the projected region of the volume on the base-plane, by repeating he sequence of steps specified in the ray-template. We carefully choose the type of line to be s employed and the way the template is being placed on the base-plane in order to assure uniform ampling of the volume by the discrete rays. We conclude by describing an optimized software K  implementation of our algorithm and reporting its performance. eywords: volume rendering, ray casting, template, parallel projection 1. Introduction  Volume visualization is the process of converting complex volume data to a format that is p amenable to human understanding while maintaining the integrity and accuracy of the data. Th...
1085|Volume Rendering by Adaptive Refinement|Volume rendering is a technique for visualizing sampled scalar functions of three spatial dimensions by computing 2D projections of a colored semi-transparent gel. This paper presents a volume rendering algorithm in which image quality is adaptively refined over time. An initial image is generated by casting a small number of rays into the data, less than one ray per pixel, and interpolating between the resulting colors. Subsequent images are generated by alternately casting more rays and interpolating. The usefulness of these rays is maximized by distributing them according to measures of local image complexity. Examples from two applications are given: molecular graphics and medical imaging. Key words: Volume rendering, voxel, adaptive refinement, adaptive sampling, ray tracing. 1. Introduction In this paper, we address the problem of visualizing sampled scalar functions of three spatial dimensions, henceforth referred to as volume data. We focus on a relatively new visualization tec...
1086|Volume Rendering using the Fourier Projection-Slice Theorem|The Fourier projection-slice theorem states that the inverse transform of a slice extracted from the frequency domain representation of a volume yields a projection of the volume in a direction perpendicular to the slice. This theorem allows the generation of attenuation-only renderings of volume data in O (N  2  log N) time for a volume of size N  3  . In this paper, we show how more realistic renderings can be generated using a class of shading models whose terms are Fourier projections. Models are derived for rendering depth cueing by linear attenuation of variable energy emitters and for rendering directional shading by Lambertian reflection with hemispherical illumination. While the resulting images do not exhibit the occlusion that is characteristic of conventional volume rendering, they provide sufficient depth and shape cues to give a strong illusion that occlusion exists. Keywords: Volume rendering, Fourier projections, Shading models, Scientific visualization, Medical imaging...
1087|A Data Distributed, Parallel Algorithm for Ray-Traced Volume Rendering|This paper presents a divide-and-conquer ray-traced volume rendering algorithm and a parallel image compositing method, along with their implementation and performance on the Connection Machine CM-5, and networked workstations. This algorithm distributes both the data and the computations to individual processing units to achieve fast, high-quality rendering of high-resolution data. The volume data, once distributed, is left intact. The processing nodes perform local raytracing of their subvolume concurrently. No communication between processing units is needed during this locally ray-tracing process. A subimage is generated by each processing unit and the #nal image is obtained by compositing subimages in the proper order, which can be determined a priori. Test results on both the CM-5 and a group of networked workstations demonstrate the practicality of our rendering algorithm and compositing method.  y  This researchwas supported in part by the National Aeronautics and Space Administration under NASA contract NAS1-19480 while the author was in residence at the Institute for Computer Application in Science and Engineering #ICASE#, NASA Langley Research Center, Hampton, VA 23681-0001.  i  1 
1088|Parallel Volume Visualization on a Hypercube Architecture|A parallel solution to the visualisation of high resolution vol- ume data is presented. Based on the ray tracing (RT) visu- alization technique, the system works on a distributed memory MIMD architecture. A hybrid strategy to ray tracing parallelization is applied, using ray dataflow within an image partition approach. This strategy allows the flexible and effective management of huge dataset on architectures with limited local memory. The dataset is distributed over the nodes using a slice-partitioning technique. The simple data partition chosen implies a straighforward communications pattern of the visualization processes and this improves both software design and eJciency, while providing deadlock prevention. The partitioning technique used and the network interconnection topology allow for the efficient implementation of a statical load balancing technique through pre-rendering of a low resolution image. Details related to the practical issues involved in the parallelization of volumetric RT are discussed, with particular reference to deadlock and termi- nation issues.
1089|Parallel Volume Rendering and Data Coherence|The two key issues in implementing a parallel ray-casting volume renderer are the work distribution and the data distribution. We have implemented such a renderer on the Fujitsu AP1000 using an adaptive image-space subdivision algorithm based on the worker-farm paradigm for the work distribution, and a distributed virtual memory, implemented in software, to provide the data distribution. Measurements show that this scheme works efficiently and effectively utilizes the data coherence that is inherent in volume data. Categories and Subject Descriptors: C.1.2 [Proces- sor Architectures]: Multiple Data Stream Architectures -- multiple-instruction-stream, multiple-data-stream (MIMD); I.3.1 [Computer Graphics]: Hardware Architecture -- parallel processing; I.3.7 [Computer Graphics]: ThreeDimensional Graphics and Realism -- ray tracing Key Words: Visualization, volume rendering, worker farm, image space, distributed virtual memory. 1 Introduction Volume rendering using ray-casting is a...
1090|Cube-3: A Real-Time Architecture for High-Resolution Volume Visualization|This paper describes a high-performance special-purpose system, Cube-3, for displaying and manipulating high-resolution volumetric datasets in real-time. A primary goal of Cube-3 is to render 512³, 16-bit per voxel, datasets at about 30 frames per second. Cube-3 implements a ray-casting algorithm in a highly-parallel and pipelined architecture, using a 3D skewed volume memory, a modular fast bus, 2D skewed buffers, 3D interpolation and shading units, and a ray projection cone. Cube-3 will allow users to interactively visualize and investigate in real-time static (3D) and dynamic (4D) high-resolution volumetric datasets.
1091|Transfer Equations in Global Illumination|The purpose of these notes is to describe some of the physical and mathematical properties of the equations occurring in global illumination. We first examine the physical assumptions that make the particle model of light an appropriate paradigm for computer graphics and then derive a balance equation for photons. In doing this we establish connections with the field of radiative transfer and its more abstract counterpart, transport theory. The resulting balance equation, known as the equation of transfer, accounts for large-scale interaction of light with participating media as well as complex reflecting surfaces. Under various simplifying assumptions the equation of transfer reduces to more conventional equations encountered in global illumination. 1 Introduction  Global illumination connotes a physically-based simulation of light appropriate for synthetic image generation. The task of such a simulation is to model the interplay of light among large-scale objects of an environment in...
1092|A Lipschitz Method for Accelerated Volume Rendering|Interpolating discrete volume data into a continuous form adapts implicit surface techniques for rendering volumetric iso-surfaces. One such algorithm uses the Lipschitz condition to create an octree representation that accelerates volume rendering. Furthermore, only one preprocessing step is needed to create the Lipschitzoctree representation that accelerates rendering of isosurfaces for any threshold value.
1093|Data Shaders|The process of visualizing a scientific data set requires an extensive knowledge of the domain in which the data set is created. Because an in-depth knowledge of all scientific domains is not available to the creator of visualization software, a flexible and extensible visualization system is essential in providing a productive tool to the scientist. This paper presents a shading language, based on the RenderMan shading language, that extends the shading model used to render volume data sets. Data shaders, written in this shading language, give the users of a volume rendering system a means of specifying how a volume data set is to be rendered. This flexibility is useful both as a visualization tool in the scientific community and as a research tool in the visualization community. 1 Introduction  As science is a diverse and far reaching topic, scientific visualization must be prepared to deal with diverse requirements when scientific data sets are examined, explored, and analyzed. In m...
1094|Annotations for sparse data streams|ar
1095|On the complexity of space bounded interactive proofs|Some of the most exciting developments in complexity theory in recent years concern the complexity of interactive proof systems, defined by Goldwasser, Micali and Rackoff (1985) and independently by Babai (1985). In this paper, we survey results on the complexity of space bounded interactive proof systems
1096|Property Testing Lower Bounds Via Communication Complexity|We develop a new technique for proving lower bounds in property testing, by showing a strong connection between testing and communication complexity. We give a simple scheme for reducing communication problems to testing problems, thus allowing us to use known lower bounds in communication complexity to prove lower bounds in testing. This scheme is general and implies a number of new testing bounds, as well as simpler proofs of several known bounds. For the problem of testing whether a boolean function is k-linear (a parity function on k variables), we achieve a lower bound of ?(k) queries, even for adaptive algorithms with two-sided error, thus confirming a conjecture of Goldreich [25]. The same argument behind this lower bound also implies a new proof of known lower bounds for testing related classes such as k-juntas. For some classes, such as the class of monotone functions and the class of s-sparse GF(2) polynomials, we significantly strengthen the best known bounds.
1097|Arthur-Merlin Streaming Complexity|We study the power of Arthur-Merlin probabilistic proof systems in the data stream model. We show a canonical AM streaming algorithm for a wide class of data stream problems. The algorithm offers a tradeoff between the length of the proof and the space complexity that is needed to verify it. As an application, we give an AM streaming algorithm for the Distinct Elements problem. Given a data stream of length m over alphabet of size n, the algorithm uses Õ(s) space and a proof of size Õ(w), for every s, w such that s · w = n (where Õ hides a polylog(m, n) factor). We also prove a lower bound, showing that every MA streaming algorithm for the Distinct Elements problem that uses s bits of space and a proof of size w, satisfies s · w = ?(n). As a part of the proof of the lower bound for the Distinct Elements problem, we show a new lower bound of ? (  v n) on the MA communication complexity of the Gap Hamming Distance problem, and prove its tightness. Keywords:
1098|QMA/qpoly ? PSPACE/poly: De-Merlinizing quantum protocols|This paper introduces a new technique for removing existential quantifiers over quantum states. Using this technique, we show that there is no way to pack an exponential number of bits into a polynomial-size quantum state, in such a way that the value of any one of those bits can later be proven with the help of a polynomial-size quantum witness. We also show that any problem in QMA with polynomial-size quantum advice, is also in PSPACE with polynomial-size classical advice. This builds on our earlier result that BQP/qpoly ? PP/poly, and offers an intriguing counterpoint to the recent discovery of Raz that QIP/qpoly = ALL. Finally, we show that QCMA/qpoly ? PP/poly and that QMA/rpoly = QMA/poly. 1
1099|The Randomized Communication Complexity of Set Disjointness|Abstract: We study the communication complexity of the disjointness function, in which each of two players holds a k-subset of a universe of size n and the goal is to determine whether the sets are disjoint. In the model of a common random string we prove that O(k) communication bits are sufficient, regardless of n. In the model of private random coins O(k + loglogn) bits suffice. Both results are asymptotically tight. 1
1100|The non-adaptive query complexity of testing k-parities|We prove tight bounds of T(k log k) queries for non-adaptively testing whether a function f: {0, 1} n ? {0, 1} is a k-parity or far from any k-parity. Both upper and lower bounds are new. The lower bound combines a recent method of Blais, Brody and Matulef [BBM11] to get testing lower bounds from communication complexity, with a new T(k log k) bound for the one-way communication complexity of k-disjointness. 1
1101|Certifying equality with limited interaction |The equality problem is usually one’s first encounter with communication complexity and is one of the most fundamental problems in the field. Although its deterministic and randomized communication complexity were settled decades ago, we find several new things to say about the problem by focusing on three subtle aspects. The first is to consider the expected communication cost (at a worst-case input) for a protocol that uses limited interaction—i.e., a bounded number of rounds of communication—and whose error probability is zero or close to it. The second is to treat the false negative error rate separately from the false positive error rate. The third is to consider the information cost of such protocols. We obtain asymptotically optimal rounds-versus-cost tradeoffs for equality: both expected communication cost and information cost scale as T(log log ·  ·  · logn), with r - 1 logs, where r is the number of rounds. These bounds hold even when the false negative rate approaches 1. For the case of zero-error communication cost, we obtain essentially matching bounds, up to a tiny additive constant. We also provide some applications.
1102|Best-Order Streaming model |Abstract. We study a new model of computation called stream checking on graph problems where a space-limited verifier has to verify a proof sequentially (i.e., it reads the proof as a stream). Moreover, the proof itself is nothing but a reordering of the input data. This model has a close relationship to many models of computation in other areas such as data streams, communication complexity, and proof checking and could be used in applications such as cloud computing. In this paper we focus on graph problems where the input is a sequence of edges. We show that checking if a graph has a perfect matching is impossible to do deterministically using small space. To contrast this, we show that randomized verifiers are powerful enough to check whether a graph has a perfect matching or is connected. 1
1104|Books in graphs|A set of q triangles sharing a common edge is called a book of size q. We write ß (n, m) for the the maximal q such that every graph G (n, m) contains a book of size q. In this note 1) we compute ß ( n, cn 2) for infinitely many values of c with 1/4 &lt; c &lt; 1/3, 2) we show that if m = (1/4 - a) n 2 with 0 &lt; a &lt; 17 -3 (), and G has no book of size at least graph G1 of order at least
1105|Additive Logistic Regression: a Statistical View of Boosting|Boosting (Freund &amp; Schapire 1996, Schapire &amp; Singer 1998) is one of the most important recent developments in classification methodology. The performance of many classification algorithms can often be dramatically improved by sequentially applying them to reweighted versions of the input data, and taking a weighted majority vote of the sequence of classifiers thereby produced. We show that this seemingly mysterious phenomenon can be understood in terms of well known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multi-class generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multi-class generalizations of boosting in most...
1106|Logistic Regression, AdaBoost and Bregman Distances|We give a unified account of boosting and logistic regression in which each learning problem is cast in terms of optimization of Bregman distances. The striking similarity of the two problems in this framework allows us to design and analyze algorithms for both simultaneously, and to easily adapt algorithms designed for one problem to the other. For both problems, we give new algorithms and explain their potential advantages over existing methods. These algorithms can be divided into two types based on whether the parameters are iteratively updated sequentially (one at a time) or in parallel (all at once). We also describe a parameterized family of algorithms which interpolates smoothly between these two extremes. For all of the algorithms, we give convergence proofs using a general formalization of the auxiliary-function proof technique. As one of our sequential-update algorithms is equivalent to AdaBoost, this provides the first general proof of convergence for AdaBoost. We show that all of our algorithms generalize easily to the multiclass case, and we contrast the new algorithms with iterative scaling. We conclude with a few experimental results with synthetic data that highlight the behavior of the old and newly proposed algorithms in different settings.  
1107|Fast Monte Carlo Algorithms for Matrices II: Computing a Low-Rank Approximation to a Matrix|... matrix A. It is often of interest to find a low-rank approximation to A, i.e., an approximation  D to the matrix A of rank not greater than a specified rank k, where k is much smaller than  m and n. Methods such as the Singular Value Decomposition (SVD) may be used to find an  approximation to A which is the best in a well defined sense. These methods require memory  and time which are superlinear in m and n; for many applications in which the data sets are  very large this is prohibitive. Two simple and intuitive algorithms are presented which, when  given an m n matrix A, compute a description of a low-rank approximation D    to A, and  which are qualitatively faster than the SVD. Both algorithms have provable bounds for the  error matrix A D    . For any matrix X , let kXk    and kXk 2 denote its Frobenius norm and  its spectral norm, respectively. In the  rst algorithm, c = O(1) columns of A are randomly  chosen. If the m c matrix C consists of those c columns of A (after appropriate rescaling)  then it is shown that from C    C approximations to the top singular values and corresponding  singular vectors may be computed. From the computed singular vectors a description D    of  the matrix A may be computed such that rank(D    )  k and such that            holds with high probability for both  = 2; F . This algorithm may be implemented without  storing the matrix A in Random Access Memory (RAM), provided it can make two passes  over the matrix stored in external memory and use O(m + n) additional RAM memory. The  second algorithm is similar except that it further approximates the matrix C by randomly  sampling r = O(1) rows of C to form a r  c matrix W . Thus, it has additional error, but  it can be implemented in three passes over the matrix using only constant ...
1108|Approximating extent measure of points |We present a general technique for approximating various descriptors of the extent of a set of points in?when the dimension?is an arbitrary fixed constant. For a given extent measure?and a parameter??, it computes in time a subset?of size, with the property that. The specific applications of our technique include?-approximation algorithms for (i) computing diameter, width, and smallest bounding box, ball, and cylinder of, (ii) maintaining all the previous measures for a set of moving points, and (iii) fitting spheres and cylinders through a point set. Our algorithms are considerably simpler, and faster in many cases, than previously known algorithms. 1
1109|Matrix Approximation and Projective Clustering via Volume Sampling| Frieze, Kannan, and Vempala (JACM 2004) proved that a small sample of rows of a given matrix A spans the rows of a low-rank approximation D that minimizes ||A-D||F within a small additive error, and the sampling can be done efficiently using just two passes over the matrix. In this paper, we generalize this result in two ways. First, we prove that the additive error drops exponentially by iterating the sampling in an adaptive manner (adaptive sampling). Using this result, we give a pass-efficient algorithm for computing a low-rank approximation with reduced additive error. Our second result is that there exist k rows of A whose span contains the rows of a multiplicative (k + 1)-approximation to the best rank-k matrix; moreover, this subset can be found by sampling k-subsets of rows from a natural distribution (volume sampling). Combining volume sampling with adaptive sampling yields the existence of a set of k + k(k + 1)/e rows whose span contains the rows of a multiplicative (1 + e)-approximation. This leads to a PTAS for the following NP-hard
1111|Near-linear time construction of sparse neighborhood covers|Abstract. This paper introduces a near-linear time sequential algorithm for constructing a sparse neighborhood cover. This implies analogous improvements (from quadratic to near-linear time) for any problem whose solution relies on network decompositions, including small edge cuts in planar graphs, approximate shortest paths, and weight- and distance-preserving graph spanners. In particular, an O(log n) approximation to the k-shortest paths problem on an n-vertex, E-edge graph is obtained that runs in Õ (n + E + k) time.
1112|A simple linear time algorithm for computing a (2k - 1)-spanner of O(n 1+1/k ) size in weighted graphs  (2003) |) edges are required in the worst case for any (2k \Gamma 1)-spanner, which has been proved for k = 1; 2; 3; 5. There exist polynomial time algorithms that can construct spanners with the size that matches this conjectured lower bound, and the best known algorithm takes O(mn 1=k) expected running time. In this paper, we present an extremely simple linear time randomized algorithm that computes a (2k \Gamma 1)-spanner of size matching the conjectured lower bound. An important feature of our algorithm is its local approach. Unlike all the previous algorithms which require computation of shortest paths, the new algorithm merely explores the edges in the neighborhood of a vertex or a group of vertices. This feature leads to designing simple external-memory and parallel algorithms for computing sparse spanners, whose running times are optimal up to logarithmic factors.
1113|Estimating entropy and entropy norm on data streams|Abstract. We consider the problem of computing information theoretic functions such as entropy on a data stream, using sublinear space. Our first result deals with a measure we call the “entropy norm ” of an input stream: it is closely related to entropy but is structurally similar to the well-studied notion of frequency moments. We give a polylogarithmic space one-pass algorithm for estimating this norm under certain conditions on the input stream. We also prove a lower bound that rules out such an algorithm if these conditions do not hold. Our second group of results are for estimating the empirical entropy of an input stream. We first present a sublinear space one-pass algorithm for this problem. For a stream of m items and a given real parameter a, our algorithm uses space?O(m 2a) and provides an approximation of 1/a in the worst case and (1 + e) in “most ” cases. We then present a two-pass polylogarithmic space (1+e)-approximation algorithm. All our algorithms are quite simple. 1
1114|Computing Diameter in the Streaming and Sliding-Window Models|We investigate the diameter problem in the streaming and sliding-window models. We show that, for a stream of n points or a sliding window of size n, any exact algorithm for diameter requires ?(n) bits of space. We present a simple ?-approximation 1algorithm for computing the diameter in the streaming model. Our main result is an ?-approximation algorithm that maintains the diameter in two dimensions in the sliding windows model using O ( 1 ?3/2 log 3 n(log R + log log n + log 1 ?)) bits of space, where R is the maximum, over all windows, of the ratio of the diameter to the minimum non-zero distance between any two points in the window. 1 introduction In recent years, massive data sets have become increasingly important in a wide range of applications. In many applications, the input can be viewed as a data stream [12, 7] that the
1115|A Linear Time Approximation Algorithm for Weighted Matchings in Graphs|Approximation algorithms have so far mainly been studied for problems that are not known to have polynomial time algorithms for solving them exactly. Here we propose an approximation algorithm for the weighted matching problem in graphs which can be solved in polynomial time. The weighted matching problem is to find a matching in an edge weighted graph that has maximum weight. The first polynomial time algorithm for this problem was given by Edmonds in 1965. The fastest known algorithm for the weighted matching problem has a running time of O(nm+n 2 log n). Many real world problems require graphs of such large size that this running time is too costly. Therefore there is considerable need for faster approximation algorithms for the weighted matching problem. We present a linear time approximation algorithm for the weighted matching problem with a performance ratio arbitrarily close to 2/3
1116|Estimating the sortedness of a data stream|The distance to monotonicity of a sequence is the minimum number of edit operations required to transform the sequence into an increasing order; this measure is complementary to the length of the longest increasing subsequence (LIS). We address the question of estimating these quantities in the one-pass data stream model and present the first sub-linear space algorithms for both problems. We first present O (  v n)-space deterministic algorithms that approximate the distance to monotonicity and the LIS to within a factor that is arbitrarily close to 1. We also show a lower bound of ?(n) on the space required by any randomized algorithm to compute the LIS (or alternatively the distance from monotonicity) exactly, demonstrating that approximation is necessary for sub-linear space computation; this bound improves upon the existing lower bound of ? (  v n) [LNVZ06]. Our main result is a randomized algorithm that uses only O(log 2 n) space and approximates the distance to monotonicity to within a factor that is arbitrarily close to 4. In contrast, we believe that any significant reduction in the space complexity for approximating the length of the LIS is considerably hard. We conjecture that any deterministic (1 + ?) approximation algorithm for LIS requires ? (  v n) space, and as a step towards this conjecture, prove a space lower bound of ? (  v n) for a restricted yet natural class of deterministic algorithms. 1
1117|A Space-Optimal Data-Stream Algorithm for Coresets in the Plane  |Given a point set P ? R², a subset Q ? P is an e-kernel of P if for every slab W containing Q, the (1+e)-expansion of W also contains P. We present a data-stream algorithm for maintaining an e-kernel of a stream of points in R² that uses O(1/ve) space and takes O(log(1/e)) amortized time to process each point. This is the first space-optimal data-stream algorithm for this problem. As a consequence, we obtain improved data-stream approximation algorithms for other extent measures, such as width, robust kernels, as well as e-kernels in higher dimensions. 
1118|Sketching information divergences|When comparing discrete probability distributions, natural measures of similarity are not lp distances but rather are information divergences such as Kullback-Leibler and Hellinger. This paper considers some of the issues related to constructing small-space sketches of distributions in the data-stream model, a concept related to dimensionality reduction, such that these measures can be approximated from the sketches. Related problems for lp distances are reasonably well understood via a series of results by Johnson &amp; Lindenstrauss (1984), Alon et al. (1999), Indyk (2000), and Brinkman &amp; Charikar (2003). In contrast, almost no analogous results are known to date about constructing sketches for the information divergences used in statistics and learning theory. Our main result is an impossibility result that shows that no small-space sketches exist for the multiplicative approximation of any commonly used f-divergences and Bregman divergences with the notable exceptions of l1 and l2 where small-space sketches exist. We then present data-stream algorithms for the additive approximation of a wide range of information divergences. Throughout, our emphasis is on providing general characterizations.
1119|An Approximate L p -Difference Algorithm for Massive Data Streams|Several recent papers have shown how to approximate the difference  P  i ja i \Gamma b i j or  P  ja i \Gamma b i j  2  between two functions, when the function values a i and b i are given in a data stream, and their order is chosen by an adversary. These algorithms use little space (much less than would be needed to store the entire stream) and little time to process each item in the stream and approximate with small relative error. Using different techniques, we show how to approximate the L  p  -difference  P  i ja i \Gamma b i j  p  for any rational-valued p 2 (0; 2], with comparable efficiency and error. We also show how to approximate  P  i ja i \Gamma b i j  p  for larger values of p but with a worse error guarantee. Our results fill in gaps left by recent work, by providing an algorithm that is precisely tunable for the application at hand. These results can be used to assess the difference between two chronologically or physically separated massive data sets, making one quick...
1120|The Space Complexity of Pass-Efficient Algorithms for Clustering |We present multiple pass streaming algorithms for a basic clustering problem for massive data sets. If our algorithm is allotted 2l passes, it will produce an approximation with error at most ? using Õ(k3 /?2/l)bitsof memory, the most critical resource for streaming computation. We demonstrate that this tradeoff between passes and memory allotted is intrinsic to the problem and model of computation by proving lower bounds on the memory requirements of any l pass randomized algorithm that are nearly matched by our upper bounds. To the best of our knowledge, this is the first time nearly matching bounds have been proved for such an exponential tradeoff for randomized computation. In this problem, we are given a set of n points drawn randomly according to a mixture of k uniform distributions and wish to approximate the density function of the mixture. The points are placed in a datastream (possibly in adversarial order), which may only be read sequentially by the algorithm. We argue that this models, among others, the datastream produced by a national census of the incomes of all citizens.  
1121|Lower bounds on streaming algorithms for approximating the length of the longest increasing subsequence|We show that any deterministic data-stream algorithm that makes a constant number of passes over the input and gives a constant factor approximation of the length of the longest increasing subsequence in a sequence of length n must use space ? (  v n). This proves a conjecture made by Gopalan, Jayram, Krauthgamer and Kumar [GJKK07] who proved a matching upper bound. Our results yield asymptotically tight lower bounds for all approximation factors, thus resolving the main open problem from their paper. Our proof is based on analyzing a related communication problem and proving a direct sum type property for it. 1
1123|Faster streaming algorithms for graph spanners|Given an undirected graph G = (V, E) on n vertices, m edges, and an integer t = 1, a subgraph (V, ES), ES ? E is called a t-spanner if for any pair of vertices u, v ? V, the distance between them in the subgraph is at most t times the actual distance. We present streaming algorithms for computing a t-spanner of essentially optimal size-stretch trade offs for any undirected graph. Our first algorithm is for the classical streaming model and works for unweighted graphs only. The algorithm performs a single pass on the stream of edges and requires O(m) time to process the entire stream of edges. This drastically improves the previous best single pass streaming algorithm for computing a t-spanner which requires ?(mn 2 t) time to process the stream and computes spanner with size slightly larger than the optimal. Our second algorithm is for StreamSort model introduced by Aggarwal et al. [2], which is the streaming model augmented with a sorting primitive. The StreamSort model has been shown to be a more powerful and still very realistic model than the streaming model for massive data sets applications. Our algorithm, which works of weighted graphs as well, performs O(t) passes using O(log n) bits of working memory only. Our both the algorithms require elementary data structures.
1124|Massive Metric Data Streams |Arithmetic on SRSPs
1125|Consistency of data-driven histogram methods for density estimation and classification|We present general sufficient conditions for the almost sure L1-consistency of his-togram density estimates based on data-dependent partitions. Analogous condi-tions guarantee the almost-sure risk consistency of histogram classification schemes based on data-dependent partitions. Multivariate data is considered throughout. In each case, the desired consistency requires shrinking cells, subexponential growth of a combinatorial complexity measure, and sub-linear growth of the num-ber of cells. It is not required that the cells of every partition be rectangles with sides paralles to the coordinate axis, or that each cell contain a minimum number of points. No assumptions are made concerning the common distribution of the training vectors. We apply the results to establish the consistency of several known partitioning estimates, including the kn-spacing density estimate, classifiers based on statisti-cally equivalent blocks, and classifiers based on multivariate clustering schemes.
1127|Statistical challenges in data stream applications |With the development of computing systems in every sector of activity, more and more data is now available only in the form of streams, i.e. structured data arriving continuously in a streaming way so that the standard paradigm of ‘store then process data ’ cannot stand anymore. Several approaches have been developed recently to handle such data streams: (1) DSMS (Data Stream Management Systems) are new data base systems enabling to query data streams, (2) Data Stream Mining methods enable to apply data mining algorithms to data streams. Several applications motivated the research in this area: monitoring of computer networks, analyzing telecommunication calls, analysis of stock market data, monitoring human activity like road traffic or electric power consumption,  … The challenge of these approaches is to process raw detailed data as it arrives and extract as much information as possible with ‘on the fly ’ algorithms’. The main idea to reduce the complexity of processing streams is that queries or data mining algorithms usually apply to temporal sliding windows (the last 2 hours, the last 2 months, …). When the size of sliding windows is high or when new queries or data mining tasks appear after the beginning of the stream, there is a need for summarizing streams. This communication will present two ways of summarizing streams: sampling and clustering which are standard approaches of statistical data analysis. Summarizing data streams poses new
1128|Research issues in data stream association rule mining|There exist emerging applications of data streams that require association rule mining, such as network traffic monitoring and web click streams analysis. Different from data in traditional static databases, data streams typically arrive continuously in high speed with huge amount and changing data distribution. This raises new issues that need to be considered when developing association rule mining techniques for stream data. This paper discusses those issues and how they are addressed in the existing literature. 1.
1129|Differencing data streams|We present external-memory algorithms for differencing large hierarchical datasets. Our methods are especially suited to streaming data with bounded differences. For input sizes m and n and maximum output (difference) size e, the I/O, RAM, and CPU costs of our algorithm rdiff are, respectively, m + n, 4e + 8, and O(MN). That is, given 4e + 8 blocks of RAM, our algorithm performs no I/O operations other than those required to read both inputs. We also present a variant of the algorithm that uses only four blocks of RAM, with I/O cost 8me + 18m + n + 6e + 5 and CPU cost O(MN). 1
1130|RCS --  a system for version control|An important problem in program development and maintenance is version control, i.e., the task of keeping a software system consisting of many versions and configurations well organized. The Revision Control System (RCS) is a software tool that assists with that task. RCS manages revisions of text documents, in particular source programs, documentation, and test data. It automates the storing, retrieval, logging and identification of revisions, and it provides selection mechanisms for composing configurations. This paper introduces basic version control concepts and discusses the practice of version control using RCS. For conserving space, RCS stores deltas, i.e., differences between successive revisions. Several delta storage methods are discussed. Usage statistics show that RCS’s delta storage method is space and time efficient. The paper concludes with a detailed survey of version control tools.
1131|Simple fast algorithms for the editing distance between trees and related problems|Ordered labeled trees are trees in which the left-to-right order among siblings is. significant. The distance between two ordered trees is considered to be the weighted number of edit operations (insert, delete, and modify) to transform one tree to another. The problem of approximate tree matching is also considered. Specifically, algorithms are designed to answer the following kinds of questions: 1. What is the distance between two trees? 2. What is the minimum distance between T and T when zero or more subtrees can be removed from T2 3. Let the pruning of a tree at node n mean removing all the descendants of node n. The analogous question for prunings as for subtrees is answered. A dynamic programming algorithm is presented to solve the three questions in sequential time O(I Tll x IT2lxmin (depth ( Tt), leaves ( T)) x min (depth(T2), leaves(T2))) and space O(Ir, x lT21) compared with o(I T,I IT=I x(depth(T)): x (depth(T2))) for the best previous published algorithm due to Tai [J. Assoc. Comput. Mach., 26 (1979), pp. 422-433]. Further, the algorithm presented here can be parallelized to give
1132|An O(ND) Difference Algorithm and Its Variations  (1986) |The problems of finding a longest common subsequence of two sequences A and B and a shortest edit script for transforming A into B have long been known to be dual problems. In this paper, they are shown to be equivalent to finding a shortest/longest path in an edit graph. Using this perspective, a simple O(ND) time and space algorithm is developed where N is the sum of the lengths of A and B and D is the size of the minimum edit script for A and B. The algorithm performs well when differences are small (sequences are similar) and is consequently fast in typical applications. The algorithm is shown to have O(N +D    expected-time performance under a basic stochastic model. A refinement of the algorithm requires only O(N) space, and the use of suffix trees leads to an O(NlgN +D    ) time variation.
1133|Representing and querying changes in semistructured data|Semistructured data may be irregular and incomplete and does not necessarily conform to a fixed schema. As with structured data, it is often desirable to maintain a history of changes to data, and to query over both the data and the changes. Representing and querying changes in semistructured data is more difficult than in structured data due to the irregularity and lack of schema. We present a model for representing changes in semistructured data and a language for querying over these changes. An important feature of our approach is that we represent and query changes directly as annotationson the affected data, instead of indirectly as the difference between database states. We describe the implementation of our model and query language. We also describe the design and implementation of a query subscription service that permits users to subscribe to changes in semistructured information sources. 1
1134|A file comparison program|This paper presents a simple method for computing a shortest sequence of insertion and deletion commands that converts one given file to another. The method is particularly efficient when the difference between the two files is small compared to the files &#039; lengths. In experiments performed on typical files, the program often ran four times faster than the UNIX diff command. KEY WORDS Edit distance Edit script Filc comparison
1135|A System for Approximate Tree Matching|Ordered, labeled trees are trees in which each node has a label and the left-to-right order of its children (if it has any) is fixed. Such trees have many applications in vision, pattern recognition, molecular biology, programming compilation and natural language processing. Many of the applications involve comparing trees or retrieving/extracting information from a repository of trees. Examples include classification of unknown patterns, analysis of newly sequenced RNA structures, semantic taxonomy for dictionary definitions, generation of interpreters for nonprocedural programming languages, and automatic error recovery and correction for programming languages. Previous systems use exact matching (or generalized regular expression matching) for tree comparison. This paper presents a system, called Approximate-Tree-By-Example (ATBE), which allows inexact matching of trees. The ATBE system interacts with the user through a simple, but powerful query language; graphical devices a...
1136|Comparing hierarchical data in external memory|We present an external-memory algorithm for computing a minimum-cost edit script between two rooted, ordered, labeled trees. The I/O, RAM, and CPU costs of our algorithm are, respectively, 4mn+7m+5n, 6S, andO(MN+(M+N)S1:5), whereMandNare the input tree sizes,Sis the block size,m=M=S, andn=N=S. This algorithm can make effective use of surplus RAM capacity to quadratically reduce I/O cost. We extend to trees the commonly used mapping from sequence comparison problems to shortest-path problems in edit graphs. 1
1137|Efficient Snapshot Differential Algorithms for Data Warehousing|Detecting and extracting modifications from information sources is an integral part of data  warehousing. For unsophisticated sources, in practice it is often necessary to infer modifications  by periodically comparing snapshots of data from the source. Although this sapshot di/rem  tial problem is closely related to traditional joins and outerjoins, there are significant differences,  which lead to simple new algorithms. In particular, we present algorithms that perform (possibly  lossy) compression of records. We also present a window algorithm that works very well  if the snapshots are not &#034;very different.&#034; The algorithms are studied via analysis and an implementation  of two of them; the results illustrate the potential gains achievable with the new  algorithms.
1138|Parallel ROLAP Data Cube Construction on Shared-Nothing Multiprocessors|The pre-computation of data cubes is critical to improving the response time of On-Line Analytical Processing (OLAP) systems and can be instrumental in accelerating data mining tasks in large data warehouses. In order to meet the need for improved performance created by growing data sizes, parallel solutions for generating the data cube are becoming increasingly important. This paper presents a parallel method for generating data cubes on a sharednothing multiprocessor. Since no (expensive) shared disk is required, our method can be used on low cost Beowulf style clusters consisting of standard PCs with local disks connected via a data switch. Our approach uses a ROLAP representation of the data cube where views are stored as relational tables. This allows for tight integration with current relational database technology.
1139|Structural Matching and Discovery in Document Databases|This memo is being written to ... the SGML markup minimization ... .................................................. Although only one tag is visible in ... &#034;carbon copy&#034; recipient), the SGML ... Yours truly, ................................................ &lt;!doctype memo SYSTEM&gt; Fig. 2. An SGML memo document A. Charles F. Goldfarb
1140|Statistical Mining in Data Streams|by
1141|A master-slave system to acquire biometric imagery of humans at distance|The Distant Human Identification (DHID) system is a masterslave, real-time surveillance system designed to acquire biometric imagery of humans at distance. A stationary wide field of view master camera is used to monitor an environment at distance. When the master camera detects a moving person, a narrow field of view slave camera is commanded to turn to that direction, acquire the target human, and track them while recording zoomed-in images. These zoomed-in views provide meaningful biometric imagery of the distant humans, who are not recognizable in the master view. Based on the lenses we currently use, the system can detect and track moving people at distances up to 50 meters, within a 60 o field of regard.
1142|Counting Hypergraphs in Data Streams|We present the first streaming algorithm for counting an arbitrary hypergraph H of constant size in a massive hypergraph G. Our algorithm can handle both edge-insertions and edge-deletions, and is applicable for the distributed setting. Moreover, our approach provides the first family of graph polynomials for the hypergraph counting problem. Because of the close relationship between hypergraphs and set systems, our approach may have applications in studying similar problems. 1
1143|On the desirability of acyclic database schemes| A class of database schemes, called acychc, was recently introduced. It is shown that this class has a number of desirable properties. In particular, several desirable properties that have been studied by other researchers m very different terms are all shown to be eqmvalent to acydicity. In addition, several equivalent charactenzauons of the class m terms of graphs and hypergraphs are given, and a smaple algorithm for determining acychclty is presented. Also given are several eqmvalent characterizations of those sets M of multivalued dependencies such that M is the set of muRlvalued dependencies that are the consequences of a given join dependency. Several characterizations for a conflict-free (in the sense of Lien) set of muluvalued dependencies are provided.
1144|Degrees of acyclicity for hypergraphs and relational database schemes|Abstract. Database schemes (winch, intuitively, are collecuons of table skeletons) can be wewed as hypergraphs (A hypergraph Is a generalization of an ordinary undirected graph, such that an edge need not contain exactly two nodes, but can instead contain an arbitrary nonzero number of nodes.) A class of &amp;quot;acychc &amp;quot; database schemes was recently introduced. A number of basic desirable propemes of database schemes have been shown to be equivalent to acyclicity This shows the naturalness of the concept. However, unlike the situation for ordinary, undirected graphs, there are several natural, noneqmvalent notions of acyclicity for hypergraphs (and hence for database schemes). Various desirable properties of database schemes are constdered and it is shown that they fall into several equivalence classes, each completely characterized by the degree of acycliclty of the scheme The results are also of interest from a purely graph-theoretic viewpomt. The original notion of aeyclicity has the countermtmtive property that a subhypergraph of an acychc hypergraph can be cyclic. This strange behavior does not occur for the new degrees of acyelicity that are considered.
1145|Learning with hypergraphs: Clustering, classification, and embedding|We usually endow the investigated objects with pairwise relationships, which can be illustrated as graphs. In many real-world problems, however, relationships among the objects of our interest are more complex than pairwise. Naively squeezing the complex relationships into pairwise ones will inevitably lead to loss of information which can be expected valuable for our learning tasks however. Therefore we consider using hypergraphs instead to completely represent complex relationships among the objects of our interest, and thus the problem of learning with hypergraphs arises. Our main contribution in this paper is to generalize the powerful methodology of spectral clustering which originally operates on undirected graphs to hypergraphs, and further develop algorithms for hypergraph embedding and transductive classification on the basis of the spectral hypergraph clustering approach. Our experiments on a number of benchmarks showed the advantages of hypergraphs over usual graphs. 1
1146|Efficient semi-streaming algorithms for local triangle counting in massive graphs |In this paper we study the problem of local triangle counting in large graphs. Namely, given a large graph G = (V, E) we want to estimate as accurately as possible the number of triangles incident to every node v ? V in the graph. The problem of computing the global number of triangles in a graph has been considered before, but to our knowledge this is the first paper that addresses the problem of local triangle counting with a focus on the efficiency issues arising in massive graphs. The distribution of the local number of triangles and the related local clustering coefficient can be used in many interesting applications. For example, we show that the measures we compute can help to detect the presence of spamming activity in large-scale Web graphs, as well as to provide useful features to assess content quality in social networks. For computing the local number of triangles we propose two approximation algorithms, which are based on the idea of min-wise independent permutations (Broder et al. 1998). Our algorithms operate in a semi-streaming fashion, using O(|V |) space in main memory and performing O(log |V |) sequential scans over the edges of the graph. The first algorithm we describe in this paper also uses O(|E|) space in external memory during computation, while the second algorithm uses only main memory. We present the theoretical analysis as well as experimental results in massive graphs demonstrating the practical efficiency of our approach. Luca Becchetti was partially supported by EU Integrated
1147|Estimating frequency moments of data streams using random linear combinations|Abstract. The problem of estimating the k th frequency moment Fk for any nonnegative k, over a data stream by looking at the items exactly once as they arrive, was considered in a seminal paper by Alon, Matias and Szegedy [1, 2]. The space complexity of their algorithm is Õ(n1 - 1 k). For k&gt; 2, their technique does not apply to data streams with arbitrary insertions and deletions. In this paper, we present an algorithm for estimating Fk for k&gt; 2, over general update streams 1 whose space complexity is Õ(n1 - k-1) and time complexity of processing each stream update is Õ(1). Recently, an algorithm for estimating Fk over general update streams with similar space complexity has been published by Coppersmith and Kumar [7]. Our technique is, (a) basically different from the technique used by [7], (b) is simpler and symmetric, and, (c) is significantly more efficient in terms of the time required to 1 process a stream update ( Õ(1) compared with Õ(n1 - k-1)). 1
1148|Counting arbitrary subgraphs in data streams|Abstract. We study the subgraph counting problem in data streams. We provide the first non-trivial estimator for approximately counting the number of occurrences of an arbitrary subgraph H of constant size in a (large) graph G. Our estimator works in the turnstile model, i.e., can handle both edge-insertions and edge-deletions, and is applicable in a distributed setting. Prior to this work, only for a few non-regular graphs estimators were known in case of edge-insertions, leaving the problem of counting general subgraphs in the turnstile model wide open. We further demonstrate the applicability of our estimator by analyzing its concentration for several graphs H and the case where G is a power law graph.
1149|Approximate Counting of Cycles in Streams |Subgraph counting is a fundamental problem in algorithm design and has many applications in data mining, biology, social networks, and many other domains. Over the past years this problem has been studied extensively from a theoretical point of view. Because of the intensive computational resources required, traditional algorithms are infeasible even for medium sized graphs. A natural way to address this problem in a massive graph is to use the data streaming model, where edges arrive in an arbitrary order and the algorithm is required to use limited memory to approximate the number of subgraphs. Prior to our work, most subgraph counting algorithms are based on edge sampling. In this paper we develop a novel approach for counting cycles of an arbitrary but fixed size in the turnstile model, i. e., the input stream is a sequence of edge insertions and deletions. Our algorithm is based on the idea of computing instances of complex-valued random variables over the given stream, and improves drastically upon the naïve sampling algorithms. In contrast to most existing approaches, our algorithm can also be easily applied in the distributed setting. We believe that the idea of using complex-valued random variables will find further applications, in particular with respect to also counting more general subgraphs.
1150|Bonsai: An event-based framework for processing and controlling data streams. Frontiers in Neuroinformatics|controlling data streams
1151|Marker tracking and HMD calibration for a video-based augmented reality conferencing system|We describe an augmented reality conferencing system which uses the overlay of virtual images on the real world. Remote collaborators are represented on Virtual Monitors which can be freely positioned about a user in space. Users can collaboratively view and interact with virtual objects using a shared virtual whiteboard. This is possible through precise virtual image registration using fast and accurate computer vision techniques and HMD calibration. We propose a method for tracking fiducial markers and a calibration method for optical see-through HMD based on the marker tracking. 1.
1152|Advances in dataflow programming languages|  Many developments have taken place within dataflow programming languages in the past decade. In particular, there has been a great deal of activity and advancement in the field of dataflow visual programming languages. The motivation for this article is to review the content of these recent developments and how they came
1153|Automated monitoring and quantitative analysis of feeding behaviour in Drosophila |Food ingestion is one of the defining behaviours of all animals, but its quantification and analysis remain challenging. This is especially the case for feeding behaviour in small, genetically tractable animals such as Drosophila melanogaster. Here, we present a method based on capacitive measurements, which allows the detailed, automated and high-throughput quantification of feeding behaviour. Using this method, we were able to measure the volume ingested in single sips of an individual, and monitor the absorption of food with high temporal resolution. We demonstrate that flies ingest food by rhythmically extending their proboscis with a frequency that is not modulated by the internal state of the animal. Instead, hunger and satiety homeostatically modulate the microstructure of feeding. These results highlight similarities of food intake regulation between insects, rodents, and humans, pointing to a common strategy in how the nervous systems of different animals control food intake.
1154|Oceanstore: An architecture for global-scale persistent storage|OceanStore is a utility infrastructure designed to span the globe and provide continuous access to persistent information. Since this infrastructure is comprised of untrusted servers, data is protected through redundancy and cryptographic techniques. To improve performance, data is allowed to be cached anywhere, anytime. Additionally, monitoring of usage patterns allows adaptation to regional outages and denial of service attacks; monitoring also enhances performance through pro-active movement of data. A prototype implementation is currently under development. 1
1155|SPAND: Shared Passive Network Performance Discovery|In the Internet today, users and applications must often make decisions based on the performance they expect to receive from other Internet hosts. For example, users can often view many Web pages in low-bandwidth or high-bandwidth versions, while other pages present users with long lists of mirror sites to chose from. Current techniques to perform these decisions are often ad hoc or poorly designed. The most common solution used today is to require the user to manually make decisions based on their own experience and whatever information is provided by the application. Previous efforts to automate this decision-making process have relied on isolated, active network probes from a host. Unfortunately, this method of making measurements has several problems. Active probing introduces unnecessary network traffic that can quickly become a significant part of the total traffic handled by busy Web servers. Probing from a single host results in less accurate information and more redundant network probes than a system that shares information with nearby hosts. In this paper, we propose a system called SPAND (Shared Passive Network Performance Discovery) that determines network characteristics by making shared, passive measurements from a collection of hosts. In this paper, we show why using passive measurements from a collection of hosts has advantages over using active measurements from a single host. We also show that sharing measurements can significantly increase the accuracy and timeliness of predictions. In addition, we present a initial prototype design of SPAND, the current implementation status of our system, and initial performance results that show the potential benefits of SPAND.  
1156|IP Multicast Channels: Express Support for Large-scale Single-source Applications|In the IP multicast model, a set of hosts can be aggregated into a group of hosts with one address, to which any host can send. However, Internet TV, distance learning, file distribution and other emerging large-scale multicast applications strain the current realization of this model, which lacks a basis for charging, lacks access control, and is difficult to scale.  This paper proposes an extension to IP multicast to support the channel model of multicast and describes a specific realization called EXPlicitly REquested SingleSource (EXPRESS) multicast. In this model, a multicast  channel has exactly one explicitly designated source,  and zero or more channel subscribers. A single protocol supports both channel subscription and efficient collection of channel information such as subscriber count. We argue that EXPRESS addresses the aforementioned problems, justifying this multicast service model in the Internet.   
1157|Core based trees (CBT) multicast routing architecture  (1996) |This memo defines an Experimental Protocol for the Internet community. This memo does not specify an Internet standard of any kind. Discussion and suggestions for improvement are requested. Distribution of this memo is unlimited. CBT is a multicast routing architecture that builds a single delivery tree per group which is shared by all of the group’s senders and receivers. Most multicast algorithms build one multicast tree per sender (subnetwork), the tree being rooted at the sender’s subnetwork. The primary advantage of the shared tree approach is that it typically offers more favourable scaling characteristics than all other multicast algorithms. The CBT protocol [1] is a network layer multicast routing protocol that builds and maintains a shared delivery tree for a multicast group. The sending and receiving of multicast data by hosts on a
1158|REUNITE: A Recursive Unicast Approach to Multicast|We propose a new multicast protocol called REUNITE. The key idea of REUNITE is to use recursive unicast trees to implement multicast service. REUNITE does not use class D IP addresses. Instead, both group identification and data forwarding are based on unicast IP addresses. Compared with existing IP multicast protocols, REUNITE has several unique properties. First, only routers that are acting as multicast tree branching points for a group need to keep multicast forwarding state of the group. All other non-branching-point routers simply forward data packets by unicast routing. In addition, REUNITE can be incrementally deployed in the sense that it works even if only a subset of the routers implement the protocol. Furthermore, REUNITE supports load balancing and graceful degradation such that when a router does not have resources (forwarding table entry, buffer space, processing power) to support additional multicast groups, the branching can be automatically migrated to other less load...
1159|Performance characteristics of mirror servers on the internet|Abstract — As a growing number of web sites introduce mirrors to increase throughput, the challenge for clients becomes determining which mirror will offer the best performance when a document is to be retrieved. In this paper we present findings from measuring 9 clients scattered throughout the United States retrieving over 490,000 documents from 47 production web servers which mirror three different web sites. We have severalinteresting findings that may aid in the design of protocols for choosing among mirror servers. Though server performance varies widely, we have observed that a server’s performance relative to other servers is more stable and is independent of time scale. In addition, a change in an individual server’s transfer time is not a strong indicator that its performance relative to other servers has changed. Finally, we have found that clients wishing to achieve near-optimal performance may only need to consider a small number of servers rather than all mirrors of a particular site. I.
1160|The Breadcrumb Forwarding Service: A Synthesis of PGM and EXPRESS to Improve and Simplify|If ubiquitously deployed, IP Multicast promises to provide an efficient datagram service for an arbitrary sending host to reach an arbitrary and dynamic set of destination hosts anywhere in the Internet. Unfortunately, two very difficult problems —interdomain multicast routing and viable end-to-end multicast transport — have yet to be solved and deployed satisfactorily. This paper proposes that two existing but independent network mechanisms — the EXPRESS service model and the network component of the Pragmatic Multicast protocol (PGM) — be synthesized in a scheme we call the Breadcrumb Forwarding Service (BCFS) to simultaneouslytackle the problemsof interdomain multicast routing and end-to-end reliable multicast. Like EXPRESS, BCFS utilizes explicit-source group join and like PGM, enhances the network forwarding architecture with finer-grained group control. In this paper, we detail BCFS service model and router mechanisms to support the service. To demonstrate the flexibility and efficiency of BCFS, we describe the application examples built on this service model, which can accommodate not only PGM and also a novel reliable multicast transport protocol. 1.
1162|Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals|Abstract. Data analysis applications typically aggregate data across many dimensions looking for anomalies or unusual patterns. The SQL aggregate functions and the GROUP BY operator produce zero-dimensional or one-dimensional aggregates. Applications need the N-dimensional generalization of these operators. This paper defines that operator, called the data cube or simply cube. The cube operator generalizes the histogram, crosstabulation, roll-up, drill-down, and sub-total constructs found in most report writers. The novelty is that cubes are relations. Consequently, the cube operator can be imbedded in more complex non-procedural data analysis programs. The cube operator treats each of the N aggregation attributes as a dimension of N-space. The aggregate of a particular set of attribute values is a point in this space. The set of points forms an N-dimensional cube. Super-aggregates are computed by aggregating the N-cube to lower dimensional spaces. This paper (1) explains the cube and roll-up operators, (2) shows how they fit in SQL, (3) explains how users can define new aggregate functions for cubes, and (4) discusses efficient techniques to compute the cube. Many of these features are being added to the SQL Standard.
1163|Multiple Object Identification with Passive RFID Tags|We investigate the applicability of passive RFID systems to the task of identifying multiple tagged objects simultaneously, assuming that the number of tags is not known in advance. We present a combinatorial model of the communication mechanism between the reader device and the tags, and use this model to derive the optimal parameter setting for the reading process, based on estimates for the number of tags. Some results on the performance of an implementation are presented.
1164|Integrating Automatic Data Acquisition with Business Processes Experiences with SAP&#039;s Auto-ID Infrastructure|this paper we give an overview of the existing infrastructure, discuss lessons learned from successful customer pilots, and point out some of the open research issues
1165|Update-Pattern-Aware Modeling and Processing of Continuous Queries|A defining characteristic of continuous queries over on-line data streams, possibly bounded by sliding windows, is the potentially infinite and time-evolving nature of their inputs and outputs. New items continually arrive on the input streams and new results are continually produced. Additionally, inputs expire by falling out of range of their sliding windows and results expire when they cease to satisfy the query. This impacts continuous query processing in two ways. First, data stream systems allow tables to be queried alongside data streams, but in terms of query semantics, it is not clear how updates of tables are different from insertions and deletions caused by the movement of the sliding windows. Second, many interesting queries need to store state, which must be kept up-to-date as time goes on. Therefore, query processing efficiency depends highly on the amount of overhead involved in state maintenance. In this paper, we show that the above issues can be solved by understanding the update patterns of continuous queries and exploiting them during query processing. We propose a classification that defines four types of update characteristics. Using our classification, we present a definition of continuous query semantics that clearly states the role of relations. We then propose the notion of update-pattern-aware query processing, where physical implementations of query operators, including the data structures used for storing intermediate state, vary depending on the update patterns of their inputs and outputs. When tested on IP traffic logs, our update-pattern-aware query plans routinely outperform the existing techniques by an order of magnitude.  
1167|Loadstar: A load shedding scheme for classifying data streams|We consider the problem of resource allocation in mining multiple data streams. Due to the large volume and the high speed of streaming data, mining algorithms must cope with the effects of system overload. How to realize maximum mining benefits under resource constraints becomes a challenging task. In this paper, we propose a load shedding scheme for classifying multiple data streams. We focus on the following problems: i) how to classify data that are dropped by the load shedding scheme? and ii) how to decide when to drop data from a stream? We introduce a quality of decision (QoD) metric to measure the level of uncertainty in classification when exact feature values of the data are not available because of load shedding. A Markov model is used to predict the distribution of feature values and we make classification decisions using the predicted values and the QoD metric. Thus, resources are allocated among multiple data streams to maximize the quality of classification decisions. Furthermore, our load shedding scheme is able to learn and adapt to changing data characteristics in the data streams. Experiments on both synthetic data and real-life data show that our load shedding scheme is effective in improving the overall accuracy of classification under resource constraints.
1168|Temporal Aggregation over Data Streams using Multiple Granularities|Temporal aggregation is an important but costly operation for applications that maintain time-evolving data (data warehouses, temporal databases, etc.). In this paper we examine the problem of computing temporal aggregates over data streams. Such aggregates are maintained using multiple levels of temporal granularities: older data is aggregated using coarser granularities while more recent data is aggregated with finer detail. We present specialized indexing schemes for dynamically and progressively maintaining temporal aggregates.
1169|Efficient Execution of Sliding-Window Queries Over Data Streams|Emerging data stream processing systems rely on windowing to enable on-the-fly processing of continuous queries over unbounded streams. As a result, several recent e#orts have developed window-aware implementations of query operators such as joins and aggregates. This focus on individual operators, however, ignores the larger issue of how to coordinate the pipelined execution of such operators when combined into a full windowed query plan. In this paper, we first show how the straightforward application of traditional pipelined query processing techniques to sliding window queries can result in ine#cient and incorrect behavior. We then present three alternative execution techniques that guarantee correct behavior for pipelined sliding window queries and develop new algorithms for correctly evaluating window-based duplicateelimination, Group-By and Set operators in this context. We implemented all of these techniques in a prototype data stream system and report the results of a detailed performance study of the system.
1170|Control-based quality adaptation in data stream management systems|Abstract. Unlike processing snapshot queries in a traditional DBMS, the processing of continuous queries in a data stream management system (DSMS) needs to satisfy quality requirements such as processing delay. When the system is overloaded, quality degrades significantly thus load shedding becomes necessary. Maintaining the quality of queries is a difficult problem because both the processing cost and data arrival rate are highly unpredictable. We propose a quality adaptation framework that adjusts the application behavior based on the current system status. We leverage techniques from the area of control theory in designing the quality adaptation framework. Our simulation results demonstrate the effectiveness of the control-based quality adaptation strategy. Comparing to solutions proposed in previous works, our approach achieves significantly better quality with less waste of resources. 1
1171|Flexible time management in data stream systems|Continuous queries in a Data Stream Management System (DSMS) rely on time as a basis for win-dows on streams and for defining a consistent semantics for multiple streams and updatable relations. The system clock in a centralized DSMS provides a convenient and well-behaved notion of time, but often it is more appropriate for a DSMS application to define its own notion of time—its own clock(s), sequence numbers, or other forms of ordering and timestamping. Flexible application-defined time poses challenges to the DSMS, since streams may be out of order and uncoordinated with each other, they may incur latency reaching the DSMS, and they may pause or stop. We formalize these challenges and specify how to generate heartbeats so that queries can be evaluated correctly and continuously in an application-defined time domain. Our heartbeat generation algorithm is based on parameters capturing skew between streams, unordering within streams, and latency in streams reaching the DSMS. We also describe how to estimate these parameters at run-time, and we discuss how heartbeats can be used for processing continuous queries. 1
1172|Agile Data Streaming for Grid Applications |The grid is proposed to be the new computing infrastructure for cross-domain resource sharing and collaboration in virtual organizations. While most current work in grid computing community focus on adaptability of grid resource management, agility is proposed in this work as another essential requirement, aiming to provide mass customization and personalization on grid computing service provision. This work is focused on data streaming aspects of grid agility. Since volumes of data streams are usually extremely high but available bandwidth and storage are often very limit in a grid environment, an enabling environment for grid data streaming applications is implemented with supports of on-demand data transfers and just-in-time data cleanups in this work. The implementation includes performance sensors, predictors and a scheduler, with real-time measurements, prediction and scheduling capabilities. The GridFTP is utilized and data transfer schedules are performed using the on-the-fly adjustable GridFTP parallelism. Experimental results show that the data streaming environment is agile enough to meet dynamically changing application data processing requirements and scale well regarding to storage and bandwidth usage.
1173|Globus: A Metacomputing Infrastructure Toolkit|Emerging high-performance applications require the ability to exploit diverse, geographically distributed resources. These applications use high-speed networks to integrate supercomputers, large databases, archival storage devices, advanced visualization devices, and/or scientific instruments to form networked virtual supercomputers or metacomputers. While the physical infrastructure to build such systems is becoming widespread, the heterogeneous and dynamic nature of the metacomputing environment poses new challenges for developers of system software, parallel tools, and applications. In this article, we introduce Globus, a system that we are developing to address these challenges. The Globus system is intended to achieve a vertically integrated treatment of application, middleware, and network. A low-level toolkit provides basic mechanisms such as communication, authentication, network information, and data access. These mechanisms are used to construct various higher-level metacomp...
1174|Mapping Abstract Complex Workflows onto Grid Environments |In this paper we address the problem of automatically generating job workflows for the Grid. These workflows describe the execution of a complex application built from individual application components. In our work we have developed two workflow generators: the first (the Concrete Workflow Generator CWG) maps an abstract workflow defined in terms of application-level components to the set of available Grid resources. The second generator (Abstract and Concrete Workflow Generator, ACWG) takes a wider perspective and not only performs the abstract to concrete mapping but also enables the construction of the abstract workflow based on the available components. This system operates in the application domain and chooses application components based on the application metadata attributes. We describe our current ACWG based on AI planning technologies and outline how these technologies can play a crucial role in developing complex application workflows in Grid environments. Although our work is preliminary, CWG has already been used to map high energy physics applications onto the Grid. In one particular experiment, a set of production runs lasted 7 days and resulted in the generation of 167,500 events by 678 jobs. Additionally, ACWG was used to map gravitational physics workflows, with hundreds of nodes onto the available resources, resulting in 975 tasks, 1365 data transfers and 975 output files produced.  
1175|GriPhyN and LIGO, Building a Virtual Data Grid for Gravitational Wave Scientists|Many Physics experiments today generate large volumes of data. That data is then processed in a variety of ways in order to achieve the understanding of fundamental physical phenomena. The goal of the NSF-funded GriPhyN project (Grid Physics Network) is to enable scientists to seamlessly access data whether it is raw experimental data or a data product which is a result of further processing. GriPhyN provides a new degree of transparency in how datahandling and processing capabilities are integrated to deliver data products to end-users or applications, so that requests for such products are easily mapped into computation and/or data access at multiple locations. GriPhyN refers to the set of all data products available to the user as Virtual Data. Among the physics applications participating in the project is the Laser Interferometer Gravitationalwave Observatory (LIGO), which is being built to observe the gravitational waves predicted by general relativity. In this paper, we describe our initial design and prototype of a Virtual Data Grid for LIGO.
1176|Scheduling data-intensive workflows onto storage-constrained distributed resources|In this paper we examine the issue of optimizing disk usage and of scheduling large-scale scientific workflows onto distributed resources where the workflows are dataintensive, requiring large amounts of data storage, and where the resources have limited storage resources. Our approach is two-fold: we minimize the amount of space a workflow requires during execution by removing data files at runtime when they are no longer required and we schedule the workflows in a way that assures that the amount of data required and generated by the workflow fits onto the individual resources. For a workflow used by gravitationalwave physicists, we were able to improve the amount of storage required by the workflow by up to 57 %. We also designed an algorithm that can not only find feasible solutions for workflow task assignment to resources in diskspace constrained environments, but can also improve the overall workflow performance. 1.
1177|High performance threaded data streaming for large scale simulations|We have developed a threaded parallel data streaming approach using Logistical Networking (LN) to transfer multi-terabyte simulation data from computers at NERSC to our local analysis/visualization cluster, as the simulation executes, with negligible overhead. Data transfer experiments show that this concurrent data transfer approach is more favorable compared with writing to local disk and later transferring this data to be post-processed. Our algorithms are network aware, and can stream data at up to 97Mbs on a 100Mbs link from CA to NJ during a live simulation, using less than 5 % CPU overhead at NERSC. This method is the first step in setting up a pipeline for simulation workflow and data management. 1.
1178|Grid-based parallel data streaming implemented for the gyrokinetic toroidal code|Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
1179|at Chicago “High Performance Data Streaming in Service Architecture|Applications dealing with large data sets obtained via simulation or actual real-time sensor networks are increasing in abundance. The data obtained from real-time sources may contain certain discrepancies which arise from the dynamic nature of the source. Furthermore, certain computations may not require all the data and hence this data must be filtered before it can be processed. By installing adaptive filters that can be controlled in real-time, we can filter out only the relevant parts of the data thereby improving the overall computation speed. In this paper we present an architecture that links these distributed filters to achieve high throughput dataflow for real-time streaming and high-performance applications.
1180|Approximate Clustering on Distributed Data Streams |Abstract- We investigate the problem of clustering on distributed data streams. In particular, we consider the k-median clustering on stream data arriving at distributed sites which communicate through a routing tree. Distributed clustering on high speed data streams is a challenging task due to limited communication capacity, storage space, and computing power at each site. In this paper, we propose a suite of algorithms for computing (1 + £)-approximate k-median clustering over distributed data streams under three different topology settings: topologyoblivious, height-aware, and path-aware. Our algorithms reduce the maximum per node transmission to polylog N (opposed to Q(N) for transmitting the raw data). We have simulated our algorithms on a distributed stream system with both real and synthetic datasets composed of millions of data. In practice, our algorithms are able to reduce the data transmission to a small fraction of the original data. Moreover, our results indicate that the algorithms are scalable with respect to the data volume, approximation factor, and the number of sites. I.
1181|Geometric approximation via coresets|  The paradigm of coresets has recently emerged as a powerful tool for efficiently approximating various extent measures of a point set P. Using this paradigm, one quickly computes a small subset Q of P, called a coreset, that approximates the original set P and and then solves the problem on Q using a relatively inefficient algorithm. The solution for Q is then translated to an approximate solution to the original point set P. This paper describes the ways in which this paradigm has been successfully applied to various optimization and extent measure problems.  
1182|Distributed data clustering can be efficient and exact |bzhana~hpl.hp.com Data clustering is one of the fundamental techniques in scientific data analysis and data mining. It partitions a data set into groups of similar items, as measured by some distance metric. Over the years, data set sizes have grown rapidly with the exponential growth of computer storage and increasingly automated business and manufacturing processes. Many of these datasets are geographically distributed across multiple sites, e.g. different sales or warehouse locations. To cluster such large and distributed ata sets, efficient distributed algorithms are called for to reduce the communication overhead, central storage requirements, and computation time, as well as to bring the resources of multiple machines to bear on a given problem as the data set sizes scale-up. We describe a technique for parallelizing a family of center-based data clustering algorithms. The central idea is to communicate only sufficient statistics, yielding linear speed-up with excellent efficiency. The technique does not involve approximation and may be used orthogonally in conjunction with sampling or aggregation-based methods, such as BIRCH, to lessen the quality degradation of their approximation or to handle larger data sets. We demonstrate in this paper that even for relatively small problem sizes, it can be more cost effective to cluster the data in-place using an exact distributed algorithm than to collect the data in one central location for clustering. Keywords multidimensional data clustering, data mining, very large
1183|Towards Effective and Efficient Distributed Clustering|Clustering has become an increasingly important task in modern application domains such as marketing and purchasing assistance, multimedia, molecular biology as well as many others. In many of these areas, the data are originally collected at different sites. In order to extract information out of these data, they are brought together and then clustered. In this paper, we propose a different approach. We cluster the data locally and extract suitable representatives out of these clusters. These representatives are sent to a global server site where we restore the complete clustering based on the local representatives. This approach is very efficient, because the local clustering can be carried out quickly and independently from each other. Furthermore, we have low transmission cost, as the number of transmitted representatives is much smaller than the cardinality of the complete data set. Based on this small number of representatives, the global clustering can be done very efficiently. For both the local and the global clustering, we use a density based clustering algorithm. The combination of both the local and the global clustering forms our new DBDC (Density Based Distributed Clustering) algorithm. In our experimental evaluation, we will show that we do not have to sacrifice the clustering quality in order to gain an efficiency advantage if we use distributed clustering.
1184|On abnormality detection in spuriously populated data streams|In recent years, advances in hardware technology have made it increasingly easy to collect large amounts of multidimensional data in an automated way. Such databases continuously grow over time, and are referred to as data streams. The behavior of such streams is sensitive to the underlying events which create the stream. In many applications, it is useful to predict abnormal events in the stream in a fast and online fashion. This is often a difficult goal in a fast data stream because of the time criticality of the detection process. Furthermore, the rare events may often be embedded with other spurious abnormalities, which affect the stream in similar ways. Therefore, it is necessary to be able to distinguish between different kinds of events in order to create a credible detection system. This paper discusses a method for supervised abnormality detection from multi-dimensional data streams, so that high specificity of abnormality detection is achieved. We present empirical results illustrating the effectiveness of our method. 1
1187|Transformation Algorithms for Data Streams|Next generation data processing systems must deal with very high data ingest rates and massive volumes of data. Such conditions are typically encountered in the Intelligence Community (IC) where analysts must search through huge volumes of data in order to gather evidence to support or refute their hypotheses. Their effort is made all the more difficult given that the data appears as unstructured text that is written in multiple languages using characters that have different encodings. Human Analysts have not been able to keep pace with reading the data and a large amount of data is discarded even though it might contain key information. The goal of our project is to assess the feasibility of incrementally replacing humans with automation in key areas of information processing. These areas include document ingest, content categorization, language translation, and context-andtemporally -based information retrieval.
1188|Deep Packet Inspection Using Parallel Bloom Filters|this memory core, five random-memory locations are readable in a single clock cycle. So performing 35 concurrent memory operations requires seven parallel memory cores, each with one-seventh of the required array size, as Figure 5b illustrates. Because the basic Bloom filter allows any hash function to map to any bit in the vector, it is possible that for some member, more than five hash functions map to the same memory segment, thereby exceeding the lookup capacity of this memory core. We can solve this problem by restricting the range of each hash function to a given memory, preventing memory contention
1189|A Stateful Intrusion Detection System for World-Wide Web Servers|Web servers are ubiquitous, remotely accessible, and often misconfigured. In addition, custom web-based applications may introduce vulnerabilities that are overlooked even by the most security-conscious server administrators. Consequently, web servers are a popular target for hackers. To mitigate the security exposure associated with web servers, intrusion detection systems are deployed to analyze and screen incoming requests. The goal is to perform early detection of malicious activity and possibly prevent more serious damage to the protected site. Even though intrusion detection is critical for the security of web servers, the intrusion detection systems available today only perform very simple analyses and are often vulnerable to simple evasion techniques. In addition, most systems do not provide sophisticated attack languages that allow a system administrator to specify custom, complex attack scenarios to be detected. This paper presents WebSTAT, an intrusion detection system that analyzes web requests looking for evidence of malicious behavior. The system is novel in several ways. First of all, it provides a sophisticated language to describe multistep attacks in terms of states and transitions. In addition, the modular nature of the system supports the integrated analysis of network traffic sent to the server host, operating system-level audit data produced by the server host, and the access logs produced by the web server. By correlating different streams of events, it is possible to achieve more effective detection of web-based attacks.
1190|A modular system for FPGA-based TCP flow processing in high-speed networks|Abstract. Field Programmable Gate Arrays (FPGAs) can be used in Intrusion Prevention Systems (IPS) to inspect application data contained within network flows. An IPS operating on high-speed network traffic can be used to stop the propagation of Internet worms and to protect networks from Denial of Services (DoS) attacks. When used in the backbone of a core network, the device will be exposed to millions of active flows simultaneously. In order to protect the data in each connection, network devices will need to track the state of every flow. This must be done at multi-gigabit line rates without introducing significant delays. This paper describes a high performance TCP processing system called TCP-Processor which supports flow processing in high-speed networks utilizing multiple devices. This circuit provides stateful flow tracking, TCP stream reassembly, context storage, and flow manipulation services for applications which process TCP data streams. A simple client interface eases the complexities associated with processing TCP data streams. In addition, a set of encoding and decoding circuits has been developed which efficiently transports this interface between multiple FPGA devices. The circuit has been implemented in FPGA hardware and tested using live Internet traffic. 1
1191|On Futuristic Query Processing in Data Streams |Abstract. Recent advances in hardware technology have resulted in the ability to collect and process large amounts of data. In many cases, the collection of the data is a continuous process over time. Such continuous collections of data are referred to as data streams. One of the interesting problems in data stream mining is that of predictive query processing. This is useful for a variety of data mining applications which require us to estimate the future behavior of the data stream. In this paper, we will discuss the problem from the point of view of predictive summarization. In predictive summarization, we would like to store statistical characteristics of the data stream which are useful for estimation of queries representing the behavior of the stream in the future. The example utilized for this paper is the case of selectivity estimation of range queries. For this purpose, we propose a technique which utilizes a local predictive approach in conjunction with a careful choice of storing and summarizing particular statistical characteristics of the data. We use this summarization technique to estimate the future selectivity of range queries, though the results can be utilized to estimate a variety of futuristic queries. We test the results on a variety of data sets and illustrate the effectiveness of the approach. 1
1192|CPU Reservations and Time Constraints: Efficient, Predictable Scheduling of Independent Activities|Workstations and personal computers are increasingly being used for applications with real-time characteristics such as speech understanding and synthesis, media computations and I/O, and animation, often concurrently executed with traditional non-real-time workloads. This paper presents a system that can schedule multiple independent activities so that: . activities can obtain minimum guaranteed execution rates with application-specified reservation granularities via CPU Reservations, . CPU Reservations, which are of the form &#034;reserve X units of time out of every Y units&#034;, provide not just an average case execution rate of X/Y over long periods of time, but the stronger guarantee that from any instant of time, by Y time units later, the activity will have executed for at least X time units, . applications can use Time Constraints to schedule tasks by deadlines, with on-time completion guaranteed for tasks with accepted constraints, and . both CPU Reservations and Time Constraints...
1193|Scheduling algorithms and operating systems support for real-time systems|This paper summarizes the state of the real-time field in the areas of scheduling and operating system kernels. Given the vast amount of work that has been done by both the operations research and computer science communities in the scheduling area, we discuss four paradigms underlying the scheduling approaches and present several exemplars of each. The four paradigms are: static table-driven scheduling, static priority preemptive scheduling, dynamic planning-based scheduling, and dynamic best efSort scheduling. In the operating system context, we argue that most of the proprietary commercial kernels as well as real-time extensions to time-sharing operating system kernels do not fit the needs of predictable real-time systems. We discuss several research kernels that are currently being built to explicitly meet the needs of real-time applications.  
1194|Earliest Deadline Scheduling for Real-Time Database Systems|Earlier studies have observed that in moderately-loaded real-time database systems, using an Earliest Deadline policy to schedule tasks results in the fewest missed deadlines. When the real-time system is overloaded, however, an Earliest Deadline schedule performs worse than most other policies. This is due to Earliest Deadline giving the highest priority to transactions that are close to missing their deadlines. In this paper, we present a new priority assignment algorithm called Adaptive Earliest Deadline (AED), which features a feedback control mechanism that detects overload conditions and modifies transaction priority assignments accordingly. Using a detailed simulation model, we compare the performance of AED with respect to Earliest Deadline and other fixed priority schemes. We also present and evaluate an extension of the AED algorithm called Hierarchical Earliest Deadline (HED), which is designed to handle applications that assign different values to transactions and where the...
1195|Value-Based Scheduling in Real-Time Database Systems|In a real-time database system, an application may assign a value to a transaction to reflect the return it expects to receive if the transaction commits before its deadline. Most prior research on real-time database systems has focused on systems where all transactions are assigned the same value, with the performance goal being to minimize the number of missed deadlines. When transactions may be assigned different values, the goal of the system shifts to maximizing the sum of the values of those transactions that commit by their deadlines. Minimizing the number of missed deadlines becomes a secondary concern in such systems. In this paper, we address the problem of establishing a priority ordering among transactions characterized by both values and deadlines that results in maximizing the realized value. Of particular interest is the tradeoff that needs to be established between these values and deadlines in constructing the priority ordering. Using a detailed simulation model, we ev...
1196|Sequence Pattern Mining in Data Streams |Sequential pattern mining in data streams environment is an interesting data mining problem. The problem of finding sequential patterns in static databases had been studied extensively in the past years, however mining sequential patterns in the data streams still an active field for researches. In this research a new greedy sequence pattern mining algorithm for the data streams is introduced, it will be used to find the strongly supported sequences. The proposed algorithm is built based on the sequence tree which is used to find the sequential patterns in static databases. The proposed algorithm divides the streams into patches or windows and each patch will update the sequence tree which built from the previous windows. An example is introduced to explain how this algorithm works. We also show the efficiency and the effectiveness of the proposed algorithm on a synthetic dataset and prove how it is suited for data streams environment. We showed experimentally that the proposed algorithm is more efficient than the PrefixSpan algorithm for patterns with any support less than 30 % for CPU time and with any support less than 60 % for memory usage.
1197|data streams: challenges and opportunities |Enhancing disease surveillance with novel
1198|You Are What You Tweet: Analyzing Twitter for Public Health |Analyzing user messages in social media can measure different population characteristics, including public health measures. For example, recent work has correlated Twitter messages with influenza rates in the United States; but this has largely been the extent of mining Twitter for public health. In this work, we consider a broader range of public health applications for Twitter. We apply the recently introduced Ailment Topic Aspect Model to over one and a half million health related tweets and discover mentions of over a dozen ailments, including allergies, obesity and insomnia. We introduce extensions to incorporate prior knowledge into this model and apply it to several tasks: tracking illnesses over times (syndromic surveillance), measuring behavioral risk factors, localizing illnesses by geographic region, and analyzing symptoms and medication usage. We show quantitative correlations with public health data and qualitative evaluations of model output. Our results suggest that Twitter has broad applicability for public health research.
1199|Using Internet Searches for Influenza Surveillance |Background: The Internet is an important source of health information. Thus, the frequency of internet searches may provide information regarding infectious disease activity. As an example, we examine the relationship between searches for influenza and actual influenza occurrence. Methods: Using search queries from
1201|P.M.: The Use of Twitter to Track Levels of Disease Activity and |Twitter is a free social networking and micro-blogging service that enables its millions of users to send and read each other’s ‘‘tweets,’ ’ or short, 140-character messages. The service has more than 190 million registered users and processes about 55 million tweets per day. Useful information about news and geopolitical events lies embedded in the Twitter stream, which embodies, in the aggregate, Twitter users ’ perspectives and reactions to current events. By virtue of sheer volume, content embedded in the Twitter stream may be useful for tracking or even forecasting behavior if it can be extracted in an efficient manner. In this study, we examine the use of information embedded in the Twitter stream to (1) track rapidly-evolving public sentiment with respect to H1N1 or swine flu, and (2) track and measure actual disease activity. We also show that Twitter can be used as a measure of public interest or concern about health-related events. Our results show that estimates
1202|N.: Tracking the flu pandemic by monitoring the Social Web|Abstract—Tracking the spread of an epidemic disease like seasonal or pandemic influenza is an important task that can reduce its impact and help authorities plan their response. In particular, early detection and geolocation of an outbreak are important aspects of this monitoring activity. Various methods are routinely employed for this monitoring, such as counting the consultation rates of general practitioners. We report on a monitoring tool to measure the prevalence of disease in a population by analysing the contents of social networking tools, such as Twitter. Our method is based on the analysis of hundreds of thousands of tweets per day, searching for symptom-related statements, and turning statistical information into a flu-score. We have tested it in the United Kingdom for 24 weeks during the H1N1 flu pandemic. We compare our flu-score with data from the Health Protection Agency, obtaining on average a statistically significant linear correlation which is greater than 95%. This method uses completely independent data to that commonly used for these purposes, and can be used at close time intervals, hence providing inexpensive and timely information about the state of an epidemic. I.
1203|Separating Fact from Fear: Tracking Flu Infections on Twitter |Twitter has been shown to be a fast and reliable method for disease surveillance of common illnesses like influenza. However, previous work has relied on simple content analysis, which conflates flu tweets that report infection with those that express concerned awareness of the flu. By discriminating these categories, as well as tweets about the authors versus about others, we demonstrate significant improvements on influenza surveillance using Twitter. 1
1204|A (2009) Web Queries as a Source for Syndromic Surveillance  (2012) |In the field of syndromic surveillance, various sources are exploited for outbreak detection, monitoring and prediction. This paper describes a study on queries submitted to a medical web site, with influenza as a case study. The hypothesis of the work was that queries on influenza and influenza-like illness would provide a basis for the estimation of the timing of the peak and the intensity of the yearly influenza outbreaks that would be as good as the existing laboratory and sentinel surveillance. We calculated the occurrence of various queries related to influenza from search logs submitted to a Swedish medical web site for two influenza seasons. These figures were subsequently used to generate two models, one to estimate the number of laboratory verified influenza cases and one to estimate the proportion of patients with influenza-like illness reported by selected General Practitioners in Sweden. We applied an approach designed for highly correlated data, partial least squares regression. In our work, we found that certain web queries on influenza follow the same pattern as that obtained by the two other surveillance systems for influenza epidemics, and that they have equal power for the estimation of the influenza burden in society. Web queries give a unique access to ill individuals who are not (yet) seeking care. This paper shows the potential of web queries as an accurate, cheap and labour extensive source for syndromic surveillance.
1205|The utility of “Google Trends ” for epidemiological research: Lyme disease as an example |Abstract. Internet search engines have become an increasingly popular resource for accessing health-related information. The key words used as well as the number and geographic location of searches can provide trend data, as have recently been made available by Google Trends. We report briefly on exploring this resource using Lyme disease as an example because it has well-described seasonal and geographic patterns. We found that search traffic for the string “Lyme disease ” reflected increased likelihood of exposure during spring and summer months; conversely, the string “cough ” had higher relative traffic during winter months. The cities and states with the highest amount of search traffic for “Lyme disease ” overlapped considerably with those where Lyme is known to be endemic. Despite limitations to over-interpretation, we found Google Trends to approximate certain trends previously identified in the epidemiology of Lyme disease. The generation of this type of data may have valuable future implications in aiding surveillance of a broad range of diseases.
1206|Text and Structural Data Mining of Influenza Mentions in Web and Social Media|  Text and structural data mining of web and social media (WSM) provides a novel disease surveillance resource and can identify online communities for targeted public health communications (PHC) to assure wide dissemination of pertinent information. WSM that mention influenza are harvested over a 24-week period, 5 October 2008 to 21 March 2009. Link analysis reveals communities for targeted PHC. Text mining is shown to identify trends in flu posts that correlate to real-world influenza-like illness patient report data. We also bring to bear a graph-based data mining technique to detect anomalies among flu blogs connected by publisher type, links, and user-tags.
1207|National and local influenza surveillance through twitter: An analysis of the 2012-2013 influenza epidemic |Social media have been proposed as a data source for influenza surveillance because they have the potential to offer real-time access to millions of short, geographically localized messages containing information regarding personal well-being. However, accuracy of social media surveillance systems declines with media attention because media attention increases “chatter ”  – messages that are about influenza but that do not pertain to an actual infection – masking signs of true influenza prevalence. This paper summarizes our recently developed influenza infection detection algorithm that automatically distinguishes relevant tweets from other chatter, and we describe our current influenza surveillance system which was actively deployed during the full 2012-2013 influenza season. Our objective was to analyze the performance of this system during the most recent 2012–2013 influenza season and to analyze the performance at multiple levels of geographic granularity, unlike past studies that focused on national or regional surveillance. Our system’s influenza prevalence estimates were strongly correlated with surveillance data from the Centers for Disease Control and Prevention for the United States (r = 0.93, p &lt; 0.001) as well as surveillance data from the Department of Health and Mental Hygiene of New York City (r = 0.88, p &lt; 0.001). Our system detected the weekly change in direction (increasing or decreasing) of influenza prevalence with 85 % accuracy, a nearly twofold
1209|Influenza forecasting with google flu trends|Background: We developed a practical influenza forecast model based on real-time, geographically focused, and easy to access data, designed to provide individual medical centers with advanced warning of the expected number of influenza cases, thus allowing for sufficient time to implement interventions. Secondly, we evaluated the effects of incorporating a real-time influenza surveillance system, Google Flu Trends, and meteorological and temporal information on forecast accuracy. Methods: Forecast models designed to predict one week in advance were developed from weekly counts of confirmed influenza cases over seven seasons (2004–2011) divided into seven training and out-of-sample verification sets. Forecasting procedures using classical Box-Jenkins, generalized linear models (GLM), and generalized linear autoregressive moving average (GARMA) methods were employed to develop the final model and assess the relative contribution of external variables such as, Google Flu Trends, meteorological data, and temporal information. Results: A GARMA(3,0) forecast model with Negative Binomial distribution integrating Google Flu Trends information provided the most accurate influenza case predictions. The model, on the average, predicts weekly influenza cases during 7 out-of-sample outbreaks within 7 cases for 83 % of estimates. Google Flu Trend data was the only source of external information to provide statistically significant forecast improvements over the base model in four of the seven out-of-
1210|Using Search Query Surveillance to Monitor Tax Avoidance and Smoking Cessation following the United States ’ 2009 ‘‘SCHIP’ ’ Cigarette Tax Increase |Smokers can use the web to continue or quit their habit. Online vendors sell reduced or tax-free cigarettes lowering smoking costs, while health advocates use the web to promote cessation. We examined how smokers ’ tax avoidance and smoking cessation Internet search queries were motivated by the United States ’ (US) 2009 State Children’s Health Insurance Program (SCHIP) federal cigarette excise tax increase and two other state specific tax increases. Google keyword searches among residents in a taxed geography (US or US state) were compared to an untaxed geography (Canada) for two years around each tax increase. Search data were normalized to a relative search volume (RSV) scale, where the highest search proportion was labeled 100 with lesser proportions scaled by how they relatively compared to the highest proportion. Changes in RSV were estimated by comparing means during and after the tax increase to means before the tax increase, across taxed and untaxed geographies. The SCHIP tax was associated with an 11.8 % (95 % confidence interval [95%CI], 5.7 to 17.9; p,.001) immediate increase in cessation searches; however, searches quickly abated and approximated differences from pre-tax levels in Canada during the months after the tax. Tax avoidance searches increased 27.9 % (95%CI, 15.9 to 39.9; p,.001) and 5.3 % (95%CI, 3.6 to 7.1; p,.001) during and in the months after the tax compared to Canada, respectively, suggesting avoidance is the more pronounced and durable response. Trends were similar for state-specific tax increases but suggest strong interactive processes across taxes. When the SCHIP tax followed Florida’s tax, versus not, it promoted more
1211|Enhancing Twitter Data Analysis with Simple Semantic Filtering: Example in Tracking Influenza-Like Illnesses|Abstract—Systems that exploit publicly available user gen-erated content such as Twitter messages have been successful in tracking seasonal influenza. We developed a novel filtering method for Influenza-Like-Ilnesses (ILI)-related messages using 587 million messages from Twitter micro-blogs. We first filtered messages based on syndrome keywords from the BioCaster Ontology, an extant knowledge model of laymen’s terms. We then filtered the messages according to semantic features such as negation, hashtags, emoticons, humor and geography. The data covered 36 weeks for the US 2009 influenza season from 30th August 2009 to 8th May 2010. Results showed that our system achieved the highest Pearson correlation coefficient of 98.46% (p-value&lt;2.2e-16), an improvement of 3.98 % over the previous state-of-the-art method. The results indicate that simple NLP-based enhancements to existing approaches to mine Twitter data can increase the value of this inexpensive resource. Index Terms—Twitter; natural language processing; influenza; social media I.
1212|Using Web Search Query Data to Monitor Dengue Epidemics: A New Model for Neglected Tropical Disease |Background: A variety of obstacles including bureaucracy and lack of resources have interfered with timely detection and reporting of dengue cases in many endemic countries. Surveillance efforts have turned to modern data sources, such as Internet search queries, which have been shown to be effective for monitoring influenza-like illnesses. However, few have evaluated the utility of web search query data for other diseases, especially those of high morbidity and mortality or where a vaccine may not exist. In this study, we aimed to assess whether web search queries are a viable data source for the early detection and monitoring of dengue epidemics.
1213|Predicting Epidemic Tendency through Search Behavior Analysis|The possibility that influenza activity can be generally detected through search log analysis has been explored in recent years. However, previous studies have mainly focused on influenza, and little attention has been paid to other epidemics. With an analysis of web user behavior data, we consider the problem of predicting the tendency of hand-foot-and-mouth disease 1 (HFMD), whose outbreak in 2010 resulted in a great panic in China. In addition to search queries, we consider users’ interactions with search engines. Given the collected search logs, we cluster HFMD-related search queries, medical pages and news reports into the following sets: epidemic-related queries (ERQs), epidemic-related pages (ERPs) and epidemic-related news (ERNs). Furthermore, we count their own frequencies as different features, and we conduct a regression analysis with current HFMD occurrences. The experimental results show that these features exhibit good performances on both accuracy and timeliness. 
1214|Wikipedia Usage Estimates Prevalence of Influenza-Like Illness |Circulating levels of both seasonal and pandemic influenza require constant surveillance to ensure the health and safety of the population. While up-to-date information is critical, traditional surveillance systems can have data availability lags of up to two weeks. We introduce a novel method of estimating, in near-real time, the level of influenza-like illness (ILI) in the United States (US) by monitoring the rate of particular Wikipedia article views on a daily basis. We calculated the number of times certain influenza- or health-related Wikipedia articles were accessed each day between December 2007 and August 2013 and compared these data to official ILI activity levels provided by the Centers for Disease Control and Prevention (CDC). We developed a Poisson model that accurately estimates the level of ILI activity in the American population, up to two weeks ahead of the CDC, with an absolute average difference between the two estimates of just 0.27 % over 294 weeks of data. Wikipedia-derived ILI models performed well through both abnormally high media coverage events (such as during the 2009 H1N1 pandemic) as well as unusually severe influenza seasons (such as the 2012–2013 influenza season). Wikipedia usage accurately estimated the week of peak ILI activity 17 % more often than Google Flu Trends data and was often more accurate in its measure of ILI intensity. With further study, this method could potentially be implemented for continuous monitoring of ILI activity in the US and to provide support for traditional influenza surveillance tools.
1215|DISPATCHES Internet Queries and Methicillin- Resistant Staphylococcus |The Internet is a common source of medical information and has created novel surveillance opportunities. We assessed the potential for Internet-based surveillance of methicillin-resistant Staphylococcus aureus and examined the extent to which it refl ects trends in hospitalizations and news coverage. Google queries were a useful predictor of hospitalizations for methicillin-resistant S. aureus infections. Staphylococcus aureus is the most common bacterial pathogen isolated from human infections (1). Methicillin-resistant Staphylococcus aureus (MRSA) isolates are strains constitutively resistant to ß-lactam antimicrobial drugs. MRSA was initially largely confined to patients with health care exposures (2), but in the late 1990s, genetically distinct strains emerged and spread rapidly among healthy persons in the United States. These new strains, known as community-associated MRSA (CA-MRSA), differ epidemiologically and genetically from older strains (2,3). CA-MRSA strains have become the most common cause of skin infections in US emergency departments (4). There is no systematic surveillance system in the United States for MRSA. The Centers for Disease Control and Prevention (CDC) tracks a limited group of infections defined as invasive through the Active Bacterial Core (ABC) surveillance system reported from 9 regions. These include MRSA infections at normally sterile sites. In a 2007 report, CDC used ABC surveillance to estimate that there were 94,000 cases and 18,650 deaths caused by invasive MRSA disease in the United States in 2005 (5). This report received extensive media coverage and increased public awareness of MRSA (6). Recent efforts to overcome surveillance limitations, in particular delay and limited geographic coverage, have included Internet protocol (IP) surveillance. IP surveillance monitors Internet search terms related to a specific disease,
1216|Do Seasons Have an Influence on the Incidence of Depression? The Use of an Internet Search Engine Query Data as a Proxy of Human Affect |Background: Seasonal depression has generated considerable clinical interest in recent years. Despite a common belief that people in higher latitudes are more vulnerable to low mood during the winter, it has never been demonstrated that human’s moods are subject to seasonal change on a global scale. The aim of this study was to investigate large-scale seasonal patterns of depression using Internet search query data as a signature and proxy of human affect. Methodology/Principal Findings: Our study was based on a publicly available search engine database, Google Insights for Search, which provides time series data of weekly search trends from January 1, 2004 to June 30, 2009. We applied an empirical mode decomposition method to isolate seasonal components of health-related search trends of depression in 54 geographic areas worldwide. We identified a seasonal trend of depression that was opposite between the northern and southern hemispheres; this trend was significantly correlated with seasonal oscillations of temperature (USA: r =20.872, p,0.001; Australia: r =20.656, p,0.001). Based on analyses of search trends over 54 geological locations worldwide, we found that the degree of correlation between searching for depression and temperature was latitude-dependent (northern hemisphere: r =20.686; p,0.001; southern hemisphere: r = 0.871; p,0.0001). Conclusions/Significance: Our findings indicate that Internet searches for depression from people in higher latitudes are
1217|Using collaborative filtering to weave an information tapestry|predicated on the belief that information filtering can be more effective when humans are involved in the filtering process. Tapestry was designed to support both content-based filtering and collaborative filtering, which entails people collaborating to help each other perform filtering by recording their reactions to documents they read. The reactions are called annotations; they can be accessed by other people’s filters. Tapestry is intended to handle any incoming stream of electronic documents and serves both as a mail filter and repository; its components are the indexer, document store, annotation store, filterer, little box, remailer, appraiser and reader/browser. Tapestry’s client/server architecture, its various components, and the Tapestry query language are described.
1218|Browsing electronic mail: Experiences interfacing a mail system to a DBMS|Abstract: A database management system provides the ideal support for electronic mail applications. The Walnut mail system built at the Xerox Palo Alto Research Center was recently redesigned to take better advantage of its underlying database facilities. The ability to pose ad-hoc queries with a “fill-in-the-form” browser allows people to browse their mail quickly and effectively, while database access paths guarantee fast retrieval of stored information. Careful consideration of the systems ’ usage was reflected in both the database schema representation and the user-interface for browsing mail.
1219|By Force of Habit: A Consumption-Based Explanation of Aggregate Stock Market Behavior|We present a consumption-based model that explains a wide variety of dynamic asset pricing phenomena, including the procyclical variation of stock prices, the long-horizon predictability of excess stock returns, and the countercyclical variation of stock market volatility. The model captures much of the history of stock prices from consumption data. It explains the short- and long-run equity premium puzzles despite a low and constant risk-free rate. The results are essentially the same whether we model stocks as a claim to the consumption stream or as a claim to volatile dividends poorly correlated with consumption. The model is driven by an independently and identically distributed consumption growth process and adds a slow-moving external habit to the standard power utility function. These features generate slow countercyclical variation in risk premia. The model posits a fundamentally novel description of risk premia: Investors fear stocks primarily because they do poorly in recessions unrelated to the risks of long-run average consumption growth.
1220|The Equity Premium: A Puzzle|Restrictions that a class of general equilibrium models place upon the average returns of equity and Treasury bills are found to be strongly violated by the U.S. data in the 1889-1978 period. This result is robust to model specification and measurement problems. We conclude that, most likely, an equilibrium model which is not an Arrow-Debreu economy will be the one that Simultaneously rationalizes both historically observed large average equity return and the small average risk-free return. 1.
1223|Intertemporally dependent preferences and the volatility of consumption and wealth|In this article we construct a model in which a consumer’s utility depends on the consumption history We describe a general equilibrium framework similar to Cox, Ingersoll, and Ross (1985a). A simple example is then solved in closedform in this general equilibrium setting to rationalize the observed stickiness of the consumption series relative to the fluctuations in stock market wealth. The sample paths of consumption generated from this model imply lower variability in consumption growth rates compared to those generated by models with separable utilizations. We then present a partial equilibrium model similar to Merton (1969, 1971) and extend Merton’s results on optimal consumption and portfolio rules to accommodate nonseparability in preferences. Asset pricing implications of our framework are briefly explored. The idea that a given bundle of consumption goods will provide the same level of satisfaction at any date regardless of one’s past consumption experience is implicit in models that use time-separable utility functions to represent preferences. Separable utility functions have been the mainstay in much of the literature on asset pricing and optimal consumption and portfolio The results reported in this article were first presented at the EFA meetings in Bern, Switzerland, in 1985 [see Sundaresan (1984)]. Subsequently the article was presented at a number of universities and conferences. I thank the participants at those presentations for their feedback. I am especially thankful to Doug Breeden, Michael Brennan, John Cox, Chi-fu Huang, and Krishna Ramaswamy for their thoughtful comments and criticisms. I also thank Tong-sheng Sun for explaining the simulation procedure for stochastic differential equations and for his comments and suggestions. I am responsible for any remaining errors. Correspondence should be sent to Suresh M. Sundaresan, Graduate
1224|The equity premium and the concentration of aggregate shocks|This paper examines an economy in which aggregate shocks are not dispersed equally throughout the population. Instead, while these shocks affect all individuals ex ante, they are concentrated among a few ex post. The equity premium in genera) depends on the concentration of these aggregate shocks; it follows that one cannot estimate the degree of risk aversion from aggregate data alone. These findings suggest that the empirical usefulness of aggregation theorems for capital asset pricing models is limited. 1.
1225|Volatility Tests and Efficient Markets: A Review Essay|About two thirds of Market Watility is a collection of Robert Shiller’s papers. The other third consists of excellent nontechnical summaries of the papers and overviews and interpretations of the literature. Most of the book
1226|A Hierarchical Internet Object Cache| This paper discusses the design andperformance  of a hierarchical proxy-cache designed to make Internet information systems scale better. The design was motivated by our earlier trace-driven simulation study of Internet traffic. We believe that the conventional wisdom, that the benefits of hierarchical file caching do not merit the costs, warrants reconsideration in the Internet environment.  The cache implementation supports a highly concurrent stream of requests. We present performance measurements that show that the cache outperforms other popular Internet cache implementations by an order of magnitude under concurrent load. These measurements indicate that hierarchy does not measurably increase access latency. Our software can also be configured as a Web-server accelerator; we present data that our httpd-accelerator is ten times faster than Netscape&#039;s Netsite and NCSA 1.4 servers.  Finally, we relate our experience fitting the cache into the increasingly complex and operational world of Internet information systems, including issues related to security, transparency to cache-unaware clients, and the role of file systems in support of ubiquitous wide-area information systems.  
1227|Scale and performance in a distributed file system|The Andrew File System is a location-transparent distributed tile system that will eventually span more than 5000 workstations at Carnegie Mellon University. Large scale affects performance and complicates system operation. In this paper we present observations of a prototype implementation, motivate changes in the areas of cache validation, server process structure, name translation, and low-level storage representation, and quantitatively demonstrate Andrew’s ability to scale gracefully. We establish the importance of whole-file transfer and caching in Andrew by comparing its performance with that of Sun Microsystem’s NFS tile system. We also show how the aggregation of files into volumes improves the operability of the system.
1228|The Case for Geographical Push-Caching|Most existing wide-area caching schemes are client initiated. Decisions on when and where to cache information are made without the benefit of the server&#039;s global knowledge of the situation. We believe that the server should play a role in making these caching decisions, and we propose  geographical push-caching as a way of bringing the server back into the loop. The World Wide Web is an excellent example of a wide-area system that will benefit from geographical push-caching, and we present an architecture that allows a Web server to autonomously replicate HTML pages. 1 Introduction  The World-Wide Web [1] operates for the most part as a cache-less distributed system. When two neighboring clients retrieve a document from the same server, the document is sent twice. This is inefficient, especially considering the ease with which Web browsers allow users to transfer large multimedia documents. To combat this problem, some Web browsers have begun to add local client caches. These prevent ...
1229|The Harvest Information Discovery and Access System|It is increasingly difficult to make effective use of Internet information, given the rapid growth in data volume, user base, and data diversity. In this paper we introduce Harvest, a system that provides a scalable, customizable architecture for gathering, indexing, caching, replicating, and accessing Internet information.  
1230|Alex -- a global filesystem|The Alex filesystem provides users and applications transparent read access to files in Internet anonymous FTP sites. Today there are thousands of anonymous FTP sites with a total of a few million files and roughly a terabyte of data. The standard approach to accessing these files involves logging in to the remote machine. This means that an application can not access remote files and that users do not have any of their aliases or local tools available when connected to a remote site. Users who want to use an application on a remote file must first manually make a local copy of the file. Not only is this inconvenient, it creates two more problems. First, there is no mechanism for automatically updating this local copy when the remote file changes. The users must keep track of where they get their files from and check to see if there are updates, and then fetch these. Second, many different users at the same site may have made copies of the same remote file, thus wasting disk space. Alex addresses the problems with the above approach while maintaining compatibility with the existing FTP protocol so that the large collection of currently available files can be accessed. To get reasonable performance, long term file caching must be used. Thus consistency must be addressed. Traditional solutions to the cache consistency problem do not work in the Internet FTP domain: callbacks are not an
1231|Multi-level Caching in Distributed File Systems or Your cache ain’t nuthin’ but trash|We are investigating the potential for intermediate file servers to address scaling problems in increasingly large distributed file systems. To this end, we have run trace-driven simulations based on data from DEC-SRC and our own data collection to determine the potential of caching-only intermediate servers. The degree of sharing among clients is central to the effectiveness of an intermediate server. This turns out to be quite low in the traces available to us. All told, fewer than 10 % of block accesses are to files shared by more than one file system client. Trace-driven simulation shows that even with an infinite cache at the intermediate, cache hit rates are disappointingly low. For client caches as small as 20 MB, we observe hit rates less than 19%. As client cache sizes increase, the hit rate at the intermediate approaches the degree of sharing among all clients. On the other hand, the intermediate does appear to be effective in reducing the peak load presented to upstream file servers.
1232|Demand-based Document Dissemination for the World-Wide Web|We analyzed the logs of our departmental HTTP server
1233|Raptor codes|LT-Codes are a new class of codes introduced in [1] for the purpose of scalable and fault-tolerant distribution of data over computer networks. In this paper we introduce Raptor Codes, an extension of LT-Codes with linear time encoding and decoding. We will exhibit a class of universal Raptor codes: for a given integer k, and any real e&gt; 0, Raptor codes in this class produce a potentially infinite stream of symbols such that any subset of symbols of size k(1 + e) is sufficient to recover the original k symbols with high probability. Each output symbol is generated using O(log(1/e)) operations, and the original symbols are recovered from the collected ones with O(k log(1/e)) operations. We will also introduce novel techniques for the analysis of the error probability of the decoder for finite length Raptor codes. Moreover, we will introduce and analyze systematic versions of Raptor codes, i.e., versions in which the first output elements of the coding system coincide with the original k elements. 1
1234|LT Codes|We introduce LT codes, the first rateless erasure codes that are very efficient as the data length grows.
1235|Efficient erasure correcting codes|Abstract—We introduce a simple erasure recovery algorithm for codes derived from cascades of sparse bipartite graphs and analyze the algorithm by analyzing a corresponding discrete-time random process. As a result, we obtain a simple criterion involving the fractions of nodes of different degrees on both sides of the graph which is necessary and sufficient for the decoding process to finish successfully with high probability. By carefully designing these graphs we can construct for any given rate and any given real number a family of linear codes of rate which can be encoded in time proportional to ??@I A times their block length. Furthermore, a codeword can be recovered with high probability from a portion of its entries of length @IC A or more. The recovery algorithm also runs in time proportional to ??@I A. Our algorithms have been implemented and work well in practice; various implementation issues are discussed. Index Terms—Erasure channel, large deviation analysis, lowdensity parity-check codes. I.
1236|Improved low-density parity-check codes using irregular graphs|Abstract—We construct new families of error-correcting codes based on Gallager’s low-density parity-check codes. We improve on Gallager’s results by introducing irregular parity-check matrices and a new rigorous analysis of hard-decision decoding of these codes. We also provide efficient methods for finding good irregular structures for such decoding algorithms. Our rigorous analysis based on martingales, our methodology for constructing good irregular codes, and the demonstration that irregular structure improves performance constitute key points of our contribution. We also consider irregular codes under belief propagation. We report the results of experiments testing the efficacy of irregular codes on both binary-symmetric and Gaussian channels. For example, using belief propagation, for rate I R codes on 16 000 bits over a binary-symmetric channel, previous low-density parity-check codes can correct up to approximately 16 % errors, while our codes correct over 17%. In some cases our results come very close to reported results for turbo codes, suggesting that variations of irregular low density parity-check codes may be able to match or beat turbo code performance. Index Terms—Belief propagation, concentration theorem, Gallager codes, irregular codes, low-density parity-check codes.
1237|Irregular Repeat Accumulate Codes|In this paper we will introduce an ensemble of codes called irregular repeat-accumulate (IRA) codes. IRA codes are a generalization of the repeat-accumulate codes introduced in [1], and as such have a natural linear time encoding algorithm. We shall prove that on the binary erasure channel, IRA codes can be decoded reliably in linear time, using iterater] sum-product decoding,a# ra#SJ a#SJ8T a#SJ8 close tocha#T36 ca pa#J464 Asimila# resulta#u ea#S to be true on the AWGN channel, although we have no proof of this. We illustrate our results with numerical and experimenta# examples.
1238|Analysis of Random Processes via And-Or Tree Evaluation|We introduce a new set of probabilistic analysis tools based on the analysis of And-Or trees with random inputs. These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes of interest, including random loss-resilient codes, solving random k-SAT formula using the pure literal rule, and the greedy algorithm for matchings in random graphs. In addition, these tools allow generalizations of these problems not previously analyzed to be analyzed in a straightforward manner. We illustrate our methodology on the three problems listed above. 1 Introduction  We introduce a new set of probabilistic analysis tools related to the amplification method introduced by [12] and further developed and used in [13, 5]. These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes of interest, including the random loss-resilient codes introduced ...
1239|Capacity-Achieving Ensembles for the Binary Erasure Channel with Bounded Complexity|We present two sequences of ensembles of non-systematic irregular repeat-accumulate codes which asymptotically (as their block length tends to infinity) achieve capacity on the binary erasure channel (BEC) with bounded complexity. This is in contrast to all previous constructions of capacity-achieving sequences of ensembles whose complexity grows at least like the log of the inverse of the gap to capacity. The new bounded complexity result is achieved by allowing a su#cient number of state nodes in the Tanner graph representing the codes.
1240|Sesame: A Generic Architecture for Storing and Querying RDF and RDF Schema|RDF and RDF Schema are two W3C standards aimed at  enriching the Web with machine-processable semantic data.
1241|Resource Description Framework (RDF) Model and Syntax Specification  (1998) |This document is a revision of the public working draft dated 1998-08-19 incorporating suggestions received in review comments and further deliberations of the W3C RDF Model and Syntax Working Group. With the publication of this draft, the RDF Model and Syntax Specification enters &#034;last call.&#034; The last call period will end on October 23, 1998. Comments on this specification may be sent to www-rdf-comments@w3.org. The archive of public comments is available at http://www.w3.org/Archives/Public/www-rdf-comments. Significant changes from the previous draft are highlighted in Appendix E. While we do not anticipate substantial changes, we still caution that further changes are possible. Therefore while we encourage active implementation to test this specification we also recommend that only software that can be easily field-upgraded be implemented to this specification at this time. This is a W3C Working Draft for review by W3C members and other interested parties. Publication as a working draft does not imply endorsement by the W3C membership. The RDF Model and Syntax  Working Group will not allow early implementation to constrain their ability to make changes to this specification prior to final release. This is a draft document and may be updated, replaced or obsoleted by other documents at any time. It is inappropriate to cite W3C Working Drafts as other than &#034;work in progress&#034;. This work is part of the W3C Metadata Activity.
1242|The RDFSuite: Managing Voluminous RDF Description Bases|Metadata are widely used in order to fully exploit information resources available  on corporate intranets or the Internet. The Resource Description Framework (RDF)  aims at facilitating the creation and exchange of metadata as any other Web data. The  growing number of available information resources and the proliferation of description  services in various user communities, lead nowadays to large volumes of RDF metadata.  Managing such RDF resource descriptions and schemas with existing low-level APIs and  file-based implementations does not ensure fast deployment and easy maintenance of realscale  RDF applications. In this paper, we advocate the use of database technology to  support declarative access, as well as, logical and physical independence for voluminous  RDF description bases.  We present RDFSuite, a suite of tools for RDF validation, storage and querying.  Specifically, weintroduce a formal data model for RDF description bases created using  multiple schemas. Compared to ...
1243|Querying Community Web Portals|Anewgeneration of information systems suchasorganizational memories, vertical aggregators,  infomediaries, etc. is emerging nowadays. Such systems, termed CommunityWeb  Portals, intend to support specific communities of interest (e.g., enterprise, professional, trading)  on corporate intranets or the Web. More precisely, Portal Catalogs, organize and describe  various information resources (e.g., sites, documents, data) for diverse target audiences  (corporate, inter-enterprise, e-marketplace, etc.), in a multitude of ways, which are far more  flexible and complex than those provided by standard (relational or object) databases. Yet, in  commercial software for deploying CommunityPortals, querying is still limited to full-text (or  attribute-value) retrieval and more advanced information-seeking needs implies navigational  access. Furthermore, recentWeb standards for describing resources are completely ignored.
1244|Dynamic histograms: Capturing evolving data sets |In this paper, we introduce dynamic histograms, which are constructed and maintained incrementally. We develop several dynamic histogram construction algorithms and show that they come close to static histograms in quality. Our experimental study covers a wide range of datasets and update patterns, including histogram maintenance in a shared-nothing environment. Building upon the insights offered by the dynamic algorithms, we also propose a new static histogram construction algorithm that is very fast and generates histograms that are close in quality to the highly accurate (but expensive to construct!) V-Optimal histograms. 1
1245|Towards exploratory visualization of spatio-temporal data|In the paper we focus on the problem of supporting visual exploration of data having spatial and temporal reference. We suggest some methods and tools based on cartographic visualization of the data. The tools involve a dynamic, highly interactive map display that can change its properties in real time, in particular, perform animation. We seek to advance our tools beyond mere animation towards facilitating exploratory analysis of spatio-temporal data. We diversify our approaches depending on properties of data and the character of their variation in time: changing existence, position, values of thematic attributes etc. 1.
1246|Tinydb: An acquisitional query processing system for sensor networks|We discuss the design of an acquisitional query processor for data collection in sensor networks. Acquisitional issues are those that pertain to where, when, and how often data is physically acquired (sampled) and delivered to query processing operators. By focusing on the locations and costs of acquiring data, we are able to significantly reduce power consumption over traditional passive systems that assume the a priori existence of data. We discuss simple extensions to SQL for controlling data acquisition, and show how acquisitional issues influence query optimization, dissemination, and execution. We evaluate these issues in the context of TinyDB, a distributed query processor for smart sensor devices, and show how acquisitional techniques can provide significant reductions in power consumption on our sensor devices. Categories and Subject Descriptors: H.2.3 [Database Management]: Languages—Query languages; H.2.4 [Database Management]: Systems—Distributed databases; query processing
1247|The Cricket Location-Support System|This paper presents the design, implementation, and evaluation of Cricket, a location-support system for in-building, mobile, locationdependent applications. It allows applications running on mobile and static nodes to learn their physical location by using listeners that hear and analyze information from beacons spread throughout the building. Cricket is the result of several design goals, including user privacy, decentralized administration, network heterogeneity, and low cost. Rather than explicitly tracking user location, Cricket helps devices learn where they are and lets them decide whom to advertise this information to; it does not rely on any centralized management or control and there is no explicit coordination between beacons; it provides information to devices regardless of their type of network connectivity; and each Cricket device is made from off-the-shelf components and costs less than U.S. $10. We describe the randomized algorithm used by beacons to transmit information, the use of concurrent radio and ultrasonic signals to infer distance, the listener inference algorithms to overcome multipath and interference, and practical beacon configuration and positioning techniques that improve accuracy. Our experience with Cricket shows that several location-dependent applications such as in-building active maps and device control can be developed with little effort or manual configuration.  1 
1248|The nesC language: A holistic approach to networked embedded systems|We present nesC, a programming language for networked embedded systems that represent a new design space for application developers. An example of a networked embedded system is a sensor network, which consists of (potentially) thousands of tiny, lowpower “motes, ” each of which execute concurrent, reactive programs that must operate with severe memory and power constraints. nesC’s contribution is to support the special needs of this domain by exposing a programming model that incorporates event-driven execution, a flexible concurrency model, and component-oriented application design. Restrictions on the programming model allow the nesC compiler to perform whole-program analyses, including data-race detection (which improves reliability) and aggressive function inlining (which reduces resource consumption). nesC has been used to implement TinyOS, a small operating system for sensor networks, as well as several significant sensor applications. nesC and TinyOS have been adopted by a large number of sensor network research groups, and our experience and evaluation of the language shows that it is effective at supporting the complex, concurrent programming style demanded by this new class of deeply networked systems.
1249|Timing-Sync Protocol for Sensor Networks|Wireless ad-hoc sensor networks have emerged as an interesting and important research area in the last few years. The applications envisioned for such networks require collaborative execution of a distributed task amongst a large set of sensor nodes. This is realized by exchanging messages that are timestamped using the local clocks on the nodes. Therefore, time synchronization becomes an indispensable piece of infrastructure in such systems. For years, protocols such as NTP have kept the clocks of networked systems in perfect synchrony. However, this new class of networks has a large density of nodes and very limited energy resource at every node; this leads to scalability requirements while limiting the resources that can be used to achieve them. A new approach to time synchronization is needed for sensor networks.
1250|A Transmission Control Scheme for Media Access in Sensor Networks|We study the problem of media access control in the novel regime of sensor networks, where unique application behavior and tight constraints in computation power, storage, energy resources, and radio technology have shaped this design space to be very different from that found in traditional mobile computing regime. Media access control in sensor networks must not only be energy efficient but should also allow fair bandwidth allocation to the infrastructure for all nodes in a multihop network. We propose an adaptive rate control mechanism aiming to support these two goals and find that such a scheme is most effective in achieving our fairness goal while being energy effcient for both low and high duty cycle of network traffic.
1251|Routing indices for peer-to-peer systems|Finding information in a peer-to-peer system currently requires either a costly and vulnerable central index, or ooding the network with queries. In this paper we introduce the concept of Routing Indices (RIs), which allow nodes to forward queries to neighbors that are more likely to have answers. If a node cannot answer a query, it forwards the query to a subset of its neighbors, based on its local RI, rather than by selecting neighbors at random or by ooding the network by forwarding the query to all neighbors. We present three RI schemes: the compound, the hop-count, and the exponential routing indices. We evaluate their performance via simulations, and nd that RIs can improve performance by one or two orders of magnitude vs. a ooding-based system, and by up to 100 % vs. a random forwarding system. We also discuss the tradeo s between the di erent RIschemes and highlight the e ects of key design variables on system performance.
1253|Optimization of nonrecursive queries|State-of-the-art optimization approaches for relational database systems, e.g., those used in systems such as OBE, SQL/DS, and commercial INGRES. when used for queries in non-traditional database applications, suffer from two problems. First, the time complexity of their optimization algorithms, being combinatoric, is exponential in the number of relations to be joined in the query. Their cost is therefore prohibitive in situa-tions such as deductive databases and logic oriented languages for knowledge bases, where hundreds of joins may be required. The second problem with the traditional approaches is that, al-beit effective in their specific domain, it is not clear whether they can be generalized to different scenarios (e.g. parallel evalua-tion) since they lack a formal model to define the assumptions and critical factors on which their valiclity depends. This paper
1254|Extensible/Rule Based Query Rewrite Optimization in Starburst|This paper describes the Query Rewrite facility of the Starburst extensible database system, a novel phase of query optimization. We present a suite of rewrite rules used in Starburst to transform queries into equivalent queries for faster execution, and also describe the production rule engine which is used by Starburst to choose and execute these rules. Examples are provided demonstrating that these Query Rewrite transformations lead to query execution time improvements of orders of magnitude, suggesting that Query Rewrite in general --- and these rewrite rules in particular --- are an essential step in query optimization for modern database systems.  1 Introduction  In traditional database systems, query optimization typically consists of a single phase of processing in which access methods, join orders and join methods are chosen to provide an efficient plan for executing a user&#039;s declarative query. We refer to this phase as plan optimization. In this paper we present a distinct ph...
1255|Querying in highly mobile distributed environments|New challenges to the database field brought about by the rapidly growing area of wireless personal communication are presented. Preliminary solutions to two of the major problems, control of update volume and integration of query processing and data acquisition, are discussed along with the simulation results. 1
1256|Database System Issues in Nomadic Computing|Mobile computers and wireless networks are emerging technologies that will soon be available to a  wide variety of computer users. Unlike earlier generations of laptop computers, the new generation  of mobile computers can be an integrated part of a distributed computing environment, one in  which users change physical location frequently. The result is a new computing paradigm, nomadic  computing. This paradigm will affect the design of much of our current systems software, including  that of database systems.  This paper discusses in some detail the impact of nomadic computing on a number of traditional  database system concepts. In particular, we point out how the reliance on short-lived batteries  changes the cost assumptions underlying query processing. In these systems, power consumption  competes with resource utilization in the definition of cost metrics. We also discuss how the likelihood  of temporary disconnection forces consideration of alternative transaction processing pr...
1257|Optimization techniques for queries with expensive methods|Object-Relational database management systems allow knowledgeable users to de ne new data types, as well as new methods (operators) for the types. This exibility produces an attendant complexity, which must be handled in new ways for an Object-Relational database management system to be e cient. In this paper we study techniques for optimizing queries that contain time-consuming methods. The focus of traditional query optimizers has been on the choice of join methods and orders; selections have been handled by \pushdown &#034; rules. These rules apply selections in an arbitrary order before as many joins as possible, using the assumption that selection takes no time. However, users of Object-Relational systems can embed complex methods in selections. Thus selections may take signi cant amounts of time, and the query optimization model must be enhanced. In this paper, we carefully de ne a query cost framework that incorporates both selectivity and cost estimates for selections. We develop an algorithm called Predicate Migration, and prove that it produces optimal plans for queries with expensive methods. We then describe our implementation of Predicate Migration in the commercial Object-Relational database management system Illustra, and discuss practical issues that a ect our earlier assumptions. We compare Predicate Migration to a variety of simpler optimization techniques, and demonstrate that Predicate Migration is the best general solution to date. The alternative techniques we presentmaybe useful for constrained workloads.
1258|Adaptive Parallel Aggregation Algorithms|Aggregation and duplicate removal are common in SQL queries. However, in the parallel query processing literature, aggregate processing has received surprisingly little attention; furthermore, for each of the traditional parallel aggregation algorithms, there is a range of grouping selectivities where the algorithm performs poorly. In this work, we propose new algorithms that dynamically adapt, at query evaluation time, in response to observed grouping selectivities. Performance analysis via analytical modeling and an implementation on a workstation-cluster shows that the proposed algorithms are able to perform well for all grouping selectivities. Finally, we study the effect of data skew and show that for certain data sets the proposed algorithms can even outperform the best of traditional approaches. 1 Introduction  SQL queries are replete with aggregate and duplicate elimination operations. One measure of the perceived importance of aggregation is that in the proposed TPCD benchmark...
1260|Bluetooth and Sensor Networks: A Reality Check|The current generation of sensor nodes rely on commodity components. The choice of the radio is particularly important as it impacts not only energy consumption but also software design (e.g., network self-assembly, multihop routing and in-network processing). Bluetooth is one of the most popular commodity radios for wireless devices. As a representative of the frequency hopping spread spectrum radios, it is a natural alternative to broadcast radios in the context of sensor networks. The question is whether Bluetooth can be a viable alternative in practice. In this paper, we report our experience using Bluetooth for the sensor network regime. We describe our tiny Bluetooth stack that allows TinyOS applications to run on Bluetooth-based sensor nodes, we present a multihop network assembly procedure that leverages Bluetooth&#039;s device discovery protocol, and we discuss how Bluetooth favorably impacts in-network query processing. Our results show that despite obvious limitations the Bluetooth sensor nodes we studied exhibit interesting properties, such as a good energy per bit sent ratio. This reality check underlies the limitations and some promises of Bluetooth for the sensor network regime.
1261|Aggregation and Relevance in Deductive Databases|In this paper we present a technique to optimize queries on deductive databases that use aggregate operations such as min, max, and “largest Ic values. ” Our approach is based on an extended notion of relevance of facts to queries that takes aggregate operations into account. The approach has two parts: a rewriting part that labels predica.tes with “ag-gregate selections, ” and an evaluat,ion part. t.hat, makes use of “aggregate selections ” to detect that facts are irrelevant and discards them. The rewriting complements standard rewrit-ing algorithms like Magic sets, and the evaluation essentially refines Semi-Naive evaluation. 1
1262|Query Optimization In Compressed Database Systems|Over the lastd ecad es, improvements in CPU speed have outpaced improvements in main memory and d isk access rates by ord ers of magnitud , enabling the use ofd ata compression techniques to improve the performance ofd atabase systems. Previous work d scribes the benefits of compression for numerical attributes, whered8 a is stored in compressed  format ond isk. Despite the abund3&amp; e of stringvalued  attributes in relational schemas there is little work on compression for string attributes in ad atabase context. Moreover, none of the previous work suitablyad2 esses the role of the query optimizer: During query execution, dD a is either eagerly d compressed when it is read into main memory, or dD a lazily stays compressed in main memory and is d compressed ond emand only. In this paper, we present an e#ective approach for dD abase compression based on lightweight, attribute-level compression techniques. We propose a Hierarchical ictionary Encod  ing strategy that intelligently selects the most e#ective compression method for string-valued attributes. We show that eager and lazy d compression strategies prod1 e suboptimal plans for queries involving compressed string attributes. We then formalize the problem of compressionaware query optimizationand propose one provably optimal  and two fast heuristic algorithms for selecting a query plan for relational schemas with compressed attributes; our algorithms can easily be integrated into existing cost-based query optimizers. Experiments using TPC-Hd atad emonstrate the impact of our string compression method s and show the importance of compression-aware query optimization. Our approach results in up to an or d r speed up over existing approaches.  1. 
1263|The Design and Implementation of the Ariel Active Database Rule System|This paper describes the design and implementation of the Ariel DBMS and it&#039;s tightlycoupled forward-chaining rule system. The query language of Ariel is a subset of POSTQUEL, extended with a new production-rule sublanguage. Ariel supports traditional relational database query and update operations efficiently, using a System Rlike query processing strategy. In addition, the Ariel rule system is tightly coupled with query and update processing. Ariel rules can have conditions based on a mix of patterns, events, and transitions. For testing rule conditions, Ariel makes use of a discrimination network composed of a special data structure for testing single-relation selection conditions efficiently, and a modified version of the TREAT algorithm, called A-TREAT, for testing join conditions. The key modification to TREAT (which could also be used in the Rete algorithm) is the use of virtual ff-memory nodes which save storage since they contain only the predicate associated with the memory n...
1264|DOMINO: Databases fOr MovINg Objects tracking|Consider a database that represents information about moving objects and their location. For example, for a database representing the location of taxi-cabs a typical query may be: retrieve the free cabs that are currently within 1 mile of 33 N. Michigan Ave., Chicago (to pick-up a customer); or for a trucking company database a typical query may be: retrieve the trucks that are currently within 1 mile of truck ABT312 (which needs assistance); or for a database representing the current location of objects in a battlefield a typical query may be: retrieve the friendly helicopters that are in a given region, or, retrieve the friendly helicopters that are expected to enter the region within the next 10 minutes. The queries may originate from the moving objects, or from stationary users. We will refer to applications with the above characteristics as moving-objects-database (MOD) applications, and to queries as the ones mentioned above as MOD queries.
1265|From ethnography to design in a vineyard, in|This paper summarizes the process from ethnographic study of a vineyard to concept development and interaction design for a ubiquitous computing solution. It provides examples of vineyard interfaces and the lessons learned that could be generally applied to the interaction design of ubiquitous systems. These are: design for multiple perspectives on data, design for multiple access points, and design for varying levels of attention.
1266|Query Optimization in Mobile Environments|We consider the issue of optimizing queries for a distributed processing in mobile environment. An interesting characteristic of mobile machines is that they depend on battery as a source of energy which may not be substantial enough. Hence, the appropriate optimization criterion in a mobile environment considers both resource utilization and energy consumption at the mobile client. In this scenario, the optimal plan for a query depends on the residual battery level of the mobile client and the load at the server. We approach this problem by compiling a query into a sequence of candidate plans, such that for any state of the client-server system, the optimal plan is one of the candidate plans. A general solution is proposed by adapting the partial order dynamic programming search algorithm [17, 18] (p.o dp) such that the coverset of the query is the set of candidate plans. We propose two novel algorithms, namely, the linear combinations algorithm and the linearset algorithm (referred t...
1267|Online Dynamic Reordering|We present a mechanism for providing dynamic user control during long running, data-intensive operations. Users  can see partial results and dynamically direct the processing to suit their interests, thereby enhancing the interactivity  in several contexts such as online aggregation and large-scale spreadsheets.  In this paper, we develop a pipelining, dynamically tunable reorder operator for providing user control. Users  specify preferences for different data items based on prior results, so that data of interest is prioritized for early  processing. The reordering mechanism is efficient and non-blocking, and can be used over arbitrary data streams  from files and indexes, as well as continuous data feeds. We also investigate several policies for the reordering  based on the performance goals of various typical applications. We present performance results for reordering in the  context of an Online Aggregation implementation in Informix, and in the context of sorting and scrolling in...
1268|QStream: Deterministic Querying of Data Streams|Current developments in processing data  streams are based on the best-e#ort principle  and therefore not adequate for many application  areas. When sensor data is gathered  by interface hardware and is used for triggering  data-dependent actions, the data has to  be queried and processed not only in an efficient  but also in a deterministic way. Our  streaming system prototype embodies novel  data processing techniques. It is based on an  operator component model and runs on top of  a real-time capable environment. This enables  us to provide real Quality-of-Service for data  stream queries.
1269|On the Quantitative Specification of Jitter Constrained Periodic Streams|An increasing number of application systems can be characterized by their requirement to process sequences of events in real-time. These sequences are principally of constant rate, but may vary within given limits. Hence, several parameter sets that seem to differ only slightly have been proposed to describe such sequences. This includes the parameter sets used in the Tenet Protocol Suite, in the traffic description of an ATM connection, and in the model of linear bounded arrival processes (LBAP) for transferring continuous media.  The existence of several parameter sets raises the question whether or not the parameter sets differ in principle or in notation only. To answer this question, the paper proposes a generalized model for jitter constrained periodic streams. That model subsumes the parameter sets mentioned above, allows to prove their equivalence and to transform the different sets of parameters each to another.  1. Introduction  Multimedia and other real-time applications can...
1270|multiple-data-stream processors |Current shared memory multicore and multiprocessor systems are nondeterministic. Each time these systems execute a multithreaded application, even if supplied with the same input, they can produce a different output. This frustrates debugging and limits the ability to properly test multithreaded code, becoming a major stumbling block to the much-needed widespread adoption of parallel programming. In this paper we make the case for fully deterministic shared memory multiprocessing (DMP). The behavior of an arbitrary multithreaded program on a DMP system is only a function of its inputs. The core idea is to make inter-thread communication fully deterministic. Previous approaches to coping with nondeterminism in multithreaded programs have focused on replay, a technique useful only for debugging. In contrast, while DMP systems are directly useful for debugging by offering repeatability by default, we argue that parallel programs should execute deterministically in the field as well. This has the potential to make testing more assuring and increase the reliability of deployed multithreaded software. We propose a range of approaches to enforcing determinism and discuss their implementation trade-offs. We show that determinism can be provided with little performance cost using our architecture proposals on future hardware, and that software-only approaches can be utilized on existing systems.
1271|The SPLASH-2 programs: Characterization and methodological considerations|The SPLASH-2 suite of parallel applications has recently been released to facilitate the study of centralized and distributed shared-address-space multiprocessors. In this context, this paper has two goals. One is to quantitatively characterize the SPLASH-2 programs in terms of fundamental properties and architectural interactions that are important to understand them well. The properties we study include the computational load balance, communication to computation ratio and traffic needs, important working set sizes, and issues related to spatial locality, as well as how these properties scale with problem size and the number of processors. The other, related goal is methodological: to assist people who will use the programs in architectural evaluations to prune the space of application and machine parameters in an informed and meaningful way. For example, by characterizing the working sets of the applications, we describe which operating points in terms of cache size and problem size are representative of realistic situations, which are not, and which re redundant. Using SPLASH-2 as an example, we hope to convey the importance of understanding the interplay of problem size, number of processors, and working sets in designing experiments and interpreting their results.
1272|Transactional Memory: Architectural Support for Lock-Free Data Structures |A shared data structure is lock-free if its operations do not require mutual exclusion. If one process is interrupted in the middle of an operation, other processes will not be prevented from operating on that object. In highly concurrent systems, lock-free data structures avoid common problems associated with conventional locking techniques, including priority inversion, convoying, and difficulty of avoiding deadlock. This paper introduces transactional memory, a new multiprocessor architecture intended to make lock-free synchronization as efficient (and easy to use) as conventional techniques based on mutual exclusion. Transactional memory allows programmers to define customized read-modify-write operations that apply to multiple, independently-chosen words of memory. It is implemented by straightforward extensions to any multiprocessor cache-coherence protocol. Simulation results show that transactional memory matches or outperforms the best known locking techniques for simple benchmarks, even in the absence of priority inversion, convoying, and deadlock.  
1273|Pin: building customized program analysis tools with dynamic instrumentation|Robust and powerful software instrumentation tools are essential for program analysis tasks such as profiling, performance evaluation, and bug detection. To meet this need, we have developed a new instrumentation system called Pin. Our goals are to provide easy-to-use, portable, transparent, and efficient instrumentation. Instrumentation tools (called Pintools) are written in C/C++ using Pin’s rich API. Pin follows the model of ATOM, allowing the tool writer to analyze an application at the instruction level without the need for detailed knowledge of the underlying instruction set. The API is designed to be architecture independent whenever possible, making Pintools source compatible across different architectures. However, a Pintool can access architecture-specific details when necessary. Instrumentation with Pin is mostly transparent as the application and Pintool observe the application’s original, uninstrumented behavior. Pin uses dynamic compilation to instrument executables while they are running. For efficiency, Pin uses several techniques, including inlining, register re-allocation, liveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach delivers significantly better instrumentation performance than similar tools. For example, Pin is 3.3x faster than Valgrind and 2x faster than DynamoRIO for basic-block counting. To illustrate Pin’s versatility, we describe two Pintools in daily use to analyze production software. Pin is publicly available for Linux platforms on four architectures: IA32 (32-bit x86), EM64T (64-bit x86), Itanium R ? , and ARM. In the ten months since Pin 2 was released in July 2004, there have been over 3000 downloads from its website. Categories and Subject Descriptors D.2.5 [Software Engineering]: Testing and Debugging-code inspections and walk-throughs,
1274|LLVM: A compilation framework for lifelong program analysis &amp; transformation|... a compiler framework designed to support transparent, lifelong program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in Static Single Assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems. 
1275|The problem with threads|Copyright © 2006, by the author(s).
1276|Transactional memory coherence and consistency|In this paper, we propose a new shared memory model: Transactional
1277|Speculative Versioning Cache|Dependences among loads and stores whose addresses are unknown hinder the extraction of instruction level parallelism during the execution of a sequential program. Such ambiguous memory dependences can be overcome by memory dependence speculation which enables a load or store to be speculatively executed before the addresses of all preceding loads and stores are known. Furthermore, multiple speculative stores to a memory location create multiple speculative versions of the location. Program order among the speculative versions must be tracked to maintain sequential semantics. A previously proposed approach, the Address Resolution Buffer(ARB) uses a centralized buffer to support speculative versions. Our proposal, called the Speculative Versioning Cache(SVC), uses distributed caches to eliminate the latency and bandwidth problems of the ARB. The SVC conceptually unifies cache coherence and speculative versioning by using an organization similar to snooping bus-based coherent caches. A preliminary evaluation for the Multiscalar architecture shows that hit latency is an important factor affecting performance, and private cache solutions trade-off hit rate for hit latency. 1.
1278|BugNet: Continuously recording program execution for deterministic replay debugging|Significant time is spent by companies trying to reproduce and fix the bugs that occur for released code. To assist developers, we propose the BugNet architecture to continuously record information on production runs. The information collected before the crash of a program can be used by the developers working in their execution environment to deterministically replay the last several million instructions executed before the crash. BugNet is based on the insight that recording the register file contents at any point in time, and then recording the load values that occur after that point can enable deterministic replaying of a program’s execution. BugNet focuses on being able to replay the application’s execution and the libraries it uses, but not the operating system. But our approach provides the ability to replay an application’s execution across context switches and interrupts. Hence, BugNet obviates the need for tracking program I/O, interrupts and DMA transfers, which would have otherwise required more complex hardware support. In addition, BugNet does not require a final core dump of the system state for replaying, which significantly reduces the amount of data that must be sent back to the developer. 1
1279|Deterministic Replay of Java Multithreaded Applications|Threads and concurrency constructs in Java introduce nondeterminism to a program&#039;s execution, which makes it hard to understand and analyze the execution behavior. Nondeterminism in execution behavior also makes it impossible to use execution replay for debugging, performance monitoring, or visualization. This paper discusses a record/replay tool for Java, DejaVu, that provides deterministic replay of a program&#039;s execution. In particular, this paper describes the idea of the logical thread schedule, which makes DejaVu efficient and independent of the underlying thread scheduler. The paper also discusses how to handle the various Java synchronization operations for record and replay. DejaVu has been implemented by modifying the Sun Microsystems&#039; Java Virtual Machine.  1 Introduction  The ubiquity of the Java programming language in current software systems has made development of advanced programming environment tools for writing efficient and correct Java programs very important. Build...
1280|A Chip-Multiprocessor Architecture with Speculative Multithreading|AbstractÐMuch emphasis is now placed on chip-multiprocessor (CMP) architectures for exploiting thread-level parallelism in an application. In such architectures, speculation may be employed to execute applications that cannot be parallelized statically. In this paper, we present an efficient CMP architecture for speculative execution of sequential binaries without source recompilation. We present the software support that enables identification of threads from a sequential binary. The hardware includes a memory disambiguation mechanism that enables the detection of interthread memory dependence violations during speculative execution. This hardware is different from past proposals in that it does not rely on a snoopy-based cache-coherence protocol. Instead, it uses an approach similar to a directory-based scheme. Furthermore, the architecture includes a simple and efficient hardware mechanism to enable register-level communication between on-chip processors. Evaluation of this software-hardware approach shows that it is quite effective in achieving high performance when running sequential binaries. Index TermsÐChip-multiprocessor, speculative multithreading, data-dependence speculation, control speculation. 1
1281|DeLorean: Recording and Deterministically Replaying Shared-Memory Multiprocessor Execution Efficiently * |Support for deterministic replay of multithreaded execution can greatly help in finding concurrency bugs. For highest effectiveness, replay schemes should (i) record at production-run speed, (ii) keep their logging requirements minute, and (iii) replay at a speed similar to that of the initial execution. In this paper, we propose a new substrate for deterministic replay that provides substantial advances along these axes. In our proposal, processors execute blocks of instructions atomically, as in transactional memory or speculative multithreading, and the system only needs to record the commit order of these blocks. We call our scheme DeLorean. Our results show that DeLorean records execution at a speed similar to that of Release Consistency (RC) execution and replays at about 82 % of its speed. In contrast, most current schemes only record at the speed of Sequential Consistency (SC) execution. Moreover, DeLorean only needs 7.5 % of the log size needed by a state-of-the-art scheme. Finally, DeLorean can be configured to need only 0.6 % of the log size of the state-of-the-art scheme at the cost of recording at 86 % of RC’s execution speed — still faster than SC. In this configuration, the log of an 8-processor 5-GHz machine is estimated to be only about 20GB per day. 1.
1282|Recording Shared Memory Dependencies Using Strata|Significant time is spent by companies trying to reproduce and fix bugs. BugNet and FDR are recent architecture proposals that provide architecture support for deterministic replay debugging. They focus on continuously recording information about the program’s execution, which can be communicated back to the developer. Using that information, the developer can deterministically replay the program’s execution to reproduce and fix the bugs. In this paper, we propose using Strata to efficiently capture the shared memory dependencies. A stratum creates a time layer across all the logs for the running threads, which separates all the memory operations executed before and after the stratum. A strata log allows us to determine all the shared memory dependencies during replay and thereby supports deterministic replay debugging for multi-threaded programs.
1283|The Design, Implementation, and Evaluation of Jade|this article we discuss the design goals and decisions that determined the final form of Jade and present an overview of the Jade implementation. We also present our experience using Jade to implement several complete scientific and engineering applications. We use this experience to evaluate how the different Jade language features were used in practice and how well Jade as a whole supports the process of developing parallel applications. We find that the basic idea of preserving the serial semantics simplifies the program development process, and that the concept of using data access specifications to guide the parallelization offers significant advantages over more traditional control-based approaches. We also find that the Jade data model can interact poorly with concurrency patterns that write disjoint pieces of a single aggregate data structure, although this problem arises in only one of the applications.  Categories and Subject Descriptors: D.1.3 [Programming Te
1284|Rerun: Exploiting Episodes for Lightweight Memory Race Recording |Multiprocessor deterministic replay has many potential uses in the era of multicore computing, including enhanced debugging, fault tolerance, and intrusion detection. While sources of nondeterminism in a uniprocessor can be recorded efficiently in software, it seems likely that hardware support will be needed in a multiprocessor environment where the outcome of memory races must also be recorded. We develop a memory race recording mechanism, called Rerun, that uses small hardware state (~166 bytes/core), writes a small race log (~4 bytes/kiloinstruction), and operates well as the number of cores per system scales (e.g., to 16 cores). Rerun exploits the dual of conventional wisdom in race recording: Rather than record information about individual memory accesses that conflict, we record how long a thread executes without conflicting with other threads. In particular, Rerun passively creates atomic episodes. Each episode is a dynamic instruction sequence that a thread happens to execute without interacting with other threads. Rerun uses Lamport Clocks to order episodes and enable replay of an equivalent execution. 1.
1285|Hardware-Assisted Replay of Multiprocessor Programs|Shared-memory parallel programs can be highly nondeterministic due to the unpredictable order in which shared references are satisfied. However, deterministic execution is extremely important for debugging and can also be used for fault-tolerance and other replay-based algorithms. We present a hardware/software design that allows the order of memory references in a parallel program to be logged efficiently by recording a subset of the cache traffic between memory and the CPU&#039;s. This log can then be used along with hardware and software control to replay execution. Simulation of several parallel programs shows that our device records no more than 1.17 MB/second for an application exhibiting fine-grained sharing behavior on a 16-way multiprocessor consisting of 12 MIP CPU&#039;s. In addition, no probe effect or performance degradation is introduced. This represents several orders of magnitude improvement in both performance and log size over purely software-based methods proposed previously. ...
1286|Optimizing Away Joins on Data Streams |Abstract. Monitoring aggregates on IP traffic data streams is a compelling appli-cation for data stream management systems. Often, such streaming aggregation queries involve joining multiple streams (e.g., streams of SYN and ACK packets) using temporal join conditions (e.g., within 5 seconds), followed by computa-tion of aggregates (e.g., COUNT) over temporal tumbling windows (e.g., every 5 minutes). While such a query expression is natural, its evaluation over high speed IP traffic data streams is infeasible in practice. In this paper, we develop rewrit-ing techniques for streaming aggregation queries that identify conditions under which such joins can be optimized away, while providing error bounds for results of the rewritten queries. The basis of the optimization is a powerful but decidable theory in which constraints over data streams can be formulated. The result error bounds are specified as functions of the boundary effects incurred during query rewriting. 1
1287|Efficient Checking of Temporal Integrity Constraints Using Bounded History Encoding|: We present an efficient implementation method for temporal integrity constraints formulated in Past Temporal Logic. Although the constraints can refer to past states of the database, their checking does not require that the entire database history be stored. Instead, every database state is extended with auxiliary relations that contain the historical information necessary for checking constraints. Auxiliary relations can be implemented as materialized relational views. 1 Introduction  Integrity constraints form an essential part of every database application. It is customary to distinguish between two kinds of constraints: static and temporal (or dynamic). Static  constraints refer to the current state of the database, e.g.,&#034;every manager is also an employee &#034;, while temporal constraints may refer to past and future states in addition to the current state, e.g., &#034;salaries of employees should never decrease&#034; or &#034;once a student drops out of the Ph.D. program, she should not be readmit...
1288|Handling Infinite Temporal Data|In this paper, we present a powerful framework for describing, storing, and  reasoning about infinite temporal information. This framework is an extension of  classical relational databases. It represents infinite temporal information by generalized  tuples defined by linear repeating points and constraints on these points.
1289|Static optimization of conjunctive queries with sliding windows over infinite streams|We define a framework for static optimization of sliding window conjunctive queries over infinite streams. When computational resources are sufficient, we propose that the goal of optimization should be to find an execution plan that minimizes resource usage within the available resource constraints. When resources are insufficient, on the other hand, we propose that the goal should be to find an execution plan that sheds some of the input load (by randomly dropping tuples) to keep resource usage within bounds while maximizing the output rate. An intuitive approach to load shedding suggests starting with the plan that would be optimal if resources were sufficient and adding &amp;quot;drop boxes &amp;quot; to this plan. We find this to be often times suboptimal – in many instances the optimal partial answer plan results from adding drop boxes to plans that are not optimal in the unlimited resource case. In view of this, we use our framework to investigate an approach to optimization that unifies the placement of drop boxes and the choice of the query plan from which to drop tuples. The effectiveness of our optimizer is experimentally validated and the results show the promise of this approach. 1.
1291|Extending Existing Dependency Theory to Temporal Databases|Normal forms play a central role in the design of relational databases. Several normal forms for temporal relational databases have been proposed. These definitions are particular to specific temporal data models, which are numerous and incompatible.
1292|Logical Design for Temporal Databases with Multiple Temporal Types|The purpose of good database logical design is to eliminate data redundancy and insertion  and deletion anomalies. In order to achieve this objective for temporal databases, the  notions of temporal types and temporal functional dependencies (TFDs) are introduced. A  temporal type is a monotonic mapping from ticks of time (represented by positive integers)  to time sets (represented by subsets of reals) and is used to capture various standard and  user-defined calendars. A TFD is a proper extension of the traditional functional dependency  and takes the form X \Gamma!  Y , meaning that there is a unique value for Y during  one tick of the temporal type  for one particular X value. An axiomatization for TFDs  is given. Since a finite set of TFDs usually implies an infinite number of TFDs, we introduce  the notion of and give an axiomatization for a finite closure to effectively capture a  finite set of implied TFDs that are essential to the logical design. Temporal normalization  proced...
1293|Description Logics for Modelling Dynamic Information|In the first part of this Chapter we will introduce a general temporally enhanced conceptual data model able to represent time varying data, in the spirit of a temporally enhanced Entity-Relationship data model. In the second part, we will introduce an object-oriented conceptual data model enriched with schema change operators, which are able to represent the explicit temporal evolution of the schema while maintaining a consistent view on the (static) instantiated data. We will introduce a provably correct encoding of both conceptual data models and their inference problems in Description Logics. In this way, we study the properties of both the temporal conceptual data model and the object-oriented data model with schema change facilities.
1294|Space-time block codes from orthogonal designs|Abstract — We introduce space–time block coding, a new paradigm for communication over Rayleigh fading channels using multiple transmit antennas. Data is encoded using a space–time block code and the encoded data is split into ? streams which are simultaneously transmitted using ? transmit antennas. The received signal at each receive antenna is a linear superposition of the ? transmitted signals perturbed by noise. Maximumlikelihood decoding is achieved in a simple way through decoupling of the signals transmitted from different antennas rather than joint detection. This uses the orthogonal structure of the space–time block code and gives a maximum-likelihood decoding algorithm which is based only on linear processing at the receiver. Space–time block codes are designed to achieve the maximum diversity order for a given number of transmit and receive antennas subject to the constraint of having a simple decoding algorithm. The classical mathematical framework of orthogonal designs is applied to construct space–time block codes. It is shown that space–time block codes constructed in this way only exist for few sporadic values of ?. Subsequently, a generalization of orthogonal designs is shown to provide space–time block codes for both real and complex constellations for any number of transmit antennas. These codes achieve the maximum possible transmission rate for any number of transmit antennas using any arbitrary real constellation such as PAM. For an arbitrary complex constellation such as PSK and QAM, space–time block codes are designed that achieve IaP of the maximum possible transmission rate for any number of transmit antennas. For the specific cases of two, three, and four transmit antennas, space–time block codes are designed that achieve, respectively, all, QaR, and QaR of maximum possible transmission rate using arbitrary complex constellations. The best tradeoff between the decoding delay and the number of transmit antennas is also computed and it is shown that many of the codes presented here are optimal in this sense as well. Index Terms — Codes, diversity, multipath channels, multiple antennas, wireless communication.
1295|Law and finance|This paper examines legal rules covering protection of corporate shareholders and creditors, the origin of these rules, and the qual-ity of their enforcement in 49 countries. The results show that common-law countries generally have the strongest, and French-civil-law countries the weakest, legal protections of investors, with German- and Scandinavian-civil-law countries located in the mid-dle. We also find that concentration of ownership of shares in the largest public companies is negatively related to investor protec-tions, consistent with the hypothesis that small, diversified share-holders are unlikely to be important in countries that fail to protect their rights. I. Overview of the Issues In the traditional finance of Modigliani and Miller (1958), securities are recognized by their cash flows. For example, debt has a fixed promised stream of interest payments, whereas equity entitles its
1296|What Do We Know about Capital Structure? Some Evidence from International Data|We investigate the determinants of capital structure choice by analyzing the financing decisions of public firms in the major industrialized countries. At an aggregate level, firm leverage is fairly similar across the G-7 countries. We find that factors identified by previous studies as correlated in the cross-section with firm leverage in the U.S., are similarly correlated in other countries as well. However, a deeper examination of the U.S. and foreign evidence suggests that the theoretical underpinnings of the observed correlations are still largely unresolved.
1297|The Legal Environment, Banks, and Long-Run Economic Growth|This paper examines the relationship between the legal system and banking development and traces this connection through to long-run rates of per capita GDP growth, capital stock growth, and productivity growth. The data indicate that countries where the legal system (1) emphasizes creditor rights and (2) rigorously enforces contracts have better developed banks than countries where laws do not give a high priority to creditors and where enforcement is lax. Furthermore, the exogenous component of banking development -- the component defined by the legal environment -- is positively and robustly associated with per capita growth, physical capital accumulation, and productivity growth. 
1298|A survey of corporate governance|in the 10th Workshop on Corporate Governance and Investment for useful comments. The paper was written while Ken
1299|Bro: A System for Detecting Network Intruders in Real-Time|We describe Bro, a stand-alone system for detecting network intruders in real-time by passively monitoring a network link over which the intruder&#039;s traffic transits. We give an overview of the system&#039;s design, which emphasizes highspeed (FDDI-rate) monitoring, real-time notification, clear separation between mechanism and policy, and extensibility. To achieve these ends, Bro is divided into an “event engine” that reduces a kernel-filtered network traffic stream into a series of higher-level events, and a “policy script interpreter” that interprets event handlers written in a specialized language used to express a site&#039;s security policy. Event handlers can update state information, synthesize new events, record information to disk, and generate real-time notifications via syslog. We also discuss a number of attacks that attempt to subvert passive monitoring systems and defenses against these, and give particulars of how Bro analyzes the six applications integrated into it so far: Finger, FTP, Portmapper, Ident, Telnet and Rlogin. The system is publicly available in source code form.  
1300|End-to-End Internet Packet Dynamics|  We discuss findings from a large-scale study of Internet packet dynamics conducted by tracing 20 000 TCP bulk transfers between 35 Internet sites. Because we traced each 100-kbyte transfer at both the sender and the receiver, the measurements allow us to distinguish between the end-toend behaviors due to the different directions of the Internet paths, which often exhibit asymmetries. We: 1) characterize the prevalence of unusual network events such as out-of-order delivery and packet replication; 2) discuss a robust receiver-based algorithm for estimating “bottleneck bandwidth ” that addresses deficiencies discovered in techniques based on “packet pair;” 3) investigate patterns of packet loss, finding that loss events are not well modeled as independent and, furthermore, that the distribution of the duration of loss events exhibits infinite variance; and 4) analyze variations in packet transit delays as indicators of congestion periods, finding that congestion periods also span a wide range of time scales. 
1301|Empirically-Derived Analytic Models of Wide-Area TCP Connections: Extended Report|We analyze 2.5 million TCP connections that occurred during 14 wide-area traffic traces. The traces were gathered at five &#034;stub&#034; networks and two internetwork gateways, providing a diverse look at wide-area traffic. We derive analytic models describing the random variables associated with telnet, nntp, smtp, and ftp connections, and present a methodology for comparing the effectiveness of the analytic models with empirical models such as tcplib [DJ91]. Overall we find that the analytic models provide good descriptions, generally modeling the various distributions as well as empirical models and in some cases better.
1302|A Methodology for Testing Intrusion Detection Systems|Intrusion Detection Systems (IDSs) attempt to identify unauthorized use, misuse, and abuse of computer systems. In response to the growth in the use and development of IDSs, we have developed a methodology for testing IDSs. The methodology consists of techniques from the field of software testing which we have adapted for the specific purpose of testing IDSs. In this paper, we identify a set of general IDS performance objectives which is the basis for the methodology. We present the details of the methodology, including strategies for test-case selection and specific testing procedures. We include quantitative results from testing experiments on the Network Security Monitor (NSM), an IDS developed at UC Davis. We present an overview of the software platform that we have used to create user-simulation scripts for testing experiments. The platform consists of the UNIX tool expect and enhancements that we have developed, including mechanisms for concurrent scripts and a record-and-replay ...
1303|Collaborative Load Shedding for Media-Based Applications|The VuSystem is a software-intensive video environment developed on operating systems without real-time features. In the course of our work with this system, interesting questions have been brought up about how resources on a workstation can be best divided between applications, and what resource management features (if any) are required. This paper&#039;s main purpose is to outline a rationale for collaborative load shedding and to create an awareness within the operating system community; it also discusses some our early experiences with simple collaborative load shedding schemes.  1 1.0 Introduction  The VuSystem[3,4] is a software-intensive system for manipulating video streams on workstations. The VuSystem runs on a wide variety of workstations, including Suns, DECStations, DEC Alpha workstations, and Silicon Graphics workstations. Its performance varies  from workstation to workstation, simply trying to do &#034;the best&#034; it can on each platform. This system works very well for workstation...
